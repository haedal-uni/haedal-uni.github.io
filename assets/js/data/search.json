[ { "title": "통합 파일 작성하기", "url": "/posts/%ED%86%B5%ED%95%A9-%ED%8C%8C%EC%9D%BC-%EC%9E%91%EC%84%B1%ED%95%98%EA%B8%B0/", "categories": "", "tags": "", "date": "2025-10-30 00:00:00 +0900", "snippet": "통합 파일 작성하기기존 형식의 엑셀 파일(results.xlsx)에 여러 개의 새로운 엑셀 데이터를 자동으로 통합하고수식과 서식을 자동으로 정리하는 프로세스를 구축했다.주요 단계1. 기존 엑셀의 데이터를 삭제 (수식은 유지하기위해 첫번째 행 제거x)2. 최신 엑셀 파일 자동 탐색 및 불러오기3. 파일 확장자 및 시트명 처리4. 테이블 생성 및 수식·서식 자동 적용5. 전체 자동 실행 및 예외 처리기본from openpyxl import load_workbook# 엑셀 파일 열기 wb = load_workbook(\"test.xlsx\") # data_only=True : 계산된 값(수식x) wb.sheetnames # 전체 시트 리스트ws = wb['abc'] # 'abc' 시트ws['E2'].value # E2 셀 값 읽기 1. 기존 데이터 제거엑셀 내의 기존 데이터를 삭제하되 수식이 존재하는 첫 번째 행은 유지했다. (ex. =sum(...))시트마다 헤더 위치가 달라(1행 또는 2행) 조건문으로 삭제 기준을 다르게 적용했다.# 경고 메시지 import warningswarnings.filterwarnings('ignore')from openpyxl import load_workbookpath = 'excel/'wb = load_workbook(path + \"raw_data.xlsx\") for i in range(10): ws = wb.worksheets[i] max_row = ws.max_row if i &lt;= 7: if max_row &gt;= 4: ws.delete_rows(4, amount=max_row - 3) else: if max_row &gt;= 3: ws.delete_rows(3, amount=max_row - 2)wb.save(\"results.xlsx\")*숨겨진 시트도 포함되므로 시트 개수(range(10))는 전체 시트 수 기준으로 작성해야한다.log 설정import logginglogger = logging.getLogger(name = \"00. 기존 데이터 제거.py\")logger.setLevel(logging.INFO)formatter = logging.Formatter('[ %(name)s ] ( %(levelname)s ) %(message)s')stream_handler = logging.StreamHandler()stream_handler.setFormatter(formatter)logger.addHandler(stream_handler)파일별 로그명(name)을 다르게 설정해 동일한 로깅 포맷으로 관리했다.2. 파일 불러오기각 시트에 들어갈 데이터를 최근에 저장된 파일에서 불러왔다.파일 하나씩 실행하면서 아래 함수를 실행하므로 가장 최근 파일로만 진행했다. openpyxl → 엑셀 내부 편집 용도 pandas → 엑셀 데이터를 분석/가공 용도 openpyxl은 엑셀 기준 (1부터 시작) pandas는 파이썬 기준 (0부터 시작) xls → xlsx로 변환.xls 파일은 win32com을 통해 Excel을 직접 실행시켜 .xlsx로 변환했다.def convert_xls_to_xlsx(file_path): if not file_path.lower().endswith(\".xls\"): raise ValueError(\"Only .xls files can be converted.\") # 에러를 일부러 발생시키는 키워드 abs_path = os.path.abspath(file_path) new_path = abs_path + \"x\" # .xlsx excel = win32.gencache.EnsureDispatch('Excel.Application') excel.DisplayAlerts = False try: wb = excel.Workbooks.Open(abs_path) wb.SaveAs(new_path, FileFormat=51) # .xlsx wb.Close() print(f\"변환 완료: {new_path}\") except Exception as e: print(f\"변환 실패: {e}\") new_path = None finally: excel.Quit() return new_pathwin32com : 엑셀을 직접 실행시키고 저장최신 파일 불러오기def load_latest_excel(path, skiprows=0): excel_files = glob.glob(os.path.join(path, \"*.xls*\")) + glob.glob(os.path.join(path, \"*.csv\")) if not excel_files: logger.error(\"다운로드 폴더 - Excel 또는 CSV 파일 X\") return None, None latest_file = max(excel_files, key=os.path.getmtime) print(f\"가장 최근 파일: {os.path.basename(latest_file)}\") if latest_file.lower().endswith(\".csv\"): df = pd.read_csv(latest_file, sep='\\t', encoding='utf-16', skiprows=skiprows) elif latest_file.lower().endswith(\".xls\"): try : df = pd.read_excel(latest_file, skiprows=skiprows, engine='xlrd') except : converted = convert_xls_to_xlsx(latest_file) if converted: df = pd.read_excel(converted, skiprows=skiprows, engine='openpyxl') else: raise Exception(\"변환 실패로 .xls 파일 열 수 없음!\") elif latest_file.lower().endswith(\".xlsx\"): df = pd.read_excel(latest_file, skiprows=skiprows, engine=\"openpyxl\") else: raise ValueError(\"지원하지 않는 파일 형식\")` return df, latest_file glob.glob() 으로 모든 엑셀 파일을 불러오고 os.path.getmtime() 으로 가장 최신 파일을 선택 확장자에 따라 다르게 처리(.csv, .xls, .xlsx 파일 구분 처리) 3. 파일 통합 및 저장확장자def process_excel(sheet_name, start_row=2, skiprows=0, header_row = 2): path = r\"C:\\Users\\Downloads\" df, latest_file = load_latest_excel(path, skiprows=skiprows) if df is None: print(f\"{sheet_name} 파일이 없습니다.\") return # 파일명 시트 이름으로 변경 ext = os.path.splitext(latest_file)[1].lower() # 확장자 new_filename = f\"{sheet_name}{ext}\" new_filepath = os.path.join(path, new_filename) if latest_file != new_filepath: os.rename(latest_file, new_filepath) print(f\"파일 이름 변경: {os.path.basename(latest_file)} → {new_filename}\") exist_file = \"results.xlsx\" wb = load_workbook(exist_file) if sheet_name in wb.sheetnames: ws = wb[sheet_name] else: ws = wb.create_sheet(sheet_name)엑셀 파일의 확장자가 .xlsx뿐 아니라 .xls와 .csv도 존재한다.splitext : 파일명을 입력으로 받아 파일명과 확장자를 분리해서 반환한다.최신 파일명을 시트명으로 통일해 저장했다.(이름 변경)헤더 및 데이터 붙여넣기# 데이터 중에 info 와 같이 필요없는 데이터가 있는 경우가 있어 제거df = df[~df.iloc[:, 0].astype(str).str.contains(\"info\")] # 여러 행 첫번째 열# header 붙여넣기for j, col in enumerate(df.columns, start=1): ws.cell(row=header_row, column=j, value=col)# 데이터 붙여넣기 (2행부터 수식 열 전까지)for i, row in df.iterrows(): # 1부터 시작 for j, value in enumerate(row, start=1): # 1부터 시작 ws.cell(row=i + start_row, column=j, value=value)각 시트마다 헤더 위치(header_row)가 다르기 때문에 인자로 받았다.기본값은 대부분의 시트에 맞춰 header_row=2로 설정했다.테이블 생성# 테이블 범위table_start_row = header_rowtable_end_row = start_row + len(df) - (1 if header_row == 1 else 0)end_col_letter = get_column_letter(df.shape[1] + 3)table_range = f\"A{table_start_row}:{end_col_letter}{table_end_row}\"# 기존 테이블 삭제for tbl_name in list(ws.tables.keys()): del ws.tables[tbl_name]# 테이블 생성table = Table(displayName=sheet_name, ref=table_range)table.tableStyleInfo = TableStyleInfo( name=\"TableStyleMedium2\", showFirstColumn=False, showLastColumn=False, showRowStripes=True, showColumnStripes=False)ws.add_table(table) get_column_letter : 열의 인덱스 정보를 입력받고 해당 열에 대한 문자를 반환 *행은 숫자, 열은 문자 수식 및 서식 자동 적용끝에서 3개의 열(수식 포함)에 기존 행의 서식을 복사 적용def apply_formatting(ws, table_start_row, table_end_row, columns_to_format): for col in range(1, ws.max_column+1) : first_row_cell = ws.cell(row=table_start_row+1, column=col) if col in columns_to_format: # 끝에서 3번째까지 열 for row in range(table_start_row + 1, table_end_row + 1): cell = ws.cell(row=row, column=col) cell.value = first_row_cell.value cell.number_format = first_row_cell.number_format else : for row in range(table_start_row+1, table_end_row+1) : cell = ws.cell(row=row, column=col) cell.number_format = first_row_cell.number_format적용# 서식 자동 적용 (끝에서 3개 열만 서식 적용)columns_to_format = [df.shape[1]+1, df.shape[1]+2, df.shape[1]+3] # 끝에서 3개 열apply_formatting(ws, table_start_row, table_end_row, columns_to_format)wb.save(exist_file)print(f\"{sheet_name} 완료\")호출x = '자동화/01. data/'subprocess.run([\"python\", x + \"00. 기존 데이터 제거.py\"])time.sleep(2)data = subprocess.run([\"python\", x + \"01. data_1.py\"], capture_output=True, text=True)output = data.stdoutif \"데이터 확인\" in output : logger.info(\"데이터 존재 x\")else : process_excel(\"data_1\")time.sleep(2) STDOUT (Standard Output, 1, 출력을 위한 스트림) 표준 출력은 프로그램이 출력 데이터를 기록하는 스트림으로 줄여서 stdout 으로 표현 capture_output = True : 표준 출력(stdout)과 표준 에러(stderr)가 캡처 text=True : 문자열 01. data_1.py에서 조건문에 print(\"데이터 확인\")를 추가하여원하는 조건이 실행 되었을 때 print문이 출력되고해당 파일이 끝이나면 해당 값을 output에 저장하여값 유무에 따라 process_excel(\"data_1\")를 실행 여부를 결정문제 해결 과정 정리날짜 형식 문제데이터 붙여넣기 시 날짜가 “YYYY-MM-DD HH:MM:SS” 형태로 변환되던 문제 해결if (j==1) &amp; (\"data_1\" in sheet_name): value = value.strftime(\"%Y-%m-%d\")이후 셀 서식 자동 적용 기능이 완성되면서 제거했다.수식 자동 반영 문제끝 3열에 존재하는 수식이 신규 행에 자동 복사되지 않는 문제 해결첫 번째 데이터 행의 수식을 기준으로 아래 행에 복사이후 일반 셀에도 서식 전체 적용(본문 내용 참고 - apply_formatting())REFERENCE [새로 배운 코드 조각] 파일 이름에서 확장자 분리하기 : os.path.splitext(file_name) 04-02. 엑셀 데이터 읽기 표준 스트림과 stdin, stdout, stderr subprocess — 서브 프로세스 관리 파이썬(Python) logging 모듈을 이용한 로그(Log) 남기기 openpyxl로 엑셀 다루기 016. get_column_letter 함수로 열에 대한 문자 얻기 (column letter)" }, { "title": "Win32com.gen_py", "url": "/posts/win32com.gen_py/", "categories": "Analysis", "tags": "error", "date": "2025-10-14 00:00:00 +0900", "snippet": "pywin32엑셀 파일을 열어 특정 지표를 가져오는 과정에서module 'win32com.gen_py.00020813-0000-0000-C000-000000000046x0x1x9' has no attribute 'CLSIDToClassMap' 라는 오류가 떴다.stackoverflow 를 참고해 오류를 해결했다.python -c \"import win32com; print(win32com.__gen_path__)\"를 실행해출력된 해당 위치에 오류가 나는 “00020813-0000-0000-C000-000000000046x0x1x9” 폴더를 제거한 후 실행했더니 정상적으로 동작했다." }, { "title": "Excel_자동화", "url": "/posts/Excel_%EC%9E%90%EB%8F%99%ED%99%94/", "categories": "Analysis", "tags": "excel", "date": "2025-09-19 00:00:00 +0900", "snippet": "자동화Python 기본 문법 및 개념파일 실행__name__ == \"__main__\"해당 파이썬 파일이 직접 실행될 때만 그 안의 코드를 실행하도록 하는 구문다른 파일에서 import할 경우에는 실행되지 않는다.Import다른 파일에서 실행할 때 import 구문으로 가져오기 위해 파일명을 간단하게 작성# a.pydef hello_word() : print(\"wow\")# b.pyimport ax = a.hello_world()# wow 출력in, not inx = \"hello world\"y = \"hello world _ with python\"if x in y : print(\"wow\")# wow 문자열 포함 여부 확인 리스트, 튜플, 딕셔너리에서도 활용 가능 문자열 가공df['ROAS'] = ((df['매출'] / df['광고비']) * 100).round(0).astype(int).astype(str) + \"%\" (계산) → 숫자 Series .astype(str) → 각 값이 문자열로 변환 ”%” → 퍼센트 기호 붙이기 *결측치가 없다면 astype()으로 한번에 변환.변환할 수 없는 데이터가 포함된다면 pd.to_numeric()으로 처리날짜 설정datetime.timedelta는 시간 간격을 나타내는 객체로 날짜나 시간에 특정 기간을 더하거나 뺄 때 사용한다.n일 전의 날짜를 구하려면 뺄셈, n일 후의 날짜를 구하려면 덧셈을 하면 된다.from datetime import date, timedeltatoday = date.today()x = timedelta(days=365)print(today + x)print(today - x)# 2026-09-19# 2024-09-19from datetime import datetime, timedelta#### 오늘 ~ 2주 전today = datetime.today()two_weeks_ago = today - timedelta(weeks=2)target_date = two_weeks_ago + timedelta(days=1)formatted = target_date.strftime(\"%Y-%m-%d\")#### 전날 ~ 2주today = datetime.today()yesterday = today - timedelta(days=1)two_weeks_ago = yesterday - timedelta(weeks=2)formatted = two_weeks_ago.strftime(\"%Y-%m-%d\")print(formatted)Win32comMicrosoft에서 제공하는 윈도우 프로그램을 파이썬으로 제어할 수 있도록 만든 APIMicrosoft Excel, Power point, Word, Outlook 등 제어 가능pip install pywin32import win32com.client as pyoutlook = py.Dispatch(\"Outlook.Application\").GetNamespace(\"MAPI\")outlook.GetDefaultFolder(6) # 받은 편지함실행 5초마다 확인하고 최대 90초까지 대기 최신순 정렬 후 보낸 사람이 TARGET_SENDER와 일치하는 메일을 탐색 현재 시간 기준 5분 이내 메일이라면 본문 2번째 줄을 출력 def email_code(): TARGET_SENDER = \"EXCEL\" WAIT_TIMEOUT = 90 CHECK_INTERVAL = 5 outlook = py.Dispatch(\"Outlook.Application\").GetNamespace(\"MAPI\") inbox = outlook.GetDefaultFolder(6) start_time = time.time() while time.time() - start_time &lt;= WAIT_TIMEOUT: try: messages = inbox.Items # 받은 편지함 - 모든 메시지 받기 messages.Sort(\"[ReceivedTime]\", True) # 최신순 정렬 latest_mail = messages.GetFirst() # 최신 메일 하나만 가져오기 if latest_mail and TARGET_SENDER in latest_mail.SenderName: # 발신인 now = datetime.now() mail_time = latest_mail.ReceivedTime.replace(tzinfo=None) if (mail_time.date() == now.date()) and (abs((now - mail_time).total_seconds()) &lt;= 300): body_lines = latest_mail.Body.splitlines() if len(body_lines) &gt; 1: return body_lines[1] else: print(\"본문 줄 수 부족\") return None else: print(\"대기 중\") except Exception as e: print(\"오류:\", e) time.sleep(CHECK_INTERVAL) print(\"시간 초과\") return Noneprint(email_code())Excel 자동화데이터 삭제import pandas as pdfrom openpyxl import load_workbooknew_path = 'new/' # 새로 추가할 엑셀 파일 위치old_path = 'old/' # 붙여넣을 엑셀 파일 위치# header → index 기준df1 = pd.read_excel(new_path + 'new_apple.xlsx', sheet_name='apple', header=1)print(df1.shape)df2 = pd.read_excel(new_path + 'new_mango.xlsx', sheet_name='mango', header=2)print(df2.shape)wb = load_workbook(old_path + 'fruit.xlsx')# excel은 1번부터ws = wb['apple']for row_idx in range(ws.max_row, df1.shape[0]+3, -1): # 4번째 행~ ws.delete_rows(row_idx)wb.save(\"fruit.xlsx\")wb = load_workbook('fruit.xlsx')ws = wb['mango']for row_idx in range(ws.max_row, df2.shape[0]+2, -1): # 3번째 행 ~ ws.delete_rows(row_idx)wb.save(\"fruit.xlsx\")새 데이터가 500행이고 기존 데이터가 600행이라면 → 남은 100행은 제거데이터 붙여넣기이해하기 쉽게 시트명을 변경해봤다.(위와 동일x)from openpyxl import load_workbookpath = 'new/' # apple과 mango의 파일 위치a = 'new_apple.xlsx'b = 'new_mango.xlsx'c = 'fruit.xlsx' # 복붙할 xlsxa_wb = load_workbook(path + a, data_only = True) # 수식x. 값만 가져오기a_ws = a_wb['apple']# 행의 개수 만큼 튜플 반환data_to_copy = []for row in a_ws.iter_rows(min_row=4, max_row=a_ws.max_row, values_only=True): data_to_copy.append(row)b_wb = load_workbook(c)b_ws = b_wb['old_apple'] # 저장할 시트 명# excel은 1부터 시작 → start=4, start=1for row_idx, data_row in enumerate(data_to_copy, start=4): for col_idx, value in enumerate(data_row, start=1): b_ws.cell(row=row_idx, column=col_idx, value=value)b_wb.save('new_fruit.xlsx')# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #a_wb = load_workbook(path + b, data_only = True)a_ws = a_wb['mango']# 행의 개수 만큼 튜플 반환data_to_copy = []for row in a_ws.iter_rows(min_row=4, max_row=a_ws.max_row, values_only=True): data_to_copy.append(row)b_wb = load_workbook('fruit.xlsx')b_ws = b_wb['old_mango']# excel은 1부터 시작 → start=3, start=1for row_idx, data_row in enumerate(data_to_copy, start=3): for col_idx, value in enumerate(data_row, start=1): b_ws.cell(row=row_idx, column=col_idx, value=value)b_wb.save('new_fruit.xlsx')DataFramedf_platforms = pd.DataFrame.from_dict(df[\"플랫폼별\"], orient=\"index\").reset_index()df_platforms = df_platforms.rename(columns={\"index\": \"플랫폼\"})results = { \"NAVER\": {\"광고비\": 1000, \"매출\": 3000, \"노출\": 5000, \"유입\": 200}, \"GOOGLE\": {\"광고비\": 2000, \"매출\": 6000, \"노출\": 8000, \"유입\": 350}}pd.DataFrame.from_dict(results, orient=\"index\")바깥 딕셔너리의 key 를 DataFrame의 index 로 사용 . 광고비 매출 노출 유입 NAVER 1000 3000 5000 200 GOOGLE 2000 6000 8000 350 .reset_index()Index를 컬럼으로 빼기 위해 사용 index 광고비 매출 노출 유입 NAVER 1000 3000 5000 200 GOOGLE 2000 6000 8000 350 .rename(columns={\"index\": \"플랫폼\"})컬럼 이름 index를 플랫폼으로 변경REFERENCE win32com 소개 및 설치 방법 006 두 날짜의 차이를 알려면? ― datetime.timedelta" }, { "title": "광고 데이터", "url": "/posts/%EA%B4%91%EA%B3%A0-%EB%8D%B0%EC%9D%B4%ED%84%B0/", "categories": "Analysis", "tags": "Analysis", "date": "2025-08-31 00:00:00 +0900", "snippet": "데이터 전처리 &amp; 분석 데이터 : 2025.08.01 ~ 2025.08.29 (임의 생성 데이터) random.randint, random.choice 활용 지표 계산 : CTR, CPC, 전환율, CPA, ROAS, CPM 전처리 : INF → NaN → 0 대체, 반올림 처리, 정수형 변환 sampledf.head(5) date 노출수 click 전환수 cost revenue CTR CPC 전환율 CPA ROAS CPM 2025-08-01 76422 438 19 86557 51000 0.57 198 4.34 4556 59 1133 2025-08-02 35795 398 27 93763 0 1.11 236 6.78 3473 0 2619 2025-08-03 20860 408 14 92606 89000 1.96 227 3.43 6615 96 4439 2025-08-04 58158 519 27 71534 68000 0.89 138 5.20 2649 95 1230 2025-08-05 74343 537 6 89127 172000 0.72 166 1.12 14854 193 1199 df.info()Data columns (total 12 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 date 29 non-null datetime64[ns] 1 노출수 29 non-null int64 2 click 29 non-null int64 3 전환수 29 non-null int64 4 cost 29 non-null int64 5 revenue 29 non-null int64 6 CTR 29 non-null float64 7 CPC 29 non-null int64 8 전환율 29 non-null float64 9 CPA 29 non-null int64 10 ROAS 29 non-null int64 11 CPM 29 non-null int64df.describe() . 노출수 click 전환수 cost revenue CTR CPC 전환율 CPA ROAS CPM count 29 29.000000 29.000000 29.00000 29.000000 29.000000 29.000000 29.000000 29.000000 29.000000 29.000000 mean 48840.000000 444.379310 13.586207 80454.37931 105241.379310 1.107931 184.827586 3.156897 15024.241379 137.344828 2034.448276 min 20769.000000 358.000000 1.000000 61016.00000 0.000000 0.490000 113.000000 0.210000 2179.000000 0.000000 860.000000 25% 31284.000000 400.000000 6.000000 69268.00000 51000.000000 0.680000 154.000000 1.180000 3839.000000 68.000000 1150.000000 50% 48693.000000 438.000000 13.000000 82002.00000 99000.000000 0.890000 169.000000 3.020000 6615.000000 131.000000 1633.000000 75% 64732.000000 484.000000 21.000000 89127.00000 155000.000000 1.640000 227.000000 4.680000 13714.000000 225.000000 2502.000000 max 79735.000000 539.000000 29.000000 99976.00000 278000.000000 2.230000 268.000000 7.840000 93159.000000 304.000000 4771.000000 std 20123.509439 60.875994 9.206043 12358.18273 66029.027801 0.543345 41.004415 2.237111 21905.027738 88.517261 1127.575578 전반적으로 평균과 중앙값이 유사하지만 CPA, CPM의 분산이 매우 크다.시각화import plotly.graph_objects as gofrom plotly.subplots import make_subplots# 추세 분석 (광고비 vs 매출액)fig1 = go.Figure()fig1.add_trace(go.Scatter(x=df[\"date\"], y=df[\"cost\"], mode=\"lines+markers\", name=\"광고비\"))fig1.add_trace(go.Scatter(x=df[\"date\"], y=df[\"revenue\"], mode=\"lines+markers\", name=\"매출액\"))fig1.update_layout(title=\"일자별 광고비 vs 매출액\", template=\"plotly_white\")fig1.update_yaxes(tickformat=',') # 퍼널 분석 (노출 → 클릭 → 전환)fig2 = go.Figure(go.Funnel( y=[\"노출수\", \"클릭수\", \"전환수\"], x=[df[\"노출수\"].sum(), df[\"click\"].sum(), df[\"전환수\"].sum()], textinfo=\"value+percent initial\"))fig2.update_layout(title=\"퍼널 분석 (노출 → 클릭 → 전환)\")fig2.update_yaxes(tickformat=',')# 비용 효율성 비교 (CPC, CPM, CPA)fig3 = go.Figure()fig3.add_trace(go.Bar(x=df[\"date\"], y=df[\"CPC\"], name=\"CPC\"))fig3.add_trace(go.Bar(x=df[\"date\"], y=df[\"CPM\"], name=\"CPM\"))fig3.add_trace(go.Bar(x=df[\"date\"], y=df[\"CPA\"], name=\"CPA\"))fig3.update_layout(barmode=\"group\", title=\"주차별 비용 효율 비교\", template=\"plotly_white\")fig3.update_yaxes(tickformat=',')# 상관관계 분석 (클릭수 vs 전환수, 광고비 vs 매출액)fig4 = make_subplots(rows=1, cols=2, subplot_titles=(\"클릭수 vs 전환수\", \"광고비 vs 매출액\"))fig4.add_trace(go.Scatter( x=df[\"click\"], y=df[\"전환수\"], mode=\"markers\", text=df[\"date\"].dt.strftime(\"%m-%d\"), hoverinfo=\"text+x+y\", name=\"클릭→전환\"), row=1, col=1)fig4.add_trace(go.Scatter( x=df[\"cost\"], y=df[\"revenue\"], mode=\"markers\", text=df[\"date\"].dt.strftime(\"%m-%d\"), hoverinfo=\"text+x+y\", name=\"광고비→매출\"), row=1, col=2 )fig4.update_layout(title=\"상관관계 분석\", template=\"plotly_white\")fig4.update_yaxes(tickformat=',')# 성과 비율 시각화 (CTR, 전환율)conversion_rate = df[\"전환수\"].sum() / df[\"click\"].sum()fig5 = go.Figure(data=[ go.Pie(labels=[\"CTR 평균\", \"전환율 평균\"], values=[df[\"CTR\"].mean(), conversion_rate])])fig5.update_layout(title=\"CTR &amp; 전환율 비율 비교\")# 효율지표 종합 대시보드 (ROAS, CPC, CPA)fig6 = make_subplots(rows=1, cols=3, subplot_titles=(\"ROAS\", \"CPC\", \"CPA\"))fig6.add_trace(go.Bar(x=df[\"date\"], y=df[\"ROAS\"], name=\"ROAS\", marker_color=\"skyblue\"), row=1, col=1)fig6.add_trace(go.Bar(x=df[\"date\"], y=df[\"CPC\"], name=\"CPC\", marker_color=\"orange\"), row=1, col=2)fig6.add_trace(go.Bar(x=df[\"date\"], y=df[\"CPA\"], name=\"CPA\", marker_color=\"green\"), row=1, col=3)fig6.update_layout(title=\"효율지표 종합 대시보드\", template=\"plotly_white\")fig6.update_yaxes(tickformat=',')fig1.show()fig2.show()fig3.show()fig4.show()fig5.show()fig6.show()(1) 일자별 광고비 vs 매출액 광고비는 일정하지만 매출은 들쭉날쭉 광고비가 매출을 직접적으로 설명하지 못함(영향x) 매출이 갑자기 튀는 구간은 특정 이벤트/프로모션, 채널별 차이일 가능성이 높다. “광고비 증가 = 매출 증가”라는 단순 구조가 아님(2) 퍼널 분석 (노출 → 클릭 → 전환) 노출 대비 클릭률, 클릭 대비 전환률 모두 낮음 광고는 보이지만 흥미를 못 끎 → 타겟팅 문제 가능성 클릭 후 전환 장벽이 큼 → 랜딩 페이지 UX, 구매 과정 문제 가능성 개선 포인트: 타겟 세분화, 랜딩 페이지 개선(3) 비용 효율성 (CPC, CPM, CPA) CPC 낮음 → 클릭 자체는 잘 유도됨 CPM 중간 → 노출 대비 비용은 보통 CPA 높음 → 전환수가 적어 단위 비용이 급등 구조적 문제 : 클릭은 잘 되는데, 전환이 안 되는 병목 존재(4) 상관관계 분석 클릭수 ↔ 전환수 : 강한 선형 패턴 없음 → 상관성 낮음 광고비 ↔ 매출액 : 상관성 약함 → 광고비 증액이 매출 증가를 보장하지 않음(다른 외부 요인 영향 큼) 광고비 자체보다 소재·채널·타겟팅 요인·이벤트 등 외부요인이 더 중요한 변수일 수 있다.(5) CTR &amp; 전환율 비교 CTR 평균 &gt; 전환율 평균 광고 자체는 주목을 잘 받지만(CTR 높음), 클릭 후 기대 행동으로 이어지지 않음(전환율 낮음). (6) 효율지표 종합 대시보드 (ROAS, CPC, CPA) ROAS: 일정치 않음 → 광고 효율 불안정(투자 대비 효율 일정x) CPC: 안정적 → 클릭 단가는 유지 CPA: 급등락 반복 → 전환 효율이 가장 큰 문제 클릭은 충분히 발생하나 전환 최적화 부족 → CPA 비정상적으로 높음(전환 효율이 개선 포인트) 정리 광고 클릭은 잘 발생하지만 전환으로 이어지지 않아 CPA가 상승 광고비 대비 매출의 변동성이 크고 불안정해 효율성이 낮음 CTR은 양호하지만 전환율이 낮아 타겟팅 정교화와 랜딩 경험 등 개선 필요 광고비와 성과 간 상관관계가 약해 비용 증가만으로 성과를 보장하지 않음 → 따라서 광고 성과 개선의 핵심은 전환 최적화(CRO) 와 세분화된 타겟팅 전략이다.CTR이 높은 점을 보면 광고 자체의 매력도는 충분하다. → 광고는 소비자에게 잘 전달되고 있다.그러나 실제 구매 전환 성과는 부족한 상황이다." }, { "title": "Sql order 데이터 분석", "url": "/posts/SQL-ORDER-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%B6%84%EC%84%9D/", "categories": "Analysis", "tags": "Analysis", "date": "2025-08-17 00:00:00 +0900", "snippet": "SQL ORDER 데이터 분석최신 날짜 데이터 확인하기SELECT *FROM ordersORDER BY order_date DESCLIMIT 100;데이터가 많아 로딩하는게 시간이 많이 소요되어 limit로 제한을 두었다.데이터는 25.06월까지 존재한다.6 ~ 8월 데이터를 확인하기 위해 2024년의 데이터를 가지고 진행했다.24년 06~08월 월별 구매 건수 DATE_FORMAT(날짜 , 형식) : 날짜를 지정한 형식으로 출력SELECT DATE_FORMAT(order_date, '%Y-%m') date, COUNT(order_id) countFROM ordersWHERE order_date BETWEEN '2024-06-01' AND '2024-08-31'GROUP BY DATE_FORMAT(order_date, '%Y-%m') ;| date | count | | :—: | :—: | | 2024-06 | 10462 | | 2024-07 | 9163 | | 2024-08 | 12531 |8월에 구매건수가 상승했다.*year(order_date)=2024 AND MONTH(order_date)&gt;=06 AND MONTH(order_date)&lt;=0824년 06~08월 데이터 중 가장 많은 금액을 지불한 고객 TOP 3*소수점 없이 출력상위 고객의 결제 금액에 전체 매출에 영향을 미칠 수 있다.SELECT member_id, FORMAT(MAX(order_price), 0)FROM ordersWHERE year(order_date)=2024 AND MONTH(order_date)&gt;=06 AND MONTH(order_date)&lt;=08 AND member_id !=''GROUP BY member_idLIMIT 3; member_id FORMAT(MAX(order_price), 0) 123 1,690,420 456 1,083,520 789 892,350 가장 비싼 주문 1건을 조회했다.가장 많이 지불한 고객을 보기 위해선 SUM(order_price)을 사용해야할듯 하다.24년 06~08월 데이터 중 가장 많이 구매한 고객 TOP 3충성 고객 식별SELECT member_id, COUNT(order_id)FROM ordersWHERE order_date BETWEEN '2024-06-01' AND '2024-08-31 23:59:59' AND member_id !=''GROUP BY member_idORDER BY COUNT(order_id) DESCLIMIT 3; member_id COUNT(order_id) 59595 42 98765 25 82821 17 고액 결제 고객과 구매 횟수 상위 고객이 일치하지 않을 수 있다.구매 횟수 상위 고객을 중심으로 재구매 유도를 할 수 있다.*between A and B 는 A 이상 B 이하하지만 날짜 데이터를 다루는 경우 시분초 데이터까지 생각해야한다.시분초 없이 날짜만 이용한다면 00시 00분 00초로 자동으로 인식한다. between A and B : 0.063 초 year, month 쓰는 경우 : 0.078 초 year(order_date)=2024 AND MONTH(order_date)&gt;=06 AND MONTH(order_date)&lt;=08 BETWEEN을 활용하는게 시간이 더 적게 소요되어 이후에 BETWEEN으로 작성했다.24년 06~08월 월별 구매건수와 구매액SELECT DATE_FORMAT(order_date, '%y - %m') date, COUNT(order_id) count, FORMAT(SUM(order_price), 0) total_priceFROM ordersWHERE order_date BETWEEN '2024-06-01' and '2024-08-31:23:59:59'GROUP BY DATE_FORMAT(order_date, '%y - %m'); date count total_price 24 - 06 10462 786,543,210 24 - 07 9163 876,543,210 24 - 08 12531 987,654,320 6월은 구매건수는 7월보다 많지만 구매액은 적었는데 해당 시기에 할인 이벤트가 있었을 수 있다. → 상품군별 분석 7월은 구매건수는 감소했지만 평균 구매액이 상승했는데 소수의 고액 구매자가 영향을 준 것으로 보여진다. → 고액 결제 고객 분석 8월의 구매건수와 구매액이 모두 증가했다. 24년 6월과 25년 6월 데이터 구매건수 및 구매액 비교동일 시기의 전년 대비 성과 비교SELECT DATE_FORMAT(order_date, '%y - %m') date, COUNT(order_id) count, FORMAT(SUM(order_price), 0) total_price FROM ordersWHERE (year(order_date)=2024 AND MONTH(order_date)=06) OR (year(order_date)=2025 AND MONTH(order_date)=06)GROUP BY DATE_FORMAT(order_date, '%y - %m'); date count total_price 24 - 06 10462 786,543,210 25 - 06 8521 762,482,320 24년 6월에 비해 25년의 6월 주문량과 구매액이 적은 것을 알 수 있다.25년 6월은 전년 동월 대비 주문량 19% 감소, 매출 3% 감소했다.프로모션, 경제 상황 등 파악 필요주문 사이트 별 총 구매 가격각 판매 채널의 매출 규모 파악SELECT order_site_id, SUM(order_price) priceFROM orders JOIN orderitemsUSING (order_id)GROUP BY order_site_id ORDER BY price DESC; order_site_id price homepage 123,456,789,250 mobile 100,000,000,690 google 85,156,753,710 naver 82,456,750,390 coupang 75,412,689,580 kakao 71,498,273,190 daum 59,268,152,170 홈페이지 구매액이 가장 높다.채널별 고객 특성 분석을 통해 마케팅 효율 최적화를 진행할 수 있을 것 같다.REFERENCE [mysql] DATE_FORMAT - 날짜 형식 설정" }, { "title": "Google analytics", "url": "/posts/Google-Analytics/", "categories": "Analysis", "tags": "Analysis", "date": "2025-08-03 00:00:00 +0900", "snippet": "획득을 사용자 획득과 트래픽 획득 두 종류로 구분한다.사용자 획득은 사람 단위이며 트래픽 획득은 세션 단위다.ex) 한 명의 사람이 총 5번 방문했다면사용자 획득은 1(명의 사람), 트래픽 획득은 5(번의 방문)가 된다.사용자가 웹사이트에 방문하여 세션이 시작되면 session_start 이벤트를 실행,해당 사용자가 처음 방문한 신규 사용자라면 first_visit 이벤트도 함께 실행시킨다.→ 신규 사용자 유입 분석만 집중적으로 필요하다면 사용자 획득 보고서전체 사용자의 전반적인 유입 분석이 필요하다면 트래픽 획득 보고서를 보면 된다.*참고로 데이터는 임의로 작성해 정리한 것도 있으며 기존 데이터를 활용해 정리한 것도 있다.1. 웹사이트 사용자 유입 분석전체 사용자의 전반적인 유입 분석이 가능한 [트래픽 획득] 탭 클릭&lt;세션 기본 채널 그룹▼&gt; 으로 초기 측정기준이 설정되어있다.웹사이트에 사용자들의 가장 많은 유입처를 확인하기 위해 사용자 측정항목의 데이터를 확인 세션 기본 채널 그룹 Organic Search Direct Referral Paid Search Organic Social Paid Social Display Organic Search(다양한 검색 엔진에서의 자연 검색)의 사용자가 가장 많다.검색광고(Paid Search)와 디스플레이 광고(Display), SNS 플랫폼(Organic Social)도 있다는 것을 알 수 있다.하지만 세션 기본 채널 그룹으로는 어떤 검색 엔진에서의 자연 검색 유입이 많은지 등 자세한 정보를 알기 어렵다.측정기준을 &lt;세션 소스/매체▼&gt; 로 변경했다. 세션 기본 채널 그룹 세션 수 google / organic 47.6% (direct) / (none) 36.9% github.com / referral 11.7% google / cpc 2.2% FBIG / 1 1.3% naver / organic 0.3% google / organic → 구글에서의 자연 검색이 가장 많다.google / cpc를 통해 광고 역시 구글 광고의 유입이 가장 많은 것을 확인할 수 있다.결론 : 해당 웹사이트의 사용자들은 구글에서의 자연 검색(google / organic)으로의 유입이 가장 많다.github를 통한 유입은 전체 세션 중 11.7%로 적은 편이지만 참여율은 82%로 다른 유입 경로 대비 가장 높다.google / organic(58%)이나 (direct) / (none)(72%)의 참여율은 github보다 낮다.이는 github에서 유입된 사용자가 다른 유입에 비해 관심도가 높다라고 볼 수 있다.2. 시간대에 따른 유입 분석 전체 사용자에 대한 데이터가 필요 → [ 트래픽 획득 ] 탭 클릭 측정 기준 &lt;세션 소스 / 매체 ▼&gt; 로 변경 가장 상단에 &lt;필터추가+&gt; 클릭 측정 기준 세션 소스/매체 검색 유형 : 알아서 체크(‘다음과 정확하게 일치’로 체크함) 값 : google / organic (google / cpc 등 분석하고 싶은 부분 체크) 보조 측정기준 &lt;+&gt; 클릭해서 시간 체크import matplotlib.pyplot as pltratio = [10.73, 9.75, 9.75, 9.46, 7.49, 6.21, 5.79, 40.82]labels = ['17', '14', '15', '16', '11', '13', '18', 'else']plt.pie(ratio, labels=labels, autopct='%.1f%%')plt.show()‘17’, ‘14’, ‘15’, ‘16’ 순으로 나와 오후 시간대에 유입이 많은 것 같았지만퍼센트로 확인해보면 시간대 별 큰 차이가 있어보이지는 않는다.참여 세션이란 세션이 10초 이상 지속되었거나주요 이벤트가 1회 이상 발생했거나, 페이지 또는 화면 조회수가 2회 이상인 세션을 의미한다.[GA4] 참여도 개요 보고서검색해서 들어온 사람들의 참여율은 50% 수준이다.전체적으로 약 절반가량의 세션에서 사용자가 10초 이내에 이탈하거나 추가 이벤트 없이 종료된 것으로 확인된다.전체적으로 이탈률이 높은 것인지 특정 글에서 높은 것인지 추가로 확인해봤다.방문자 수가 적은(10 이하) 글을 제외하고 가장 높은 수치는 76%의 참여율을 보였다.참여율이 높지 않은 것으로 보아 대부분의 참여율이 50~60%에 미치는 것으로 보여진다.REFERENCE구글 애널리틱스 4 유입 분석의 첫 단계: 획득 보고서 보기" }, { "title": "입출고, 반품 데이터", "url": "/posts/%EC%9E%85%EC%B6%9C%EA%B3%A0,-%EB%B0%98%ED%92%88-%EB%8D%B0%EC%9D%B4%ED%84%B0/", "categories": "Analysis", "tags": "Python, Analysis", "date": "2025-07-18 00:00:00 +0900", "snippet": "Excel 데이터 구조 시트 목록: info, date, 출고, 입고, 반품 특징 정리 idx가 같으면 fruit, date도 같다. idx, fruit가 같아도 location은 다를 수 있다. type은 입고, 출고, 미출고, 반품이 있다. date는 입고 날짜를 의미 중복 데이터 가능 import pandas as pdinfo = pd.read_excel('test.xlsx', sheet_name='info')date = pd.read_excel('test.xlsx', sheet_name='date')df_출고 = pd.read_excel('test.xlsx', sheet_name='출고')df_입고 = pd.read_excel('test.xlsx', sheet_name='입고')df_반품 = pd.read_excel('test.xlsx', sheet_name='반품')작성일자 변경date index 연월 작성일 0 1111-11-01 1111-01-18 date['연월'] = '2025-06-01'date['작성일'] = '2025-07-18'date index 연월 작성일 0 2025-06-01 2025-07-18 출고idx 값이 비어있으면 info 시트에서 값 찾아 넣기df_출고.info()&lt;class 'pandas.core.frame.DataFrame'&gt;RangeIndex: 87 entries, 0 to 86Data columns (total 4 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 idx 77 non-null object 1 fruit 87 non-null object 2 date 87 non-null int64 3 type 87 non-null object10개의 idx값이 없다.a = info.set_index('fruit')['idx'].to_dict()a{'Apple': '02_Ap', 'Strawberry': '03_St', 'Lemon': '04_Le', 'Mango': '05_Ma', 'Grape': '06_Gr', 'Orange': '07_Or', 'Kiwi': '08_Ki', 'Pineapple': '09_Pi', 'Melon\\xa0': '10_Me', 'Peach\\xa0': '11_Pe', 'Watermelon\\xa0': '12_Wa', 'Guava': '25_Gu', 'Pear': '14_Pe', 'Banana': '15_Ba', 'Blueberry': '16_Bl', 'Coconut': '17_Co', 'Cherry': '18_Ch', 'Grapefruit': '19_Gr', 'Durian': '20_Du', 'Mangosteen': '21_Ma', 'Apricot': '22_Ap', 'Lychee': '23_Ly'} df_출고[df_출고['idx'].isnull()] index idx fruit date type 6 NaN Coconut 250717 출고 9 NaN Mangosteen 250721 출고 14 NaN Grapefruit 250719 출고 24 NaN Mango 250705 출고 29 NaN Kiwi 250708 출고 40 NaN Grapefruit 250719 출고 46 NaN Kiwi 250708 출고 61 NaN Blueberry 250716 출고 83 NaN Pear 250714 출고 84 NaN Banana 250715 출고 df_출고['idx'] = df_출고['idx'].fillna(df_출고['fruit'].map(a)) df_출고[df_출고['idx'].isnull()] index idx fruit date type           df_출고[df_출고['type']=='미출고'] index idx fruit date type 11 15_Ba Banana 250715 미출고 43 19_Gr Grapefruit 250719 미출고 57 11_Pe Peach  250711 미출고 70 09_Pi Pineapple 250709 미출고 86 18_Ch Cherry 250718 미출고 df_출고.loc[df_출고['type'] == '미출고', 'idx'] = '-'*처음에 df_출고[df_출고['type']=='미출고']['idx']='-'로 작성했었다. A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead 라고 뜬다.df_출고[df_출고['type']=='미출고'] index idx fruit date type 11 - Banana 250715 미출고 43 - Grapefruit 250719 미출고 57 - Peach  250711 미출고 70 - Pineapple 250709 미출고 86 - Cherry 250718 미출고 입고type이 반품인 경우 returns 값이 비어있을 경우 [반품] 에서 찾아 입력df_입고[(df_입고['type'] == '반품') &amp; (df_입고['returns'].isna())] index idx fruit date returns type 4 08_Ki Kiwi 250708 NaN 반품 12 25_Gu Guava 250713 NaN 반품 20 15_Ba Banana 250715 NaN 반품 37 12_Wa Watermelon  250712 NaN 반품 56 18_Ch Cherry 250718 NaN 반품 58 15_Ba Banana 250715 NaN 반품 78 14_Pe Pear 250714 NaN 반품 80 16_Bl Blueberry 250716 NaN 반품 102 12_Wa Watermelon  250712 NaN 반품 lo = df_반품.groupby(['fruit','location']).size().unstack(fill_value=0)lo['count'] = lo.sum(axis=1)lo fruit 1호점 2호점 3호점 4호점 5호점 count Apple 1 0 0 0 1 2 Apricot 0 0 0 0 1 1 Banana 1 1 0 1 1 4 Blueberry 0 1 0 2 0 3 Cherry 1 1 0 1 1 4 Durian 1 2 1 0 0 4 Grape 1 0 1 1 0 3 Grapefruit 0 0 0 1 0 1 Guava 0 0 0 2 4 6 Kiwi 0 0 0 2 0 2 Lychee 2 0 0 0 0 2 Mango 0 0 0 0 1 1 Melon  0 0 0 2 0 2 Orange 0 0 1 1 2 4 Peach  0 1 1 0 1 3 Pear 1 0 1 0 0 2 Strawberry 0 0 0 0 1 1 Watermelon  0 0 0 0 3 3 참고) Counter각 원소가 몇 번씩 나오는지 출력from collections import Counterdf = x.copy()for fruit in df['fruit'].unique(): all_returns = df_반품[df_반품['fruit'] == fruit]['location'].dropna().tolist() all_counter = Counter(all_returns) print(all_counter)Counter({'4호점': 2})Counter({'5호점': 4, '4호점': 2})Counter({'5호점': 1, '1호점': 1, '2호점': 1, '4호점': 1})Counter({'5호점': 3})Counter({'4호점': 1, '2호점': 1, '1호점': 1, '5호점': 1})Counter({'1호점': 1, '3호점': 1})Counter({'4호점': 2, '2호점': 1})입고 시트에서 type이 반품인 경우 returns 값이 비어있을 때반품 시트의 과일명과 일치하는 location을 찾아 returns의 데이터에 값을 넣는 과정을 진행했다.여기서 문제는 같은 과일이더라도 location이 다르다 라는 것이다.어떤 식으로 값을 넣을까 고민하다가 Counter를 통해서반품 시트에서 과일별 location 개수를 Counter로 저장하고입고 시트에서 returns 값이 이미 있는 경우 해당 location의 개수를 -1한다.Counter에서 value가 0이상인 값들만 결측치에 하나씩 넣는다.for fruit in df_입고[df_입고['type'] == '반품']['fruit'].unique(): refund_locs = df_반품[df_반품['fruit'] == fruit]['location'].tolist() refund_counter = Counter(refund_locs) # {location : count} existing_returns = df_입고[ (df_입고['fruit'] == fruit) &amp; (df_입고['type'] == '반품') &amp; (df_입고['returns'].notna())]['returns'].tolist() for loc in existing_returns: # notna_returns list refund_counter[loc] -= 1 fill_loc = [] for loc, count in refund_counter.items(): # 데이터의 key, value 값 튜플 if count &gt; 0: fill_loc.extend([loc] * count) nan_index = df_입고[ (df_입고['fruit'] == fruit) &amp; (df_입고['type'] == '반품') &amp; (df_입고['returns'].isna())].index.tolist() for idx, loc in zip(nan_index, fill_loc): df_입고.at[idx, 'returns'] = locexpected = df_반품.groupby(['fruit', 'location']).size().unstack(fill_value=0)actual = df_입고[df_입고['type'] == '반품'].groupby(['fruit', 'returns']).size().unstack(fill_value=0)comparison = expected.subtract(actual, fill_value=0)comparison['diff'] = comparison.abs().sum(axis=1)comparison fruit 1호점 2호점 3호점 4호점 5호점 diff Apple 0 0 0 0 0 0 Apricot 0 0 0 0 0 0 Banana 0 0 0 0 0 0 Blueberry 0 0 0 0 0 0 Cherry 0 0 0 0 0 0 Durian 0 0 0 0 0 0 Grape 0 0 0 0 0 0 Grapefruit 0 0 0 0 0 0 Guava 0 0 0 0 0 0 Kiwi 0 0 0 0 0 0 Lychee 0 0 0 0 0 0 Mango 0 0 0 0 0 0 Melon  0 0 0 0 0 0 Orange 0 0 0 0 0 0 Peach  0 0 0 0 0 0 Pear 0 0 0 0 0 0 Strawberry 0 0 0 0 0 0 Watermelon  0 0 0 0 0 0 모두 알맞게 들어갔다.반품이 아닌 경우 returns ‘-‘로 표시하기df_입고 . idx fruit date returns type 0 02_Ap Apple 250702 1호점 반품 1 03_St Strawberry 250703 2호점 입고 2 05_Ma Mango 250705 4호점 입고 3 06_Gr Grape 250706 3호점 반품 4 08_Ki Kiwi 250708 4호점 반품 … … … … … … 99 05_Ma Mango 250705 3호점 입고 100 06_Gr Grape 250706 1호점 입고 101 07_Or Orange 250707 5호점 - 102 12_Wa Watermelon 250712 5호점 반품 103 21_Ma Mangosteen 250721 4호점 입고 104 rows × 5 columnsdf_입고['type'].value_counts() type count 입고 54 반품 48 ’-‘ 2 총 56개를 수정해야한다.df_입고['returns'].value_counts() returns count 5호점 27 4호점 22 3호점 21 1호점 19 2호점 15 returns는 1~5호점까지 존재한다.df_입고.loc[df_입고['type'] != '반품', 'returns'] = '-'df_입고['returns'].value_counts() returns count ’-‘ 56 5호점 16 4호점 13 1호점 8 2호점 6 3호점 5 56개의 데이터가 ‘-‘ 로 표시된 것을 확인할 수 있다.type이 ‘-‘인 경우 idx도 ‘-‘ 표시df_입고['type'].value_counts() type count 입고 54 반품 48 ’-‘ 2 ’-‘로 되어있는 데이터가 2개 있다.df_입고['idx'].unique()array(['02_Ap', '03_St', '05_Ma', '06_Gr', '08_Ki', '10_Me', '11_Pe', '25_Gu', '15_Ba', '20_Du', '22_Ap', '23_Ly', '18_Ch', '04_Le', '07_Or', '12_Wa', '09_Pi', '21_Ma', '14_Pe', '16_Bl', '17_Co', '19_Gr'], dtype=object)df_입고.loc[df_입고['type']=='-', 'idx'] = '-'df_입고['idx'].unique()array(['02_Ap', '03_St', '05_Ma', '06_Gr', '08_Ki', '10_Me', '11_Pe', '25_Gu', '15_Ba', '20_Du', '22_Ap', '23_Ly', '18_Ch', '04_Le', '-', '07_Or', '12_Wa', '09_Pi', '21_Ma', '14_Pe', '16_Bl', '17_Co', '19_Gr'], dtype=object)’-‘ 가 추가되었다.참고) Counterfrom collections import Counterc = Counter(['A', 'B', 'A', 'C'])print(c) # Counter({'A': 2, 'B': 1, 'C': 1})print(c['A']) # 2print(c['D']) # 0c['A'] -= 1print(c) # Counter({'A': 1, 'B': 1, 'C': 1})REFERENCECounter 파이썬 collections 모듈의 Counter 사용법" }, { "title": "No kernel", "url": "/posts/No-Kernel/", "categories": "Error", "tags": "error", "date": "2025-05-03 00:00:00 +0900", "snippet": "Jupyter Notebook에서 No Kernel로 인해 실행이 되지 않았다.stack overflow를 보고 해결했다.Anaconda Prompt 에서 아래와 같이 입력 후 실행되었다.python -m pip install --upgrade setuptoolspython -m ensurepip --upgradepython -m pip install --upgrade pip" }, { "title": "E commerce", "url": "/posts/e-commerce/", "categories": "", "tags": "", "date": "2025-03-27 00:00:00 +0900", "snippet": "Kaggle의 e-commerce-customer-for-behavior-analysis 데이터를 가지고 진행했다.데이터 가져오기 및 확인import pandas as pddf = pd.read_csv('ecommerce_customer_data_large.csv')df.head()# df.tail() index Customer ID Purchase Date Product Category Product Price Quantity Total Purchase Amount Payment Method Customer Age Returns Customer Name Age Gender Churn 0 44605 2023-05-03 21:30:02 Home 177 1 2427 PayPal 31 1.0 John Rivera 31 Female 0 1 44605 2021-05-16 13:57:44 Electronics 174 3 2448 PayPal 31 1.0 John Rivera 31 Female 0 2 44605 2020-07-13 06:16:57 Books 413 1 2345 Credit Card 31 1.0 John Rivera 31 Female 0 3 44605 2023-01-17 13:14:36 Electronics 396 3 937 Cash 31 0.0 John Rivera 31 Female 0 4 44605 2021-05-01 11:29:27 Books 259 4 2598 PayPal 31 1.0 John Rivera 31 Female 0 평균이 중앙값보다 크거나 작은 차이가 크지 않은걸 보아 데이터가 한쪽으로 치우치는 경향이 없어보인다.데이터 확인하기df.shape # (250000, 13) 행, 열 개수 확인df.columns # 전체 column 확인Index(['Customer ID', 'Purchase Date', 'Product Category', 'Product Price', 'Quantity', 'Total Purchase Amount', 'Payment Method', 'Customer Age', 'Returns', 'Customer Name', 'Age', 'Gender', 'Churn'], dtype='object')kaggle에서 컬럼에 관한 정보를 확인했을 때는 12개로 나왔으나 실제 데이터는 13개가 존재했다.확인을 해보니 Customer Age와 Age가 존재했다.cts_age = df['Customer Age']age = df['Age']if cts_age.equals(age) : print(\"same\")else : print(\"diff\")출력 결과 동일하게 나와서 설명에 없는 Age 열을 삭제했다.df.drop('Age', axis = 1, inplace=True) # 열 삭제결측치 확인df.isna().sum()Returns 열에만 Nan값이 있어 개수를 확인했다. 총 47382로 전체 데이터의 약 19%를 차지한다.df.dropna(inplace=True) # 결측치 제거 df.describe()df.info() index Customer ID Product Price Quantity Total Purchase Amount Customer Age Returns Churn count 202618.0 202618.0 202618.0 202618.0 202618.0 202618.0 202618.0 mean 25020.140234332586 254.8990662231391 3.0084197850141647 2725.817661806947 43.817923382917606 0.500824211077002 0.20108776120581587 std 14412.38867355113 141.72042520520375 1.4143385567083016 1442.2684914912043 15.35606675487065 0.5000005545271854 0.4008145037060417 min 1.0 10.0 1.0 100.0 18.0 0.0 0.0 25% 12599.25 133.0 2.0 1478.0 30.0 0.0 0.0 50% 25018.0 255.0 3.0 2727.0 44.0 1.0 0.0 75% 37444.0 377.0 4.0 3975.0 57.0 1.0 0.0 max 50000.0 500.0 5.0 5350.0 70.0 1.0 1.0 &lt;class 'pandas.core.frame.DataFrame'&gt;Index: 202618 entries, 0 to 249999Data columns (total 12 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 Customer ID 202618 non-null int64 1 Purchase Date 202618 non-null object 2 Product Category 202618 non-null object 3 Product Price 202618 non-null int64 4 Quantity 202618 non-null int64 5 Total Purchase Amount 202618 non-null int64 6 Payment Method 202618 non-null object 7 Customer Age 202618 non-null int64 8 Returns 202618 non-null float64 9 Customer Name 202618 non-null object 10 Gender 202618 non-null object 11 Churn 202618 non-null int64 시각화연령대 변환 및 날짜 처리기본적인 데이터를 가지고 시각화를 진행했다.성별, 연령대, 반품, 이탈, 제품, 날짜를 시각화 했으며 연령을 연령대로 변환해 진행했다.# 제품 카테고리 확인 df['Product Category'].unique() # 'Home', 'Electronics', 'Books', 'Clothing'# 연령대 설정def age_group(age): if age &lt; 20: return \"10대\" elif age &lt; 30: return \"20대\" elif age &lt; 40: return \"30대\" elif age &lt; 50: return \"40대\" elif age &lt; 60: return \"50대\" elif age &lt; 70: return \"60대\" else: return \"70대\"df[\"Age_Group\"] = df[\"Customer Age\"].apply(age_group)# 날짜 설정df['Purchase Date'] = pd.to_datetime(df['Purchase Date'], format='%Y-%m-%d %H:%M:%S')df['Year'] = pd.to_datetime(df['Purchase Date']).dt.yeardf['Month'] = pd.to_datetime(df['Purchase Date']).dt.monthdf['Hour'] = pd.to_datetime(df['Purchase Date']).dt.hourdf[\"Weekday\"] = df[\"Purchase Date\"].dt.day_name()subplot 시각화import matplotlibimport matplotlib.pyplot as pltmatplotlib.rcParams['font.family'] = 'NanumGothic'matplotlib.rcParams['axes.unicode_minus'] = Falsefig, ax = plt.subplots(4,2, figsize=(13,19))# 성별gender = df['Gender'].value_counts()ax[0][0].pie(gender, labels=gender.index, autopct='%.1f%%', startangle=90)ax[0][0].set_title('성별')# 연령대age_order = [\"10대\", \"20대\", \"30대\", \"40대\", \"50대\",\"60대\", \"70대\"]df[\"Age_Group\"] = pd.Categorical(df[\"Age_Group\"], categories=age_order, ordered=True)age_counts = df[\"Age_Group\"].value_counts().sort_index() # value_counts() : 고유한 값의 등장 횟수 ax[0][1].bar(age_counts.index, age_counts.values, color='skyblue', edgecolor='black')ax[0][1].set_title('연령대')ax[0][1].set_ylabel('Count')for idx, val in age_counts.items() : # (index, value) 형태 ax[0][1].text(idx, (val*1.01), str(val), ha='center') # x좌표, y좌표, 문자열 # 반품returns = df['Returns'].value_counts()ax[1][0].pie(returns, labels=returns.index, autopct='%.1f%%', startangle=90)ax[1][0].set_title(\"반품\")# 이탈churn = df['Churn'].value_counts()ax[1][1].pie(churn, labels=churn.index, autopct='%.1f%%', startangle=90)ax[1][1].set_title('이탈')# 제품category = df['Product Category'].value_counts()ax[2][0].bar(category.index, category.values, color='skyblue', edgecolor='black')ax[2][0].set_title('제품')# 날짜year_category = df['Year'].value_counts().sort_index()ax[2][1].bar(year_category.index, year_category.values, color='skyblue', edgecolor='black')ax[2][1].set_xticks(year_category.index) # x축 눈금을 연도별로 설정ax[2][1].set_xticklabels(year_category.index.astype(str)) # 소수점 없이 정수 연도로 표시ax[2][1].set_title('Year')month_category = df['Month'].value_counts()ax[3][0].bar(month_category.index, month_category.values, color='skyblue', edgecolor='black')ax[3][0].set_title('Month')hour_category = df['Hour'].value_counts()ax[3][1].bar(hour_category.index, hour_category.values, color='skyblue', edgecolor='black')ax[3][1].set_title('Hour') 성별 : 남녀의 비율은 거의 비슷하게 분포 연령대 : 20대~60대는 고르게 분포되었으며 10대와 70대는 상대적으로 적은 비율을 차지 반품율 : 전체 구매 중 반품 비율은 50.1%로 절반 수준 이탈 고객 : 전체 고객 중 20.1%가 이탈한 것으로 나타남 제품별 구매 비율 : 전체적으로 제품이 고르게 판매됨 연도별 구매: 2020~2022년까지는 구매가 많았으나 2023년에는 구매가 감소했다. 월별 구매: 1 ~ 8월에 구매율이 높고 9 ~ 12월에는 상대적으로 낮음 시간대별 구매 분포: 전체적으로 고른 분포를 보이고 있음연령대별연령대별 평균 구매 금액import seaborn as snsimport matplotlib.pyplot as pltimport numpy as npfig, ax = plt.subplots(figsize=(8, 5))total_purchase = df.groupby(\"Age_Group\")[\"Total Purchase Amount\"].mean().round(1)sns.barplot(x=total_purchase.index, y=total_purchase.values)for idx, val in total_purchase.items() : # (index, value) 형태 ax.text(idx, val + 30, str(val), ha='center')plt.title(\"연령대별 평균 구매 금액\")plt.show()연령대가 높을수록 평균 구매 금액이 증가하는 형태를 보인다.연령대, 총 구매 금액import plotly.express as pxco_matrix = df[['Total Purchase Amount', 'Customer Age']].corr().round(2)px.imshow(co_matrix, text_auto=True)연령대와 총 구매 가격의 상관계수는 0.06으로 서로 관련이 없다는 것을 보여준다.날짜별요일 별 구매 빈도plt.figure(figsize=(8, 5))sns.countplot(x=\"Weekday\", data=df, order=[\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"])plt.title(\"요일별 구매 건수\")plt.show()요일별 차이가 거의 없다.log로 변환해서 요일 별 차이를 크게 나타냈다.plt.figure(figsize=(8, 5))sns.countplot(x=\"Weekday\", data=df, order=[\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"])plt.title(\"요일별 구매 건수\")plt.yscale('log')plt.show()수, 목, 토요일 순으로 구매 건수가 높고 일요일이 가장 낮다.월별 카테고리 판매량month_product = df.groupby([\"Month\", \"Product Category\"])[\"Quantity\"].sum().unstack()# 히트맵 시각화plt.figure(figsize=(10, 6))sns.heatmap(month_product, cmap=\"Blues\", annot=True, fmt=\".0f\") # 데이터 값 표시 : annot=True plt.title(\"월별 제품 카테고리 판매량\")plt.xlabel(\"제품 카테고리\")plt.ylabel(\"월\")plt.show()이전에 살펴본 월별 구매 그래프와 같이 1 ~ 8월에는 전체적으로 판매량이 높지만9 ~ 12월에는 판매량이 제품과 상관없이 저조해지는 것을 볼 수 있다.반품반품 데이터'''만약 Nan이 존재하는 컬럼이라면 notna()를 사용하여 필터링df_returns = df[df[\"Returns\"].notna()] 와 같이 작성해서 data에 넣어준다.'''g = sns.FacetGrid(df, col=\"Returns\", height=5, aspect=1, hue=\"Churn\")g.map_dataframe(sns.histplot, x=\"Age_Group\", alpha=0.5)g.add_legend()plt.show()반품(Returns) 여부에 따른 연령대 분포를 보여주며 이탈(Churn) 여부를 색상으로 구분했다.연령대별 고객 분포가 유사하게 나타났으며반품을 한 경우에도 비슷한 연령대 분포가 유지됨을 확인할 수 있다.연령대별 반품 고객의 이탈 여부를 비교하여 특정 연령대에서 이탈이 더 높은지 확인하기 위해 추가 분석했다.연령대별 반품 고객의 이탈 비율df_returns = df[df[\"Returns\"] == 1] # 반품한 고객만 선택churn_rates = df_returns.groupby(\"Age_Group\")[\"Churn\"].mean() # 연령대별 이탈 비율 계산plt.figure(figsize=(10, 5))sns.barplot(x=churn_rates.index, y=churn_rates.values)plt.title(\"연령대별 반품 고객의 이탈 비율\")plt.xlabel(\"Age Group\")plt.ylabel(\"Churn Rate\")plt.ylim(0, 1) # Churn의 데이터가 0과 1로만 이루어져있으므로 plt.show()이를 표로 보면 아래와 같다.반품 경험이 있는 고객의 경우 연령대와 관계없이 일정 수준의 이탈 비율을 보이는 경향이 있다.제품 카테고리 별제품 카테고리 별 반품 비율# 반품 비율이 높은 제품 카테고리 분석return_rates = df.groupby(\"Product Category\")[\"Returns\"].mean().sort_values(ascending=False)plt.figure(figsize=(10, 5))sns.barplot(x=return_rates.index, y=return_rates.values)plt.title(\"제품 카테고리별 반품 비율\")plt.xticks(rotation=45)plt.ylim(0, 1)plt.show()모든 제품의 반품 비율이 비슷하게 나와서 차이를 파악하기 힘들다.고객 별고객 별 구매 개수customer_purchase = df.groupby(\"Customer ID\")[\"Purchase Date\"].count().sort_values(ascending=True)plt.hist(customer_purchase, edgecolor='black') 고객의 구매 횟수를 분석한 결과대부분의 고객이 1~6회 구매에 몰려 있으며 7회 이상 구매하는 고객은 상대적으로 적다이탈이탈 고객 분석fig = make_subplots(rows=1, cols=3, subplot_titles=[\"연령대\", \"성별\", \"구매 횟수\"])# 이탈 고객 (Churn=1)fig.add_trace(go.Bar(x=df[df[\"Churn\"] == 1][\"Age_Group\"].value_counts().index, y=df[df[\"Churn\"] == 1][\"Age_Group\"].value_counts().values, name=\"이탈 고객 연령대\"), row=1, col=1)fig.add_trace(go.Bar(x=df[df[\"Churn\"] == 1][\"Gender\"].value_counts().index, y=df[df[\"Churn\"] == 1][\"Gender\"].value_counts().values, name=\"이탈 고객 성별\"), row=1, col=2)fig.add_trace(go.Bar(x=df[df[\"Churn\"] == 1][\"Quantity\"].value_counts().index, y=df[df[\"Churn\"] == 1][\"Quantity\"].value_counts().values, name=\"이탈 고객 구매 횟수\"), row=1, col=3)fig.update_layout(title_text=\"이탈 고객 분석\")fig.show()이탈 고객 분석을 연령대, 성별, 구매 횟수에 따라 구분을 하였다.기존 연령대 분포, 성별, 구매횟수의 분포와 비슷한 형태를 띈다." }, { "title": "상호작용과 성과 분석", "url": "/posts/%EC%83%81%ED%98%B8%EC%9E%91%EC%9A%A9%EA%B3%BC-%EC%84%B1%EA%B3%BC-%EB%B6%84%EC%84%9D/", "categories": "Eng-Project, Analysis", "tags": "log, Python, Analysis", "date": "2025-02-20 00:00:00 +0900", "snippet": "문제 정의사용자들의 학습성과를 높이려면?기능 구현을 하면서 사용자들의 학습 성과를 높이려면 어떤 요소가 중요한지 고민하며 분석을 진행했다.데이터는 Kaggle의 ONLINE EDUCATION SYSTEM REVIEW 데이터를 사용했으며실제 프로젝트 데이터는 양이 적어 편향된 결과를 가져올 수 있어 제외했다.데이터 전처리import pandas as pddata = pd.read_csv('../kaggle/ONLINE EDUCATION SYSTEM REVIEW.csv')data.head()data.shape # 1033개의 행, 23개의 열결측치 확인print(data.isnull().sum()) 결측치 없음범주형 개수 확인data.info()data.nunique()data['Gender'].nunique() # 2data['Home Location'].nunique() # 2data['Level of Education'].nunique() # 3data['Device type used to attend classes'].nunique() # 3data['Economic status'].nunique() # 3data['Are you involved in any sports?'].nunique() # 2data['Do elderly people monitor you?'].nunique() # 2data['Interested in Gaming?'].nunique() # 2data['Have separate room for studying?'].nunique() # 2data['Engaged in group studies?'].nunique() # 2data['Average marks scored before pandemic in traditional classroom'].nunique() # 10data['Interested in?'].nunique() # 3data['Your level of satisfaction in Online Education'].nunique() # 3이상치 확인data.describe()계산 가능한 데이터들 가운데 평균과 중앙값(50%)의 차이가 크지 않은것으로 보아특이점이나 이상치가 크지 않은 것으로 보인다.상관 분석import plotly.express as pxcorr_matrix = data._get_numeric_data().corr().round(2)px.imshow(corr_matrix, text_auto=True, width=930, height=930)Your interaction in online mode와 Performance in online의 상관계수 : 0.56Your interaction in online mode와 Clearing doubts with faculties in online mode의 상관계수 : 0.72상호작용이 많을수록 학습 성과가 높을 가능성이 있다.가설 설정상호작용이 많을수록 학습성과가 높을 것이다.데이터 확인data['Performance in online'].describe()data['Your interaction in online mode'].describe()데이터 시각화 및 분석산점도import plotly.express as pxfig = px.scatter(x='Your interaction in online mode', y='Performance in online', data_frame=data, trendline=\"ols\") # 추세선 추가fig.show()산점도에서 선형성이 보이지 않고 격자 형태로 띄워져 boxplot으로 분석을 진행했다.Boxplotimport plotly.express as pxfig = px.box(data, x=\"Your interaction in online mode\", y=\"Performance in online\", points=\"outliers\")fig.show()3과 4에서 이상치가 발견되었다.x=1에서 중앙값이 50%에서 살짝 위에 형성되었다.x=4, 5에서 중앙값이 Q3(상위 75%)와 같은 수준으로 높게 나타났다.→ 상호작용이 많을수록 성과 상승 가능성 증가그래프에서 이상치가 존재하여 IQR을 통해 Performance in online의 이상치 개수가 37개로 나왔으나describe()를 통해 mean과 50% 데이터의 차이가 크지 않으며min과 max 모두 정상범주에 있어 이상치를 제거하지 않고 실행했다.카이제곱qcut()을 활용했으며 몇개의 범주로 나눠야 하는지 체크했다.히스토그램sns.histplot(data[\"Performance in online\"]) plt.show()sns.histplot(data[\"Your interaction in online mode\"], discrete=True)plt.show() 2~3 : 낮은 분포 6~8: 높은 분포 (집중됨) 4 ~ 5, 9 ~ 10: 중간 정도의 분포 3에 데이터가 가장 많고 나머지는 비슷한 수준구간 개수 설정하기import pandas as pdimport numpy as npfrom scipy.stats import chi2_contingency, kruskalimport matplotlibmatplotlib.rcParams['font.family'] = 'Malgun Gothic' # Windowsmatplotlib.rcParams['axes.unicode_minus'] = Falsefor q in [2, 3, 4, 5]: print(f\"\\n=== 개수: {q} ===\") x_cut = pd.qcut(data[\"Your interaction in online mode\"], q=q, duplicates='drop') y_cut = pd.qcut(data[\"Performance in online\"], q=q, duplicates='drop') print(f\"x 개수 : {len(x_cut.cat.categories)}\") print(f\"y 개수 : {len(y_cut.cat.categories)}\") # qcut data[\"X_cut\"] = pd.qcut(data[\"Your interaction in online mode\"], q=len(x_cut.cat.categories), duplicates='drop') data[\"Y_cut\"] = pd.qcut(data[\"Performance in online\"], q=len(y_cut.cat.categories), duplicates='drop') # 카이제곱 검정 observed = pd.crosstab(data[\"X_cut\"], data[\"Y_cut\"]) chi2, p, dof, expected = chi2_contingency(observed) percentage = ((expected &lt; 5).sum() / expected.size) * 100 if percentage &gt;= 20: print(\"카이제곱 검정 사용 불가능\") else: print(\"카이제곱 검정 사용 가능\") if stats.chi2.ppf(0.95, dof).round(2) &lt; chi2 and p &lt; 0.05: print(\"대립가설 채택 (유의한 관계 있음)\") print(f\"카이제곱 통계량: {chi2.round(2)}, p-value: {p.round(2)}\") residuals = (observed - expected) / np.sqrt(expected) print(residuals) else: print(\"귀무가설 채택 (유의한 관계 없음)\") # 시각화 plt.figure(figsize=(8, 6)) sns.heatmap(residuals, annot=True, cmap=\"coolwarm\", fmt=\".2f\") # 값 표시 plt.title(\"잔차 (Residuals)\") plt.xlabel(\"Y_cut\") plt.ylabel(\"X_cut\") plt.show()=== 개수: 3 ===x 개수 : 2y 개수 : 3카이제곱 검정 사용 가능대립가설 채택 (유의한 관계 있음)카이제곱 통계량: 219.33, p-value: 0.0Y_cut (1.999, 6.0] (6.0, 8.0] (8.0, 10.0]X_cut (0.999, 3.0] 4.654189 -1.237490 -6.056555(3.0, 5.0] -7.595205 2.019469 9.883734=== 개수: 4 ===x 개수 : 4y 개수 : 4카이제곱 검정 사용 가능대립가설 채택 (유의한 관계 있음)카이제곱 통계량: 385.62, p-value: 0.0Y_cut (1.999, 6.0] (6.0, 7.0] (7.0, 8.0] (8.0, 10.0]X_cut (0.999, 2.0] 5.884570 -2.507761 -2.943029 -4.025926(2.0, 3.0] 1.086484 3.114782 -0.562652 -4.526174(3.0, 4.0] -5.339457 0.327358 5.401652 2.536907(4.0, 5.0] -5.614034 -2.550390 -1.044280 13.594376q=3과 q=4 모두 유의한 관계가 나타났으며x=2, y=4로 나눠도 큰 차이 없이 같은 경향이 나타나해석이 쉬운 q=3을 사용하여 “낮음, 보통, 높음”으로 구분했다.X(상호작용) → 2개, Y(성과) → 3개로 구분Categories (2, interval[float64, right]): [(0.999, 3.0] &lt; (3.0, 5.0]]Categories (3, interval[float64, right]): [(1.999, 6.0] &lt; (6.0, 8.0] &lt; (8.0, 10.0]]stackoverflowseaborn.heatmap *duplicates=’drop’ValueError: Bin edges must be unique: Index([1.0, 3.0, 3.0, 5.0], dtype='float64', name='Your interaction in online mode').You can drop duplicate edges by setting the 'duplicates' kwarg와 같이 에러가 떠서 설정*만약 x값도 3개로 범주를 설정했다면Bin labels must be one fewer than the number of bin edges라는 에러가 뜬다.범주화data[\"X_cut\"] = pd.qcut(data[\"Your interaction in online mode\"], q=2, labels=['낮음', '높음'], duplicates='drop')data[\"Y_cut\"] = pd.qcut(data[\"Performance in online\"], q=3, labels=['낮음', '보통', '높음'], duplicates='drop') 카이제곱 실행귀무가설: 두 변수는 연관성이 없다. (독립이다)대립가설: 두 변수는 연관성이 있다. (독립이 아니다)from scipy.stats import chi2_contingencyimport pandas as pd# scipy를 이용한 카이제곱 검정(카이제곱, p, 자유도, 기대치)observed = pd.crosstab(data['X_cut'], data['Y_cut'])chi2, p, dof, expected = chi2_contingency(observed)print(f\"카이제곱 통계량: {chi2}, p-value: {p}\")print(f\"자유도: {dof}\")print(f\"기대 빈도표: \\n{expected}\")import scipy.stats as statsprint(stats.chi2.ppf(0.95,2).round(2)) # 5.99카이제곱 통계량: 219.32830534852573, p-value: 2.3629995067156613e-48자유도: 2기대 빈도표: [[344.60212972 290.07647628 116.321394 ] [129.39787028 108.92352372 43.678606 ]]5미만 셀 개수가 0이므로 카이제곱 통계량을 활용할 수 있다.자유도가 2이고 유의 수준 0.05인 임계값 5.99보다 카이제곱 통계량이 219.3으로 크게 나왔으며유의수준인 0.05보다 p값이 더 작으므로 귀무가설을 기각하고 대립가설을 채택한다.→ 상호작용과 학습성과 간의 유의미한 관계 확인기여도 확인residuals = (observed - expected) / np.sqrt(expected)# 잔차 = (교차표(관측된 빈도수)) - 기대빈도수 / 제곱근(기대빈도 수)print(residuals)#print(pow(residuals,2)) # 기여도 강조Y_cut 낮음 보통 높음X_cut 낮음 4.654189 -1.237490 -6.056555높음 -7.595205 2.019469 9.883734상호작용이 높고 학습성과가 높은 데이터가 가장 큰 기여를 했고상호작용이 높고 학습성과가 낮은 데이터가 2번째로 높은 기여도를 보였다.ANOVA정규성 검정data[\"X_Group\"] = pd.qcut(data[\"Your interaction in online mode\"], q=2, labels=[\"Low\", \"High\"])low = data[data[\"X_Group\"] == \"Low\"][\"Performance in online\"]high = data[data[\"X_Group\"] == \"High\"][\"Performance in online\"] _, p_low = stats.shapiro(low)_, p_high = stats.shapiro(high)print(f\"p_low 정규성 검정 p-value: {p_low}\")print(f\"p_high 정규성 검정 p-value: {p_high}\")if p &gt; 0.05 : print(\"정규성 만족\")else : print(\"정규성 만족 X\")정규성 검정 결과 P값이 0.0으로 나와 귀무가설이 기각되어 정규성을 만족하지 않아비모수 검정인 Kruskal-Wallis(크루스칼 왈리스) 검정을 진행했다.Kruskal-Wallis 검정귀무가설 : 모든 그룹의 중앙값이 같다대립가설 : 모든 그룹의 중앙값이 모두 같은 것은 아니다.H, p = stats.kruskal(low, high)print(f\"Kruskal-Wallis 결과: H-statistic={H.round(2)}, p-value={p.round(2)}\")if p &lt; 0.05 : print(\"중앙값 차이 존재\")p-value=0.0으로 나와 0.05보다 작으므로 중앙값 차이가 존재한다고 볼 수 있다.사후 검정Kruskal-Wallis 검정 결과에서 유의미한 차이가 있었으므로어떤 그룹 간 차이가 존재하는지 확인을 해봤다.귀무 가설(H0) : 그룹 간에 차이가 없다. (그룹간의 평균값은 같다.)대립 가설(H1) : 그룹 간에 차이가 있다. (적어도 하나의 평균값은 다르다.)import scikit_posthocs as sp # scikit-posthocs로 설치# Dunn's test (Bonferroni 보정 적용)dunn_result = sp.posthoc_dunn([low, high], p_adjust='bonferroni')print(dunn_result.round(2)) 1 21 1.0 0.02 0.0 1.0으로 나와 p-value &lt; 0.05이므로 그룹 간 차이가 유의미하다.scikit_posthocs.posthoc_dunn결론상호작용이 많을수록 학습성과가 높아지는 것을 확인했다.특히 상호작용이 가장 높은 그룹(4, 5)의 경우 대부분 성과가 높게 나타났다.따라서 사용자의 상호작용을 높이는 다양한 기능을 제공하는 것이학습 성과를 이끄는 데 도움을 주는 요소가 될 것이다." }, { "title": "분석 방법 정리", "url": "/posts/%EB%B6%84%EC%84%9D-%EB%B0%A9%EB%B2%95-%EC%A0%95%EB%A6%AC/", "categories": "Eng-Project, Analysis", "tags": "log, Python, Analysis", "date": "2025-02-15 00:00:00 +0900", "snippet": "1. 기술 통계1.1 모수 검정 vs 비모수 검정 모수 검정: 모집단의 분포에 대한 가정을 하고 검정 예: t-검정, ANOVA, 회귀 분석 비모수 검정: 모집단의 분포를 가정하지 않고 검정 예: Mann-Whitney U Test, 카이제곱 검정 비모수 검정이 필요한 경우 데이터가 정규성을 따르지 않음 표본 크기가 작음 데이터가 서열척도 또는 명목척도 1.2 독립변수(설명변수) 유형에 따른 분석 독립변수 종속변수 사용 기법 범주형 범주형 카이제곱 검정 범주형 (2개 그룹) 연속형 t-검정 (독립표본 또는 대응표본) 범주형 (3개 이상 그룹) 연속형 ANOVA (분산분석) 연속형 연속형 회귀분석 (OLS, 다중회귀, 다항회귀) 연속형 + 범주형 연속형 공분산분석 (ANCOVA) 연속형 범주형 (이진) 로지스틱 회귀 분석 연속형 범주형 (다중) 다항 로지스틱 회귀 1.3 범주형 변수 처리 (Dummy Variable)범주형 변수를 회귀 분석에 사용하려면 가변수(Dummy Variable) 변환이 필요ex) Gender 변수를 0(Female), 1(Male)로 변환 범주가 여러 개인 경우 기준 범주를 제외하고 가변수 생성 1.4 IQR(이상치 확인)1.1.1 사분위수(Q1, Q3) Q1 (제1사분위수): 데이터의 하위 25% 위치의 값 Q3 (제3사분위수): 데이터의 상위 75% 위치의 값 1.1.2 IQR (Interquartile Range) IQR = Q3 - Q1 데이터의 중앙 50%가 흩어진 정도를 의미 1.1.3 이상치 판단 기준 Minimum = Q1 - (IQR * 1.5) Maximum = Q3 + (IQR * 1.5) Minimum보다 크거나 Maximum보다 작으면 정상 데이터로 판단할 수 있으며 이를 벗어난 데이터는 이상치로 간주1.1.4 전체 데이터에서 이상치 제거이상치를 제거하려면 quantile()을 활용하여 Q1, Q3 값을 구하고 이를 기준으로 필터링한다.q1 = data[\"변수\"].quantile(0.25)q3 = data[\"변수\"].quantile(0.75)iqr = q3 - q1lower_bound = q1 - 1.5 * iqrupper_bound = q3 + 1.5 * iqrprint(f\"이상치 범위: {lower_bound} ~ {upper_bound}\")x = len(data)# 이상치 제거: 기준 범위 내의 데이터만 선택filtered_data = data[(data[\"변수\"] &gt;= lower_bound) &amp; (data[\"변수\"] &lt;= upper_bound)]print(f\"제거된 이상치 개수: {x - len(filtered_data)}\")# 데이터 갱신data = filtered_data1.1.5 범주별 이상치 제거# 독립변수(x)에 따른 종속변수(y)의 이상치 제거for category in data[\"X\"].unique(): subset = data[data[\"X\"] == category] q1 = subset[\"Y\"].quantile(0.25) q3 = subset[\"Y\"].quantile(0.75) iqr = q3 - q1 lower_bound = q1 - 1.5 * iqr upper_bound = q3 + 1.5 * iqr # 기준을 벗어난 값(이상치) 제거 filtered_data = data[~((data[\"X\"] == category) &amp; ((data[\"Y\"] &lt; lower_bound) | (data[\"Y\"] &gt; upper_bound)))]outlier_count = len(data) - len(filtered_data)print(f\"제거된 이상치 개수: {outlier_count}\")# 데이터 갱신data = filtered_data1.2 데이터 시각화1.2.1 기본 그래프 막대 그래프 (Bar Chart) x축 : 범주형 변수 y축 : 수치형 변수 → 각 범주의 평균, 합계 등을 비교 분석 산점도 (Scatter Plot) x축 : 수치형 변수 y축 : 수치형 변수 → 두 변수 간의 상관관계 및 분포를 확인 1.2.2 boxplotBoxplot은 데이터의 중앙값, 사분위 범위, 이상치를 한눈에 확인할 수 있는 시각화 도구import matplotlib.pyplot as pltimport seaborn as snsplt.figure(figsize=(8, 6))sns.boxplot(x=\"X\", y=\"Y\", hue=\"색상 구분을 위한 추가범주\", data=data, palette=\"coolwarm\", legend=False)plt.xlabel(\"X\")plt.ylabel(\"Y\")plt.title(\"Distribution of Y by X\") plt.show()상자 밖에 표시된 점(o)은 이상치로 판단한다.1.2.3 Implotlmplot은 두 변수 간의 선형 관계를 시각적으로 확인할 수 있는 도구*컬럼명을 문자열로 직접 전달 *변수 적용시 sns.regplot() 사용import matplotlib.pyplot as pltimport seaborn as snssns.lmplot(x='X', y='Y', data=data)plt.show()ex)import matplotlib.pyplot as pltimport seaborn as sns# 1)sns.lmplot(x='Study time', y='Performance', data=data)plt.show()# 2) X = data['Study time']y = data['Performance']sns.regplot(x=X, y=y)plt.show()1.2.4 plotlyPlotly Express를 사용하면 대화형 그래프를 쉽게 생성할 수 있다.import plotly.express as pxhistogram데이터 분포가 정규분포 형태를 따르는지 확인할 수 있다.px.histogram(data, x='독립변수', y='종속변수')종 모양의 대칭적 분포인지 확인 → 정규분포의 형태scatter두 변수간의 관계를 파악하기 좋은 도구import plotly.express as pxfig = px.scatter(x='독립변수', y='종속변수', data_frame=data)fig.show()# 성별에 따른 산점도 px.scatter(data, x='독립변수', y='종속변수', facet_col='Gender')ex)import plotly.express as px# 1)X = data['Study time (Hours)']y = data['Performance in online']fig = px.scatter(x=X, y=y, trendline='ols')fig.show()# 2)fig = px.scatter(x='Study time (Hours)', y='Performance in online', data_frame=data, trendline='ols')fig.show()Matrix Heatmap변수 간의 상관관계를 한눈에 확인할 수 있다.z = data[['X', 'Y']].corr().round(2)px.imshow(z, text_auto=True, width=600, height=600) text_auto=True : Heatmap위에 텍스트 넣기2. 적합도 검정H0 : 데이터가 정규분포를 따른다.H1 : 데이터가 정규분포를 따르지 않는다.2.1 카이제곱 검정두 범주형 변수 간의 관계를 분석하며 관측 빈도와 기대 빈도의 차이가 통계적으로 유의한지 평가2.1.1 범주형 데이터 변환연속형 변수를 범주형으로 변환할 때는 pd.cut() 또는 pd.qcut()을 사용 pandas.cut : 데이터의 값 범위를 기준으로 일정한 간격으로 분할(각 구간에 속하는 데이터 개수는 다를 수 있음) pd.cut(컬럼, bins=구간 수, labels=[\"라벨1\", \"라벨2\", \"라벨3\"]) pandas.qcut : 데이터를 개수가 비슷한 그룹으로 나눔(각 구간에 속하는 데이터 개수가 비슷함) pd.qcut(컬럼, q=구간 수, labels=[\"라벨1\", \"라벨2\", \"라벨3\"]) # cut을 사용한 범주화 예시 data['Y_cut'] = pd.cut(data['Y'], bins=[60, 80, 90, 100], labels=['낮음', '중간', '높음'])data['X_cut'] = pd.cut(data['X'], bins=[50, 65, 75, 100], labels=['낮음', '중간', '높음'])# qcut을 사용한 범주화 예시 data[\"Y_cut\"] = pd.qcut(data[\"Y\"], q=3, labels=['낮음', '중간', '높음'])data[\"X_cut\"] = pd.qcut(data[\"X\"], q=3, labels=['낮음', '중간', '높음'])pandas.qcut2.1.2 카이제곱귀무가설: 두 변수는 연관성이 없다. (독립이다)대립가설: 두 변수는 연관성이 있다. (독립이 아니다)scipy를 이용한 카이제곱 검정from scipy.stats import chi2_contingencyimport pandas as pd# scipy를 이용한 카이제곱 검정(카이제곱, p, 자유도, 기대치)observed = pd.crosstab(data['변수1'], data['변수2'])chi2, p, dof, expected = chi2_contingency(observed)print(f\"카이제곱 통계량: {chi2}, p-value: {p}\") print(f\"자유도: {dof}\")print(f\"기대 빈도표: \\n{expected}\")# 기대 빈도 중 5 미만 셀 개수 확인cells = (expected &lt; 5).sum()percentage = (cells / expected.size) * 100print(f\"5 미만 셀 개수: {cells}\")print(f\"전체 셀 대비 비율: {percentage:.1f}%\") crosstab()을 사용하여 분팔표를 만듦 기대빈도가 5 미만인 셀이 전체 셀의 20% 이상이면 카이제곱 검정을 사용할 수 없다. p-value &lt; 0.05이면 귀무가설 기각 → 두 변수는 독립이 아님 (즉, 관련 있음) 임계값 확인import scipy.stats as statsprint(stats.chi2.ppf(0.95,4).round(2)) # 유의수준 95%, 자유도 4 ex) 카이제곱 검정 통계량(X²=___)이 임계값(9.49)보다 크고p-value가 0.0 (&lt; 0.05)이므로 귀무가설을 기각하고 대립가설을 채택기여도(잔차) 분석residuals = (observed - expected) / np.sqrt(expected)# 잔차 = (교차표(관측된 빈도수)) - 기대빈도수 / 제곱근(기대빈도 수) print(residuals)#print(pow(residuals,2))표준화잔차 = 원시 잔차를 기대 카운트의 제곱근으로 나눈 값각 셀의 카이제곱에 대한 기여도 = 표준화 잔차 제곱각 셀의 표준화 잔차를 계산하여 어떤 셀이 기여도가 큰지 평가# 그룹별 데이터 추출 (ex. Low, Medium, High 그룹) low = data[data['독립변수'] == 'Low']['종속변수']medium = data[data['독립변수'] == 'Medium']['종속변수']high = data[data['독립변수'] == 'High']['종속변수']2.2 정규성 검정히스토그램import seaborn as snssns.histplot(x, kde=True) # histogram과 kde를 한 그래프에 나타내기 Q-Q plotfrom scipy import statsimport matplotlib.pyplot as pltstats.probplot(x, dist=\"norm\", plot=plt);Shapiro-Wilk 검정 (n &lt; 5000)표본 수가 적을 때 (n &lt; 5000) *공식문서import scipy.stats as statsstatis_x, p_x = stats.shapiro(data[\"X\"])statis_y, p_y = stats.shapiro(data[\"Y\"])print(f\"x 정규성 검정 p-value: {p_x}\")print(f\"y 정규성 검정 p-value: {p_y}\")Kolmogorov-Smirnov 검정 (n &gt; 5000)표본 수가 많을 때 (n &gt; 5000)# kstest(독립변수, 'norm', (평균, 표준편차)) statis_x, p_x = stats.kstest(data[\"X\"], 'norm')statis_y, p_y = stats.kstest(data[\"Y\"], 'norm')print(f\"성적 정규성 검정 p-value: {p_x}\")print(f\"출석률 정규성 검정 p-value: {p_y}\")*norm : 정규분포(𝑁(𝜇,𝜎²))*데이터(변수)가 정규분포를 따르는지 검정하는 역할*기본적으로 표준 정규분포(𝑁(0,1))와 비교*모집단에서 표본을 추출한 경우 (np.mean(변수), np.std(변수)) 지정유의수준 5%에서 귀무가설이 기각된다면 정규분포가 아니므로 비모수통계를 이용해서 분석해야한다.ks_1samp : 적합도를 확인하기 위해 단일 표본 Kolmogorov-Smirnov 검정을 수행 ks_2samp : 적합도를 확인하기 위해 두 표본 Kolmogorov-Smirnov 검정을 수행 kstest : 적합도를 확인하기 위해 (단일 표본 또는 두 표본) Kolmogorov-Smirnov 검정을 수행공식문서3. 상관 분석두 변수 간의 관계를 파악하는 데 사용된다.정규성 여부에 따라 Pearson (정규 분포) / Spearman (비모수) 선택 척도에 따른 방법 선택 등간척도/비율척도 → Pearson 서열척도 → Spearman 명목척도 → 상관 분석 불가 Pandas 내장 메서드 활용data.corr() # data.corr(method='pearson')data.corr(method='kendall')data.corr(method='spearman')scipy 활용from scipy import stats# 데이터 생성X = [1, 2, 3, 4, 5] y = [50, 55, 60, 65, 70] # Pearson Correlation correlation, _ = stats.pearsonr(X, y) # _는 p-value를 무시하겠다는 의미print(f\"Pearson 상관계수: {correlation}\")# Spearman Correlationcorrelation, p_value = stats.spearmanr(X, y)print(f'스피어만 상관계수: {correlation}, p-value: {p_value}')# Kendall Tau correlation, p_value = stats.kendalltau(X, y)print(f'켄달 상관계수: {correlation}, p-value: {p_value}')3.2 Pearson 상관분석두 수치형 변수 간 선형 관계를 측정상관계수: -1(완벽한 음의 관계) ~ +1(완벽한 양의 관계)correlation = data['독립변수'].corr(data['종속변수'])print(f\"독립변수와 종속변수 간의 Pearson 상관계수: {correlation.round(2)}\") pearsonr() : 상관계수, p-value 반환 corr(): 상관계수만 반환 3.3 spearman 상관분석순위(서열) 기반 상관관계를 측정정규성 불만족, 이상치 포함 데이터에 적합from scipy import statsspearman_corr, spearman_p = stats.spearmanr(data['X'], data['Y'])print(f\"Spearman 상관계수: {spearman_corr}, p-value: {spearman_p}\")# 3개 이상vars = data[['X1', 'X2', 'Y']]spearman_corr_matrix, spearman_p_matrix = stats.spearmanr(vars) 성적과 출석률 → Pearson (연속형 데이터) 성적 순위와 출석률 순위 → Spearman (서열 기반) 4. 집단 간 평균 차이 분석t-검정, F-검정 t-검정 두 그룹 간 평균 차이 검정 독립변수가 종속변수에 유의한 영향을 미치는지 확인 F-검정 ANOVA(분산 분석)에서 그룹 간 평균 차이 검정 회귀분석에서 전체 모델이 유의한지 검정 t-검정은 개별 변수, F-검정은 전체 모형 검정 주요 검정 방법 검정 방법 설명 사용 조건 활용 예 일표본 t-검정 (One-sample t-test) 모집단 평균이 특정 값과 같은지 검정 단일 모집단 표본 특정 약물 복용 후 체온 변화 확인 대응표본 t-검정 (Paired t-test) 같은 집단에서 두 번 측정한 값 비교 같은 개체에서 측정된 두 데이터 비교 학습 전후 성적 변화 분석 독립표본 t-검정 (Independent t-test) 서로 다른 두 그룹의 평균 비교 두 그룹이 독립적이고 정규성 만족 A 그룹과 B 그룹 간 점수 비교 ANOVA (분산분석) 세 개 이상의 그룹 간 평균 비교 정규성 만족, 독립변수: 범주형, 종속변수: 연속형 A, B, C 그룹 간 평균 비교 Mann-Whitney U Test 독립표본 T-검정의 비모수 검정 정규성을 만족하지 않을 때 두 그룹 간 중앙값 차이 검정 Kruskal-Wallis Test ANOVA의 비모수 검정 정규성을 만족하지 않을 때 세 개 이상의 그룹 중앙값 차이 검정 T-test는 두 그룹 간 평균 차이를 검정할 때 사용 ANOVA는 세 개 이상의 그룹 간 평균 차이를 검정할 때 사용 일표본 T-검정 (One-sample t-test)귀무가설(H₀): 모집단 평균이 기준값(μ₀)과 같다.대립가설(H₁): 모집단 평균이 기준값(μ₀)과 다르다.from scipy import statst_stat, p_value = stats.ttest_1samp(data, popmean=75) # 모집단 평균 75와 비교print(\"T-statistic:\", t_stat)print(\"P-value:\", p_value) p-value &lt; 0.05 → 모집단 평균이 75와 같지 않다. (유의미한 차이 존재) p-value ≥ 0.05 → 모집단 평균이 75와 같다. 독립표본 T-검정 (Independent t-test)두 그룹(A, B)의 평균 차이 검정등분산성 만족 → equal_var=True등분산성 불만족 → equal_var=Falsefrom scipy import stats# 독립표본 T-검정 수행t_statistic, p_value = stats.ttest_ind(group1, group2, equal_var=True)print(\"t-statistic:\", t_statistic)print(\"p-value:\", p_value)# 유의수준 0.05에서의 검정if p_value &lt; 0.05: print(\"두 그룹 간에는 통계적으로 유의미한 차이가 있다.\")else: print(\"두 그룹 간에는 통계적으로 유의미한 차이가 없다.\")비모수 검정 (Mann-Whitney U Test)정규성을 만족하지 않을 때 사용from scipy import stats# 만-위트니 U 검정 수행u_statistic, p_value = stats.mannwhitneyu(group1, group2)print(\"U-statistic:\", u_statistic)print(\"p-value:\", p_value)# 유의수준 0.05에서의 검정if p_value &lt; 0.05: print(\"두 그룹 간에는 통계적으로 유의미한 차이가 있다.\")else: print(\"두 그룹 간에는 통계적으로 유의미한 차이가 없다.\") p-value &lt; 0.05 → 두 그룹 간 중앙값 차이 존재 p-value ≥ 0.05 → 중앙값 차이 없음 ANOVA 분석세 개 이상의 그룹 간 평균 비교 정규성 만족 → ANOVA 진행 정규성 불만족 → Kruskal-Wallis 검정 H₀(귀무가설): 모든 독립변수는 Y에 영향을 주지 않음 H₁(대립가설): 적어도 하나의 독립변수는 Y에 영향을 줌 low = data[data['독립변수'] == 'Low']['종속변수']medium = data[data['독립변수'] == 'Medium']['종속변수']high = data[data['독립변수'] == 'High']['종속변수']1. 정규성 검정 (Shapiro-Wilk or Kolmogorov-Smirnov)from scipy import statsstat, p = stats.shapiro(data['종속변수'])print(f\"정규성 검정 결과: p-value = {p}\") p-value &gt; 0.05 → 정규성 만족 → ANOVA 진행 p-value &lt; 0.05 → 정규성 불만족 → 비모수 검정(ex. Kruskal-Wallis) 적용 2. 등분산성 검정 (Levene, Bartlett) 귀무가설(H₀): 그룹 간 분산이 같다.(등분산이다.) 대립가설(H₁): 그룹 간 분산이 다르다.(이분산이다.) ## 방법 1stat, p = stats.levene(low, medium, high) # Levene Test# stat, p = stats.bartlett(low, medium, high)print(f\"등분산성 검정 결과: p-value = {p}\")## 방법 2import pingouin as pgpg.homoscedasticity(dv='종속변수', group='독립변수', data='데이터프레임')등분산 불만족(p-value ≤ 0.05) → Welch’s ANOVA 적용levene, bartlett“분산이 같다”는 것그룹 간 분산이 같다는 것은 그룹 내 데이터의 변동성이 유사하다는 의미다.분산이 다르면 ANOVA 결과가 왜곡될 가능성이 있음 p &gt; 0.05 → 등분산성 만족 → ANOVA 진행 p ≤ 0.05 → Welch’s ANOVA 진행 3. ANOVA 데이터가 특정 분포(정규분포 등)를 따른다고 가정하지 않는 검정 방법. Kruskal-Wallis 검정은 정규분포 가정을 하지 않기 때문에 비모수 검정에 해당(정규성을 만족하지 않는 데이터에서도 사용할 수 있음) 3-1. ANOVA 정규성 &amp; 등분산 만족 → ANOVA 정규성 만족 &amp; 등분산 불만족 → Welch’s ANOVA 정규성 불만족 → Kruskal-Wallis 일원분산분석 (One-way ANOVA, 독립변수 1개) 방법 설명 anova_lm(ols(\"종속변수 ~ C(독립변수)\", data=df).fit(), typ=2) 통계 모델 기반 분석 f_oneway(그룹1, 그룹2, 그룹3) 리스트 형태 입력 방식 pg.anova(dv='종속변수', between='독립변수', data) DataFrame 활용 분석 이원분산분석 (Two-way ANOVA, 독립변수 2개) 방법 설명 anova_lm(ols(\"종속변수 ~ C(독립변수1) + C(독립변수2)\", data=df).fit(), typ=2) 이원분산분석 가능 pg.anova(dv, between=['독립변수1', '독립변수2'], data=데이터) DataFrame 기반 이원분산분석 ANOVA 실행# 방법 1)from scipy.stats import f_onewayanova_result = f_oneway(low, medium, high)print(f\"ANOVA 결과: F-statistic={anova_result.statistic}, p-value={anova_result.pvalue}\")if anova_result.pvalue &lt; 0.05 : print(\"그룹 간 평균 차이가 유의미하다.\")# 방법 2)import pingouin as pgpg.anova(dv='종속변수', between='독립변수', data='데이터프레임', detailed=True)p-value &lt; 0.05 → 그룹 간 평균 차이가 유의미statsmodels를 활용한 ANOVA 분석 (anova_lm)from statsmodels.formula.api import olsimport statsmodels.api as smdf = data[['독립변수', '종속변수']]## ols(\"종속변수 ~ C(독립변수)\", data=df).fit()model = ols(\"Attendance ~ C(Motivation_Level)\", data=df).fit() # y ~ x는 y=ax+banova_results = sm.stats.anova_lm(model, typ=2)print(anova_results)*C(독립변수): 범주형 변수 처리*독립변수가 연속형 → typ=2, 범주형 → typ=3ANOVA3-2. Welch’s ANOVA (등분산성 불만족 시 사용)import pingouin as pgpg.welch_anova(dv='종속변수', between='독립변수', data='데이터프레임')3-3. Kruskal-Wallis (비모수 검정) 분산분석에서 정규성을 만족하지 않을 때 사용하는 비모수 검정법 셋 이상의 그룹 간 차이를 비교할 때 사용 모수 검정(ANOVA)은 평균을 비교하지만 Kruskal-Wallis 검정은 중앙값을 비교 귀무가설 : 모든 그룹의 중앙값은 같다대립가설 : 모든 그룹의 중앙값이 모두 같은 것은 아니다.(적어도 하나의 그룹의 중앙값이 다르다)# Kruskal-Wallis 검정H, p = stats.kruskal(low, medium, high)print(f\"Kruskal-Wallis 결과: H-statistic={H}, p-value={p}\")p &lt; 0.05 → 그룹 간 중앙값 차이 존재Kruskal-Wallis 검정은 그룹 간 차이가 존재하는지만 확인 가능하다.→ 어떤 그룹이 다른지는 알 수 없으므로 사후검정을 통해 어떤 그룹이 차이가 있는지 분석한다.4. 사후검정 (Post-hoc test)ANOVA나 Kruskal-Wallis 검정에서 유의미한 차이가 있으면 어떤 그룹 간 차이가 존재하는지 확인하는 과정그룹 간 차이를 확인하기 위해 모든 그룹 조합에 대해 유의한 차이 여부를 검정ex) 5개 그룹이 있을 경우 nC2 : 5C2 → 10번 비교문제점검정을 여러 번 수행하면 1종 오류(실제값은 False인데 True로 나올 확률)가 커지는 문제가 발생한다.이를 위해 여러 사후 검정 방법들이 존재한다.ex) Bonferroni유의수준(α = 0.05)을 비교 횟수(nC2)로 나눠서 조정ex) 5개 그룹 → 10번 비교 → 0.05 / 10 = 0.005p값이 0.005보다 작아야 유의미한 차이라고 판단귀무 가설(H0) : 그룹 간에 차이가 없다. (그룹간의 평균값은 같다.)대립 가설(H1) : 그룹 간에 차이가 있다. (적어도 하나의 평균값은 다르다.) 사후검정 방법 설명   Tukey HSD 모든 그룹 쌍 간 차이 비교 집단별 표본의 수와 분산이 동일해야함 Bonferroni 유의수준을 1/N(검사한 개수) 낮춰 검정 집단별로 표본의 수는 다르지만 분산이 동일한 경우 Dunn’s Test 비모수 검정용 사후검정 데이터의 순위를 기반으로 세 그룹 이상의 집단에서 효과적 Tukey HSD (Honestly Significant Difference) 검정# Tukey 라이브러리 가져오기from statsmodels.stats.multicomp import pairwise_tukeyhsd# endog = 종속변수, groups = 독립변수tukey_result = pairwise_tukeyhsd(endog=data['종속변수'], groups=data['독립변수'], alpha=0.05) # Significance level(유의수준)print(tukey_result)reject 값이 False이면 두 그룹 간 차이가 없다는 의미(True 일 경우 차이가 있다는 의미)Dunn’s test : 비모수 검정용 사후검정import scikit_posthocs as sp # scikit-posthocs로 설치# Dunn's test (Bonferroni 보정 적용)dunn_result = sp.posthoc_dunn([low, medium, high], p_adjust='bonferroni')print(dunn_result)p-value &lt; 0.05 → 그룹 간 유의미한 차이보정 방법(p_adjust)으로 bonferroni, holm, fdr_bh 등을 사용할 수 있다.이상치 boxplotplot_data = [low, medium, high]ax = plt.boxplot(plot_data)plt.show()5. 회귀 분석독립 변수(X)가 종속 변수(Y)에 미치는 영향 분석OLS(Ordinary Least Squares)는 최소제곱법(Least Squares Method)을 기반으로 한 회귀 분석 방법기본 가정(선형성, 정규성, 등분산성, 독립성 등) 검토 필요 분석 종류 사용 함수 목적 회귀 분석 (OLS) smf.ols().fit() 독립 변수(X)가 종속 변수(Y)에 미치는 영향 평가 분산 분석 (ANOVA) anova_lm(smf.ols().fit()) 그룹 간 차이 분석 (범주형 변수의 영향 검정) from statsmodels.formula.api import olsfrom statsmodels.stats.anova import anova_lm# 회귀 분석model = ols(\"종속변수 ~ C(독립변수)\", data=data).fit() print(model.summary()) # 회귀 분석 결과# ANOVA 분석anova_results = anova_lm(model)print(anova_results) # ANOVA 결과5.1 회귀 분석 기본 개념잔차의 평균은 0 잔차와 독립 변수는 상관관계가 없음(0이다.) 구분 의미   단순 회귀 (Simple Linear Regression) 독립변수(X) 1개, 종속변수(Y) 1개 독립변수 1개와 종속변수 1개 사이의 관계 다중 회귀 (Multiple Linear Regression) 독립변수(X) 2개 이상, 종속변수(Y) 1개 여러 독립변수가 종속변수에 미치는 영향 평가 선형 회귀 (Linear Regression) X가 증가할 때 Y가 일정한 비율로 증가하는 관계 독립변수 변화에 따라 종속변수가 일정 비율로 변화 비선형 회귀 (Nonlinear Regression) X와 Y의 관계가 곡선 형태로 변화 독립변수와 종속변수 간의 관계가 곡선 형태일 때 적용 (예: 다항 회귀) 단순 또는 다중 선형 회귀는 독립변수와 종속변수 간의 선형 관계를 가정한다.만약 선형 가정이 위배된다면 다항 회귀(Polynomial Regression) 등을 통해 비선형 관계를 모델링할 수 있다.5.2 회귀 모형의 가정 확인 선형성: 독립 변수와 종속 변수의 관계가 선형인지 확인 잔차 plot : 잔차가 무작위로 분포하면 선형성 가정 충족 특정한 패턴(예, 음의 선형 패턴 또는 곡선 형태)이 보이면 비선형 요소 존재 정규성: 잔차가 정규 분포를 따르는지 확인 Q-Q Plot: 대부분의 점이 직선에 가까워야 정규성을 만족 큰 이상치가 존재하면 정규성 위배 등분산성: 잔차의 분산이 일정한지 확인 독립성: 잔차 간의 상관관계가 없어야 함5.3 회귀 분석 (formula vs OLS)Ho(귀무가설) : 회귀식이 유용하지 않다. ( β1=0 )H1(대립가설) : 회귀식이 유용하다. ( β1≠0 )산점도자료가 회귀분석에 적합한지를 보기 위해 x와 y의 산점도를 그려본다.*다중회귀는 잔차분석을 통해 확인import plotly.express as pxfig = px.scatter(x='Exam_Score', y='Attendance', data_frame=data, trendline=\"ols\") # 추세선 추가fig.show()ex) 대부분 관계가 직선인 것을 보아 x와 y는 양의 선형관계를 갖고 있음을 알 수 있다.Y = β0 + β1X + e5.3.1 OLS() 방식을 이용한 회귀 분석*pd.get_dummies()를 사용하여 범주형 변수를 변환import statsmodels.api as smX = data[['독립변수1', '독립변수2', '독립변수3', '독립변수4']] # 수치형 y = data['종속변수']X = pd.get_dummies(X, columns=['Gender'], drop_first=True)'''X = pd.get_dummies(X, columns=['Gender'], drop_first = True)첫번째 열을 자동으로 삭제해서 다중공선성을 피함Male이 1이면 Female은 자동으로 0이되는 더미변수 생성'''X = sm.add_constant(X) # 절편 추가model = sm.OLS(y, X).fit() # 다중 회귀 분석 실행print(model.summary()) # 결과 출력 coef (계수) : 기울기와 절편(상수항) R-squared: 결정계수(설명력) P&gt;|t| : p-값 (0.05 미만이면 유의미) F-statistic : 전체 모델의 유의성을 검정하는 F-통계량. Prob(F-statistic) : 모델 전체의 p-값회귀선 그리기import matplotlibimport matplotlib.pyplot as pltimport statsmodels.api as smmatplotlib.rcParams['font.family'] = 'Malgun Gothic' # Windowsdata_X = data['X'] y = data['Y']X = sm.add_constant(data_X) # 절편 추가model = sm.OLS(y, X).fit()# 원본 데이터 플로팅plt.scatter(data_X, y, label='Data')# 회귀선 플로팅plt.plot(data_X, model.predict(X), color='red', label='Fitted line')plt.legend()plt.xlabel('x')plt.ylabel('y')plt.title('Linear Regression with statsmodels')plt.show()5.3.2 formula 방식을 이용한 회귀 분석*범주형 변수는 C()를 사용하여 자동으로 더미 변수로 변환import statsmodels.formula.api as smfformula = \"Y ~ X1 + X2 + C(범주형 변수)\"model = smf.ols(formula, data=data).fit()# 결과 출력print(model.summary())*수정된 결정계수 확인특수문자나 공백이 포함된 변수명 허용하기변수 명 중에 ‘?’이나 공백이 들어간 변수명이 있어서 SyntaxError: invalid syntax 오류가 생겼다.Q()를 사용해 동작하면 된다.from statsmodels.formula.api import olsformula = \"Q('Clearing doubts with faculties in online mode') ~ Q('Your interaction in online mode')\" model = ols(formula, data=data).fit()print(model.summary())patsy.builtins.Q(name)stackoverflowpredictmodel.predict(pd.DataFrame({\"독립변수명\": [예측하고 싶은 x값]}))model.predict(pd.DataFrame({ \"독립변수1\": [예측할 X 값], \"독립변수2\": [예측할 X 값] }))예시)model.predict(pd.DataFrame({\"x\": [1]}))X가 1일 때, Y의 예측 값은 1.363917결과 분석하기 검정 사용 목적 해석 결정계수(R²) 모델의 설명력 확인 값이 클수록 좋은 모델 F-검정 전체 회귀 모형 유의성 검정 p-value &lt; 0.05 → 모델 유의 t-검정 개별 회귀 계수 유의성 검정 p-value &lt; 0.05 → 해당 변수 유의 잔차 분석 모델 가정 충족 여부 검토 정규성, 등분산성, 독립성 확인 (1) 결정계수(R²) 및 수정된 결정계수(Adj. R²) 결정계수(R²): 회귀 모델이 종속변수의 변동을 얼마나 설명하는지 나타냄. (0~1 사이 값) 독립변수 개수가 많아지면 R²값이 증가하는 경향이 있다. 독립변수의 개수와 표본 크기 고려 → 수정된 결정계수(Adj. R²) Adj. R²이 높을수록 좋은 모델 → __% 설명력을 가지고 있다.(2) F-검정 F-statistic : 회귀 모델 전체의 유의성을 검정하는 통계량 Prob (F-statistic) : F-검정의 p-value (0.05 미만이면 유의미한 모델) p-value &lt; 0.05 → 회귀식이 유용함 p-value ≥ 0.05 → 회귀식이 유용하지 않음 구분 사용 목적 해석 t-검정 개별 회귀 계수가 유의한지 검정 p-value &lt; 0.05 → 해당 변수가 유의함 F-검정 전체 회귀 모형이 유의한지 검정 p-value &lt; 0.05 → 회귀 모델이 유의함 (3) 개별 회귀 계수 검정 (t-검정) P&gt;|t| 값 확인 : 회귀계수가 유의한지 검정 p-value &lt; 0.05 → 해당 독립변수가 종속변수에 유의한 영향을 미침 p-value ≥ 0.05 → 해당 독립변수는 유의하지 않음 (4) 회귀 계수 (coef) 해석 Y = β0 + β1X1 + β2X2 + … coef 값이 클수록 종속변수(Y)에 미치는 영향력이 큼 표준 오차(std err): 해당 회귀 계수의 신뢰성을 나타내며 값이 작을수록 신뢰도가 높다. → 표준오차가 작으면 참값(모집단의 평균)에 더 가깝다model.params 으로도 회귀 계수(절편과 기울기 출력 가능)(5) 잔차 분석 및 정규성 검정 잔차의 정규성 검정 Omnibus 검정(Prob(Omnibus)), Jarque-Bera((Prob(JB))) 검정 확인 p-value &lt; 0.05 → 잔차가 정규성을 따르지 않음 p-value ≥ 0.05 → 잔차가 정규성을 따름 Durbin-Watson(DW) 검정 (잔차의 독립성 검정) 1.5 ~ 2.5 사이이면 독립성이 있다고 판단 → 회귀모형 적합 0에 가까울 수록 양의 상관관계, 4에 가까울수록 음의 상관관계 (6) 다중공선성 확인 VIF : 독립변수들 간에 강한 상관관계가 존재할 때 발생하는 문제를 평가하는 지표 VIF &lt; 10 → 다중공선성 문제 없음 VIF ≥ 10 → 다중공선성 문제 있음 (변수 제거 고려) 조건수(Condition Number) : 행렬의 수치적 안정성을 나타내는 값 Cond. No &gt; 30 → 다중공선성 문제 가능성 높음(단순회귀에서는 조건수를 신경쓰지 않아도 된다.) from numpy.linalg import condimport statsmodels.api as smX = data[['독립변수1', '독립변수2']]X_with_const = sm.add_constant(X) # 조건수 계산condition_number = cond(X_with_const)print(f\"Condition Number: {condition_number}\")# 다항회귀 조건수 계산 from sklearn.preprocessing import PolynomialFeaturesfrom numpy.linalg import condimport statsmodels.api as smpoly = PolynomialFeatures(degree=2, include_bias=False)X_poly = poly.fit_transform(data[['독립변수1', '독립변수2']])X_poly_with_const = sm.add_constant(X_poly)condition_number = cond(X_poly_with_const)print(f\"Condition Number: {condition_number}\")(7) 잔차 독립성 및 등분산성 검정 Breusch-Godfrey 검정 (잔차 독립성 검토) p-value &lt; 0.05 → 잔차 간 자기상관 존재 (독립성 위배) p-value ≥ 0.05 → 자기상관 없음 (독립성 충족) Breusch-Pagan 검정 (잔차 등분산성 검정) p-value &lt; 0.05 → 등분산성이 없음 (이분산성 존재) p-value ≥ 0.05 → 등분산성이 있음 (회귀 모델 적합) (8) 이상치 탐색 (Cook’s Distance, Leverage) Cook’s Distance 값이 크면 영향력이 큰 이상치일 가능성이 높음 Leverage 값이 크면 특정 데이터가 모델에 과도한 영향을 미칠 가능성이 있음5.4 다항 회귀 (Polynomial Regression)독립변수와 종속변수 관계가 비선형일 때 사용*독립변수가 1개일 수도 있음from sklearn.preprocessing import PolynomialFeaturesimport statsmodels.api as smpoly = PolynomialFeatures(degree=2, include_bias=False) # 2차항 생성 X_poly = poly.fit_transform(data[['X1', 'X2']])y = data['Y']model = sm.OLS(y, sm.add_constant(X_poly)).fit()print(model.summary())*수정된 결정계수 확인5.5 다중공선성 (Variance Inflation Factor : VIF)다중공선성과 조건수는 독립변수가 하나일 때는 의미가 없으므로 2개 이상일 때만 확인하면 된다.다중공선성이란 독립변수들 간의 높은 상관관계로 인해 너무 비슷한 정보가 포함되어회귀계수가 불안정해지는 문제를 말한다.독립변수 간의 상관관계로 인해 회귀 분석이 왜곡되는지 확인*종속변수(Y)와의 관계가 아니라, X끼리의 관계를 분석해야 함from statsmodels.stats.outliers_influence import variance_inflation_factorX = data[['X1', 'X2']]# 상수항 추가X = sm.add_constant(X)vif_data = pd.DataFrame()vif_data[\"Variable\"] = X.columnsvif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]print(vif_data)한 변수를 다른 변수로 예측할 수 있을수록 VIF 값이 커진다. VIF &lt; 10 → 다중공선성 문제 없음 VIF ≥ 10 → 다중공선성 문제 있음 (변수 제거 고려)5.6 잔차잔차 독립성 및 등분산성 검정잔차 독립성 (Breusch-Godfrey)DW에 이어 추가적으로 자기상관 검토 가능 *자기상관이 있다 = 잔차(오차)가 특정 패턴을 보이며 독립적이지 않다from statsmodels.stats.diagnostic import acorr_breusch_godfreylm_test = acorr_breusch_godfrey(model, nlags=1)print(lm_test) p-value &lt; 0.05 → 잔차 간 자기상관이 존재 (독립성 위배) p-value ≥ 0.05 → 잔차 간 자기상관 없음 (독립성 만족) statsmodels.stats.diagnostic.acorr_breusch_godfrey잔차의 등분산성 검정 (Breusch-Pagan Test)*샘플수가 많아야 함, 오차항은 독립이고 정규분포를 따라야 한다., 오차의 분산은 설명변수(x)와 연관이 있어야 한다.from statsmodels.stats.diagnostic import het_breuschpaganbp_test = het_breuschpagan(residuals, model.model.exog) # 잔차, exog_hetprint(bp_test) p-value &lt; 0.05 → 등분산성이 없음 (이분산성 존재) p-value ≥ 0.05 → 등분산성이 있음 (등분산성 가정 충족)het_breuschpagan이상치 탐색 표준화 잔차 및 영향 점수 (Leverage, Cook’s Distance) 확인import numpy as np# 영향력 분석influence = model.get_influence()# Cook’s Distance (값이 크면 영향력이 큰 이상치 가능성 높음)cooks_d = influence.cooks_distance[0] # (거리 값, p-value) # Leverage (값이 크면 특정 데이터가 모델에 과도한 영향 가능성) leverage = influence.hat_matrix_diagprint(\"Cook’s Distance:\", np.max(cooks_d))print(\"Leverage:\", np.max(leverage))그래프import statsmodels.api as smimport matplotlib.pyplot as pltimport scipy.stats as stats# 1. 다중 회귀X = sm.add_constant(filtered_data[['독립변수1', '독립변수2']])y = filtered_data['종속변수']model = sm.OLS(y, X).fit()residuals = model.resid # 잔차# 2. 다항 회귀poly = PolynomialFeatures(degree=2, include_bias=False)X_poly = poly.fit_transform(data[['독립변수1', '독립변수2']])# OLS 모델 적용model = sm.OLS(data['종속변수'], sm.add_constant(X_poly)).fit() residuals = model.resid # 잔차################# 1. 잔차 히스토그램 (정규성 확인)plt.hist(residuals, bins=20, edgecolor='black')plt.xlabel(\"Residuals\")plt.ylabel(\"Frequency\")plt.title(\"Histogram of Residuals\")plt.show()# 2. Q-Q Plot (정규성 확인)## 잔차가 정규 분포를 따르는지를 보는 것으로 직선으로 나와야 한다.stats.probplot(residuals, dist=\"norm\", plot=plt)plt.title(\"Q-Q Plot\")plt.show()# 3. 잔차 산점도 (등분산성 확인)## 특별한 패턴이 보이지 않으면 오차항의 분산이 같다고 볼 수 있다. plt.scatter(model.fittedvalues, residuals) # x축 : 예측된 Y값, Y축 : 잔차plt.axhline(y=0, color='red', linestyle='--')plt.xlabel(\"Fitted Values\")plt.ylabel(\"Residuals\")plt.title(\"Residuals vs Fitted Values\")plt.show()matplotlib.pyplot.histscipy.stats.probplotmatplotlib.pyplot.scatter모델 평가 지표 log(L) (로그우도) : 모델이 데이터에 얼마나 잘 맞는지(적합도)를 측정 p :\t선택된 독립변수의 개수 n\t: 데이터 샘플 개수 지표 의미 해석 AIC (Akaike Information Criterion) 모델 적합도 평가 값이 작을수록 좋은 모델 BIC (Bayesian Information Criterion) AIC와 비슷하나 모델 단순성을 더 강조 값이 작을수록 좋은 모델 우도(likelihood)를 가장 크게 하는 동시에 변수 갯수는 가장 적은 최적의 모델(parsimonious &amp; explainable)을 의미AIC = -2 * log(L) + 2pBIC = -2*log(L) + log(n)pBIC: AIC와 유사하지만 마지막 패널티를 수정함으로써 AIC를 보완BIC의 경우 변수가 많을 수록 AIC보다 더 페널티를 가하는 성격을 가진다.AIC 보다 변수 증가에 더 민감해 변수 갯수가 작은 것이 우선 순위라면 AIC보다 BIC를 참고하는게 좋다.AIC와 BIC를 활용한 변수 선택 방법 방법 설명 전진 선택 (Forward Selection) 처음에는 변수가 없고 단계적으로 가장 설명력이 높은 변수를 추가 후진 제거 (Backward Elimination) 모든 변수를 포함한 상태에서 시작하여 설명력이 낮은 변수를 제거 단계적 선택 (Stepwise Selection) 전진 선택을 수행하면서도 통계적으로 유의하지 않은 변수를 제거 *AIC/BIC는 변수를 추가하거나 제거할 때 모델 선택 기준으로 사용할 수 있다. 전진 선택: AIC/BIC가 가장 감소하는 변수를 추가 후진 제거: AIC/BIC가 가장 적게 증가하는 변수를 제거 단계적 선택: AIC/BIC를 고려하며 추가 또는 제거를 반복REFERENCE 기술통계 다중 선형회귀에서 범주형 설명변수2:가변 seaborn 패키지를 이용한 상자그림(Boxplot) 작성하기 14-10 분위수 (quantile) 06-01 Scatter Plot 08-02 Heatmap 적합도 검정 카이-제곱 연관성 검정에 대해 표시할 통계량 선택 cut, qcut 상관 분석 10_09. scipy를 이용하여 상관분석 하기 - scipy.stats.pearsonr( ) 분산분석 분산 분석, 일원분산분석, 이원 분산분석 Kruskal-Wallis Test 회귀분석 회귀분석 수치해석 및 의미 10_081. 회귀분석의 변수선택법 AIC, BIC, Mallow’s Cp 쉽게 이해하기 오차의 등분산성 검정(테스트)하기 잔차분석 drop_first=True " }, { "title": "데이터 분석", "url": "/posts/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%B6%84%EC%84%9D/", "categories": "Eng-Project, Analysis", "tags": "log, Python, Analysis", "date": "2025-01-26 00:00:00 +0900", "snippet": "데이터 분석1. 데이터 가져오기import pandas as pd# CSV 파일 불러오기data = pd.read_csv('../kaggle/StudentPerformanceFactors.csv')print(data.head())pandas : 데이터 처리 및 분석을 위한 라이브러리read_csv : CSV 파일을 데이터프레임 형태로 읽어온다.head() : 데이터의 첫 5행 출력데이터에 어떤 변수가 있는지는 kaggle 에서 확인하면 된다.2. 변수 범주화 처리공부 시간 (Hours_Studied)평균, 표준편차, 최솟값, 최댓값을 계산하고 이를 기준으로 “적음”, “보통”, “많음”이라는 범주로 나눈다.import numpy as npfrom scipy import statshours = np.array(data[\"Hours_Studied\"])# 평균, 표준편차, 최솟값, 최댓값 계산mean = np.mean(hours)std_dev = np.std(hours)min_value = np.min(hours)max_value = np.max(hours)print(f'평균: {mean}, 표준편차: {std_dev}, 최솟값: {min_value}, 최댓값: {max_value}')'''평균: 19.98, 표준편차: 5.99, 최솟값: 1, 최댓값: 44 '''이를 토대로 적음 : 0 ~ 15, 보통 : 15 ~ 30, 많음 : 30 ~ 45를 적용했다.시험 점수 (Exam_Score)score = np.array(data[\"Exam_Score\"])mean = np.mean(score)std_dev = np.std(score)min_value = np.min(score)max_value = np.max(score)print(f'평균: {mean}, 표준편차: {std_dev}, 최솟값: {min_value}, 최댓값: {max_value}')'''평균: 67.23, 표준편차: 3.89, 최솟값: 55, 최댓값: 101'''낮음 : 50 ~ 65, 보통 : 65 ~ 75, 높음 : 75 ~ 100시험 점수의 최댓값이 101이므로 100점을 초과한 값은 이상치로 간주했다.3. 상관분석 (Pearson 상관계수)공부 시간과 시험 점수 간의 관계를 수치적으로 파악하기 위해 Pearson 상관계수를 계산했다.Pearson 상관 계수는 모두 연속형 자료여야한다.corr() : 각 열 간의 상관 계수를 반환하는 메서드method 옵션이 있는데 pearson은 default값이라 생략가능하다.# 이상치 제거data = data[data[\"Exam_Score\"] &lt;= 100]correlation = data['Hours_Studied'].corr(data['Exam_Score'])print(f\"공부 시간과 시험 점수 간의 Pearson 상관계수: {correlation.round(2)}\") # 0.45'''공부 시간과 시험 점수 간의 Pearson 상관계수: 0.45'''상관계수 0.45는 약한 양의 상관관계를 의미한다.공부 시간이 많을 수록 시험 점수가 높아지는 경향이 있지만공부 시간 외 제 3의 요인에 영향을 받을 가능성이 크다.lmplot 시각화Seaborn 라이브러리의 lmplot을 사용하여 두 변수 간의 선형 관계를 시각화한다.import matplotlib.pyplot as pltimport seaborn as snssns.lmplot(x='Hours_Studied', y='Exam_Score', data=data)plt.show()그래프의 회귀선 주변에 점들이 흩어져 있다. → 완벽한 선형 관계가 아님을 알 수 있다.4. 교차 분석 (카이제곱 검정)가설 설정귀무가설 (H₀) : 학습 시간과 시험 점수는 연관성이 없다. (독립이다.)대립가설 (H₁) : 학습 시간과 시험 점수는 연관성이 있다. (독립이 아니다.)chisquare는 적합성 검정(데이터가 특정 분포에 적합한지)을 수행하는 데 사용되고chi2_contingency는 독립성 검정(두 범주형 변수 간의 관계)을 확인하는 데 사용된다.카이제곱 검정은 범주형 데이터를 분석하기 때문에 데이터를 범주형으로 변환했다.카이제곱import pandas as pdfrom scipy.stats import chi2_contingency# 이상치 제거 data = data[data[\"Exam_Score\"] &lt;= 100]data['study_time'] = pd.cut(data['Hours_Studied'], bins=[0, 10, 25, 45], labels=['적음', '보통', '많음'])data['exam'] = pd.cut(data['Exam_Score'], bins=[50, 65, 75, 100], labels=['낮음', '중간', '높음'])# 교차표 생성 (분할표 만들기는 crosstab을 사용하여 분석)observed = pd.crosstab(data['study_time'], data['exam'])# scipy를 이용한 카이제곱 검정(카이제곱, p, 자유도, 기대치) chi2, p, dof, expected = chi2_contingency(observed) observed : 교차표(관측된 빈도수) chi2 : 카이제곱 통계량 p : 귀무가설이 참이라는 가정하에 관측된 데이터를 얻을 확률 dof : 자유도(Degrees of Freedom) expected : 기대 빈도수 적합도 검정 (Goodness of Fit Test)모집단을 대표하는지 검정할 수 있는지 확인하는 방법이다.# 기대 빈도 중 5 미만 셀 개수 확인cells = (expected &lt; 5).sum()percentage = (cells / expected.size) * 100print(f\"5 미만 셀 개수: {cells}\")print(f\"전체 셀 대비 비율: {percentage:.1f}%\")[[4.8550e+02 1.0024e+03 1.7100e+01][1.5639e+03 3.2291e+03 5.5000e+01][8.1600e+01 1.6850e+02 2.9000e+00]]각 셀의 기대빈도는 5 이상이어야 한다.*각 셀의 기대빈도가 5보다 작은 셀이 25% 미만이어야 카이제곱 검정 통계량 값을 사용할 수 있다.계산 결과 11%로 나와서 카이제곱 검정 통계량 값을 사용할 수 있다.df(자유도) = (행 개수-1) * (열 개수-1) = 4카이 제곱표를 보면 df가 4이고 유의수준이 0.05이면 임계값은 9.49가 된다.아래 코드로도 확인할 수 있다.import scipy.stats as statsprint(stats.chi2.ppf(0.95,4).round(2)) # 유의수준, 자유도카이제곱 검정 통계량(X²=710.5)이 임계값(9.49)보다 크므로 귀무가설을 기각하고 대립가설을 채택한다.독립성 검정 (Chi-Square Test of Independence)# scipy를 이용한 카이제곱 검정(카이제곱, p, 자유도, 기대치) chi2, p, dof, expected = chi2_contingency(observed)print(f\"카이제곱 통계량: {chi2}, p-value: {p}\")'''카이제곱 통계량: 710.507724463204, p-value: 1.8491304034075416e-152'''p-value가 유의 수준인 0.05보다 작으므로 대립가설을 채택한다.따라서 학습 시간과 시험 점수는 연관성이 있다라고 볼 수 있다.기여도 분석어떤 범주가 카이제곱 통계량에 가장 큰 영향을 미쳤는지 확인하기 위해 표준화 잔차를 계산했다.표준화 잔차 : 잔차(또는 관측 카운트와 기대 카운트 간의 차이)를 기대 카운트의 제곱근으로 나눈 값residuals = (observed - expected) / np.sqrt(expected)print(residuals)점수 범주 낮음 중간 높음공부 시간 범주 적음 17.754313 -12.133973 -1.665438보통 -8.046655 5.708677 -0.858997많음 -8.035393 4.575550 7.818131“공부 시간이 적고 점수가 낮음”, “공부 시간이 많고 점수가 높음” → 대립가설 채택에 기여상관분석 결과, 공부 시간과 시험 점수 간에는 약한 양의 상관관계가 있는 것으로 나타났다.카이제곱 검정을 통해 학습 시간과 시험 점수는 연관성이 있음을 확인하였으며특히 공부 시간이 적고 점수가 낮은 범주 및 공부 시간이 많고 점수가 높은 범주가 분석 결과에 가장 크게 기여했다.REFERENCE 카이제곱 [python] 가설 검정 중 교차분석(카이제곱, 카이스퀘어, chi2) 10_04. 카이제곱검정 실행하기 - scipy.stats 이용 카이-제곱 연관성 검정에 대한 모든 통계량 해석상관계수 lmplot 15-05 상관계수 (corr / corrwith) 강의 04 상관 계수적합도 검정 카이제곱 검정 - 독립성검정 in python" }, { "title": "Python을 활용한 파이차트 이미지 생성", "url": "/posts/Python%EC%9D%84-%ED%99%9C%EC%9A%A9%ED%95%9C-%ED%8C%8C%EC%9D%B4%EC%B0%A8%ED%8A%B8-%EC%9D%B4%EB%AF%B8%EC%A7%80-%EC%83%9D%EC%84%B1/", "categories": "Eng-Project", "tags": "log, Python, Flask", "date": "2025-01-25 00:00:00 +0900", "snippet": "Python을 활용한 파이 차트 이미지 생성이번 글은 python에서 파이 차트를 만들어 js에서 이미지로 보여주는 과정을 정리한 글이다.1. DB 연결하기환경변수 설정환경 변수 파일(.env)을 활용하여 DB 연결 정보를 보호한다.DB_TYPE=mysqlDB_DRIVER=pymysqlDB_HOST=127.0.0.1DB_USER=rootDB_PASSWORD=@DB_NAME=wowDB_PORT=3300127.0.0.1은 로컬 컴퓨터를 가리키는 루프백 주소로 localhost와 동일하다.환경변수 로드dotenv 패키지를 사용해 .env 파일의 내용을 불러온다.from dotenv import load_dotenvimport os# .env 파일 로드load_dotenv()db_type = os.getenv(\"DB_TYPE\")db_driver = os.getenv(\"DB_DRIVER\")db_host = os.getenv(\"DB_HOST\")db_user = os.getenv(\"DB_USER\")db_password = os.getenv(\"DB_PASSWORD\")db_name = os.getenv(\"DB_NAME\")db_port = int(os.getenv(\"DB_PORT\")) # port should be of type int PyMySQL로 DB 조회하기PyMySQL은 MySQL을 Python에서 사용할 수 있도록 하는 라이브러리다.import pymysql# DB 연결 설정 conn = pymysql.connect( host=db_host, user=db_user, password=db_password, db=db_name, port=db_port, charset=\"utf8\")cursor = conn.cursor() # 튜플 형식으로 반환'''# DATA DICTRIONARY로 변환 시)cursor = conn.cursor(pymysql.cursors.DictCursor)# 출력[{'id': 1, 'username': 'username', 'password': 'pw'}]'''# SQL 실행username = \"username\" sql = \"SELECT * FROM user WHERE username = %s\"cursor.execute(sql, (username,))# 결과 가져오기result = cursor.fetchall()print(result) # ((1, 'username', 'pw'),)# 연결 닫기cursor.close()conn.close() connect : DB 연결 객체를 생성 cursor : SQL 쿼리를 실행하거나 결과를 가져온다. execute : SQL 쿼리를 실행 execute(sql, params) 형식으로 호출하며 파라미터를 튜플 형태로 전달한다. fetchall : 실행한 쿼리의 결과를 모두 가져온다. close : 연결 종료 pandas로 DB 조회하기pandas.read_sql은 SQL 쿼리를 실행하고 결과를 바로 DataFrame으로 반환한다.*SQLAlchemy: Java의 JPA와 같이 Python의 ORM 라이브러리from sqlalchemy import create_enginefrom urllib.parse import quote_plusimport pandas as pd# 비밀번호 인코딩encoded_password = quote_plus(db_password)# SQLAlchemy 엔진 생성(mysql+pymysql://username:password@host:port/database_name)engine = create_engine( f\"{db_type}+{db_driver}://{db_user}:{encoded_password}@{db_host}:{db_port}/{db_name}\")'''# session 사용할 경우from sqlalchemy.orm import sessionmaker# SessionLocal 세션 클래스를 생성SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)- autocommit=Fasle: 자동커밋 비활성화- autoflush=False: 자동 flush 비활성 - fk 문제는 true로 설정해 flush를 통해 트랜잭션 순서를 보장- bind로 create_engine으로 생성한 db 엔진을 바인딩'''# pandas.read_sql 사용query = \"SELECT user.id FROM user WHERE username = %s\"username = \"hello\"df = pd.read_sql_query(query, con=engine, params=(username,))print(df)''' id0 1'''create_engine 참고 옵션 pool_size : 연결할 수 있는 connection의 크기를 지정 pool_recycle: 주어진 초 이후에 connection을 재사용 (ex.pool_recycle=600 : 600초 후 재사용) echo=True : query문 출력 *mysql의 경우 일정 시간동안 connection이 없을 경우 connection을 끊어버리게 되는데pool_recycle을 설정함으로써 강제로 끊어지는 현상을 막을 수가 있다.참고로 pool_recycle 시간이 mysql의 wait_timeout 시간보다 작게 설정되어야 한다.*여러번의 쿼리(INSERT, UPDATE 등)을 수행할 때는 sessionmaker를 적용하지만여기서는 조회 한번 후 더 이상의 연결이 필요없어서 적용하지 않았다.pd.read_sql과 pd.read_sql_query의 차이를 찾아봤을 때pd.read_sql은 표준 쿼리에 더 적합한 반면pd.read_sql_query는 사용자 지정 조건이 있는 복잡한 쿼리를 실행하는 데 더 적합하다.SQLAlchemy는 파이썬의 대표적인 ORM(Object-Relational Mapping) 라이브러리로데이터베이스와의 상호작용을 객체 지향적으로 처리할 수 있게 해준다.ORM의 특징인 SQL 쿼리를 직접 작성하지 않고도 데이터베이스 작업을 수행할 수 있으며코드의 가독성과 유지보수성을 크게 향상시킬 수 있다.SQLAlchemy에서 트랜잭션 관리는 Session 객체를 통해 수행한다.Java는 @Transactional으로 관리하듯 Python은 session으로 관리하는 것 같다.오류(pymysql.err.OperationalError) (2003, “Can’t connect to MySQL server on ‘@127.0.0.1’ ([Errno 11003] getaddrinfo failed)”)engine을 출력해보고 오류의 원인을 찾았다. 비번이 @로 설정되면서 생긴 문제였다.engine에서 출력할 때 Engine(mysql+pymysql://root:***@127.0.0.1:3306/db_name)와 같이 출력되어야 하는데Engine(mysql+pymysql://root:***@@127.0.0.1:3306/db_name)으로 출력되고 있었다.따라서 quote_plus()를 통해 해결했다.파이 차트 생성하기DB에서 가져온 데이터를 활용해 matplotlib를 사용하여 파이 차트를 생성했다.동적 쿼리를 작성할 때 %s를 통해 구현했다.@Query(\"select new com.eng.dto.LevelResponseDto(c.level, count(c.level)) from Sentence c where c.id in (select s.sentence.id from Study s where s.user.id = :userId) group by c.level\")List&lt;LevelResponseDto&gt; findLevelByUserId(Long userId);🔽# 결과 출력user_id = df[\"id\"][0]query = (\"select s.level, count(s.level) cnt \" \"from sentence s \" \"join study st on s.id = st.sentence_id \" \"where st.user_id = %s \" \"group by s.level\")df = pd.read_sql(query, con=engine, params=(user_id,))# level 별 cnt 값 가져오기 level_0 = df[df['level'] == 0]['cnt'].iloc[0] # .iloc[0] : 첫 번째 값을 가져온다. level_1 = df[df['level'] == 1]['cnt'].iloc[0]level_2 = df[df['level'] == 2]['cnt'].iloc[0]참고) Study 테이블에서 UNIQUE user_id (user_id, word_id, meaning_id, sentence_id)로 설정을 해 해당 조합은 중복이 되지않는다. count()는 중복을 포함해서 중복을 제거하고 싶다면 DISTINCT를 적용하면 된다. import matplotlib.pyplot as pltratio = [level_0, level_1, level_2]labels = ['Easy', 'Medium', 'Hard']colors = ['#FF9999', '#FFCC99', '#99CCFF'] # 색상 지정 explode = [0.03, 0.03, 0.03]plt.pie(ratio, labels=labels, autopct='%.1f%%', startangle=90, counterclock=False, colors=colors, explode=explode, shadow=True)plt.show() autopct : 부채꼴 안에 표시될 숫자의 형식을 지정 → 소수점 한자리까지 표시하도록 설정 startangle : 부채꼴이 그려지는 시작 각도를 설정(default : 0도) counterclock=False로 설정하면 시계 방향 순서로 부채꼴 영역이 표시 (true : 반시계방향) explode : 부채꼴이 파이 차트의 중심에서 벗어나는 정도를 설정 3% 만큼 벗어나도록 설정 shadow = True : 파이 차트에 그림자가 표시이미지 저장 및 반환matplotlib.pyplot 모듈의 savefig() 함수를 사용해서 그래프를 이미지 파일 등으로 저장한다.import iofrom flask import send_fileimport matplotlib.pyplot as plt# 이미지 저장 및 반환img = io.BytesIO()plt.savefig(img, format='png')img.seek(0) # 메모리 포인터를 처음으로 이동plt.close() # 그래프 닫기return send_file(img, mimetype='image/png') format : 저장할 이미지 형식Flask로 이미지 전송Flask에서는 RequestParam을 통해서 작성할 떄 request.args.get('username')로 값을 받으면 되지만PathVariable을 사용할 때는 /&lt;username&gt;와 같이 &lt;&gt;를 활용해야한다.from flask_cors import CORSfrom src.py_mysql import levelPieCORS(app, resources={r\"/my-page/*\": {\"origins\": \"*\"}})@app.route('/my-page/level/image/&lt;username&gt;', methods=['GET'])def level_pie_image(username): return levelPie(username)본 프로젝트의 메인은 java+spring이기 때문에 cors에러가 뜬다.따라서 해당 요청사항의 url만 cors를 허용했다.ErrorRuntimeError: main thread is not in main loop→ Agg 백엔드 적용하기import matplotlibmatplotlib.use('Agg') # GUI 백엔드 비활성화 matplotlib는 기본적으로 TkAgg 백엔드를 사용하며 GUI 기반이다. (TkAgg, FltkAgg, GTK, GTKAgg, GTKCairo, Wx)대부분의 GUI 백엔드는 메인 스레드에서 실행해야한다.GUI가 없는 환경에서 실행하는 경우 에러가 발생한다. 따라서 GUI를 사용하지 않는 백엔드로 전환한다.jsfunction levelPieIMG(){ const url = `http://127.0.0.1:5000/my-page/level/image/${username}`; // Flask 서버 URL $.ajax({ type: \"GET\", url: url, xhrFields: { responseType: 'blob' // 이미지 데이터를 Blob 형식으로 요청 }, success: function (response) { // Blob URL 생성 const imgBlob = new Blob([response], { type: 'image/png' }); const imgURL = URL.createObjectURL(imgBlob); // 새 창 열기 const newWindow = window.open(\"\", \"_blank\", \"width=640,height=480\"); const imgElement = newWindow.document.createElement(\"img\"); imgElement.src = imgURL; imgElement.alt = \"Level Pie Chart\"; newWindow.document.body.appendChild(imgElement); }, error: function (err) { console.error(\"이미지를 로드하는 중 오류가 발생했습니다.\"); } })}REFERENCE SQLAlchemy SQLite, MySQL 등 데이터베이스 연동 SQLAlchemy_docs [SQLALCHEMY] session 관리인코딩 SQLAlchemy에서 비밀번호에 ‘@’이 들어가서 연결에 실패할 때read_sql pd.read_sql vs pd.read_sql_query What’s the Difference?matplotlib 22. Matplotlib 파이 차트 그리기 29. Matplotlib 이미지 저장하기RuntimeError: main thread is not in main loop Matplotlib and :RuntimeError: main thread is not in main loop:이미지 저장 및 띄우기 matplotlib와 flask 연결하기 image Blob 객체를 url로 바꾸어 img 띄우기 Using jQuery’s ajax method to retrieve images as a blob" }, { "title": "Socketio와 nltk를 사용한 챗봇 구현", "url": "/posts/SocketIO%EC%99%80-NLTK%EB%A5%BC-%EC%82%AC%EC%9A%A9%ED%95%9C-%EC%B1%97%EB%B4%87-%EA%B5%AC%ED%98%84/", "categories": "Eng-Project", "tags": "log, Python, Flask, SocketIO, NLTK", "date": "2025-01-22 00:00:00 +0900", "snippet": "Python-SocketIO와 NLTK를 사용한 챗봇 구현Python-SocketIO를 활용하여 실시간 양방향 통신을 구현하고 NLTK를 사용한 간단한 챗봇 기능을 추가했다.Spring과 WebSocket으로 채팅을 구현한 경험이 있어 이를 비교하면서 적용하니 이해가 더 쉬웠다.Spring WebSocket 경험이 있다면 SocketIO을 이해하는 데 도움이 될 것이다.1. 기본 설정가상환경python -m venv venvsource venv/Scripts/activatedeactivate라이브러리 설치pip install nltkpip install python-socketiopip install eventlet2. Python-SocketIOPython-SocketIO는 Python 애플리케이션에서 Socket.IO 서버와 client를 쉽게 구현할 수 있게 해주는 라이브러리다.Socket.IO는 실시간 웹 애플리케이션을 위한 JavaScript 라이브러리 및 프로토콜로WebSocket을 기반으로 하면서 WebSocket이 제공하지 않는 기능들(ex: 자동 재연결, 방(broadcasting), room)을 추가로 지원한다.주요 기능 양방향 통신 : 서버와 클라이언트 간의 실시간 양방향 통신을 구현할 수 있다. 네임스페이스 및 room 지원 : 메시지의 범위를 제한하기 위해 네임스페이스와 room을 사용할 수 있다. 다양한 클라이언트 지원 : JavaScript, iOS, Android 등 다양한 client와 통신이 가능하다. 비동기 서버 지원 : asyncio, gevent, eventlet과 같은 Python의 비동기 프레임워크와 통합하여 사용할 수 있다. 내장된 WSGI 애플리케이션 : 별도의 웹 서버 없이도 독립적으로 실행할 수 있는 WSGI 애플리케이션을 제공한다. 네임스페이스와 Room내가 이해한대로 정리를 하자면네임스페이스 : Spring에서 WebSocket 경로를 지정하는 endpoint와 유사registry.addEndpoint(\"/coco\").setAllowedOriginPatterns(\"*\").withSockJS();registry.addEndpoint(\"/coco/chat\").setAllowedOriginPatterns(\"*\").withSockJS();Room : Spring에서 UUID를 생성해 사용자별 roomId를 관리하는 방식과 유사Python에서는 client를 그룹화해 개별 Room을 제공 (기본적으로 세션 ID(sid)를 사용하여 구분)spring의 websocket과 차이점spring : @MessageMapping을 통해 메시지 경로 연결client.send(\"/app/chat.sendMessage\", {}, JSON.stringify(chatMessage));@MessageMapping(\"chat.sendMessage\")public void sendMessage(@Payload ChatMessage chatMessage) { rabbitTemplate.convertAndSend(sendExchange, \"room.\" + roomId, chatMessage);}Python-SocketIO : 이벤트 이름으로 동작socket.emit(\"my_message\", { command: selectedCommand, word: message }); @sio.eventdef my_message(sid, data): sio.emit('reply', {\"response\": response})socket.on(\"reply\", function (data) {})Spring에서는 uuid를 생성해 roomId로 개별 채팅을 구분했지만Python에서는 기본 제공하는 세션 ID(sid)로 개별 채팅 가능했다. (별도의 설정x)sio.emit('message', data, room=sid)spring websocket에서는 사용자가 채팅을 종료할 때 모달에서 진행되다보니 새로고침이 아닌닫기 버튼이나 다른 화면을 클릭해 채팅 모달만 없어지게 하는 경우종료 감지가 되지 않아 disconnect라고 client에서 값을 줘야 했는데Python-SocketIO에서는 Client에서 따로 작성하지 않아도 disconnect가 처리되었다.구현 : Python-SocketIOsocket.py으로 client와 연결 후 nltk_command.py를 통해 사용자가 원하는 결과값을 제공하는 것으로 구현했다.src |__ socket.py # SocketIO 서버 구현 |__ nltk_command.py # NLTK 관련 명령 처리 import … from …import socketiosio = socketio.Server(cors_allowed_origins=\"*\")app.wsgi_app = socketio.WSGIApp(sio, app.wsgi_app)#########################################################from socketio import Server, WSGIAppsio = Server(cors_allowed_origins=\"*\")app.wsgi_app = WSGIApp(sio, app.wsgi_app)import ~ 라이브러리 전체를 가져온다. (모든 것을 사용할 수 있지만 필요 없는 항목까지 로드)from ... import ... : 라이브러리에서 특정 항목만 가져온다. (필요한 물건(ex. WSGIApp)만 꺼내 사용)from a import b : 모듈 a에서 특정 항목 b만 가져온다.*후자는 socketio 모듈 전체가 필요하지 않고 특정 클래스(Server, WSGIApp)만 사용해 from을 사용한 것.이벤트 핸들링@sio.on('event_name') : 명시적으로 이벤트 이름 지정(이벤트 이름이 함수 이름과 다를 경우)@sio.event : 함수 이름을 이벤트 이름으로 자동 설정(이벤트 이름과 함수 이름이 동일할 경우)@sio.on('message')def handle_message(sid, data): print(\"Message received\")@sio.eventdef connect(sid, environ): print(f\"Client connected: {sid}\")@sio.eventdef my_message(sid, data): sio.emit('reply', {\"response\": \"Message Received\"}, room=sid)@sio.eventdef disconnect(sid): print(f\"Client disconnected: {sid}\") 연결(connect): sid(client의 세션 ID)와 environ(환경 정보) 확인 environ : client 연결과 관련된 HTTP 환경 정보 (IP 주소, 헤더 등) 메시지 수신(my_message): 데이터 처리 연결 종료(disconnect): 자동 감지*connect, disconnect와 같이 이미 정의된 event의 파라미터는 필수로 작성해야한다.(connect는 연결된 클라이언트의 정보를 처리하기 위해 sid와 environ이 필요)비동기 서버 실행RuntimeError: You need to use the eventlet serverFlask의 기본 실행 방법인 app.run()을 사용했더니 오류가 떴다.Flask의 기본 실행 방식(app.run())은 WebSocket 통신을 지원하지 않는다.→ Eventlet를 적용 (비동기 지원을 위해 이벤트 기반 웹 서버를 실행)eventlet.wsgi.server(eventlet.listen(('0.0.0.0', 5000)), app)roomsio.emit('reply', {\"response\": response}, room=sid)Socket.IO는 자동으로 클라이언트를 세션 ID(sid)에 해당하는 기본 Room에 연결한다. (따로 설정x)따라서 room=sid로 특정 클라이언트에게만 메시지를 전송할 수 있다.Room을 별도로 생성하고 관리하려면 아래와 같이 구현하면 된다.room_id = generate_room_id() # Room ID 생성(임의의 uuid 생성 함수) sio.enter_room(sid, room_id) # Room에 join sio.emit('message', data, room=room_id) # Room에 메시지 전송room1은 챗봇, room2는 일반 채팅방과 같이 분리를 할 수 있다.sio.emit('message', data, room='room1') # 'room1'에만 전송*client는 특정 room에 지속적으로 연결 되어야 하는 경우(ex. 채팅 기록 저장) roomId를 기억해야한다.나는 단순 챗봇이고 굳이 채팅 기록을 남겨야 할 이유가 없어서 sid를 활용하기로 했다.따라서 client에서 기억할 필요가 없다.전체 코드# 기본 설정import socketiofrom flask import Flaskfrom src.nltk_command import nltk_commandimport eventletsio = socketio.Server(cors_allowed_origins=\"*\") # 모든 origin에서 연결 허용app = Flask(__name__)app.wsgi_app = socketio.WSGIApp(sio, app.wsgi_app) # Flask와 WebSocket 기능을 결합# 이벤트 핸들링@sio.eventdef connect(sid, environ): # client 연결 print(f\"environ : {environ}\") print(f\"Client connected: {sid}\")@sio.eventdef my_message(sid, data): command = data.get(\"command\") word = data.get(\"word\") if command==\"lemmatizer\" : pos = data.get(\"pos\") response = process_command(command, word, pos) else : response = process_command(command, word) # 특정 client에게 메시지 전송 sio.emit('reply', {\"option\" : command, \"response\": response}, room=sid)@sio.eventdef disconnect(sid): # client 연결 종료 print(f\"Client disconnected: {sid}\")# 서버 실행 if __name__ == '__main__': eventlet.wsgi.server(eventlet.listen(('0.0.0.0', 5000)), app) 3. nltkn: noun, v: verb, a: adjective, s: adjective satellite, r: adverbfrom nltk.corpus import wordnet as wnfrom nltk.stem import WordNetLemmatizerimport json# 동의어 def get_synonyms(word): synsets = wn.synsets(word) synonyms = [] for synset in synsets: synonyms.extend([lemma.name() for lemma in synset.lemmas()]) return list(set(synonyms)) # 중복 제거# 예문def get_examples(word): synsets = wn.synsets(word) examples = [] for synset in synsets: examples.extend(synset.examples()) # .examples()는 문자열을 반환 return list(set(examples))# 정의def get_definition(word): synsets = wn.synsets(word) definitions = [] for synset in synsets: definitions.append(synset.definition()) # 단일 문자열을 추가 return list(set(definitions))# 단어의 품사(동사, 명사 등)def get_pos(word): synsets = wn.synsets(word) pos_tags = [] for synset in synsets: pos_tags.append(synset.pos()) return list(set(pos_tags))# 표제어 추출 def get_lemmatizer(word, pos): lemmatizer = WordNetLemmatizer() return [lemmatizer.lemmatize(word, pos)]def process_command(command, word, pos=None): global response if command == \"synonyms\": response = get_synonyms(word) elif command == \"examples\": response = get_examples(word) elif command == \"definition\": response = get_definition(word) elif command == \"pos\": response = get_pos(word) elif command == \"lemmatizer\" and pos: response = get_lemmatizer(word, pos) return json.dumps(response)lemmas_list = []for lemma in synset.lemmas(): lemmas_list.append(lemma.name())→ lemmas_list = [lemma.name() for lemma in synset.lemmas()]synonyms.extend([lemma.name() for lemma in synset.lemmas()])synonyms 리스트에 lemma.name()으로 생성된 리스트를 항목별로 추가한다.4. 문제 해결append와 extend 동의어와 예문은 list 형태로 반환되므로 extend를 사용해 개별 요소를 추가 정의와 품사는 단일 문자열로 반환되므로 append 사용 append는 리스트에 하나의 객체(item)를 그대로 추가하고 a.append([1, 2]) → a = [[1, 2]]extend는 리스트에 다른 요소를 개별적으로 추가한다. a.extend([1, 2]) → a = [1, 2]synonyms = []synonyms.append([\"example\"]) # [['example']]synonyms.extend([\"example\"]) # ['example']따라서 동의어와 예문을 append()로 사용하게 된다면 [[\"a\"],[\"b\"]]와 같이 리스트 안에 리스트가 생기기 때문에개별적으로 리스트에 추가하는 extend()를 사용했다.TypeError: Object of type set is not JSON serializableimport jsonreturn json.dumps(response) 반환 데이터를 json.dumps()로 해결list와 []# 품사 알기def get_lemmatizer(word, pos): lemmatizer = WordNetLemmatizer() return [lemmatizer.lemmatize(word, pos)]처음엔 return값을 list(lemmatizer.lemmatize(word, pos))로 작성했더니hello를 입력했을 때 반환 값이 [\"h\", \"e\", \"l\", \"l\", \"o\"] 로 출력되었다.따라서 hello로 출력하기 위해 list() 대신 []를 사용해 [lemmatizer.lemmatize(word, pos)]로 작성했다.list() 함수는 문자열을 문자 단위로 쪼개어 리스트로 변환한다. hello → ['h', 'e', 'l', 'l', 'o'][]는 원하는 값을 리스트의 요소로 직접 추가한다. hello → ['hello']참고로 list()로 작성하는 것보다 [](대괄호)를 사용하는게 성능이 더 좋다고 한다.REFERENCE wordnet wordnet 워드넷(wordnet)을 재밌게 활용하기 [Python] WordNet으로 각 단어별 연관어(연상어) 추출하기 02-03 어간 추출(Stemming) and 표제어 추출(Lemmatization)python [Python] list append()와 extend() 차이점 Python, [](대괄호)와 list()의 차이Socket.IO python-socketio: 파이썬 Socket.IO 서버 및 클라이언트 [Flask] 플라스크로 채팅 기능을 구현해보자 python-socketio로 Socket.io서버를 생성하고 Django와 통합하여 배포하기" }, { "title": "검색어 자동완성", "url": "/posts/%EA%B2%80%EC%83%89%EC%96%B4-%EC%9E%90%EB%8F%99%EC%99%84%EC%84%B1/", "categories": "Eng-Project", "tags": "log", "date": "2025-01-15 00:00:00 +0900", "snippet": "검색어 자동완성사용자가 단어를 입력하면 해당 단어로 시작하거나 끝나는 단어를 검색하여 결과를 화면에 출력하는 기능을 정리한 글이다. 1. DB → Cache 저장사용자가 검색어를 입력할 때마다 DB를 실시간으로 조회하면 성능 저하가 발생할 수 있다.이를 해결하기 위해 DB 데이터를 Redis Cache에 저장하여 조회 성능을 개선했다.RedisTemplate을 활용한 데이터 캐싱ReidsConfig에 일부 로직을 추가하면서 공식문서를 읽다보니 @Resource를 알게되었다.@ResourceBean 이름 기반으로 특정 RedisTemplate을 주입받는다.@Resource(name = \"maxPageRedisTemplate\")private final RedisTemplate&lt;String, Integer&gt; numTemplate;동일한 타입의 Bean이 여러 개일 경우 @Resource를 사용해야한다.기존에 @Resource를 작성하지 않아도 동작했던 이유는생성자 주입을 통한 타입 기반 주입을 수행해 동일한 타입의 Bean이 하나이기 때문에 별도의 지정 없이도 동작한 것이다. @Autowired 기본적으로 타입 기반으로 Bean을 주입한다. 동일 타입의 Bean이 여러 개 있을 경우, 모호성이 발생한다. @Resource 기본적으로 이름 기반으로 Bean을 주입한다. 이름으로 특정 Bean을 선택할 수 있으며, type 옵션을 지정하면 타입 기반으로도 동작할 수 있다. @Resource(type = RedisConfig.class)private final RedisTemplate&lt;String, String&gt; redisTemplate;실행모든 Bean 초기화 후 실행되는 CommandLineRunner를 사용해 Redis Cache에 데이터를 저장했다.@SpringBootApplicationpublic class EngApplication { public static void main(String[] args) { SpringApplication.run(EngApplication.class, args); } @Bean public CommandLineRunner run(SearchService searchService) { return args -&gt; { searchService.addWordRedis(); }; }}모든 의존성 Bean이 초기화된 후 addWordRedis()를 실행할 수 있어NullPointerException이나 의도치 않은 오류를 방지할 수 있다.Redis 데이터 저장db에 저장된 모든 단어와 그 뜻을 조회해서 Redis에 저장한다.@Resource(name=\"addWordRedisTemplate\")private final RedisTemplate&lt;String, List&lt;String&gt;&gt; redisTemplate;public void addWordRedis() { List&lt;Word&gt; all = wordRepository.findAll(); for(Word word : all){ List&lt;MeaningDto&gt; meaning = meanRepository.findByWordApplicableMean(word.getId()); List&lt;String&gt; meaningList = meaning.stream() .map(MeaningDto::getMeaning) // .map(meaningDto -&gt; meaningDto.getMeaning()); .toList(); redisTemplate.opsForValue().set(word.getWord(), meaningList); }}2. 단어 검색사용자가 검색창에 단어를 입력하면 Redis에서 해당 단어로 시작하거나 끝나는 단어를 검색한다.검색창 하단에 자동완성 결과로 표시된다.JS입력 eventsearchInput.addEventListener(\"input\", () =&gt; { const query = searchInput.value; if (query.length &gt; 0) { }});사용자가 입력을 하는 순간 부터 서버와 통신한다.if (Object.entries(data[0]).length&gt;0 || Object.entries(data[1]).length&gt;0) {}배열안에 든 값이 없더라도 data자체의 길이는 2로 출력된다. (startWith, endWith)따라서 배열안에 든 값이 0일 경우에는 자동완성 검색 html이 띄워지지 않게 작성했다.*startWith와 endWith는 모두 동일한 로직let startData = data[0];Object.entries(startData).forEach(([key, values]) =&gt; { const li = document.createElement('li'); li.innerHTML = `${highlightMatching(key, query)} : ${values.join(', ')}`; suggestions.appendChild(li); });Object.entries서버에서 받아오는 데이터 타입은 Object로 Object.entries()는 [key, value] 쌍의 배열을 반환한다.[key, value] 형태로 값을 반환하기 때문에 parameter로 [key, value]를 작성했다.highlight사용자가 입력한 단어는 파란색으로 표시되게 작성했다. (ex. d를 입력했을 때 deploy의 d만 파란색)function highlightMatching(word, query) { const regex = new RegExp(`(${query})`, 'gi'); // 입력된 문자열과 일치하는 부분 return word.replace(regex, '&lt;span class=\"highlight\"&gt;$1&lt;/span&gt;'); // 강조 표시}1) 정규식 생성 new RegExp(pattern, flags)를 사용하여 정규식 생성 pattern : 찾고자 하는 단어(query) flags : g: 전역 검색 (모든 일치 항목을 찾음) *g flag를 사용하지 않는다면 처음으로 매칭되는 값만을 가져오게 된다. i: 대소문자 구분 없이 검색 const regex = new RegExp(`(${query})`, 'gi'); // 대소문자 구분 없이, 모든 위치에서 찾음사용자가 a를 입력하면 정규식 /a/gi가 생성되어 모든 a를 검색한다.2) 문자열 강조 replace(): 문자열에서 일치하는 패턴을 대체 (.replace(정규식, 대체문자)) 첫 번째 인자: 찾을 패턴 (정규식 사용 가능) 두 번째 인자: 대체할 내용 캡처 그룹 (()와 $1) (): 정규식에서 패턴의 일부를 캡처한다. $1: 캡처된 첫 번째 그룹을 참조한다. ()로 둘러싸인 부분은 정규식에서 캡처 그룹을 의미한다.캡처 그룹은 일치하는 문자열을 저장하거나 참조할 수 있게 만든다.const regex = /([a-z]+)([0-9]+)/;const result = 'abc123'.match(regex);console.log(result[1]); // 'abc' (첫 번째 캡처 그룹)console.log(result[2]); // '123' (두 번째 캡처 그룹)return word.replace(regex, '&lt;span class=\"highlight\"&gt;$1&lt;/span&gt;');정규식과 일치하는 단어를 &lt;span&gt; 태그로 감싸 강조한다.$1: 캡처 그룹에서 첫 번째 그룹에 해당하는 값을 참조한다.따라서 사용자가 입력한 a가 단어에 여러 번 등장하면, 모든 a가 개별적으로 $1로 참조되어 강조 표시된다.ex) abstraction 문자열에서 a를 검색하면 모든 a를 찾는다.만약 g flag를 사용하지 않으면 첫번째 a만 강조된다.Redis 직렬화/역직렬화 문제Redis에 데이터를 저장하고 가져오는 과정에서 직렬화/역직렬화 문제로 인해 아래와 같은 오류가 발생했다.com.fasterxml.jackson.databind.exc.InvalidTypeIdException: Could not resolve type id ‘설계하다’ as a subtype of java.lang.Object: no such class foundJSON 직렬화 시 타입 정보가 포함되지 않아 Jackson이 역직렬화 시 적절한 타입을 찾지 못해 발생한 문제였다.이 문제는 기존에 적용하던 캐시 중에 List&lt;Dto&gt;로 받고 있던 로직을 보고 힌트를 얻었다.@Beanpublic RedisTemplate&lt;String, List&lt;String&gt;&gt; addWordRedisTemplate() { RedisTemplate&lt;String, List&lt;String&gt;&gt; template = new RedisTemplate&lt;&gt;(); template.setConnectionFactory(redisConnectionFactory()); template.setKeySerializer(new StringRedisSerializer()); ObjectMapper objectMapper = new ObjectMapper(); objectMapper.activateDefaultTyping( objectMapper.getPolymorphicTypeValidator(), ObjectMapper.DefaultTyping.NON_FINAL, JsonTypeInfo.As.PROPERTY ); template.setValueSerializer(new GenericJackson2JsonRedisSerializer(objectMapper));// Value를 JSON으로 직렬화 return template;}GenericJackson2JsonRedisSerializer는 타입 정보를 포함한 JSON으로 데이터를 저장하고,역직렬화 시 이 정보를 기반으로 데이터를 변환한다.하지만 String은 기본 타입으로 타입 정보(@class 필드)가 포함되지 않아역직렬화할 때 Jackson이 타입(List&lt;String&gt;)을 추론하지 못해 오류가 발생한 것이다.따라서 Jackson의 ObjectMapper 설정에서 타입 정보를 강제로 저장하도록 수정했다.DefaultTyping.EVERYTHING 옵션을 사용해 모든 타입(기본 타입 포함)에 대해 타입 정보를 저장하도록 설정했다.사용자 정의 객체(List&lt;Dto&gt; 등)는 기본적으로 Jackson이 타입 정보를 포함하므로 DefaultTyping.NON_FINAL로도 동작했다.@Beanpublic RedisTemplate&lt;String, List&lt;String&gt;&gt; addWordRedisTemplate() { RedisTemplate&lt;String, List&lt;String&gt;&gt; template = new RedisTemplate&lt;&gt;(); template.setConnectionFactory(redisConnectionFactory()); template.setKeySerializer(new StringRedisSerializer()); ObjectMapper objectMapper = new ObjectMapper(); objectMapper.activateDefaultTyping( objectMapper.getPolymorphicTypeValidator(), ObjectMapper.DefaultTyping.EVERYTHING, JsonTypeInfo.As.PROPERTY ); template.setValueSerializer(new GenericJackson2JsonRedisSerializer(objectMapper));// Value를 JSON으로 직렬화 return template;}*DefaultTyping.EVERYTHING 옵션은 Deprecated 되었다.GenericJackson2JsonRedisSerializer vs Jackson2JsonRedisSerializerGenericJackson2JsonRedisSerializer와 Jackson2JsonRedisSerializer의 차이에 대해서 보고 내가 이해한 바로는 구분 GenericJackson2JsonRedisSerializer Jackson2JsonRedisSerializer 타입 정보 저장 자동으로 @class 필드에 해당 클래스의 패키지 정보까지 포함하여 저장 @class 필드 없이 타입 정보 없이 JSON 형태로 저장 유연성 별도의 Class Type을 지정할 필요 없이 모든 객체를 JSON으로 직렬화 직렬화할 Class Type을 지정해야 하며 지정된 타입만 직렬화 가능 적용 예시 여러 객체 타입(User, Board, Comment 등)을 하나의 Redis 캐시에 저장 특정 타입(List&lt;String&gt; 등)을 캐시에 저장하는 경우에 사용 타입 추론 타입 추론을 자동으로 수행하여 다양한 타입을 저장할 수 있음 지정된 타입에 대해서만 직렬화/역직렬화가 가능 단점 저장된 데이터에 패키지 정보까지 포함되어 다른 프로젝트에서 사용 시 경로가 일치해야 함 지정된 클래스 타입만 직렬화/역직렬화할 수 있어 유연성이 낮음 GenericJackson2JsonRedisSerializer모든 객체를 JSON 형태로 직렬화할 수 있으며 @class 필드에 클래스의 패키지 정보까지 저장한다.이로 인해 같은 패키지 경로와 이름을 가진 클래스만 역직렬화가 가능하다.(다른 프로젝트에서 사용하려면 패키지 경로를 일치시켜야 한다.)다양한 객체 타입을 유연하게 처리할 수 있기 때문에 여러 객체를 다루는 경우 적합하다.Jackson2JsonRedisSerializer직렬화할 클래스 타입을 명시해야 하므로 List&lt;String&gt;와 같이 특정 타입만 직렬화할 수 있다.나는 여러 객체를 활용해 캐시를 저장하는 것이 아니라 특정 타입(List&lt;String&gt;)만 캐시에 저장한다.따라서 Jackson2JsonRedisSerializer를 사용하게 되었다.@Beanpublic RedisTemplate&lt;String, List&lt;String&gt;&gt; addWordRedisTemplate() { RedisTemplate&lt;String, List&lt;String&gt;&gt; template = new RedisTemplate&lt;&gt;(); template.setConnectionFactory(redisConnectionFactory()); template.setKeySerializer(new StringRedisSerializer()); template.setValueSerializer(new Jackson2JsonRedisSerializer&lt;&gt;(List.class)); return template;}REFERENCE Spring 애플리케이션 시작 시 실행되는 로직 작성하기Redis 직렬화/역직렬화 Spring RedisTemplate Serializer 설정정규식 정규표현식, 이렇게 시작하자! [자바스크립트] 정규식(Regular Expressions)" }, { "title": "직렬화와 역직렬화", "url": "/posts/%EC%A7%81%EB%A0%AC%ED%99%94%EC%99%80-%EC%97%AD%EC%A7%81%EB%A0%AC%ED%99%94/", "categories": "Study", "tags": "Java", "date": "2025-01-11 00:00:00 +0900", "snippet": "직렬화와 역직렬화직렬화(Serialization) : 객체 데이터를 저장하거나 전송 가능한 형식(ex. JSON, binary)으로 변환하는 과정역직렬화(Deserialization) : 직렬화된 데이터를 다시 원래 객체로 복원하는 과정직렬화가 필요한 이유1. 데이터 타입의 특성과 메모리 주소 의존성 기본형(Primitive Type) 실제 값을 메모리의 stack에 저장 데이터 저장/전송이 바로 가능 ex) int, float, char 참조형(Reference Type) 메모리의 heap에 데이터를 저장하고 stack에 메모리 주소를 저장 참조형 데이터는 메모리 주소를 저장하지만 주소는 프로그램 종료 시 사라지거나 시스템마다 달라 저장/전송이 불가능 ex) 객체, 리스트 → 직렬화를 통해 참조형 데이터를 기본형 데이터로 변환하여 저장/전송 가능하게 만든다.2. 포맷의 필요성데이터를 저장하거나 전송하려면 표준화된 포맷(ex. JSON, binary)으로 변환해야 다른 시스템에서도 읽을 수 있다.직렬화는 데이터의 저장과 전송을 가능하게 만들며참조형 데이터를 표준화된 포맷으로 변환해 다른 시스템과 통신할 수 있도록 하는 과정이다.REFERENCE 데이터 직렬화(serialization)는 무엇이고 왜 필요한가? JAVA 변수의 기본형 &amp; 참조형 타입 차이 이해하기" }, { "title": "Text to speech", "url": "/posts/Text-to-Speech/", "categories": "Eng-Project", "tags": "log", "date": "2025-01-03 00:00:00 +0900", "snippet": "TTS(Text to Speech)영어 학습 시 예문을 음성으로 들을 수 있도록 TTS를 적용했다.이를 위해 무료로 사용할 수 있는 Web Speech API를 활용했다.기본 사용 방법TTS는 SpeechSynthesisUtterance 객체를 생성한 뒤 이를 speechSynthesis.speak()에 전달하여 음성을 재생한다.// 음성 재생window.speechSynthesis.speak(new SpeechSynthesisUtterance(\"Breakaway\"));// 일시 중지window.speechSynthesis.pause();// 다시 재생window.speechSynthesis.resume();// 재생 중단window.speechSynthesis.cancel();SpeechSynthesisUtteranceSpeechSynthesisUtterance는 읽을 텍스트와 읽기 옵션(속도, 음높이, 음량 등)을 설정하는 객체다. 속도(rate): 0.1 ~ 10 사이 값 설정 음높이(pitch): 0 ~ 2 사이 값 설정 음량(volume): 0 ~ 1 사이 값 설정const utter = new SpeechSynthesisUtterance(\"Breakaway\");utter.rate = 1; // 말하는 속도utter.pitch = 1; // 음높이utter.volume = 1; // 음량window.speechSynthesis.speak(utter);지원되는 음성 목록 가져오기speechSynthesis.getVoices()를 사용하면 브라우저에서 지원하는 음성 목록을 가져올 수 있다.이를 활용하여 특정 음성을 선택하거나 사용자 UI를 구성할 수 있다.const synth = window.speechSynthesis;let voices = synth.getVoices(); // 지원되는 음성 목록 가져오기voiceSelect.innerHTML = \"\"; // 이전 목록 초기화 // 각 음성을 select 요소에 추가voices.forEach((voice) =&gt; { const option = document.createElement(\"option\"); option.textContent = `${voice.name} (${voice.lang})`; // 형식 설정 option.setAttribute(\"voice-name\", voice.name); voiceSelect.appendChild(option); });const selectedVoice = voiceSelect.selectedOptions[0].getAttribute(\"voice-name\"); // voice, pitch, rate 설정utterance.voice = voices.find((voice) =&gt; voice.name === selectedVoice); // 선택된 음성 적용utterance.pitch = parseFloat(pitchInput.value); // pitch 설정utterance.rate = parseFloat(rateInput.value); // rate 설정 synth.speak(utterance); // 음성 재생영어 학습용 TTS영어 학습을 위해 en-US를 고정 설정하고 pitch와 rate 조정을 위한 옵션을 추가했다.const synth = window.speechSynthesis;let voices = [];// 음성 목록 업데이트function populateVoiceList() { voices = synth.getVoices(); // 지원되는 음성 목록 가져오기}populateVoiceList();if (speechSynthesis.onvoiceschanged !== undefined) { speechSynthesis.onvoiceschanged = populateVoiceList;}// 실시간 pitch와 rate 값 표시 pitchInput.addEventListener(\"input\", () =&gt; { pitchValue.textContent = pitchInput.value;});rateInput.addEventListener(\"input\", () =&gt; { rateValue.textContent = rateInput.value;});// 텍스트 읽기function speakText() { const lang = \"en-US\"; // 언어 설정 const utterance = new SpeechSynthesisUtterance(sentence.textContent); utterance.lang = lang; // pitch와 rate 설정 utterance.pitch = parseFloat(pitchInput.value); utterance.rate = parseFloat(rateInput.value); synth.speak(utterance); // 텍스트 읽기 }tts를 활용해 단어를 학습할 때 자동으로 예문을 읽어주고 더 읽고 싶을 때 읽기 버튼을 클릭하게 했다.옵션 설정 값은 아래와 같다.&lt;input type=\"range\" id=\"tts-pitch\" min=\"0\" max=\"2\" step=\"0.1\" value=\"1\" /&gt;&lt;!-- 0부터 2까지 조정 가능하며 사용자는 0.1 단위로 값을 선택할 수 있고 기본값은 1이다. --&gt;&lt;input type=\"range\" id=\"tts-rate\" min=\"0.1\" max=\"2\" step=\"0.1\" value=\"1\" /&gt;&lt;!-- 0.1부터 2까지 조정 가능하며 사용자는 0.1 단위로 값을 선택할 수 있고 기본값은 1이다. --&gt; REFERENCE Web Speech API Web Speech API로 프론트엔드에서 TTS 구현하기" }, { "title": "Mypage", "url": "/posts/MyPage/", "categories": "Eng-Project", "tags": "log", "date": "2024-12-30 00:00:00 +0900", "snippet": "MyPage단순히 사용자가 영어 공부를 하고 문제를 푸는 단순한 과정만 있어서학습한 데이터를 분석해서 제공하는 MyPage를 구현하게 되었다.이번 글에서는 학습 시간 및 풀이 시간과 학습 레벨을 시각화하는 내용을 작성했다.추후에는 더 다양한 분석 데이터를 추가해 MyPage를 확장할 계획이다.학습 시간과 풀이 시간DB사용자가 학습과 퀴즈 풀이를 진행한 시간을 저장하기 위해 StudyHistory 테이블을 생성했다.create table study_history( id BIGINT AUTO_INCREMENT PRIMARY KEY, user_id BIGINT NOT NULL, study_time BIGINT, quiz_time BIGINT, date DATE , foreign key (user_id) REFERENCES user (id) on delete cascade)db 저장 방식사용자가 학습하고 문제를 푸는 시간을 초 단위로 측정하여 DB에 저장했다.(front에서는 이를 분 단위로 변환하여 표시한다.)Repository@Query(\"select s from StudyHistory s where s.date between :start and :end and s.user.id=:userId\")List&lt;StudyHistory&gt; findBy7daysTime(LocalDate start, LocalDate end, Long userId);지난 일주일 동안의 학습 및 풀이 시간을 표시했다.Front1. 데이터 초기화let studyData= Array(7).fill(0);let quizData= Array(7).fill(0);학습시간을 모아둔 배열을 studyData, 풀이 시간을 모아둔 배열을 quizData로 설정사용자의 학습 및 풀이 시간이 없는 경우를 대비해 기본 값을 0으로 채웠다.데이터 매핑 및 변환const weekDays = ['Sun', 'Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat'];const startIndex = today.getDay(); // 오늘의 요일 인덱스 (0: Sun ~ 6: Sat)for(i=0; i&lt;response.length; i++){ const x = new Date(response[i].date).getDay(); // 요일 index studyData.splice(x,1,((response[i].study_time)/60).toFixed(1)); // 초 → 분 변환 quizData.splice(x,1,((response[i].quiz_time)/60).toFixed(1));}요일별 데이터(시간)를 배열에 삽입하기 위해 splice()를 활용했으며,소수점 첫번째까지 나타내기 위해 toFixed()를 사용했다.*splice()는 배열의 기존 요소를 삭제 또는 교체하거나 새 요소를 추가하여 배열의 내용을 변경한다.요일의 인덱스에 맞춰서 일요일일 경우 index는 0이므로 배열의 0번째 값에 시간을 넣는것이다.여기서 값을 대체 하기 위해 deleteCount을 1로 설정했다.(0으로 설정하면 값이 교체가 아니라 추가가 된다.)splice(start: number, deleteCount: number, ...items: T[])3. 요일 재정렬// 오늘 날짜가 가장 마지막으로 띄우게 재정렬const orderedWeekDays = [...weekDays.slice(startIndex + 1), ...weekDays.slice(0, startIndex + 1)];studyData = [...studyData.slice(startIndex + 1), ...studyData.slice(0, startIndex + 1)];quizData = [...quizData.slice(startIndex + 1), ...quizData.slice(0, startIndex + 1)];오늘이 만약 월요일이라면 가장 첫번째 데이터는 일요일이어야 한다.4. 차트 생성data: { labels: orderedWeekDays, datasets: [ { label: '학습 시간 (분)', data: studyData, backgroundColor: 'rgba(75, 192, 192, 0.5)', }, { label: '풀이 시간 (분)', data: quizData, backgroundColor: 'rgba(255, 99, 132, 0.5)', } ]},학습 Level사용자가 학습한 예문들의 레벨을 조회하여 각 레벨별 비율을 시각적으로 나타냈다.Repository@Query(\"select new com.eng.dto.LevelResponseDto(c.level, count(c.level)) from Sentence c where c.id in (select s.sentence.id from Study s where s.user.id = :userId) group by c.level\")List&lt;LevelResponseDto&gt; findLevelByUserId(Long userId);2개 이상 Object 배열을 클래스에서 가져올 때 Mapping에 대한 정보가 없기 때문에 변환이 되지 않아No converter found capable of converting from type 라는 오류가 떴다.DTO를 Query 내부에서 명시적으로 생성하여 객체 변환 오류를 방지했다.front1. 데이터 정렬 및 변환const sum = response[0].cnt+response[1].cnt + response[2].cnt;response.sort( (prev, curr) =&gt; { if(prev.level&gt;curr.level) return 1; if(prev.level&lt;curr.level) return -1;})const count = response.map(function (e) { return (e.cnt/sum*100).toFixed(1);})0, 1, 2 순서로 ‘Easy’, ‘Medium’, ‘Hard’를 나타내기 위해 정렬했다.level 별 개수만 배열에 담아서 퍼센트로 나타냈다.(소수점 첫째짜리)2. 결과 시각화data: { labels: ['Easy', 'Medium', 'Hard'], datasets: [{ data: count, backgroundColor: ['#FF9999', '#FFCC99', '#99CCFF'] }]}REFERENCE Array.prototype.splice() Spring JPA ) No converter found capable of converting from type ERROR [JS] map함수를 이용한 배열 안 특정 객체값 추출" }, { "title": "Quiz 정답 체크", "url": "/posts/Quiz-%EC%A0%95%EB%8B%B5-%EC%B2%B4%ED%81%AC/", "categories": "Eng-Project", "tags": "log", "date": "2024-12-24 00:00:00 +0900", "snippet": "Quiz 정답 체크이번 글에서는 사용자가 퀴즈에서 정답을 맞췄을 경우 db에 정답 상태(correct=true)를 저장하는 과정을 작성했다.설계구현할 기능을 아래와 같이 나누어 생각했다. 단계 Front Back 주요 처리 1 퀴즈 정답 체크 - 정답 시 quiz_id 저장 2 모달 닫힘 이벤트 감지 - quiz_id 목록 서버 전송 3 서버로 데이터 전송 PUT 요청 성공 시 quiz_id 초기화 4 DB 업데이트 quiz_id 일괄 저장 correct=true로 상태 변경 front1. 정답 체크사용자가 퀴즈를 한 번에 맞춘 경우 해당 quiz_id를 리스트에 추가하고 localStorage에 저장한다.정답을 맞춘 퀴즈는 퀴즈 목록인 quizList에서 삭제하고 다음 퀴즈로 넘어간다.let chance = 1; // 정답 기회// 사용자가 정답을 한 번에 맞췄을 경우 db에 저장할 목록들을 담아둔다. if(chance===1){ if(!quizId_List.includes(quizList[quizCurrentPage][\"quizId\"])){ // 중복 체크 quizId_List.push(quizList[quizCurrentPage][\"quizId\"]); // 맞춘 quiz_id 저장 localStorage.setItem(\"quizId_List\",JSON.stringify(quizId_List)); // localstorage 저장 quizList.splice(quizCurrentPage,1); // quizList에서 정답인 quiz 삭제 quizCurrentPage-=1; // page index }}2. Modal event사용자가 퀴즈 모달창을 닫으면 quiz_id 목록이 있을 때 서버로 데이터를 전송한다.quizModal.addEventListener(\"hidden.bs.modal\", () =&gt; { if(quizId_List.length&gt;0){ changeCorrect(); }});3. AJAX : 정답 처리데이터를 서버에 전송한 후 성공 시 quizId_List를 초기화한다.function changeCorrect(){ $.ajax({ type: \"PUT\", url: `/quiz/${username}`, headers: {}, data: JSON.stringify({quizId_List}), contentType: 'application/json', processData: false, success: function (response) { quizId_List=[]; // 초기화 localStorage.removeItem(\"quizId_List\") } })}JSON.stringify({quizId_List}) : {“quizId_List”:[255,253,259,260]}JSON.stringify(quizId_List) : [255,253,259,260]DTO와 매핑 시: JSON.stringify({quizId_List}) 형태로 객체를 전송해야 함그렇지 않을 경우 JSON parse error: Cannot deserialize value of type ~ from Array value (token ‘JsonToken.START_ARRAY’)] .배열(List&lt;Long&gt;)과 매핑 시: JSON.stringify(quizId_List) 형태로 배열을 전송해야 함그렇지 않을 경우 JSON parse error: Cannot deserialize value of type java.util.ArrayList from Object valuepush() 와 concat()push(): 기존 배열에 단일 값을 추가하고 배열의 길이를 반환한다. (a.push(b);)concat(): 기존 배열을 복사한 후 새로운 배열을 반환한다. (a = a.concat(b);)기존에 push를 사용해서 id값(단일 값)을 추가했다.그러나 퀴즈 리스트는 단일 값이 아닌 배열이기 때문에 push로 사용할 수 없다.quizList.push(...response); 또는 quizList = quizList.concat(response);를 사용하면 합칠 수 있다.Spread OperatorJavaScript의 스프레드 연산자(...)를 사용하면기존 배열이나 객체의 전체 또는 일부를 다른 배열이나 객체로 빠르게 복사할 수 있다.const numbersOne = [1, 2, 3];const numbersTwo = [4, 5, 6];const numbersCombined = [...numbersOne, ...numbersTwo];document.write(numbersCombined); // 1,2,3,4,5,6Spread Operator는 배열의 원소들을 분해하여 개별 요소로 만드는 기능을 한다.push는 배열의 값을 넣기 위해 사용된다. (배열로 추가하면 그대로 값이 들어가기 때문에 배열 자체가 push 된다.)하지만 spread operator를 사용할 경우, spread operator는 배열의 요소 각각으로 분해하기 때문에 요소 하나하나가 push 된다.React ES6 Spread OperatorBackController@RequestBody List&lt;Long&gt; 형식으로 데이터를 받으면 JSON이 배열이어야 한다. (ex. [258]){\"quizId_List\":[258]} 형태로 전송했기 때문에 객체로 데이터를 처리하기 위해 DTO를 사용했다.@PutMapping(\"/quiz/{username}\")public void quiz_correct(@PathVariable String username, @RequestBody QuizRequestDto dto) { quizService.quiz_correct(dto);}만약 DTO가 아닌 List&lt;Long&gt;으로 작성했다면JSON parse error: Cannot deserialize value of type java.util.ArrayList from Object value 라는 오류가 뜬다.성능 최적화 : 개별 처리 vs 일괄 처리DB 업데이트 성능을 최적화하기 위해 하나씩 처리하는 로직과 일괄로 처리하는 로직을 작성 후어느정도의 db 개수까지 개별로 저장할지 test 했다.개별은 true로 변경 일괄은 false로 설정해 5, 10, 15 순으로 5개씩 증가하면서 test했다.Repositoryprivate final JdbcTemplate template;// 개별 update (한 번에 하나씩 SQL을 실행) public void individualUpdates(QuizRequestDto quizIdList) { String sql = \"UPDATE quiz SET correct = true WHERE id = ?\"; for (Long quizId : quizIdList.getQuizId_List()) { template.update(sql, quizId); }}// 일괄 update (batchUpdate를 사용하여 SQL을 일괄 실행) public void updateCorrect(QuizRequestDto quizIdList) { String sql = \"UPDATE quiz SET correct = false WHERE quiz.id=?\"; template.batchUpdate(sql, quizIdList.getQuizId_List(), quizIdList.getQuizId_List().size(), (qz, quizId) -&gt;{ qz.setLong(1, quizId); });}성능 비교log.info(\"correct=true 총 개수 : {} \",quizIds.getQuizId_List().size());long start = System.currentTimeMillis();jdbcRepository.individualUpdates(quizIds);long end = System.currentTimeMillis();log.info(\"개별 걸린 시간 : {}\", end - start);long start1 = System.currentTimeMillis();jdbcRepository.updateCorrect(quizIds);long end1 = System.currentTimeMillis();log.info(\"일괄 걸린 시간 : {}\", end1 - start1); 데이터 개수 개별 처리 시간(ms) 일괄 처리 시간(ms) 1 4 3 5 22 7 20 58 15 성능 테스트 결과 데이터 개수에 상관없이 일괄 처리를 사용하는 것이 성능적으로 더 유리했다.추가) WHERE IN과 NamedParameterJdbcTemplatespring framework 공식 문서에 따르면 SQL 문에서 매개변수를 표현하는 방법은 두 가지다.1. positional parameter(위치 기반)positional는 순서에 따라 파라미터값들을 넣어주는 것을 이야기한다.물음표(?)로 표시하는 경우 순서에 따라 값을 설정하기 때문에 positional parameter에 해당한다.2. named parameter(이름 기반)“named는 이 파라미터가 어떤 파라미터 입니다.” 라고 명시해주면서 코드를 작성하는 것을 의미한다.where in 같은 경우 콜론(:)을 사용한다.콜론(:)을 통해 변수를 기준으로 값을 설정하는 경우 JdbcTemplate이 아닌 NamedParameterJdbcTemplate을 사용해야한다.NamedParameterJdbcTemplate은 이름을 기준으로 값을 설정하기 때문에 파라미터의 순서를 신경 쓰지 않아도 되는 장점이 있다.private final NamedParameterJdbcTemplate namedParameterJdbcTemplate;public void updateCorrectIndividually(QuizRequestDto quizIdList) { String sql = \"UPDATE quiz SET correct = true WHERE id IN (:ids)\"; Map&lt;String, Object&gt; params = Map.of(\"ids\", quizIdList.getQuizId_List()); namedParameterJdbcTemplate.update(sql, params);}일반 Map을 사용하여 파라미터를 정의하는 방법은NamedParameterJdbcTemplate의 메소드에 파라미터로 Map&lt;String, ?&gt;을 직접 전달하는 것이다.Java 9 이상부터 of()를 활용해 map을 간단하게 작성할 수 있다.of()를 확인해보면 인자의 개수에 맞춰 오버로딩하고 있는 것을 확인할 수 있다.그러나 인자의 개수는 10개 이하로 제한되어 있으며 그 이상의 경우엔 ofEntries()를 사용하면 된다.// Map.javastatic &lt;K, V&gt; Map&lt;K, V&gt; of(K k1, V v1) {...}static &lt;K, V&gt; Map&lt;K, V&gt; of(K k1, V v1, K k2, V v2, K k3, V v3, K k4, V v4, K k5, V v5) {...}static &lt;K, V&gt; Map&lt;K, V&gt; of(K k1, V v1, K k2, V v2, K k3, V v3, K k4, V v4, K k5, V v5, K k6, V v6, K k7, V v7, K k8, V v8, K k9, V v9, K k10, V v10) {...}where과 where in의 큰 차이는 없어보인다.기타 수정사항)학습할 때 학습한 단어와 퀴즈 목록들을 저장하는데 이 과정을 실패하면redis cache update 과정도 실패로 돌아가게끔 @Transactional을 추가했다.퀴즈 목록에서 저장 실패 후 redis cache가 update 되지 않고 그대로 값이 있는 것을 확인했다.처음 학습하기 실행 후 모달을 닫았을 때 cache에는 10개의 학습 리스트가 저장되며,학습한 단어는 cache에서 삭제되는 로직을 작성했었다.따라서 update가 되었다면 10개의 데이터가 아닌 10개 미만의 데이터를 가지고 있어야 한다.REFERENCE named parametersjs - push &amp; concat [JavaScript] Array push( ) vs. concat( ) [JavaScript] 배열 합치기 (concat, spread operator, push)NamedParameterJdbcTemplate [Spring DB] NamedParameterJdbcTemplateMap.of() Map.of() 를 통한 Map 초기화 주의할 점" }, { "title": "Levenshtein distance를 활용한 빈칸 채우기", "url": "/posts/Levenshtein-distance%EB%A5%BC-%ED%99%9C%EC%9A%A9%ED%95%9C-%EB%B9%88%EC%B9%B8-%EC%B1%84%EC%9A%B0%EA%B8%B0/", "categories": "Eng-Project", "tags": "log", "date": "2024-12-11 00:00:00 +0900", "snippet": "Levenshtein distance를 활용한 빈칸 채우기빈칸 채우기 문제는 예문에서 특정 단어를 빈칸으로 대체해 퀴즈를 구성하는 방식이다.그러나 db에 저장된 단어가 예문에서 변형되어 작성된 경우기존 로직으로는 이를 처리하지 못해 예문이 퀴즈로 인식되지 않고 그대로 출력되는 문제가 발생했다.예를 들어 문제 단어가 run일 때 예문에는 running이 작성되어 있으면 기존 로직으로는 이를 처리하지 못했다.이를 해결하기 위해 Levenshtein Distance를 활용해 단어 간 유사도를 측정하고가장 유사한 단어를 빈칸으로 대체하는 방식을 적용했다.Levenshtein Distance(편집 거리 알고리즘) 란?Levenshtein Distance는 두 문자열 간의 최소 편집 거리를 계산해 유사도를 측정하는 알고리즘이다.편집 거리는 한 문자열을 다른 문자열로 변환하는 데 필요한 최소 작업 횟수를 의미한다.작업은 다음 세 가지로 구성된다. 삽입: 문자 추가 삭제: 문자 제거 교체: 문자 변경 이 세 가지 작업의 비용을 계산하여 최소값을 도출한다.계산 방법 삽입 : table[i-1][j] + 1 삭제 : table[i][j-1] + 1 교체 : 문자가 같을 경우 : table[i-1][j-1] + 0 문자가 다를 경우 : table[i-1][j-1] + 1 table[i][j]= min(삽입 비용,삭제 비용,교체 비용)테이블의 마지막 값인 table[length(a)][length(b)]가 두 문자열의 편집 거리를 나타낸다.예제1. 글자가 서로 동일하면 대각선 값을 가져온다2. 변경이 필요하면 대각선 값에서 + 1을 한다.3. 삽입이 필요하면 위의 값에서 +1을 한다.4. 삭제가 필요하면 왼쪽 값에서 +1을 한다.5. 1~4의 경우에서 최소값을 가져온다.1. 편집 거리 계산hello와 hi를 예시로 들었다.↓ 초기 테이블 설정     h i   0 1 2 h 1     e 2     l 3     l 4     o 5     계산 과정1. table[1][1] : h와 h는 서로 같으므로 비용은 0이다. 삽입 비용: table[0][1] + 1 = 2 삭제 비용: table[1][0] + 1 = 2 교체 비용: table[0][0] + 0 = 0 → 최솟값 : 0     h i   0 1 2 h 1 0   e 2     l 3     l 4     o 5     2. table[1][2] : h와 i는 서로 다르므로 비용 1 삽입 비용: table[0][2] + 1 = 3 삭제 비용: table[1][1] + 1 = 1 교체 비용: table[0][1] + 1 = 2 → 최솟값 : 1     h i   0 1 2 h 1 0 1 e 2     l 3     l 4     o 5     3. table[2][1] : e와 h는 서로 다르므로 비용 1 교체 비용: table[1][0] + 1 = 2 삽입 비용: table[1][1] + 1 = 1 삭제 비용: table[2][0] + 1 = 3 → 최솟값: 1     h i   0 1 2 h 1 0 1 e 2 1   l 3     l 4     o 5     최종 테이블 결과     h i   0 1 2 h 1 0 1 e 2 1 1 l 3 2 2 l 4 3 3 o 5 4 4 최종 값은 table[5][2] = 4이다. → hello와 hi의 편집 거리는 4이다.위 전체 결과는 아래 코드를 통해서도 확인할 수 있다.public class Main { public static void main(String[] args) throws IOException { StringBuilder sb = new StringBuilder(); String a = \"hello\"; String b = \"hi\"; int[][] table = new int[a.length()+1][b.length()+1]; // 테이블 초기화 for(int i=1; i&lt;=a.length(); i++){ table[i][0] = i; } for(int i=1; i&lt;=b.length(); i++){ table[0][i] = i; } // 거리 계산 for(int i=1; i&lt;=a.length(); i++){ for(int j=1; j&lt;=b.length(); j++){ int insert = table[i-1][j]+1; int delete = table[i][j-1]+1; int replace = (a.charAt(i-1) == b.charAt(j-1) ? 0:1) + table[i-1][j-1]; table[i][j] = Math.min(insert, Math.min(delete, replace)); sb.append(table[i][j]).append(\" \"); } sb.append(\"\\n\"); } System.out.print(sb); }}Code1. 단어 유사도 측정두 문자열의 편집 거리를 계산한다.function getLevenshteinDistance(a, b) { // 테이블 초기화 const table = Array.from({ length: a.length + 1 }, () =&gt; Array(b.length + 1).fill(0)); // 기본 설정 for (let i = 1; i &lt;= a.length; i++) { table[i][0] = i; } for (let j = 1; j &lt;= b.length; j++) { table[0][j] = j; } // 편집 거리 계산 for (let i = 1; i &lt;= a.length; i++) { for (let j = 1; j &lt;= b.length; j++) { const insert = table[i - 1][j] + 1; const del = table[i][j - 1] + 1; const replace = (a[i - 1] === b[j - 1] ? 0 : 1) + table[i - 1][j - 1]; table[i][j] = Math.min(insert, del, replace); } } // 결과 반환 return table[a.length][b.length];}2. 가장 유사한 단어 찾기가장 작은 값을 저장해서 가장 유사한 단어를 return 시킨다.function similarWord(card, word){ let arr = card.sentence.split(\" \"); let similar; let min = 999; let x = 0; for(let i=0; i&lt;arr.length; i++){ x = getLevenshteinDistance(word, arr[i]); if(x&lt;min){ min = x; similar = arr[i]; } } return similar;}3. 단어 변환문제 단어가 예문에 포함되어 있다면 그대로 사용하고 아니라면 유사도를 기준으로 변환한다.if(card.sentence.indexOf(card.word)!==-1){ s_word = card.word}else{ s_word = similarWord(card, card.word);}코드 적용 후 예문에 포함된 단어의 변형도 문제로 출제 되는 것을 확인할 수 있다.REFERENCE Levenshtein distance [Algorithm] 문장의 유사도 분석 - 편집 거리 알고리즘 (Levenshtein Distance) 편집거리 알고리즘 Levenshtein Distance(Edit Distance Algorithm)Array Array.from을 통한 배열의 초기화" }, { "title": "Quiz 조회하기", "url": "/posts/Quiz-%EC%A1%B0%ED%9A%8C%ED%95%98%EA%B8%B0/", "categories": "Eng-Project", "tags": "log", "date": "2024-12-10 00:00:00 +0900", "snippet": "Quiz 조회 최적화 과정사용자(user_id)별로 정답을 맞히지 못한 퀴즈(correct = false)를 무작위로 10개 조회하는 기능을 구현했다.처음에는 간단한 방법을 선택했지만 성능 문제로 인해 최적화 과정을 거쳤고 이를 작성했다.*study_id, user_id, correct 컬럼을 활용했다.1. 초기 구현 : ORDER BY RAND()처음에는 ORDER BY RAND()를 사용해 무작위로 데이터를 조회했다.@Query(value = \"SELECT * FROM quiz q where q.correct=false and q.user_id = :userId order by RAND() limit 10\", nativeQuery = true)List&lt;Quiz&gt; findQuizByInCorrect(Long userId);그러나 ORDER BY RAND()는 대량의 데이터를 다룰 경우 속도가 매우 느려진다는 단점이 있었다.대안 찾기application에서 랜덤 숫자를 생성해 해당 id 값을 조회하려고 했지만사용자 별로 study_id가 연속적이지 않아 적합하지 않았다.*JPQL → Entity 이름 사용*Native SQL → DB table 이름 사용자세한 내용은 하단에 작성했다.2. 개선 : ROW_NUMBER() 를 활용ROW_NUMBER() 는 결과 집합의 각 행에 고유 번호를 부여한다.번호는 그룹별로 정렬 기준(ORDER BY)에 따라 할당되며 번호는 항상 1부터 시작한다.그룹화 : PARTITION BY 는 그룹별로 번호를 부여하거나 생략하면 전체 데이터를 하나의 그룹으로 처리한다. (선택)정렬 : ORDER BY 는 행의 순서를 정의한다. (번호 부여 순서 지정) (필수)예시)study_id = [1, 3, 6, 15] → ROW_NUMBER() = [1, 2, 3, 4]→ ROW_NUMBER()를 사용하면 id가 중간에 비어 있어도 영향을 받지 않는다. study_id ROW_NUMBER 1 1 3 2 6 3 SELECT ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY study_id) AS r, quiz.*FROM quiz; user_id study_id ROW_NUMBER 1 1 1 1 3 2 2 2 1 2 4 2 랜덤 숫자 생성쿼리에서 랜덤하게 데이터를 선택하기 위해 MOD와 FLOOR를 활용했다.RAND() : 0과 1 사이의 난수를 반환FLOOR() : 소수점 이하를 버리고 정수로 변환MOD(a, b) : a를 b로 나눈 나머지를 반환FLOOR(RAND() * n) : 0 ~ n-1 범위의 정수 생성 FLOOR(RAND() * 3) → 0, 1, 2 FLOOR(RAND() * 10) → 0 ~ 9 FLOOR(RAND() * 100) → 0 ~ 99개선된 쿼리@Query(value = \"select * from \" + \"(select row_number() over(order by id) r, quiz.* \" + \"from quiz \" + \"where correct = false and user_id = :userId) sub \" + \"where mod(r, floor(rand() * 3) + 1 ) = 0 limit 10\", nativeQuery = true)List&lt;Quiz&gt; findRandomQuiz(Long userId);RAND() * 3 : 0 ~ 3 미만의 난수를 생성FLOOR(RAND() * 3) + 1 : 1 ~ 3 범위의 정수를 생성MOD(r, FLOOR(RAND() * 3) + 1) = 0 : r을 랜덤 값으로 나눴을 때 나머지가 0인 값만 선택Limit 10 : 최대 10개의 결과값 반환(만약 10보다 적은 데이터라면 그만큼의 데이터수만 가져다 준다.)ex) MOD(1, 3) = 1 (조건 불만족) MOD(2, 3) = 2 (조건 불만족) MOD(3, 3) = 0 (조건 만족)결과적으로 r = 3, 6, 9, …가 조건을 만족한다.매번 실행될 때 다른 난수를 반환하므로 랜덤 조건이 적용되었다.참고) r은 단순히 필터링된 데이터셋에서 순번을 나타내는 컬럼이며where 조건에 따라서 해당 컬럼들을 select에 작성해야해서 quiz.*로 작성했다.서브쿼리는 반드시 별칭(alias)을 지정해야해서 sub로 작성했다.3. 성능 비교 및 분석기존 쿼리(ORDER BY RAND())와 개선된 쿼리(ROW_NUMBER())의 성능을 비교했다.*편의상 일부 코드를 생략했다.List&lt;StudyResponseDto&gt; list = new ArrayList&lt;&gt;();// 1번long start = System.nanoTime();List&lt;Quiz&gt; quizByInCorrect = quizRepository.findQuizByInCorrect(user.getId());long end = System.nanoTime();log.info(\"시간 소요 1 : {} \", (end-start));// 2번long start1 = System.nanoTime();List&lt;Quiz&gt; randomQuiz = quizRepository.findRandomQuiz(user.getId());long end1 = System.nanoTime();log.info(\"시간 소요 2 : {} \", (end1-start1));quiz 2는 랜덤으로 n칸씩 띄어서 가져오기 때문에 데이터의 개수에 따라서 10개 미만으로 나올 수도 있다.따라서 2번째 test부터 quiz 1의 limit를 5로 고정해서 테스트 했다.평균적으로 6개를 조회하는데ORDER BY RAND()는 0.085862초, ROW_NUMBER()는 0.018174초가 걸렸다.개선한 쿼리가 약 4.7배 빠른 성능을 보였다. Test Case Quiz 1 (ORDER BY RAND) Quiz 2 (ROW_NUMBER) Run 1 121,789,400 (10개) 2,491,901 (5개) Run 2 128,090,999 (5개) 35,581,300 (8개) Run 3 79,390,300 (5개) 13,276,901 (7개) Run 4 35,747,301 (5개) 23,408,500 (7개) Run 5 64,292,000 (5개) 16,110,600 (6개) 성능 차이 분석개선한 쿼리도 order by는 쓰이고 있지만 성능 차이가 발생하는 이유에 대해서 분석해봤다.DBMS에서 인덱스는 데이터의 읽기 속도를 높이는 기능이다.pk는 레코드(하나의 행)를 대표하는 column의 값으로 만들어진 index를 의미한다.1. ORDER BY RAND() 임의 정렬 방식: RAND()로 각 레코드에 임의의 값을 부여하고 이를 정렬하여 결과를 반환한다. 인덱스 활용X: ORDER BY RAND()를 이용한 임의 정렬이나 조회는 인덱스를 사용할 수 없다. 전체 데이터 정렬: WHERE 조건을 만족하는 데이터를 모두 가져와 임의값으로 정렬한 후 제한(LIMIT)을 적용한다. 2. ROW_NUMBER() 인덱스 활용: ROW_NUMBER()를 사용해 데이터를 정렬할 때 인덱스를 활용해서 불필요한 정렬 작업을 줄였다. 정렬 효율성: 실제 인덱스 값이 정렬된 상태이므로 순서대로 읽는 작업만 수행한다. 추가적인 정렬 생략: MySQL 서버는 인덱스를 활용할 경우 추가적인 정렬 작업을 하지 않는다. ORDER BY RAND()는 WHERE 조건에 맞는 데이터를 모두 가져온 후 정렬하며ROW_NUMBER()는 조건에 맞는 데이터를 가져오며 정렬까지 처리하므로 성능차이가 발생한 것 같다.추가 설명)JPQLJPQL(Java Persistence Query Language)는 JPA에서 SQL을 추상화하여 만든 객체 지향 쿼리 언어다.Entity 중심 : db 테이블이 아닌 entity를 대상으로 쿼리를 작성한다.ORM 친화적: 데이터베이스의 구체적인 테이블 이름이나 필드 이름을 몰라도 Entity와 매핑된 데이터를 처리할 수 있다.데이터베이스 독립적 : JPQL은 SQL을 추상화해서 특정 데이터베이스 SQL에 의존하지 않는다.@Query(\"SELECT u FROM User u WHERE u.name = :name\")여기서 User는 JPA 엔티티 이름이다.Native SQLSQL 그대로 사용: DB에 직접 SQL 쿼리를 실행하며 테이블 이름과 컬럼 이름을 명시적으로 사용한다.데이터베이스 의존적: DB 고유의 SQL 문법(예: 특정 함수나 확장 기능)을 사용할 수 있다.유연성: JPQL로 처리하기 어려운 복잡한 쿼리를 작성할 수 있다.@Query(value = \"SELECT * FROM user WHERE name = :name\", nativeQuery = true)여기서 user는 데이터베이스의 테이블 이름이다.정리 항목 JPQL Native SQL 기준 Entity 기반 테이블 기반 유연성 JPA와 매핑된 객체만 조회 가능 모든 SQL 기능 사용 가능 의존성 데이터베이스 독립적 데이터베이스 종속적 예시 @Query(\"SELECT u FROM User u\") @Query(value = \"SELECT * FROM user\", nativeQuery = true) REFERENCE ROW_NUMBER() [MSSQL] 윈도우 함수 ROW_NUMBER() 순차번호 할당 [Oracle] 몫, 나머지 구하기 MySQL RAND 함수 사용법 및 범위 지정방법Order by [Real MySQL 8.0] [mysql] ORDER BY rand()JPQL [JPA] JPQL이란? [Spring] Spring Data JPA에서 JPQL과 Native SQL의 차이는? [JPA 기본] 객체지향 쿼리 언어 알아보기" }, { "title": "Gutter", "url": "/posts/gutter/", "categories": "Log", "tags": "Intellij", "date": "2024-12-08 00:00:00 +0900", "snippet": "Editor gutter어느 순간 pr을 열어 둔 상태에서 코드 변경 시Editor gutter(코드 라인 옆 여백)에 변경된 부분이 핑크색으로 표시되어 불편했다.코드를 변경 하면 초록색으로 눈에 띄어야 하는데 핑크색과 겹치면서 눈에 잘 띄지 않았다.File Status Colors구글링 결과 File Status Colors 설정이 많이 언급되었으나 이는 파일 단위 색상 설정으로 해결방법이 아니었다.Highlight modified lines in gutter 설정 확인Editor → Color Scheme → VCS해당 경로에서 변경된 코드 라인에 색상을 지정하는 설정을 찾았다.but, 핑크색 관련 설정은 찾을 수 없었다.그래서 “gutter 색상 pink intellij” 검색 중 동일한 문제를 겪는 사람을 발견했다.stackoverflow결론은 Disable Review Mode에 체크하면 된다. Route 53 호스팅 영역 삭제 방법사용하지 않는 Route 53 호스팅 영역 때문에 비용이 발생했다.1. 기본 SOA(권한 시작)과 NS(이름 서버) 레코드를 제외하고 호스팅 영역과 관련된 모든 레코드를 삭제한다.2. 호스팅 영역에서 삭제를 누르면 끝aws" }, { "title": "Quiz 저장하기", "url": "/posts/Quiz-%EC%A0%80%EC%9E%A5%ED%95%98%EA%B8%B0/", "categories": "Eng-Project", "tags": "log", "date": "2024-12-05 00:00:00 +0900", "snippet": "Quiz 저장하기Quiz 기능을 구현하기 위해 데이터를 저장하고 조회하는 과정을 진행했다.이 글에서는 저장 과정을 중점적으로 다루며 조회 기능은 다음 글에서 확인 할 수 있다.Quiz 저장Quiz는 사용자가 학습한 단어를 기반으로 생성된다.저장 방식 설계 시 두 가지 방안을 검토했다.1. Quiz 테이블의 status 활용Study 테이블에서 단어를 가져오고 Quiz 테이블에 정답 여부인 status(correct,incorrect)를 반영한다.2. Study와 User를 연결study_id와 user_id를 Quiz 테이블에 저장하고 정답 여부를 Boolean 값으로 관리한다.나는 후자의 방법을 선택했다.Quiz db 저장하기Entity@Entity@Getter@NoArgsConstructor(access = AccessLevel.PROTECTED) // builderpublic class Quiz { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private long id; @OneToOne(fetch = FetchType.LAZY) @JsonIgnore @JoinColumn(name=\"study_id\") private Study study; @ManyToOne(fetch = FetchType.LAZY) @JsonIgnore @JoinColumn(name = \"user_id\") private User user; @Column private boolean correct; @Builder public Quiz(Study study) { this.study = study; this.correct = false; } public static Quiz addQuiz(Study study) { return Quiz.builder() .study(study) .build(); }}사용자별로 퀴즈를 생성하고 퀴즈는 학습한 기준으로 생성하기 위해 User와 Study를 추가했다.user_id → @ManyToOne : 한 사용자가 여러 개의 Quiz를 생성 가능study_id → @OneToOne : 각 Study에 대해 Quiz는 한 번만 생성 가능부모-자식 관계의 삭제 처리 특징 CascadeType.REMOVE orphanRemoval=true 부모 엔티티 삭제 부모 삭제 시 자식도 삭제됨 부모 삭제 시 자식도 삭제됨 부모 관계 끊길 시 자식 데이터는 db에 남음 관계가 끊긴 자식도 삭제됨 orphanRemoval=true를 사용하여 관계가 끊긴 자식도 삭제되도록 설정했다.orphanRemoval=true는 부모 entity에만 설정해야한다.@Entity@Getterpublic class User { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Long id; @Column private String username; @Column private String password; @OneToMany(mappedBy = \"user\", cascade = CascadeType.REMOVE, orphanRemoval=true) @JsonIgnore private List&lt;Quiz&gt; quizList = new ArrayList&lt;&gt;();}db 설계초기 설계CREATE TABLE quiz( id BIGINT AUTO_INCREMENT PRIMARY KEY, study_id BIGINT NOT NULL, correct BOOLEAN DEFAULT false, FOREIGN KEY (study_id) REFERENCES study (id) ON DELETE CASCADE)correct의 기본 값은 false로 설정했다.수정 : 사용자별 데이터 관리 추가user_id 를 추가해 사용자별로 Quiz를 괸리할 수 있도록 적용show create table quiz;출력 값 🔽CREATE TABLE `quiz` ( `id` bigint NOT NULL AUTO_INCREMENT, `study_id` bigint NOT NULL, `correct` tinyint(1) DEFAULT '0', PRIMARY KEY (`id`), KEY `study_id` (`study_id`), CONSTRAINT `quiz_ibfk_1` FOREIGN KEY (`study_id`) REFERENCES `study` (`id`) ON DELETE CASCADE) ALTER table quiz ADD COLUMN user_id BIGINT not null;UPDATE quiz set user_id=1 where quiz.user_id=0;alter table quiz add foreign key (user_id) references user (id) on delete cascade;ALTER TABLE quiz DROP FOREIGN KEY quiz_ibfk_1;alter table quiz add unique (user_id, study_id)Batch Insert와 saveAll()Study에 값을 저장할 때 같이 Quiz도 저장하면서 성능이 좋을까에 대해 의문이 생겼다.Study의 id값을 가져와서 그 값을 Quiz에 저장을 하기 때문에 최대한 성능을 좋게 하고 싶었고그 과정에서 Batch Insert를 알게되었다.save()와 saveAll()여러 건의 데이터를 insert 할 때는 saveAll()를 사용하는 것이 성능상 더 좋다.그 이유는 @Transactional 때문이다.트랜잭션에서 다른 트랜잭션이 호출될 때 어떤 방식으로 처리할지 결정하는 것을 ‘트랜잭션의 전파 설정’이라고 한다.여기서 save()와 saveAll()의 @Transactional 전파 속성은 default 속성인 ‘REQUIRED’가 적용되어 있다.REQUIRED의 경우 별도의 트랜잭션이 설정되어 있지 않다면 새로운 트랜잭션을 생성하고트랜잭션이 설정되어 있다면 해당 트랜잭션을 재사용한다.save() : 개별적으로 엔티티를 저장각 호출 마다 entity의 기본 키(@Id)를 통해 새로운 엔티티인지 isNew()를 통해 확인한다.saveAll() : 여러 entity를 한 번에 저장내부적으로 save()를 반복 호출하지만 트랜잭션 전파 속성(REQUIRED) 덕분에 부모 트랜잭션을 재사용한다.Entity State Detection StrategiesSpring Data JPA는 엔티티가 새로운지 확인하기 위한 여러 방법을 제공한다.The following table describes the strategies that Spring Data offers for detecting whether an entity is new: Option Description @Id-Property inspection (default) By default, Spring Data inspects the identifier property of the given entity.If the identifier property is null or 0 in case of primitive types,then the entity is assumed to be new.Otherwise, it is assumed to not be new. @Version-Property inspection If a property annotated with @Version is present and null,or in case of a version property of primitive type 0the entity is considered new.If the version property has a value, it is not new.If no version property is present, Spring Data falls back to the identifier property. Implementing Persistable If an entity implements Persistable, Spring Data delegatesthe new detection to the isNew(…) method of the entity.See the Javadoc for details.Note: Properties of Persistable will get detected and persisted if you use AccessType.PROPERTY.To avoid this, use @Transient. Custom EntityInformation implementation You can customize the EntityInformation abstraction by creatinga subclass of the module-specific repository factory and overriding the getEntityInformation(…) method.You then have to register the custom implementation of the repository factory as a Spring bean.Note: This is rarely necessary. docs.spring.io에서 확인할 수 있다.Spring Data JPA는 엔티티가 새로운지 확인하기 위해 isNew() 메서드를 호출한다.// SimpleJpaRepository.class @Transactional public &lt;S extends T&gt; S save(S entity) { Assert.notNull(entity, \"Entity must not be null\"); if (this.entityInformation.isNew(entity)) { this.entityManager.persist(entity); return entity; } else { return (S)this.entityManager.merge(entity); } }// AbstractEntityInformation.class public boolean isNew(T entity) { ID id = (ID)this.getId(entity); Class&lt;ID&gt; idType = this.getIdType(); if (!idType.isPrimitive()) { // wrapper class인 경우 return id == null; } else if (id instanceof Number) { // primitive type인 경우 return ((Number)id).longValue() == 0L; } else { throw new IllegalArgumentException(String.format(\"Unsupported primitive id type %s\", idType)); } }entityInformation.getId(entity)를 통해 엔티티의 ID 값을 가져온다. ID 타입 확인 ID 타입이 primitive(기본형)(long, int, …) 이면 0L인지 확인 ID 타입이 wrapper Class(Long, Integer, …) 이면 null인지 확인 새로운 엔티티 판별 ID가 null이거나 0L인 경우: 새로운 엔티티로 간주하고 persist()를 호출한다. ID가 존재하는 경우: 기존 엔티티로 간주하고 merge()를 호출한다. save()의 경우 트랜잭션 오버헤드가 발생하며 대량 데이터 저장 시 성능 저하 가능성이 있고saveAll()은 부모 트랜잭션을 재사용하므로 여러 엔티티를 효율적으로 저장해 대량 데이터 처리에 유리하다Batch InsertBatch Insert는 여러 데이터를 한 번에 삽입하는 방법이다.// 개별 InsertINSERT INTO table (col1, col2) VALUES (val1, val11);INSERT INTO table (col1, col2) VALUES (val2, val22);INSERT INTO table (col1, col2) VALUES (val3, val33);// Batch InsertINSERT INTO table (col1, col2) VALUES(val1, val11),(val2, val22),(val3, val33);IDENTITY 전략은 데이터베이스가 기본 키(PK)를 자동으로 생성하는 방식이다.INSERT SQL 실행하고 DB에서 식별자를 조회할 수 있다.Hibernate는 보통 데이터를 DB에 저장할 때 Transactional Write Behind라는 쓰기 지연 방식을 사용한다.persist()를 호출하면 Hibernate는 INSERT SQL을 즉시 실행하지 않고쓰기 지연 SQL 저장소에 해당 SQL을 보관한다.트랜잭션이 커밋되는 시점에 한꺼번에 DB에 반영한다(이 과정을 flush라고 한다).IDENTITY 전략을 사용하면 Batch Insert는 동작하지 않는다.IDENTITY 전략에서는 persist() 호출 시 Hibernate가 즉시 DB에 INSERT SQL을 실행해야 한다.DB에서 생성된 ID 값을 Hibernate가 즉시 알아야 하기 때문이다.이 과정에서 Hibernate의 쓰기 지연 방식(Transactional Write Behind)과 충돌한다.쓰기 지연 방식은 나중에 한꺼번에 DB에 반영하려고 하지만IDENTITY 전략은 persist() 시점에 바로 DB에 값을 넣고 ID를 가져와야 한다.따라서 Hibernate는 IDENTITY 전략에서 쓰기 지연을 제대로 활용할 수 없다.테이블 전략을 변경하는 방법이 있지만 다른 대안인 JdbcTemplate를 사용하여 Batch Insert를 적용했다.JdbcTemplate를 사용하여 Batch Insert 적용하기@Repository@RequiredArgsConstructorpublic class JdbcRepository { private final JdbcTemplate template; public void batchInsert(List&lt;Quiz&gt; quizList) { // 1. Insert SQL 정의 String sql = \"INSERT INTO quiz (study_id, correct, user_id) VALUES (?, ?, ?)\"; // 2. Batch Insert 실행 (sql, batchArgs, batchSize, sql ?에 들어갈 값) template.batchUpdate(sql, quizList, quizList.size(), (ps, quiz) -&gt; { // PreparedStatement의 각 파라미터 설정 ps.setLong(1, quiz.getStudy().getId()); // Study의 ID 설정 ps.setBoolean(2, quiz.isCorrect()); // Correct 상태 설정 ps.setLong(3, quiz.getUser().getId()); // User의 ID 설정 }); }}saveAll에 비해 성능이 좋은지 실제 application을 실행하면서 시간을 측정해봤다.시간 단위는 나노초이며, 데이터 10번 저장을 5번 실행해 정리했다. Batch Insert saveAll 19426400 14945400 5702800 11311400 8972900 13566300 7505200 10237300 7945800 11400300 가장 오래 걸렸던 시간은 각각 0.019426초, 0.014945초 였고가장 짧게 걸렸던 시간은 각각 0.0057028초, 0.010237초 였다.saveAll() 보다 Batch Insert가 평균적으로 더 빠른 성능을 보였기 때문에 Batch Insert로 적용했다.Test 코드 작성테스트 환경 설정 변경1. IntelliJ IDEA 변경Gradle로 되어있어서 IntelliJ IDEA로 변경2. gradle 확인// 변경 전tasks.named('test') { useJUnitPlatform()}// 변경 후test { useJUnitPlatform()}위 설정을 제대로 하지 않으면Execution failed for task ‘:test’. &gt; There were failing tests. See the report at: 와 같은 오류가 뜬다.-parameters 옵션 설정TEST 코드를 실행하기 위해서 IntelliJ IDEA로 변경했었다.이렇게 변경 하고 나니 application 실행 할 때 아래와 같은 오류가 떴다.Name for argument of type [java.lang.String] not specified, and parameter name information not available via reflection.Ensure that the compiler uses the ‘-parameters’ flag*찾아보니 Gradle을 사용하면 -parameters 옵션이 자동으로 적용되는데 IntelliJ IDEA는 자동이 아니라서 생긴 문제였다.위와 같이 적용 후 /out 폴더를 삭제 후 컴파일되며 옵션을 적용시킨다.REFERENCE save와 saveall JPA save, saveAll 성능 차이가 발생하는 이유 [JPA]는 새로운 엔티티를 어떻게 알아볼까?Batch Insert Spring JDBC를 사용하여 Batch Insert 수행하기 [Batch Insert] 대량 데이터 Insert 성능 최적화 (JPA batch size / JDBCTemplate batch Insert / Mybatis batch Insert) [JPA/MySQL] saveAll() 쓰면 쿼리 하나로 나가는 거 아니었어? / JPA에서 Bulk Insert 처리해보기 [Spring Boot] 정기 푸시 알림(Push Notification) 전송 배치(Batch) 프로세스Test Execution failed for task ‘:test’. &gt; There were failing tests. See the report at:오류 Name for argument of type [java.lang.String] not specified [Spring/Error] Name for argument of type, @PathVariable name 생략 에러" }, { "title": "단어 학습 기능 개선", "url": "/posts/%EB%8B%A8%EC%96%B4-%ED%95%99%EC%8A%B5-%EA%B8%B0%EB%8A%A5-%EA%B0%9C%EC%84%A0/", "categories": "Eng-Project", "tags": "log, Redis", "date": "2024-11-26 00:00:00 +0900", "snippet": "단어 학습 기능 개선학습해야 할 단어를 효과적으로 관리하기 위해 Redis를 활용해 캐싱 기능을 도입하고학습 데이터를 조회 및 저장하는 방식을 개선했다.이번 글에서는 문제 해결 과정과 주요 구현 내용을 정리했다.전체 코드는 여기에서 확인 할 수 있다.문제점 발견사용자가 하루에 학습해야 할 10개의 단어 중 일부(예: 8개)만 학습했을 경우퀴즈는 이미 학습한 단어에 대해서만 제공되어야 한다.구현 메소드참고로 기존에는 getStudyWord()만 존재했으며 10개씩 조회하고해당 조회한 단어 목록을 한꺼번에 Study 테이블에 저장했으며,Study 테이블에 저장된 날짜가 오늘 날짜일 경우 오늘 날짜에 해당하는 데이터를 10개 가져오게 작성했었다.1. getStudyWord() : 학습 데이터 조회오늘 학습 데이터가 있는 경우, Study 테이블에서 데이터를 조회한다.부족한 데이터는 findNotInStudy()로 조회한다.조회한 데이터를 Redis 캐시에 저장한다.이 cache는 이후 Study 테이블을 저장하는 saveStudyWord()에서 쓰인다.if(오늘 날짜가 아니라면) { findNotInStudy();}else{ List&lt;Study&gt; study = studyRepository.findLastDayForStudy(today, user.getId()); // 오늘날짜에 학습한 데이터 조회 if (study.size() &lt; 10) { findNotInStudy(); }}redisService.addStudyList(username, studyList);2. findNotInStudy() : 학습하지 않은 데이터 조회최신 학습 날짜가 오늘이 아니거나 데이터가 10개 미만일 경우 부족한 데이터를 채운다.Pageable pageable = PageRequest.of(0, len);3. saveStudyWord() : 학습 데이터 저장사용자가 학습한 데이터를 Study 테이블에 저장한다.Redis에서 캐시 데이터를 가져와 DB에 저장후 캐시에 남은 데이터를 update한다.List&lt;StudyDto&gt; studiesToSaveDto;List&lt;StudyDto&gt; remainingCache;// 저장할 데이터와 Redis에 남길 데이터를 분리 studiesToSaveDto = new ArrayList&lt;&gt;(cachedStudyList.subList(0, endIndex));remainingCache = new ArrayList&lt;&gt;(cachedStudyList.subList(endIndex, cachedStudyList.size()));// DTO → Entity 변환 후 DB 저장 List&lt;StudyDto&gt; studiesToSave = cachedStudyList.stream() .map(dto -&gt; Study.createStudy(...)) .toList();studyRepository.saveAll(studiesToSave);// Redis Cache 업데이트redisService.addStudyList(username, remainingCache);4. generateStudyList() : 학습할 단어 생성Redis 캐시에 값이 없을 경우 DB에서 학습하지 않은 단어를 조회해 캐싱한다.오늘 날짜에 저장된 단어 개수를 확인한다.부족한 데이터는 DB에서 조회 후 읽은 단어는 Study 테이블에 저장하고 읽지 않은 단어는 Redis 캐시에 저장한다.Pageable pageable = PageRequest.of(0, 10-startPage);Page&lt;Object[]&gt; results = meanRepository.findByMeanForStudyWithSentence(user.getId(), pageable);flow : 1. 단어 학습 완료 후 모달 종료사용자가 학습을 마치면 마지막으로 읽은 단어를 기준으로 페이지 번호(maxPage)를 서버로 전달한다.2. startIndex 설정Redis에서 maxPage 값을 확인하고 없으면Study 테이블에서 오늘 날짜 기준 데이터 개수를 startIndex로 설정한다.3. 데이터 조회 및 저장 Redis 캐시에 학습할 단어 목록이 있는 경우 캐시 데이터에서 startIndex ~ maxPage 사이 데이터를 Study 테이블에 저장 캐시에서 저장된 데이터를 제거하고 남은 데이터를 Redis에 update Redis 캐시에 값이 없는 경우 generateStudyList()를 호출해 학습하지 않은 단어를 DB에서 조회한 후 처리 4. Front에서 서버 요청 최소화프론트엔드에서도 LocalStorage를 활용해 다음 정보를 관리한다. 사용자가 학습하는 단어 목록 사용자가 최대 읽은 페이지 수(maxPage) 페이지 수 갱신 여부이로써 서버 요청을 최소화했다.오류와 해결직렬화(Serialization) : 객체 데이터를 통신하기 쉬운 포맷(Byte, CSV, Json) 형태로 만들어주는 작업Java 객체를 JSON으로 변환하는 과정ex) User user = new User(\"hi\"); → {\"nickname\" : \"hi\"}역직렬화(Deserialization) : 포맷(Byte, CSV, Json) 형태에서 객체로 변환하는 과정JSON을 Java 객체로 변환하는 과정ex) {\"nickname\" : \"hi\"} 데이터를 받아서 User라는 객체의 nickname에 “hi”를 할당하고 객체를 생성1. Redis 데이터 null 값 반환문제Redis에 저장된 값을 가져왔을 때 모든 값이 null로 표시되었다.원인은 Redis가 데이터를 직렬화/역직렬화 과정에서 발생한 문제였다.원인Redis는 데이터를 직렬화하여 저장하고 가져올 때 역직렬화한다.GenericJackson2JsonRedisSerializer는 데이터를 직렬화하면서 @Class라는 키로 클래스의 패키지 정보를 함께 저장한다.특히 리스트를 저장할 경우 {“@class”:”..”} 형태가 아닌다음과 같은 형태로 저장되어 패키지를 제대로 인식하지 못하는 상황이 발생했다{\"@class\":\"java.util.ArrayList\", \"values\":[{\"@class\":\"...\"}]}이후 DTO로 수정하면서 아래와 같은 새로운 오류를 접했다.2. No serializer found 오류com.fasterxml.jackson.databind.exc.InvalidDefinitionException: No serializer found for class org.hibernate.proxy.pojo.bytebuddy.ByteBuddyInterceptorLazy 로딩된 엔티티를 Jackson이 JSON으로 변환하지 못해 발생(Serialize)해결 과정방법 1) : @JsonIgnore 적용Lazy 로딩 컬럼에 대해 직렬화를 무시하도록 오류가 나는 컬럼에 @JsonIgnore를 적용하면 되지만 이미 적용을 한 상태였다.@JsonIgnore은 JSON 직렬화, 역직렬화 작업에서 무시된다. @JsonIgnore : 클래스의 속성(필드, 멤버변수) 수준에서 사용 @JsonIgnoreProperties : 클래스 수준(클래스 선언 바로 위에)에 사용 @JsonIgnoreType : 클래스 수준에서 사용되며 전체 클래스를 무시방법 2) Hibernate5Module 을 스프링 Bean으로 등록현재 코드의 로딩 전략은 지연로딩(LAZY)전략을 사용한다.User, Word 엔티티들을 조회하는 시점에서는 실제 객체가 아닌 프록시 객체를 가지고 있다.그렇기 때문에 jackson 라이브러리는 기본적으로이 프록시 객체를 json으로 어떻게 생성해야 하는지 모르기 때문에 예외가 발생하는 것이다.따라서 Hibernate의 Proxy 객체를 JSON으로 읽을 수 있게 Jackson의 Hibernate5Module을 등록했다.Hibernate5Module을 스프링 Bean으로 등록하면… 해결될 줄 알았다.implementation 'com.fasterxml.jackson.datatype:jackson-datatype-hibernate5' @Bean public ObjectMapper objectMapper() { ObjectMapper mapper = new ObjectMapper(); mapper.registerModule(new Hibernate5Module()); // Hibernate 모듈 등록 return mapper; } @Bean public RedisTemplate&lt;String, List&lt;StudyDto&gt;&gt; studyWordsRedisTemplate() { RedisTemplate&lt;String, List&lt;StudyDto&gt;&gt; redisTemplate = new RedisTemplate&lt;&gt;(); redisTemplate.setConnectionFactory(redisConnectionFactory()); redisTemplate.setKeySerializer(new StringRedisSerializer()); redisTemplate.setValueSerializer(new GenericJackson2JsonRedisSerializer(objectMapper())); return redisTemplate; }하지만 여전히 No serializer found for class org.hibernate.proxy.pojo.bytebuddy.ByteBuddyInterceptor and no properties discovered to create BeanSerializer 오류가 떴다.해결Lazy 로딩된 엔티티의 모든 참조를 제거하고 필요한 ID 값만 저장하도록 DTO를 평면화했다.3. LocalDate 직렬화/역직렬화 오류Jackson이 LocalDate 타입을 처리하지 못해 다음과 같은 오류가 발생했다.Java 8 date/time type java.time.LocalDate not supported by default:LocalDataTime을 역직렬화하지 못해서 생기는 오류이다.해결 방법1) 의존성 추가 JavaTimeModule을 Jackson에 등록해 Java 8 날짜/시간 타입을 처리할 수 있도록 설정했다.implementation 'com.fasterxml.jackson.datatype:jackson-datatype-jsr310'implementation 'com.fasterxml.jackson.core:jackson-databind'2) 어노테이션 적용필드에 직렬화/역직렬화를 담당하는 어노테이션을 추가했다.@JsonSerialize(using = LocalDateSerializer.class)@JsonDeserialize(using = LocalDateDeserializer.class)private LocalDate date;3) ObjectMapper 설정ObjectMapper는 Java에서 JSON을 다루는 데 사용되는 Jackson 라이브러리의 주요 클래스다.주로 JSON과 Java 객체 간의 변환(즉, 직렬화 및 역직렬화)을 담당한다.날짜/시간 타입의 데이터를 처리하기 위해 추가해야 하는 모듈은 JavaTimeModule이다.JavaTimeModule은 Java 8에 도입된 새로운 날짜 및 시간 API(LocalDate, LocalTime, LocalDateTime)를Jackson 라이브러리에서 처리할 수 있게 해주는 모듈이다.기본적으로 Jackson 라이브러리는 Java 8의 새로운 날짜 및 시간 타입들을 인식하지 못하기 때문에해당 타입들을 JSON으로 직렬화하거나 JSON에서 역직렬화할 때 문제가 발생할 수 있다.이러한 문제를 해결하기 위해 JavaTimeModule을 ObjectMapper에 등록하면날짜/시간 타입들을 적절하게 직렬화하고 역직렬화할 수 있게 된다.@Beanpublic RedisTemplate&lt;String, List&lt;StudyDto&gt;&gt; studyWordsRedisTemplate() { RedisTemplate&lt;String, List&lt;StudyDto&gt;&gt; redisTemplate = new RedisTemplate&lt;&gt;(); redisTemplate.setConnectionFactory(redisConnectionFactory()); redisTemplate.setKeySerializer(new StringRedisSerializer()); ObjectMapper objectMapper = new ObjectMapper(); objectMapper.registerModule(new JavaTimeModule()); // For date/time if needed redisTemplate.setValueSerializer(new GenericJackson2JsonRedisSerializer(objectMapper)); return redisTemplate;}참고)objectMapper.configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, false);/*deserialize시 알지 못하는 property가 오더라도 실패하지 않도록 처리 ex. User에 username이 없는 경우 Json에 usernmae이 들어있을 때 위 설정이 없을 경우 exception 발생*/objectMapper.configure(DeserializationFeature.FAIL_ON_NULL_FOR_PRIMITIVES, false);/*default 값이 falsetrue : json에서 null인 값이 전달 되는 경우 exception 발생*/4. java.util.LinkedHashMap cannot be cast to classServlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed: java.lang.ClassCastException: class java.util.LinkedHashMap cannot be cast to class문제 : 명확한 타입 설정 XGenericJackson2JsonRedisSerializer는 내부적으로 ObjectMapper를 생성하며기본적으로 아래와 같이 DefaultTyping을 활성화한다.ObjectMapper objectMapper = new ObjectMapper();objectMapper.activateDefaultTyping( objectMapper.getPolymorphicTypeValidator(), ObjectMapper.DefaultTyping.NON_FINAL);GenericJackson2JsonRedisSerializer를 사용해 범용적인 Redis 캐싱을 구현하면서구체적인 타입을 지정하지 못하고 역직렬화할 클래스의 타입을 Object 타입으로 넘기고 있었다.원인역직렬화의 타입을 Object로 적용 시배열 또는 컬렉션 타입의 데이터를 역직렬화하지 못하는 문제가 발생한다.Jackson에서 제공하는 DefaultTyping 옵션이 JSON에 구체적인 타입 정보를 포함하지 않기 때문이다.Jackson은 기본적으로 ObjectMapper.readValue()에 전달된 타입 정보를 기반으로 역직렬화를 수행한다.GenericJackson2JsonRedisSerializer는 타입 정보를 JSON에 포함하지만명시적으로 @class 속성을 추가하지 않기 때문에 문제가 발생할 수 있다.해결 방법: JSON에 타입 정보 포함하기JsonTypeInfo.As.PROPERTY를 사용하면 JSON 내부에 타입 정보를 속성으로 포함시킬 수 있다.{ \"@class\": \"com.eng.StudyDto\", \"userId\": \"1\", \"wordId\": \"55\"}다음과 같이 설정하여 Jackson이 타입 정보를 처리할 수 있도록 했다.objectMapper.activateDefaultTyping( objectMapper.getPolymorphicTypeValidator(), // 안전한 타입 검증 활성화 (ex. @class) ObjectMapper.DefaultTyping.NON_FINAL, // NON_FINAL 타입 정보 포함 JsonTypeInfo.As.PROPERTY // JSON 내부에 타입 정보 추가 (@class 속성) );Option만약 유효성 검사를 수행하지 않고 모든 하위 유형을 허용하고 싶다면objectMapper.getPolymorphicTypeValidator() 대신 LaissezFaireSubTypeValidator.instance를 작성하면 된다.objectMapper.activateDefaultTyping( LaissezFaireSubTypeValidator.instance, ObjectMapper.DefaultTyping.NON_FINAL, JsonTypeInfo.As.PROPERTY);하지만 보안적인 측면에서 위험할 수 있다. (test 환경에서만 사용 권장)DefaultTyping: JSON에 타입 정보를 저장할 범위를 설정하는 옵션ObjectMapper.DefaultTyping.NON_FINAL은 모든 non-final 클래스를 대상으로 타입 정보를 포함시킨다.→ Dto, Entity(해당 클래스에서 final을 사용하거나 다른 클래스에서 final로 선언되지 않은 경우)enableDefaultTyping은 더 이상 사용하지 않으므로 activateDefaultTyping로 작성했다.5. Duplicate entry 유니크 제약 조건 충돌ex) Duplicate entry ‘1-67-25’ for key ‘study.user_id’Study에서 unique 제약 조건으로 user_id + word_id + meaning_id을 설정했었다.그런데 단어와 뜻은 같아도 예문을 여러 개 저장할 수 있게 설정했었는데 그 부분을 인지 못하고 있었다가 오류를 접했다.그래서 Study 테이블에 Sentence를 넣는 것으로 코드를 수정했다.ALTER TABLE study ADD COLUMN sentence_id BIGINT NOT NULL;-- 기존 `sentence_id`가 유효하지 않다면 1로 설정UPDATE study SET sentence_id = 1 WHERE sentence_id = 0; -- 1로 채우기 -- `sentence_id`에 대한 외래 키 제약 추가ALTER TABLE study ADD FOREIGN KEY (sentence_id) REFERENCES sentence (id) ON DELETE CASCADE;-- 기존 `user_id`에 대한 UNIQUE 제약 제거 및 새로운 UNIQUE 제약 추가ALTER TABLE study DROP INDEX user_id, ADD UNIQUE (user_id, word_id, meaning_id, sentence_id); [23000][1452] Cannot add or update a child row: a foreign key constraint fails (eng.#sql-2018_500, CONSTRAINT study_ibfk_4 FOREIGN KEY (sentence_id) REFERENCES sentence (id) ON DELETE CASCADE)외래 키 제약을 추가하려고 보니 오류가 떠서 id값을 1로 채운 후 동작했더니 오류가 뜨지 않았다.CREATE TABLE study( id BIGINT AUTO_INCREMENT PRIMARY KEY, user_id BIGINT NOT NULL, word_id BIGINT NOT NULL, meaning_id BIGINT NOT NULL, sentence_id BIGINT NOT NULL, FOREIGN KEY (user_id) REFERENCES user (id) ON DELETE CASCADE, FOREIGN KEY (word_id) REFERENCES word (id) ON DELETE CASCADE, FOREIGN KEY (meaning_id) REFERENCES meaning (id) ON DELETE CASCADE, FOREIGN KEY (sentence_id) REFERENCES sentence (id) ON DELETE CASCADE, UNIQUE user_id (user_id, word_id, meaning_id, sentence_id) -- 특정 단어-뜻-예문 중복 학습 방지);REFERENCE API 개발 고급 - 지연 로딩과 조회 성능 최적화 List 역직렬화 해결 @JsonIgnore, @JsonIgnoreProperties, @JsonIgnoreType차이점 JAVA 직렬화(Serialization)과 역직렬화(Deserialization)오류와 해결 - 3. LocalDate 직렬화/역직렬화 오류 스프링 Java 8 LocalDateTime 직렬화 역직렬화 오류(1) [Spring] ObjectMapper에서 LocalDateTime이 변환되지 않는 문제 [Spring + Jackson] Spring Boot에서는 왜 FAIL_ON_UNKNOWN_PROPERTIES default 옵션을 false로 사용하는가 ? Jackson ObjectMapper 정리오류와 해결 - 4. java.util.LinkedHashMap cannot be cast to class Spring Redis 역직렬화 삽질기 (feat. RedisSerializer) Jackson 직렬화 옵션의 적절한 활용과 Jackson에 기여하기까지 (feat. 글로벌 캐싱) [Spring] 스프링이 제공하는 레디스 직렬화/역직렬화(Redis Serializer/Deserializer)의 종류와 한계 및 개선법" }, { "title": "Redis cache를 활용한 학습 데이터", "url": "/posts/Redis-Cache%EB%A5%BC-%ED%99%9C%EC%9A%A9%ED%95%9C-%ED%95%99%EC%8A%B5-%EB%8D%B0%EC%9D%B4%ED%84%B0/", "categories": "Eng-Project", "tags": "log, Redis", "date": "2024-11-17 00:00:00 +0900", "snippet": "Redis Cache 적용 : Redis Cache를 활용한 학습 데이터 TTL 관리단어 학습 기능을 구현하며 오늘 학습할 단어는 반복 조회가 가능해야하고이전(yesterday) 또는 이후 학습할 단어(tomorrow)와 명확히 구분되도록 해야 했다.이를 해결하기 위해 Redis Cache를 도입했다.캐시를 활용하며 발생할 수 있는 다양한 예외 상황을 고려한 뒤자정까지 남은 시간을 TTL(Time-To-Live)로 설정 + 학습한 데이터는 즉시 Study 테이블에 db 저장하는 방식을 채택했다.Redis Cache 도입 배경학습 기능 구현 시 다음과 같은 요구사항을 충족해야 했다.1. 오늘 학습할 단어는 당일 동안 계속 조회될 수 있어야 한다.2. 자정 이후에는 새로운 학습 단어 목록이 제공되어야 한다.3. 데이터베이스(DB) 조회를 최소화해야 한다.이를 해결하기 위해 Redis Cache를 적용하고 자정까지 남은 시간을 TTL로 설정했다.[Redis Cache Config]TTL을 오늘 자정까지 남은 시간으로 설정[Service]@Cacheable을 활용하여 db 조회 최소화&lt;method&gt;Study 테이블에서 가장 최근 날짜 컬럼을 조회해서if (만약 오늘 날짜가 아니라면) { 1. 기존 로직과 동일하게 조회 2. Study에 해당 목록들을 db에 저장한다.} else { // 오늘 날짜라면 Study에서 오늘 날짜에 해당하는 단어 목록을 가져와서 reutrn한다.}구현 과정1. EntityStudy 테이블에 학습 날짜를 구분하기 위한 date 컬럼을 추가했다.@Columnprivate LocalDate date;SQL 변경ALTER TABLE study ADD COLUMN date DATE;2. Redis Cache Config 설정TTL은 오늘 자정까지 남은 시간을 계산하여 설정했다.@Configuration@EnableCaching // 캐시 기능 활성화public class RedisConfig { @Value(\"${spring.data.redis.host}\") private String redisHost; @Value(\"${spring.data.redis.port}\") private int redisPort; @Bean public RedisConnectionFactory redisConnectionFactory() { return new LettuceConnectionFactory(redisHost, redisPort); } @Bean public CacheManager cacheManager() { // 자정까지 남은 시간을 계산 LocalTime midnight = LocalTime.MIDNIGHT; Duration ttl = Duration.between(LocalDateTime.now(), LocalDateTime.now().toLocalDate().atTime(midnight).plusDays(1)); RedisCacheConfiguration cacheConfig = RedisCacheConfiguration.defaultCacheConfig() .disableCachingNullValues() .serializeKeysWith(RedisSerializationContext.SerializationPair.fromSerializer(new StringRedisSerializer())) .serializeValuesWith(RedisSerializationContext.SerializationPair.fromSerializer(new GenericJackson2JsonRedisSerializer())) .entryTtl(ttl); // 자정까지 남은 시간을 TTL로 설정 return RedisCacheManager.builder(redisConnectionFactory()) .cacheDefaults(cacheConfig) .build(); }}3. DB 조회 쿼리1. 가장 최근 날짜를 조회하기 위해 max() 사용@Query(\"SELECT max(s.date) FROM Study s WHERE s.user.id = :userId\")LocalDate findLastDay(Long userId);2. 오늘 날짜의 학습 데이터 조회@Query(\"select s from Study s where s.date = :today and s.user.id = :userId\")List&lt;Study&gt; findLastDayForStudy(LocalDate today, Long userId);3. meaningId에 해당하는 Sentence 데이터 조회@Query(\"select st from Sentence st where st.meaning.id = :meaningId\")Sentence findBySentence(Long meaningId);4. Service@Cacheable(key=\"#username\", value = \"getStudyWord\", unless = \"#result==null\", cacheManager = \"cacheManager\")public List&lt;StudyResponseDto&gt; getStudyWord(String username) { LocalDate date = studyRepository.findLastDay(user.getId()); LocalDate today = LocalDate.now(); if( date==null || !date.isEqual(today) ){ // 오늘 날짜가 아니라면 학습하지 않은 데이터 10개 조회 // 기존 로직 생략 studyRepository.saveAll(studyList); // study 테이블에 데이터 저장 } else { // 오늘 날짜라면 Study 테이블에서 조회 List&lt;Study&gt; study = studyRepository.findLastDayForStudy(today, user.getId()); }}@Cacheable을 활용해 DB 조회를 최소화했다.오늘 날짜와 가장 최근 학습 날짜를 비교해 조건에 따라 DB에서 데이터를 조회하거나 새 데이터를 생성했다.TTL 값 검증TTL 설정이 제대로 적용되었는지 확인하기 위해 아래 코드를 작성했다.LocalTime midnight = LocalTime.MIDNIGHT;Duration ttl = Duration.between(LocalDateTime.now(), LocalDateTime.now().toLocalDate().atTime(midnight).plusDays(1));log.info(\"ttl : \" + ttl); // ttl : PT27M40.0414405S (출력 예시) P : “Period”를 나타내는 시작 문자 (기간을 나타냄) T : 시간 정보를 시작하는 표시 H: 시간(hours) M: 분(minutes) S: 초(seconds)27M → 27분40.0414405S → 40초와 소수점 이하로 0.0414405초를 의미PT27M40.0414405S는 현재 시점에서 자정까지 남은 시간이 27분 40초 정도 남았다고 보면 된다.Front : LocalStorage TTL 설정서버에 단어를 요청하기 전에 localStorage에 값이 있는지 체크해 서버 요청을 최소화 시켰었다.하지만 학습 단어 데이터는 하루 동안 유효하므로 localStorage에 TTL을 설정했다.localStorage TTL 설정function getStudyWords(){ // 일부 코드 생략 const now = new Date(); const midnight = new Date(now.getFullYear(), now.getMonth(), now.getDate() + 1, 0, 0, 0); // 다음 날 자정 const ttl = midnight.getTime() - now.getTime(); // 밀리초 단위 남은 시간 setTTL(username,JSON.stringify(response), ttl)}function setTTL(username, value, ttl){ const expiry = Date.now() + ttl; // 현재 날짜 + TTL(ms) const item = { value, // 저장할 데이터 expiry // 만료 시간 }; localStorage.setItem(username, JSON.stringify(item));}Redis Cache와 LocalStorage를 활용해 학습 단어의 유효 기간을 관리함으로써 서버와 DB의 부하를 최소화했다.특히 오늘 자정까지 남은 시간을 TTL로 설정함으로써 학습 데이터의 유효성을 유지하는 동시에 효율성을 확보할 수 있었다." }, { "title": "성능 최적화 요약", "url": "/posts/%EC%84%B1%EB%8A%A5-%EC%B5%9C%EC%A0%81%ED%99%94-%EC%9A%94%EC%95%BD/", "categories": "Project, Chat", "tags": "log, Chat", "date": "2024-11-13 00:00:00 +0900", "snippet": "성능 최적화 요약Chat ProjectChat Project를 진행하면서 성능 개선을 위해 여러 가지 최적화 작업을 진행했다.이를 통해 로딩 시간, 조회 속도 및 응답 시간을 크게 개선했다.아래는 각 주요 최적화 작업과 성능 테스트 결과의 요약이다.더 자세한 내용은 관련 링크에서 확인할 수 있다.1. 채팅 기록 파일 조회 속도 개선2. 채팅 기록 파일 조회 횟수 감소3. Broker 적용 : STOMP 프로토콜을 지원하는 RabbitMQ Broker 적용4. db 조회 횟수 감소 : 채팅을 하는데 필요한 정보들을 Redis Cache를 활용해 db 조회 횟수 감소1. 채팅 기록 파일 조회 속도 개선처음에는 줄바꿈을 포함해 사람이 읽기 쉬운 형태로 채팅 기록 파일을 저장했다.하지만 데이터가 쌓이면서 조회 속도가 점차 느려졌고 사용자가 불편할 정도로 로딩 시간이 길어졌다.이를 개선하기 위해 채팅 기록을 한 줄로 저장하는 방식으로 변경했고 이를 통해 조회 속도가 크게 개선되었다.관련 글 : Jmh2. 채팅 기록 파일 조회 횟수 감소초기에는 채팅 버튼을 반복해서 열고 닫을 때마다 마지막 메시지를 매번 조회하는 비효율적인 방식이었다.이를 개선하기 위해 가장 최근 메시지를 HashMap에 저장해 두고채팅창을 열 때 db 조회 대신 Map에 저장된 값을 참조하도록 변경했다.마지막 글을 조회할 때 hashMap에 해당 기록을 저장하고 채팅을 할 때마다 해당 내용을 update했다.그 결과, Map 사용 시 조회 속도가 현저히 개선되었다. Map 미사용: 0.283초 (283,892,100 나노초) Map 사용: 0.017초 (17,185,200 나노초)관련 글 : Jmh, 마지막 글 조회3. Broker 적용 : STOMP 프로토콜을 지원하는 RabbitMQ Broker 적용Stomp 프로토콜을 사용할 때 기본적으로 In-Memory Message Broker를 사용했는데In-Memory Message Broker는 용량 제한, 메시지 유실 가능성, 모니터링 어려움 등의 문제점이 있었다.이를 개선하고자 외부 메시지 브로커인 RabbitMQ를 도입했다.관련 글 : RabbitMQ4. db 조회 횟수 감소Redis Cache를 활용해 자주 참조되는 데이터를 메모리에 저장하여 DB 조회 횟수를 줄였다.전체 값을 캐싱할 때는 @Cacheable과 같은 어노테이션을 사용했으며일부 값만 필요할 때는 RedisTemplate을 활용했다.이를 통해 최소한의 DB 조회만 하도록 코드를 작성했다.관련 글 : Redis Cache추가로 채팅의 마지막 메시지(LastMessage)는 항상 최신 데이터를 가지고 있어야 했다.초기에는 @Cacheable을 사용하려 했으나 캐시 갱신을 위해 @CachePut을 적용했다.하지만 메서드를 항상 실행되는 @CachePut가 실제로 캐시의 효율성을 높이는지 고민이 되었고두 가지 캐시 접근 방식의 성능을 테스트했다.테스트는 Controller에서 Service 로직 실행 후 응답 시간을 측정하는 방식으로 진행했다.1. @CachePut 사용2. RedisTemplate을 사용해 LastMessage만 제외하고 나머지 값만 캐시에 저장하는 방식@CachePut 적용 코드@CachePut(key = \"#nickname\", value = \"createRoom\", unless = \"#result == null\", cacheManager = \"cacheManager\")public ChatRoomDto createRoom(String nickname) { // 코드 생략}RedisTemplate 적용 코드// 일부 코드는 생략했다. public ChatRoomDto createRoom(String nickname) { if (!chatRepository.existsByUserId(user.getId())) { redisService.addCreateRoom(\"createRoom::\"+nickname, chatRoom); return chatRoom; } else { ChatRoomDto cachedChatRoomDto = redisService.getCreateRoom(\"createRoom::\" + nickname); if (cachedChatRoomDto != null) { cachedChatRoomDto.setLastMessage(getLastMessage(cachedChatRoomDto.getRoomId())); return cachedChatRoomDto; } else { log.info(\"[createRoom] cache 적용 x\"); redisService.addCreateRoom(\"createRoom::\"+nickname, chatRoom); return ChatRoomDto.of(user, lastLine); } }}성능 테스트 결과실행 시간은 나노초 단위로 측정되었으며 아래는 초 단위로 변환한 결과다. Map 활용 x + @CachePut : 0.089초 (89473300 나노초) Map 활용 o + @CachePut : 0.018초 (17525700 나노초) Map 활용 x + RedisTemplate : 0.051초 (51041600 나노초) Map 활용 o + RedisTemplate : 0.009초 (8879100 나노초) 테스트 결과 RedisTemplate을 활용한 방식이 @CachePut보다 응답 속도가 더 빨랐다.그 이유에 대해서 추측해보자면@CachePut은 메서드가 실행될 때마다 전체 반환값을 캐시에 갱신하면서 변하지 않는 고정 데이터까지 불필요하게 업데이트를 하게된다.반면 RedisTemplate을 활용한 로직은 고정된 데이터만 캐시에 저장하고 변동되는 데이터(LastMessage)만 조회한다.이 방식은 변하지 않는 데이터를 불필요하게 갱신하지 않아 더 효율적이며Map과 함께 사용해 자주 접근하는 데이터를 메모리에 유지하고변동되는 데이터만 별도로 갱신할 수 있어 성능을 개선할 수 있었던 것 같다." }, { "title": "단어 학습하기", "url": "/posts/%EB%8B%A8%EC%96%B4-%ED%95%99%EC%8A%B5%ED%95%98%EA%B8%B0/", "categories": "Eng-Project", "tags": "log, excel", "date": "2024-11-08 00:00:00 +0900", "snippet": "단어 학습하기이 전에는 엑셀을 통해 db를 저장했다면 이제는 해당 db를 활용해 단어를 학습하는 기능을 구현했다.전체코드는 eng에서 확인할 수 있다.구현 동작 예시주요 기능 구현 사항1. 사용자가 학습하지 않은 단어 조회2. 사용자가 학습한 단어 저장DB 설계단어 학습 기능을 구현하기 위해 user_id와 word_id가 필요하다.User와 Word는 다대다 관계(N:M)를 가지며 (사용자는 여러 단어를 학습할 수 있고 단어는 여러 사용자가 학습할 수 있다.)사용자와 단어 간의 학습 기록을 저장하기 위해 중간 테이블인 Study를 추가했다.관계 설정 User - Study : 사용자는 여러 단어를 학습할 수 있다. Word - Study : 각 단어는 여러 사용자가 학습할 수 있다.테이블 생성 과정UserCREATE TABLE user( id BIGINT AUTO_INCREMENT PRIMARY KEY, username VARCHAR(30) NOT NULL, password VARCHAR(50) NOT NULL);Study 테이블 생성🔽 최종CREATE TABLE study( id BIGINT AUTO_INCREMENT PRIMARY KEY, user_id BIGINT NOT NULL, word_id BIGINT NOT NULL, meaning_id BIGINT NOT NULL, -- 뜻(meaning)을 기준으로 학습 이력을 기록 FOREIGN KEY (user_id) REFERENCES user (id) ON DELETE CASCADE, FOREIGN KEY (word_id) REFERENCES word (id) ON DELETE CASCADE, FOREIGN KEY (meaning_id) REFERENCES meaning (id) ON DELETE CASCADE, UNIQUE user_id (user_id, word_id, meaning_id) -- 특정 단어-뜻 중복 학습 방지);초기 버전CREATE TABLE study( id BIGINT AUTO_INCREMENT PRIMARY KEY, user_id BIGINT NOT NULL, word_id BIGINT NOT NULL, FOREIGN KEY (user_id) REFERENCES user (id) ON DELETE CASCADE, FOREIGN KEY (word_id) REFERENCES word (id) ON DELETE CASCADE, UNIQUE (user_id, word_id) -- 중복 학습 방지);초기에는 단순히 user_id와 word_id만으로 유니크 제약 조건을 설정했으나단어에 여러 뜻이 있는 경우를 고려하지 않아이후 뜻(meaning) 기준으로 학습 이력을 관리하도록 meaning_id를 추가했다.중복을 방지하기 위해 기존 유니크 조건을 user_id, word_id, meaning_id 조합으로 변경했다.ALTER TABLE studyADD COLUMN meaning_id BIGINT NOT NULL;ALTER TABLE studyADD FOREIGN KEY (meaning_id) REFERENCES meaning (id) ON DELETE CASCADE;제약조건 확인기존의 유니크 제약 조건 이름을 따로 설정하지 않아서 dbms가 자동으로 생성한 이름을 확인한다.USE eng; -- USE [DB_NAME];SHOW CREATE TABLE study; -- SHOW CREATE TABLE [TABLE_NAME];user_id 임을 확인해서 아래와 같이 실행했다.ALTER TABLE studyDROP INDEX user_id,ADD UNIQUE (user_id, word_id, meaning_id);학습하지 않은 단어 조회Entity@Getter@Entity@Table( // 복합 unique key 설정 name = \"study\", uniqueConstraints = @UniqueConstraint(columnNames = {\"user_id\", \"word_id\",\"meaning_id\"}))public class Study { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private long id; @ManyToOne(fetch = FetchType.LAZY, cascade = CascadeType.REMOVE) @JoinColumn(name = \"user_id\") private User user; @ManyToOne(fetch = FetchType.LAZY, cascade = CascadeType.REMOVE) @JoinColumn(name = \"user_id\") private Word word; @Builder private Study(User user, Word word) { this.user = user; this.word = word; } public static Study createStudy(User user, Word word) { return Study.builder() .user(user) .word(word) .build(); }}user_id는 여러 study를 가질 수 있다. → 1:N 관계💡다대다 관계에서 @ManyToMany를 사용하면 안 되는 이유1. 카테시안 곱 문제다대다 관계의 조인은 RDB에서 카테시안 곱을 발생시켜 예상하지 못한 쿼리가 발생할 수 있다.2. 중간 테이블의 한계JPA의 @ManyToMany 관계를 사용할 경우 자동으로 생성되는 중간 테이블은두 테이블의 외래 키(a_id, b_id)만으로 구성된다.이 때 중간 테이블은 연결된 각각의 테이블에 대한 키값을 가지고 있을 뿐실무에서 필요한 여러 추가 정보를 포함 할 수 없다3. 복합 키로 인한 중복 데이터 문제중간 테이블에서 a_id + b_id 조합이 복합 기본 키(PK)이자 외래 키(FK) 역할을 한다.예를 들어 a_id가 1이고 b_id가 2인 경우와 a_id가 1이고 b_id가 3인 경우동일한 a_id에 대해 여러 b_id 값이 중복될 수 있다.이로 인해 a_id 만으로 데이터를 구분할 수 없다. 그 반대도 마찬가지이다.4. 데이터 무결성 문제중복된 a_id, b_id 조합을 방지하기 어렵기 때문에 데이터의 무결성과 효율성에 문제가 생길 수 있다.따라서 중간 테이블을 엔티티로 변환하여 1:N, 1:M 관계로 분리하는 것이 좋다.1차 구현Repository// WordRepository@Query(nativeQuery = true, value = \"SELECT * FROM word w WHERE w.id NOT IN \" + \"(SELECT s.word_id FROM study s WHERE s.user_id = :userId) \" + \"ORDER BY w.id LIMIT 10\")List&lt;Word&gt; findByWordsForStudy(Long userId);Study 테이블에서 사용자가 이미 학습한 단어의 word_id를 제외하고Word 테이블에서 남은 단어를 id 기준으로 순서대로 10개 가져오도록 작성했다.2차 수정 : Meaning을 기준으로 수정// MeanRepository@Query(nativeQuery = true, value = \"SELECT m FROM meaning m \" + \"WHERE m.id NOT IN ( \" + \" SELECT s.meaning_id FROM study s WHERE s.user_id = :userId \" + \") \" + \"ORDER BY m.id ASC LIMIT 10\")List&lt;Meaning&gt; findByMeanForStudy(Long userId);meaning_id를 기준으로 study 테이블에서 해당 사용자가 학습하지 않은 Meaning 데이터 10개를 가져온다.해당 meaning에 연결된 word_id와 함께 list에 담긴다.Service// 단어 가져오기public List&lt;StudyResponseDto&gt; getStudyWord(String username){ User user = userRepository.findByUsername(username).orElseThrow(UserNotFoundException::new); List&lt;Meaning&gt; result = meanRepository.findByMeanForStudy(user.getId()); List&lt;StudyResponseDto&gt; list = new ArrayList&lt;&gt;(); for(Meaning meaning : result){ Sentence sentence = sentenceRepository.findBySentence(meaning.getId()).orElseThrow(SentenceNotFoundException::new); list.add(StudyResponseDto.of( meaning.getWord().getWord(), meaning.getMeaning(), sentence.getSentence(), sentence.getSentence_meaning(), sentence.getLevel() )); } return list;}내가 원하는 흐름대로는 작성했으나sentenceRepository.findBySentence(meaning.getId())를 반복적으로 호출하면 db에 여러 번 접근하게 되어서Meaning과 Sentence를 함께 조회하기 위해 INNER JOIN을 사용했다.3차 구현 : INNER JOIN 사용LEFT JOIN보다 INNER JOIN이 성능 면에서 더 우수하며Meaning(뜻)과 Sentence(예문) 둘 다 존재해야하므로 null을 방지하는 inner join을 사용했다.// MeanRepository@Query(nativeQuery = true, value = \"SELECT m.*, s.* \" + \"FROM meaning m \" + \"INNER JOIN sentence s ON m.id = s.meaning_id \" + \"WHERE m.id NOT IN ( \" + \" SELECT study.meaning_id FROM study WHERE study.user_id = :userId \" + \") \" + \"ORDER BY m.id LIMIT 10\")List&lt;Object[]&gt; findByMeanForStudyWithSentence(Long userId);사용자가 학습하지 않은 meaning_id에 대해 meaning과 sentence의 교집합을 가져온다. SELECT m.*, s.* : meaning과 sentence 테이블의 모든 컬럼을 각각 가져온다. FROM meaning m INNER JOIN sentence s ON m.id = s.meaning_id : meaning과 sentence를 조인하여 공통적인 값만 가져온다. WHERE m.id NOT IN (~): 사용자가 이미 학습한 meaning_id를 제외한 항목들만 가져온다. ORDER BY m.id LIMIT 10: meaning의 id값을 기준으로 정렬하고 상위 10개 결과만 반환한다.(ASC)Servicereturn 값이 객체가 아닌 Meaning의 컬럼 값과 Sentence의 컬럼 값으로 return 되면서Word(단어)를 알려면 또 다시 db조회를 해야했다.public void getStudyWord(String username){ User user = userRepository.findByUsername(username).orElseThrow(UserNotFoundException::new); List&lt;Object[]&gt; results = meanRepository.findByMeanForStudyWithSentence(user.getId()); for(Object[] result:results){ System.out.println(\"result[0] = \" + result[0]); System.out.println(\"result[1] = \" + result[1]); System.out.println(\"result[2] = \" + result[2]); System.out.println(\"result[3] = \" + result[3]); System.out.println(\"result[4] = \" + result[4]); System.out.println(\"result[5] = \" + result[5]); }}출력 예시)4차 수정 : JPQL + Pageable@Query(\"SELECT m, s FROM Meaning m JOIN Sentence s ON m.id = s.meaning.id \" + \"WHERE m.id NOT IN (SELECT study.meaning.id FROM Study study WHERE study.user.id = :userId) \" + \"ORDER BY m.id\")Page&lt;Object[]&gt; findByMeanForStudyWithSentence(Long userId, Pageable pageable);nativeQuery 대신 JPQL을 사용하여 LIMIT 대신 페이징을 활용했다JPQL은 인터페이스로 구현했을 때는 @Query을 사용한다.콜론(:)을 사용해서 파라미터로 넘어온 값을 저장해준다.ServiceJPQL에서 LIMIT을 대신하기 위해 페이징을 사용했다.public List&lt;StudyResponseDto&gt; getStudyWord(String username) { User user = userRepository.findByUsername(username).orElseThrow(UserNotFoundException::new); Pageable pageable = PageRequest.of(0, 10); Page&lt;Object[]&gt; results = meanRepository.findByMeanForStudyWithSentence(user.getId(), pageable); List&lt;StudyResponseDto&gt; list = new ArrayList&lt;&gt;(); for (Object[] result : results) { Meaning meaning = (Meaning) result[0]; Sentence sentence = (Sentence) result[1]; list.add(StudyResponseDto.of( meaning.getWord().getWord(), meaning.getMeaning(), sentence.getSentence(), sentence.getSentence_meaning(), sentence.getLevel() )); } return list;} Page: 페이징을 위한 클래스 PageRequest: 현재 페이지와 한 페이지에 보여 줄 게시물 개수 등을 설정하여 페이징 요청을 하는 클래스 PageRequest.of(page, 10) : page는 조회할 페이지의 번호, 10은 한 페이지에 보여 줄 게시물의 개수 Pageable: 페이징을 처리하는 인터페이스 실행하면 아래와 같이 front에서 받게 된다.frontfront에서는 단어 목록들을 받아서 localStorage에 저장한다.첫번째와 마지막 단어를 구분하여 첫번째는 “이전” 버튼이 없으며 마지막 단어장에는 “다음” 버튼이 생기지 않게 했다.모달 창을 중간에 닫고 다시 열면 마지막에 봤던 단어장이 띄워지며이 때, 다시 서버에 요청을 해서 db를 조회하는 것이 아니라 localStorage에 있던 값을 받아 활용한다.객체 저장할 때는 아래와 같이 작성해야한다.// 단어 목록들 저장if(localStorage.getItem(username)){ cards = JSON.parse(localStorage.getItem(username)) // string → object로 변환 showStudyModal();}else{ $.ajax({ // 생략 localStorage.setItem(username,JSON.stringify(response)); // string 형태로 저장})// 가장 마지막에 읽었던 단어 페이지 수 기억let currentName = username+\"page\";let currentCard = localStorage.getItem(currentName)?localStorage.getItem(currentName):0;REFERENCE [JPA]연관관계 - 다대다(N:M) 다대다(N:M) 관계는 왜 피해야할까? [Entity] 중복데이터 저장 방지 (Unique Key, Index) 3-02 페이징 기능 추가하기 spring boot JPQL 적용. [Javascript] localStorage 객체 저장하기" }, { "title": "Db 저장하기", "url": "/posts/DB-%EC%A0%80%EC%9E%A5%ED%95%98%EA%B8%B0/", "categories": "Eng-Project", "tags": "log", "date": "2024-11-01 00:00:00 +0900", "snippet": "New Project새로운 프로젝트를 시작했다.영어 공부에 대한 필요성이 느껴져 코딩 연습과 함께 영어 공부 사이트를 만들어 보려고 했다.전체코드는 eng에서 확인할 수 있다.IDEA아이디어는 별도의 노션에서 계속 정리하고 있으며, 중간에 추가 및 수정이 많아 현재까지 완료한 작업들을 정리하기로 했다.현재 기본적인 구조는 영어 단어 학습과, 빈칸 채우기 퀴즈, 그리고 틀린 부분을 모아서 복습하는 사이트다.front는 ChatGPT를 통해 기본적인 HTML과 CSS 디자인을 구현하여 개발 시간을 절약했다.프로젝트에서 가장 중요한 부분은 데이터 저장 및 성능 개선이다.db는 중복을 피하기 위해 관계형 데이터베이스를 사용하고, 데이터 구조가 자주 변경될 일이 거의 없기 때문에 MySQL을 선택했다.아래는 db 저장 방법을 정리한 글이다.Flow파일 첨부하기로 엑셀을 업로드하면 3개의 메소드로 나누어 db에 저장한다.1. 단어 저장하기2. 단어 뜻 저장하기3. 예문, 예문 뜻, level 저장DBAUTO_INCREMENT는 1부터 시작하도록 설정한다.ALTER TABLE [Table 명] AUTO_INCREMENT=1;단어 저장하기중복 방지를 위해 단어는 UNIQUE 속성으로 저장했다.CREATE TABLE word ( id BIGINT AUTO_INCREMENT PRIMARY KEY, word VARCHAR(50) NOT NULL, UNIQUE KEY (word));단어 뜻 저장하기CREATE TABLE meaning ( id BIGINT AUTO_INCREMENT PRIMARY KEY, word_id BIGINT NOT NULL, meaning VARCHAR(100) NOT NULL, FOREIGN KEY (word_id) REFERENCES word (id) ON DELETE CASCADE);같은 뜻을 가진 단어가 여러 개 있을 수 있으므로, 단어 뜻은 UNIQUE 제약 조건을 설정하지 않았다.*참고) unique key 생성 및 삭제CREATE UNIQUE INDEX \"인덱스 이름\" ON \"테이블명\" (\"컬럼명\",\"컬럼명\"); -- 생성DROP INDEX \"인덱스 이름\" ON \"테이블명\"; -- 삭제DROP INDEX user_number ON user; -- user 테이블의 user_number 인덱스 삭제예문 저장하기단어가 아닌 뜻을 fk로 잡은 이유는 특정 뜻에 해당하는 예문을 db에 저장하기 위해서다.CREATE TABLE example ( id BIGINT AUTO_INCREMENT PRIMARY KEY, meaning_id BIGINT NOT NULL, example varchar(400) NOT NULL, example_meaning varchar(800) NOT NULL, level INT, FOREIGN KEY (meaning_id) REFERENCES meaning (id) ON DELETE CASCADE);예문마다 레벨을 설정해 초·중·고 수준에 따라 나눴으며 각각 0, 1, 2로 설정했다.이 값을 int로 설정할 것인가 string으로 설정할 것인가에 대해 고민을 하다가이 글을 보고 어떠한 계산을 하는 것이 아니기 때문에 string으로 설정했었다.그런데 엑셀에서 숫자만 입력한 데이터는 string으로 값을 얻지 못해서 int로 저장했다.Code단어 저장하기엑셀에서 가져온 단어 데이터를 Set 자료구조로 중복을 필터링한 뒤, DB에 저장한다.Entity@Entity@Getter@NoArgsConstructor(access = AccessLevel.PROTECTED) // builderpublic class Word { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Long id; @Column(unique = true, nullable = false) private String word; @Builder public Word(String word){ this.word = word; } // Set&lt;Word&gt; 중복 단어 필터링(equals와 hashCode 재정의) @Override public boolean equals(Object o) { if (this == o) return true; if (o == null || getClass() != o.getClass()) return false; Word word1 = (Word) o; return Objects.equals(word, word1.word); } @Override public int hashCode() { return Objects.hash(word); }}Servicepublic void saveWord(MultipartFile file) throws IOException { Workbook workbook = new XSSFWorkbook(file.getInputStream()); // workbook : 하나의 엑셀 파일을 의미 Sheet sheet = workbook.getSheetAt(0); // 첫번째 sheet Set&lt;Word&gt; words = new HashSet&lt;&gt;(); Iterator&lt;Row&gt; rowIterator = sheet.iterator(); if (rowIterator.hasNext()) { rowIterator.next(); // 첫 행(제목) 건너 뛰기 } while (rowIterator.hasNext()) { Row row = rowIterator.next(); Word word = Word.builder() .word(row.getCell(0).getStringCellValue().strip()) .build(); words.add(word); } // DB에 저장(중복 try~catch) try { wordRepository.saveAll(words); } catch (DataIntegrityViolationException e) { // 중복 예외 처리 }}1차적으로 엑셀 파일에 중복이 있는지 Set을 사용하여 미리 제거후 db에 저장한다.try-catch 블록을 통해 중복이 발생할 경우 SQLIntegrityConstraintViolationException 예외를 처리했다.단어 뜻 저장하기한 단어에 여러 뜻이 있을 경우를 고려하여 단어와 뜻을 분리했다.Entity@Entity@Getter@NoArgsConstructor(access = AccessLevel.PROTECTED)public class Meaning { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Long id; @ManyToOne(fetch = LAZY, cascade = CascadeType.REMOVE) // ON DELETE CASCADE @JsonIgnore @JoinColumn(name=\"word_id\") private Word word; @OneToMany(mappedBy = \"meaning\") private List&lt;Sentence&gt; sentenceList = new ArrayList&lt;&gt;(); @Column(nullable = false) private String meaning; @Builder private Meaning(Word word, String meaning){ this.word = word; this.meaning = meaning; word.getMeaningList().add(this); } public static Meaning createMeaning(Word word, String meaning){ return Meaning.builder() .word(word) .meaning(meaning) .build(); }}word와 meaning을 일대다 매핑을 하고 연관관계 편의 메소드를 작성하던 도중나는 builder 패턴으로 사용해서 연관관계 편의 메소드를 작성만 하고 service에서 사용은 안하고 있었다.인프런 [1], [2] 글을 보고 참고하여 builder와 연관관계 편의 메소드를 작성해 사용했다.Repository단어와 뜻이 모두 존재할 경우 중복을 방지하기 위해 EXISTS를 사용하여 중복 체크를 수행했다.JPQL에서는 count를 이용해 값 존재 여부를 확인한다.단순히 중복이 있는지 확인하고 바로 종료하고 싶어서jpql이 아닌 sql을 직접 정의하여 사용하는 방식인 NativeQuery를 사용했다.public interface MeanRepository extends JpaRepository&lt;Meaning, Long&gt; { @Query(nativeQuery = true, value = \"SELECT EXISTS \" + \"(SELECT 1 FROM Meaning m WHERE m.word_id = :wordId AND m.meaning = :meaning)\") int existsByWordAndMeaning(Long wordId, String meaning); @Query(nativeQuery = true, value = \"SELECT * FROM Meaning m WHERE m.word_id = :wordId AND m.meaning = :meaning LIMIT 1\") Optional&lt;Meaning&gt; findByMean(Long wordId, String meaning);}*limit를 사용할 수 있었지만 EXISTS가 더 빠른 성능을 보이므로 EXISTS를 활용했다.*return 값을 Optional&lt;Boolean&gt;을 작성하여 isPresent()로 값이 있는지 체크하는 로직을 작성했지만int로 return값을 작성한 것이 더 빠른 성능을 보여 int로 작성했다.EXISTS 쿼리의 반환 결과는 0 또는 1 형태인 것을 MySQL Tutorial을 통해 확인했다.참고로 “SELECT EXISTS “ + 부분처럼 가독성을 위해 줄바꿈으로 작성할 경우공백을 빼먹었는지 확인해준다. 공백을 빼먹으면 SQL 문법 오류가 뜬다.JpaRepository&lt;T, ID&gt;T: Entity 타입ID: Entity의 기본 키 (Primary Key) 타입Serviceprivate static final Map&lt;String, Long&gt; wordIdMap = new HashMap&lt;&gt;();public void saveMeaning(MultipartFile file) throws IOException { Workbook workbook = new XSSFWorkbook(file.getInputStream()); Sheet sheet = workbook.getSheetAt(0); // 첫번째 sheet MultiValueMap&lt;String, String&gt; map = new LinkedMultiValueMap&lt;&gt;(); // key 중복 Iterator&lt;Row&gt; rowIterator = sheet.iterator(); List&lt;Meaning&gt; list = new ArrayList&lt;&gt;(); if (rowIterator.hasNext()) { rowIterator.next(); // 첫 행(제목) 건너 뛰기 } while (rowIterator.hasNext()) { Row row = rowIterator.next(); String wordText = row.getCell(0).getStringCellValue().strip(); String meaningText = row.getCell(1).getStringCellValue().strip(); // 해당 key에 해당하는 값 중복 체크 (1차 중복 체크 - 메모리) map.putIfAbsent(wordText, new ArrayList&lt;&gt;()); if(!Objects.requireNonNull(map.get(wordText)).contains(meaningText)){ map.add(wordText,meaningText); Word word = wordRepository.findByWord(wordText) .orElseThrow(() -&gt; new NoSuchElementException(\"Word not found: \" + wordText)); wordIdMap.put(word.getWord(), word.getId()); // saveSentence()에서 db 조회 최소화 // word와 meaning이 같이 중복인 경우는 새로 추가하지 않음(2차 중복 체크 - DB) int exists = meanRepository.existsByWordAndMeaning(word.getId(), meaningText); if (exists==0) { list.add(Meaning.createMeaning(word, meaningText)); } } } // 일괄 저장 meanRepository.saveAll(list);}예문 저장하기Service단어에 해당하는 뜻에 해당하는 예문을 db에 저장한다. map에는 단어와 예문을 저장한다. map에서 단어에 해당하는 예문이 없다면? map에 단어와 예문을 저장한다. Meaning 테이블에서 해당 단어에 해당하는 뜻을 가져온다. (그냥 뜻을 가져와버리면 해당 단어가 아닌 다른 단어의 동일한 뜻을 가져와버릴 수 있다.) 해당 단어의 뜻과 예문이 중복되어있는지 db에서 체크한다. public void saveSentence(MultipartFile file) throws IOException { Workbook workbook = new XSSFWorkbook(file.getInputStream()); Sheet sheet = workbook.getSheetAt(0); Iterator&lt;Row&gt; rowIterator = sheet.iterator(); List&lt;Sentence&gt; list = new ArrayList&lt;&gt;(); MultiValueMap&lt;String, String&gt; map = new LinkedMultiValueMap&lt;&gt;(); // key 중복 if (rowIterator.hasNext()) { rowIterator.next(); // 첫 행(제목) 건너 뛰기 } while (rowIterator.hasNext()) { Row row = rowIterator.next(); String word = row.getCell(0).getStringCellValue().strip(); String meaningText = row.getCell(1).getStringCellValue().strip(); String sentence = row.getCell(2).getStringCellValue().strip(); String sentence_meaning = row.getCell(3).getStringCellValue(); int level = (int) row.getCell(4).getNumericCellValue(); map.putIfAbsent(word, new ArrayList&lt;&gt;()); if (!Objects.requireNonNull(map.get(word)).contains(sentence)) { map.add(word, sentence); Meaning meaning; if (wordIdMap.get(word) != null) { // db 조회 최소화 meaning = meanRepository.findByMean(wordIdMap.get(word), meaningText).orElseThrow(); } else { Word wordId = wordRepository.findByWord(word).orElseThrow(); meaning = meanRepository.findByMean(wordId.getId(), meaningText).orElseThrow(); } int exists = sentenceRepository.existsByMeanAndSentence(meaning.getId(), sentence); if (exists == 0) { list.add(Sentence.createSentence(meaning, sentence, sentence_meaning, level)); } } } // 일괄 저장 sentenceRepository.saveAll(list);}실제로 같은 뜻을 넣어두고 해당 단어에 맞는 예문이 저장된것을 확인했다.REFERENCE NativeQuery JPA, JPQL에서 limit 사용하기 [MySql] UNIQUE KEY 생성 및 삭제" }, { "title": "마지막 글 조회", "url": "/posts/%EB%A7%88%EC%A7%80%EB%A7%89-%EA%B8%80-%EC%A1%B0%ED%9A%8C/", "categories": "Project, Chat", "tags": "Chat", "date": "2024-09-24 00:00:00 +0900", "snippet": "마지막 글 조회 최적화기존 파일의 마지막 글을 조회할 때 while문을 없애면 시간이 더 줄어질 수 있을 것 같아 코드를 수정 했다.기존 코드는 아래와 같다.try (RandomAccessFile randomAccessFile = new RandomAccessFile(file, \"r\")) { long fileLength = file.length(); if (fileLength &gt; 0) { randomAccessFile.seek(fileLength); long pointer = fileLength - 2; while (pointer &gt; 0) { randomAccessFile.seek(pointer); char c = (char) randomAccessFile.read(); if (c == '\\n') { break; } pointer--; } randomAccessFile.seek(pointer+1); String line = randomAccessFile.readLine(); if (line == null || line.trim().isEmpty()) { return null; } if (line.startsWith(\",\")) { line = line.substring(1); } // 이하 동일파일 저장 형식{\"roomId\":\"6d0a2b57\",\"type\":\"JOINED\",\"sender\":\"hello\",\"message\":\"환영합니다.\",\"adminChat\":0,\"userChat\":0,\"day\":\"9/21\",\"time\":\"01:04\"},{\"roomId\":\"6d0a2b57\",\"type\":\"TALK\",\"sender\":\"hello\",\"message\":\"123\",\"adminChat\":1,\"userChat\":0,\"day\":\"9/21\",\"time\":\"01:04\"} 첫번째 줄만 쉼표(,)가 없고 마지막 줄은 항상 공백(줄바꿈)으로 끝나게 저장된다.1차 수정ReversedLinesFileReader를 적용했다.implementation 'commons-io:commons-io:2.11.0'try (ReversedLinesFileReader r = new ReversedLinesFileReader(file,StandardCharsets.UTF_8)) { long fileLength = file.length(); if (fileLength &gt; 0) { String line = r.readLine(); if (line == null || line.trim().isEmpty()) { return null; } if (line.startsWith(\",\")) { line = line.substring(1); } // 이하 동일 이 글을 보고 거꾸로 읽는 것이 오히려 시간을 더 잡아먹을 수 있다는 걸 알게 되었다.기존 코드와 차이가 얼마나 나는지 출력시켜봤다.(System.nanoTime()) 기존 코드 : 7,457,800ns ReversedLinesFileReader 적용 코드 : 15,646,500ns기존 코드가 오히려 더 빠르게 동작했다.RandomAccessFile와 ReversedLinesFileReader이 둘의 차이를 알고 싶어서 gpt로 찾아봤다.RandomAccessFileRandomAccessFile은 seek()를 통해 파일 포인터를 특정 위치로 바로 이동시키고 필요한 부분만 읽는다.char 단위로 읽으면서 줄바꿈 문자(\\n)를 찾아 byte 단위로 탐색한다.ReversedLinesFileReader일정한 크기로 나눈 블록을 메모리에 로드한 후 그 안에서 줄바꿈 문자(\\n)를 찾는다.한 번에 블록 단위로 읽기 때문에 블록 내에 줄바꿈 문자가 없을 경우 추가 블록을 읽어 다시 검색하는 과정을 반복한다.여러 줄을 한꺼번에 읽는 경우에는 효율적이지만, 한 줄만 읽는 경우 오버헤드가 발생한다.나는 파일의 끝에서 2번째 줄만 읽으려고 했기 때문에 RandomAccessFile가 더 빠르게 동작했던 것 같다.*오버헤드란? 추가적인 작업이나 불필요한 처리가 개입되어 원래 소요 시간보다 더 많은 시간이 걸리는 것을 의미한다. 예를 들어 원래 5초면 끝날 작업이 추가적인 처리로 인해 7초가 걸린다면 2초가 오버헤드가 된다.2차 수정사용자에 따라 변화하는 값외의 고정된 값(byte)을 계산하여 최소 값인 145를 넣었다.또한, 첫 줄만 있을 경우와 두 줄 이상의 경우 차이에 따라서도 동일하게 적용하기 위해서줄바꿈(\\n)이 아닌 { 문자를 기준으로 줄을 찾고 {부터 읽도록 수정했다.위와 같이 적용하면서 아래 코드는 필요없어졌다.if (line.startsWith(\",\")) { line = line.substring(1);}또, 테스트를 해보다가 문제점을 발견했는데첫번째 줄만 있는 경우 줄바꿈을 만나 종료하는게 아니라 {에서 종료를 하게 된다.그러면서 pointer+1을 하다보니 {가 아닌 rommId의 r부터 해당 줄을 읽게 되어버렸다.따라서 \\n가 아닌 {를 만나면 즉시 종료한 후 {부터 줄을 읽게 했다.최종 코드if (fileLength &gt; 145) { randomAccessFile.seek(fileLength); long pointer = fileLength - 145; while (pointer &gt; 0) { randomAccessFile.seek(pointer); char c = (char) randomAccessFile.read(); if (c == '{') { break; } pointer--; } randomAccessFile.seek(pointer);최종 성능 결과는 6,907,800 ns로 기존 7,457,800 ns에서 개선되었다.REFERENCE [Java] 텍스트 파일의 마지막 라인부터 읽기" }, { "title": "로그인 사용자 대비 채팅 사용자 비율 계산", "url": "/posts/%EB%A1%9C%EA%B7%B8%EC%9D%B8-%EC%82%AC%EC%9A%A9%EC%9E%90-%EB%8C%80%EB%B9%84-%EC%B1%84%ED%8C%85-%EC%82%AC%EC%9A%A9%EC%9E%90-%EB%B9%84%EC%9C%A8-%EA%B3%84%EC%82%B0/", "categories": "Project, Chat", "tags": "Redis, Chat, Cache", "date": "2024-09-17 00:00:00 +0900", "snippet": "로그인 사용자 대비 채팅 사용자 비율 계산하루 동안 로그인 한 사용자와 채팅을 한 사용자 수를 저장 한 후하루가 지나면 데이터를 기반으로 비율을 계산하여 db에 저장 한다.Codeapplicaton.propertiesspring.datasource.url=jdbc:mysql://localhost:3306/test?serverTimezone=Asia/Seoul&amp;characterEncoding=UTF-8TableCREATE TABLE stats ( id BIGINT AUTO_INCREMENT PRIMARY KEY, stat_date DATE NOT NULL, -- 해당 통계의 날짜 logged_in_users BIGINT DEFAULT 0, -- 하루 동안 로그인한 총 사용자 수 chat_users BIGINT DEFAULT 0, -- 하루 동안 채팅에 참여한 고유 사용자 수 participation_rate DECIMAL(5, 2) DEFAULT 0, -- 참여 비율 (ex. 10.00 → 10%) created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP, UNIQUE KEY (stat_date) -- 날짜별로 유일하게 설정);stat_date는 해당 통계의 날짜라면 created_at은 DB에 저장된 시점 의미한다.stat_date가 2024-09-16이라면 created_at의 날짜는 2024-09-17이 될 것 이다.Entity@Entity@Getter@NoArgsConstructor(access = AccessLevel.PROTECTED)public class Stats { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Long id; @Column(unique = true) private LocalDate statDate; // 통계 날짜 @Column private Long loggedInUsers; // 로그인한 사용자 수 @Column private Long chatUsers; // 채팅 참여 사용자 수 @Column private Double participationRate; // 참여 비율 @Column private LocalDateTime createdAt = LocalDateTime.now(); // 저장 시점 @Builder public Stats(LocalDate date, Long users, Long chat, Double participationRate ){ this.statDate = date; this.loggedInUsers = users; this.chatUsers = chat; this.participationRate = participationRate; }}Redis Configimplementation 'org.springframework.boot:spring-boot-starter-data-redis' 의존성 주입@Configuration@EnableCachingpublic class RedisConfig { @Value(\"${spring.data.redis.host}\") private String redisHost; @Value(\"${spring.data.redis.port}\") private int redisPort; @Bean public RedisConnectionFactory redisConnectionFactory() { return new LettuceConnectionFactory(redisHost, redisPort); } @Bean public RedisTemplate&lt;String, String&gt; redisTemplate() { RedisTemplate&lt;String, String&gt; redisTemplate = new RedisTemplate&lt;&gt;(); redisTemplate.setConnectionFactory(redisConnectionFactory()); redisTemplate.setKeySerializer(new StringRedisSerializer()); redisTemplate.setValueSerializer(new StringRedisSerializer()); return redisTemplate; }}Redis Cache를 이용한 사용자 수 집계public class RedisService { private final RedisTemplate&lt;String, String&gt; redisTemplate; private static final long STATSTIME = 26; public void addLoginUserCount(String key, String nickname){ redisTemplate.opsForSet().add(key, nickname); redisTemplate.expire(key, STATSTIME, TimeUnit.HOURS); } public void deleteLoginUserCount(String key){ redisTemplate.delete(key); } public void addChatUserCount(String key, String nickname){ redisTemplate.opsForSet().add(key, nickname); redisTemplate.expire(key, STATSTIME, TimeUnit.HOURS); } public void deleteChatUserCount(String key){ redisTemplate.delete(key); }}정의된 RedisTemplate&lt;String, String&gt; 설정을 사용하여 opsForSet()을 통해 Redis의 Set 자료구조를 적용했다.Redis를 이용하여 로그인 및 채팅 사용자 수를 집계하고, 26시간 동안 데이터를 유지하도록 설정했다.Scheduler@RequiredArgsConstructor@Slf4j@EnableScheduling // 스케줄링 활성화@Servicepublic class StatsScheduler { private final RedisService redisService; private final RedisTemplate&lt;String, String&gt; redisTemplate; private final StatsRepository repository; @Scheduled(cron = \"0 5 0 * * *\") // 매일 새벽 12시 5분에 실행 public void calculateDailyStats() { try{ LocalDate now = LocalDate.now(); Long totalLoginUser = Optional.ofNullable(redisTemplate.opsForSet().size(now.minusDays(1) + \"-LoginUser\")).orElse(0L); Long totalChatUser = Optional.ofNullable(redisTemplate.opsForSet().size(now.minusDays(1) + \"-ChatUser\")).orElse(0L); double participationRate = 0; if(totalLoginUser&gt;0){ participationRate = ((double) totalChatUser / totalLoginUser) * 100; } Stats stats = Stats.builder() .date(now.minusDays(1)) .users(totalLoginUser) .chat(totalChatUser) .participationRate(participationRate) .build(); repository.save(stats); redisService.deleteLoginUserCount(now.minusDays(1) + \"-LoginUser\"); redisService.deleteChatUserCount(now.minusDays(1) + \"-ChatUser\"); log.info(\"성공적으로 통계 저장 완료. 날짜: {}\", stats.getStatDate()); }catch (Exception e){ log.error(\"일일 통계 계산 중 오류 발생 \", e); } }}매일 새벽 12시 5분에 Redis에 저장된 데이터를 기반으로 통계를 계산하고DB에 저장한 후 Redis에서 해당 데이터를 삭제한다.따라서 cron 표현식을 사용해 정해진 시간에 작업이 실행되게 했다.(@Scheduled(cron = \"0 5 0 * * *\"))결과Test테스트를 위해 데이터를 10분 간격으로 저장하고 stat_date를 문자열로 변경했다.테스트를 위해서 id값을 초기화했다.ALTER TABLE Stats AUTO_INCREMENT = 1;Entity 수정@Entity@Getter@NoArgsConstructor(access = AccessLevel.PROTECTED)public class Stats { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Long id; @Column(unique = true) private String statDate; // 통계 날짜 (시간 포함) @Column private Long loggedInUsers; // 로그인한 사용자 수 @Column private Long chatUsers; // 채팅 참여 사용자 수 @Column private Double participationRate; // 참여 비율 @Column private LocalDateTime createdAt = LocalDateTime.now(); @PrePersist public void prePersist() { // 서울 시간대로 변환 후 \"yyyy-MM-dd HH:mm\" 형식으로 포맷하여 저장 DateTimeFormatter formatter = DateTimeFormatter.ofPattern(\"yyyy-MM-dd HH:mm\"); this.statDate = ZonedDateTime.now(ZoneId.of(\"Asia/Seoul\")) .toLocalDateTime() .format(formatter); // 포맷된 문자열 생성 } @Builder public Stats(Long users, Long chat, Double participationRate ){ this.loggedInUsers = users; this.chatUsers = chat; this.participationRate = participationRate; }}test를 위해 date 대신 varchar 적용*기존에는 날짜만 저장하기 때문에 date를 사용했지만 10분단위로 test를 해야하므로 시간까지 적용했다.Scheduler 수정@RequiredArgsConstructor@Slf4j@EnableScheduling // 스케줄링 활성화@Servicepublic class StatsScheduler { private final RedisTemplate&lt;String, String&gt; redisTemplate; private final StatsRepository repository; @Scheduled(fixedRate = 600000) // 10분(600,000ms) 간격으로 실행 public void calculateDailyStats() { log.info(\"[stats scheduler] 스케줄러 실행\"); try{ LocalDate now = LocalDate.now(); Long totalLoginUser = Optional.ofNullable(redisTemplate.opsForSet().size(now.getDayOfMonth() + \"-LoginUser\")).orElse(0L); Long totalChatUser = Optional.ofNullable(redisTemplate.opsForSet().size(now.getDayOfMonth() + \"-ChatUser\")).orElse(0L); double participationRate = 0; if(totalLoginUser&gt;0){ participationRate = ((double) totalChatUser / totalLoginUser) * 100; } Stats stats = Stats.builder() .users(totalLoginUser) .chat(totalChatUser) .participationRate(participationRate) .build(); repository.save(stats); log.info(\"성공적으로 통계 저장 완료. 날짜: {}\", stats.getStatDate()); }catch (Exception e){ log.error(\"일일 통계 계산 중 오류 발생 \", e); } }}@Scheduled(fixedRate = 600000)정해진 시간이 아닌 10분 단위로 실행 하기 위해서 cron 대신 fixedRate를 사용했다.fixedDelay와 fixedRatefixedDelay는 작업이 완료된 시점부터 시간을 세기 때문에작업이 오래 걸릴 경우 작업 간의 간격이 고정되기 때문에 안전하게 실행할 수 있다.@Scheduled(fixedDelay = 5000)public void hh() throws InterruptedException { log.info(\"fixedDelay\"); Thread.sleep(1000);}작업 시간(1초) + 대기 시간(5초) = 약 6초 단위로 출력되고 있다.fixedRate는 작업이 시작된 시점부터 시간을 센다.@Scheduled(fixedRate = 5000)public void gg() throws InterruptedException { log.info(\"fixedRate\"); Thread.sleep(1000);}5초 단위로 출력되고 있다.따라서 fixedDelay는 해당 작업의 실행 시간이 긴 경우 사용하면 좋고fixedRate는 작업 간격을 일정하게 유지해야 하는 경우 사용하면 좋다.지금은 메소드의 실행시간이 길지 않고 시간 단위로 분석하기 위해서 fixedRate를 사용했다.테스트 결과 로그인 x 로그인 o, 채팅 x 로그인 o, 채팅 oREFERENCE Spring Boot - 스케줄러 사용해보기 1. FixedDelay vs FixedRate" }, { "title": "Back 배포 관리", "url": "/posts/Back-%EB%B0%B0%ED%8F%AC-%EA%B4%80%EB%A6%AC/", "categories": "Project, Cloud", "tags": "summary", "date": "2024-09-12 00:00:00 +0900", "snippet": "Back 배포 관리SSH를 사용하여 Amazon EC2 인스턴스에 접속$ ssh -i {키 페어 주소} ubuntu@ipv4주소ex) ssh -i hello.pem ubuntu@12.345.678환경 변수리눅스에서는 메모장, 워드패드 같은 파일 편집기가 존재하는데 nano, vi, vim 등 많은 편집기들이 존재한다.nano는 가장 기본적인 편집기로 최소한의 기능만을 갖고 있다.vi는 nano보다 좀 더 다양한 기능을 갖고 있다.vim은 ‘vi improved’로 UNIX 기본 편집기 vi의 업그레이드 버전이라고 보면 된다.vim .env # 파일이 없으면 생성, 있으면 수정 또는 추가vi .env # 파일이 이미 존재하고 수정하고 싶을 때 접근하는 명령어환경 변수 설정 -e : 환경변수 넣어야 한다. \\ : 줄 바꿈 - 한칸 띄고 \\를 작성해야한다. (맨 마지막에는 안넣어도 됨) application.properties 파일에서 spring.batch.job.enabled=false로 작성한 것을 -e SPRING_BATCH_JOB_ENABLED=false \\ 로 작성해주면 된다. .으로 작성해왔던 것들을 _로 바꿔쓴다. 예시-e REDIRECT_URL = https://api/hello.world.site/login \\-e BOARD_URL = /board/homeRedis 설치docker image pull redisdocker run -d --name redis-container -p 6379:6379 redis --name : 컨테이너 이름 설정 -d : 백그라운드에서 실행(터미널을 종료시켜도 돌아가게끔 동작) -p : 포트 연결 -p 6379:6379: 호스트의 6379 포트를 컨테이너의 6379 포트로 포워딩한다. Redis는 기본적으로 6379 포트를 사용하므로, 호스트에서 컨테이너로의 포트 매핑을 설정하고 있다. 맨 뒤에 redis는 Docker 이미지의 이름을 지정log 보기docker logs {container 이름}Redis CLI에 연결docker exec -it redis-container redis-cli 컨테이너 접속(여기서 redis-container 는 컨테이너 이름)실행 중인 Redis 컨테이너에 접속하여 Redis CLI를 실행한다.여기서 -it는 대화형(interactive) 모드로 실행하라는 옵션key 확인keys *Reference [리눅스 기초]파일 편집(nano,vi) 이용하기 [[DEVOPOS AWS SPRING] application.yml 파일 환경변수 외부주입 - aws env 파일/intellij configuration](https://youngseo-computerblog.tistory.com/80) " }, { "title": "영속성 컨텍스트", "url": "/posts/%EC%98%81%EC%86%8D%EC%84%B1-%EC%BB%A8%ED%85%8D%EC%8A%A4%ED%8A%B8/", "categories": "Study, JPA", "tags": "JPA, 강의, summary", "date": "2024-06-09 00:00:00 +0900", "snippet": "EntityManagerFactory와 EntityManager웹 어플리케이션을 개발할 때EntityManagerFactory를 통해서 고객의 요청이 올때마다 EntityManager를 생성을 하고EntityManager는 내부적으로 DB 커넥션을 사용해서 DB를 사용하게 된다.영속성 컨텍스트 영속성 컨텍스트는 논리적인 개념으로 눈에 보이지 않는다. EntityManager를 통해서 영속성 컨텍스트에 접근한다. 영속성 컨텍스트는 Entity를 영구 저장하는 환경이다. EntityManager.persist(entity); → persist()는 db에 저장하는게 아니라 Entity를 영속성 컨텍스트에 저장한다는 뜻 J2SE 환경엔티티 매니저와 영속성 컨텍스트가 1:1→ EntityManager를 생성을 하면 그 안에 1:1로 영속성 컨텍스트가 생성이 된다.→ EntityManager안에 영속성 컨텍스트에 보이지 않는 공간이 생긴다.엔티티의 생명주기☑️ 비영속 (new/transient) : 영속성 컨텍스트와 전혀 관계가 없는 새로운 상태→ 최초의 멤버 객체를 생성한 상태☑️ 영속 (managed) : 영속성 컨텍스트에 관리되는 상태 → persist하고 난 후☑️ 준영속 (detached) : 영속성 컨텍스트에 저장되었다가 분리된 상태☑️ 삭제 (removed) : 삭제된 상태비영속세팅만 한 상태→ jpa와 관련 없는 상태// 객체를 생성한 상태(비영속) Member member = new Member(); member.setId(\"member1\"); member.setUsername(\"회원1\")영속객체를 생성한 다음에 EntityManager를 얻어와서 EntityManager에 persist해서 member 객체를 넣으면EntityManager안에 영속성 컨텍스트에 member 객체가 들어가면서 영속상태가 된다.em.persist(member); → 이 때 db에 저장되는 것이 아니다. (db 쿼리가 안날라가는 것을 확인할 수 있음)트랜잭션을 커밋하는 시점에 영속성 컨텍스트에 있던 것이 db에 쿼리가 날라간다.//객체를 생성한 상태(비영속) Member member = new Member(); member.setId(\"member1\"); member.setUsername(“회원1”);EntityManager em = emf.createEntityManager();em.getTransaction().begin();//객체를 저장한 상태(영속)em.persist(member);준영속, 삭제em.detach(member);영속성 컨텍스트에서 지운다.em.remove(member);db 삭제를 요청하는 상태엔티티 조회, 1차 캐시영속성 컨텍스트는 내부에 1차 캐시를 들고 있다.*EntityManager와 영속성 컨텍스트는 미묘한 차이가 있지만 여기서는 같다라고 보고 봐도 무방하다.// 엔티티를 생성한 상태(비영속) Member member = new Member(); member.setId(\"member1\"); member.setUsername(\"회원1\");// 엔티티를 영속 em.persist(member);영속성 컨텍스트는 내부에 1차 캐시가 있다.db의 pk로 매핑한 것이 key값이 되고 Entity 자체가 값이 된다.→ key : member1, 값 : member 객체1차 캐시에서 조회Member 객체를 저장하고 조회를 한다.em.find()로 조회를 하면 JPA에서는 먼저 영속성 컨텍스트에서 1차 캐시를 찾는다. (db를 먼저 찾아보는 것이 아님)find에서 member1을 조회한다.db에서 조회Member findMember2 = em.find(Member.class, \"member2\");member2를 조회를 한다고 가정한다.1. find에서 member2를 조회한다.2. member2는 1차 캐시에 없으므로 jpa가 db에서 조회를 한다.3. (db에 member2가 있다는 가정하에) db에서 조회한 member2를 1차 캐시에 저장을 한다.4. 그리고 member2를 반환한다.이후에 member2를 다시 조회하게 되면 영속성 컨텍스트 안에 있는 1차 캐시에 있는 member2가 반환된다.보통 EntityManager는 데이터 트랜잭션 단위로 만들고 데이터 트랜잭션이 끝날 때 영속성 컨텍스트도 종료시킨다.보통 고객 요청이 들어와서 비즈니스가 끝나버리면 영속성 컨텍스트를 지운다.1차 캐시도 다 날라가므로 굉장히 짧은 순간에서만 이점이 있다.application 전체에서 공유하는 캐시는 jpa나 hibernate에서는 2차 캐시라고 한다.1차 캐시는 db 한 트랜잭션 안에서만 효과가 있기 때문에 성능 이점을 얻을 수 있는 장점은 없다.엔티티 등록트랜잭션을 지원하는 쓰기 지연EntityManager em = emf.createEntityManager();EntityTransaction transaction = em.getTransaction();// 엔티티 매니저는 데이터 변경시 트랜잭션을 시작해야 한다.transaction.begin(); // [트랜잭션] 시작em.persist(memberA);em.persist(memberB);// 여기까지 INSERT SQL을 데이터베이스에 보내지 않는다.(예외도 있긴함)// 커밋하는 순간 데이터베이스에 INSERT SQL을 보낸다.transaction.commit(); // [트랜잭션] 커밋em.persist(memberA); 로 memberA를 저장을 하면영속성 컨텍스트 안에는 1차 캐시도 있지만 쓰기 지연 SQL 저장소도 있다.em.persist(memberA);를 실행하면 memberA가 1차 캐시에 들어간다.동시에 JPA가 INSERT SQL을 생성해서 쓰기 지연 SQL 저장소에 쌓아둔다.transaction.commit();트랜잭션을 커밋하는 시점에 쓰기 지연 SQL 저장소에 있던 것들이JPA에서는 flush라고 하는데 flush가 되면서 DB에 쿼리가 날라간다.엔티티 수정변경 감지(dirty checking)try { // 영속 // Member member1 = new Member(25L, \"A\"); Member member = em.find(Member.class, 25L); // 이전에 저장했던 값 변경하는 것 member.setName(\"C\"); System.out.println(\"==================\"); tx.commit();}member.setName() 한 다음에 em.persist(member)라고 작성해야하지 않을까?예를 들어 자바 컬렉션에서(ex.LIST) 값을 꺼내 변경한 후에는 다시 컬렉션에 집어 넣지 않는다.따라서 em.persist(member) 코드를 쓰면 안된다. JPA에서는 변경한 값만 작성한다.select 쿼리가 나가고 update 쿼리가 실행되었다.JPA는 변경감지(Dirty checking)로 인해서 db에 값이 변경된다.비밀은 영속성 컨텍스트 안에 있다.JPA는 DB 트랜잭션 커밋하는 시점에 내부적으로 flush()가 호출된다.그리고 엔티티와 스냅샷을 비교한다.1차 캐시 안에는 pk인 id가 있고 Entity와 스냅샷이 있다.스냡샷은 내가 값을 읽어 최초로 영속성 컨텍스트에 들어온 그 시점, 1차 캐시에 들어온 상태를 스냅샷으로 떠둔다.그리고 값(memberA)을 변경했을 때 JPA에서 트랜잭션 커밋되는 시점에 내부적으로 flush()가 호출되면서 비교를 한다.Entity와 스냅샷을 비교해서 memberA가 바뀐 것을 알고 UPDATE 쿼리문을 쓰기 지연 SQL 저장소에 만들어 둔다.UPDATE 쿼리문 db에 반영을 하고 commit을 한다. 👉🏻 이것을 변경 감지라고 한다.실제 내가 프로젝트에서 작성한 코드로 보면 게시글을 작성하는 코드에서는registryRepository.save(registry);를 작성한 것과 다르게 updateArticle에서는 save가 없다.*일부 코드 제거하고 필요한 코드만 작성함 // Service.java @Override @Transactional public Registry updateArticle(Long id, RegistryRequestDto requestDto){ Registry registry = registryRepository.findById(id).orElseThrow(RegistryNotFoundException::new); return registry.updateRegistry(requestDto); } // Registry.java public void updateRegistry(RegistryRequestDto requestDto){ if(requestDto.getTitle() != null){ this.title = requestDto.getTitle(); } if(requestDto.getMain() != null){ this.main = requestDto.getMain(); } }JPA 변경감지가 작동되기 위한 조건 중에 Entity가 영속상태여야 하고 트랜잭션 안에 묶여 있어야 한다.JPA를 사용해서 트랜잭션을 관리하는 방법은 @Transactional을 사용하는 방법이다.따라서 @Transactional을 작성해야한다.스프링은 @Transactional을 사용하면PlatformTransactionManager를 구현한 JpaTransactionManager를 사용해서 트랜잭션을 관리한다.스프링 컨테이너의 기본 전략스프링 컨테이너는 트랜잭션 범위의 영속성 컨텍스트 전략을 기본으로 사용한다. 트랜잭션의 범위와 영속성 컨텍스트의 생존 범위가 같다. 트랜잭션을 시작할 때 영속성 컨텍스트를 생성하고 트랜잭션이 끝날 때 영속성 컨텍스트를 종료한다. 같은 트랜잭션 안에서는 여러 위치(여러 repository)의 EntityManager를 사용해도 항상 같은 영속성 컨텍스트에 접근한다. 다양한 위치에서 EntityManager를 주입받아 사용해도 트랜잭션이 같으면 항상 같은 영속성 컨텍스트를 사용한다.트랜잭션이 다르면 동일한 엔티티 매니저를 사용해도 다른 영속성 컨텍스트를 사용한다. 자바 ORM 표준 JPA 프로그래밍 [JPA] 변경감지 개념과 @Transactional 위치에 따른 변경감지 사용 트랜잭션 범위의 영속성 컨텍스트" }, { "title": "Jmeter 성능 테스트", "url": "/posts/JMeter-%EC%84%B1%EB%8A%A5-%ED%85%8C%EC%8A%A4%ED%8A%B8/", "categories": "Project, 성능테스트", "tags": "Monitoring", "date": "2024-04-16 00:00:00 +0900", "snippet": "JMeter 성능 테스트Message Broker를 변경하면서 얼마나 성능이 좋아졌는지 비교하기 위해 JMeter를 활용했다.Test성능 테스트 1test할 sampler는 위와 같다.순서대로 진행이 되기 위해서 특정 sampler 안에 timer를 넣었다.View Results Tree를 보니 요청이 순서대로 실행이 되었지만채팅방에 입장하지 않았는데 채팅 msg를 보내려고 하는 경우와 같이실제로 서버에서 처리되는 속도에 의해서 순서가 바뀌어있었다.따라서 timer를 추가하여 채팅방 입장 후에 send와 disconnect가 동작하게 했다.Sampler 안에 Timer를 넣으면 해당 Sampler가 Timer에서 설정한 시간을 기다린 후에 동작한다.Number of Threads (users) : 3000Ramp-Up Period (in seconds) : 300 Loop Count : 1☑️ Same user on each iteration☑️ Delay Thread creation until needed사용자가 3000명이고 ramp-up 시간이 300초이며, 각 사용자는 루프(loop)를 1회 반복한다.→ 300초 동안에 3000명의 사용자가 동시에 시작하고, 각 사용자가 한 번의 루프를 수행하므로 총 3000번의 요청이 진행된다.*채팅방 send connection 타이머 설정(Thread Delay : 2 ms) *채팅방 message 보내기 sampler 타이머 설정(Thread Delay : 2 ms) *채팅방 disconnect sampler 타이머 설정(Thread Delay : 1 ms)View Results TreeSimple In-Memory Broker 적용 Label Samples Average Min Max Std.Dev. Error% Throughput Received KB/sec Sent KB/sec Avg.Bytes JSR223 Sampler 3000 0 0 16 0.4920974384091924 0.0 9.99986666844442 0.0 0.0 0.0 Debug Sampler 3000 0 0 2 0.2180968184596516 0.0 10.00040001600064 3.5632772967168687 0.0 364.865 login 3000 97 75 250 11.470683167681575 0.0 9.99710084075618 4.237052504773616 2.294256540603225 434.0 WebSocket Open Connection 3000 1 1 13 0.6146795913319394 0.0 10.00060003600216 2.3048257895473725 3.974847865871952 236.0 send connect - WebSocket Single Write Sampler 3000 0 0 2 0.25867268034246593 0.0 10.000666711114073 0.0 0.4101835955730382 0.0 subscribe - WebSocket Single Write Sampler 3000 0 0 1 0.19595917942265426 0.0 10.000666711114073 0.0 1.0840566454430294 0.0 채팅방 입장 - WebSocket Single Write Sampler 3000 0 0 1 0.1837797594948911 0.0 10.000666711114073 0.0 3.6037558753916925 0.0 채팅방 message 보내기 - WebSocket Single Write Sampler 3000 0 0 1 0.2763853991962833 0.0 10.000666711114073 0.0 3.6428209797319817 0.0 채팅방 퇴장 - WebSocket Single Write Sampler 3000 0 0 1 0.2733463411538962 0.0 10.000666711114073 0.0 3.6818860840722714 0.0 TOTAL 27000 11 0 250 30.781850912991406 0.0 89.96521345079903 10.102197332656374 18.684181699742766 114.985 Samples: 테스트 중에 수행된 작업의 총 수 Average: 모든 작업의 평균 응답 시간 Min: 가장 빨리 완료된 연결 작업의 시간 Max: 가장 오래 걸린 연결 작업의 시간 Std.Dev.: 응답 시간의 표준 편차를 말한다. 이는 응답 시간의 분산 정도를 나타내며, 값이 클수록 응답 시간의 변동이 크다는 것을 의미한다. Error%: 작업 중 실패한 비율을 나타낸다. 0%가 나왔으므로 모든 연결이 성공했다는 의미이다. Throughput: 단위 시간당 완료된 작업의 수 (여기서는 단위 시간이 sec다. 초당 ~개의 작업이 처리된다.) Received KB/sec: 서버로 수신된 데이터의 평균 속도를 KB 단위로 나타낸다. 값이 높을 수록 성능이 좋다. Sent KB/sec: 서버로 전송된 데이터의 평균 속도를 KB 단위로 나타낸다. 값이 높을 수록 성능이 좋다. Avg.Bytes: 평균적으로 서버와 클라이언트 간에 교환되는 데이터의 크기를 나타낸다. WebSocket Open Connection에서 최대 응답 시간이 다른 WebSocket Sampler에 비해 높게 나타난 것은WebSocket 프로토콜로의 연결 설정에 시간이 소요된 결과로 보여진다.HTTP와는 달리 WebSocket은 지속적인 양방향 통신을 제공하는 프로토콜이기 때문에 연결 설정에는 더 많은 리소스가 필요할 수 있다.일반적으로 HTTP에서 WebSocket으로의 프로토콜 전환은 Socket의 생성 및 핸드쉐이크 과정을 포함하며,이에는 추가적인 네트워크 라운드트립이 발생할 수 있다. 이 과정에서 최대 응답 시간이 발생할 수 있다.따라서 66초의 최대 응답 시간은 WebSocket 연결 설정에 소요된 시간으로 해석될 수 있다.login을 제외한 나머지 sampler들의 응답 시간이 모두 0으로 나타나고 있다.WebSocket과 같은 비동기 작업은 응답 시간이 0으로 표시될 수 있고서버와의 통신에서 매우 적은 시간이 소요되는 경우 응답시간이 거의 없다고 볼 수 있다.응답 시간(ms)은 샘플러가 실행되고 완료되는 데 걸리는 시간을 나타낸다.값이 작을수록 해당 샘플러의 응답 시간이 짧다는 것을 의미하고 값이 클수록 응답 시간이 긴 것을 나타낸다.그래프가 없다는 것은 실행되고 완료되는 시간이 너무 빨라서 측정이 불가능해서 나타나는 결과일 가능성이 높다.RabbitMQ 적용 Label Samples Average Min Max Std.Dev. Error% Throughput Received KB/sec Sent KB/sec Avg.Bytes JSR223 Sampler 3000 0 0 14 0.46177002453121135 0.0 10.0 0.0 0.0 0.0 Debug Sampler 3000 0 0 1 0.1990600132846597 0.0 10.000466688445462 3.573128985602662 0.0 365.8713333333333 login 3000 99 75 260 14.065816400053029 0.0 9.997400675824286 4.2371795833083405 2.294325350408894 434.0 WebSocket Open Connection 3000 1 1 14 0.5975460000888825 0.0 10.001033440122146 2.3049256756531507 3.9750201270797985 236.0 send connect - WebSocket Single Write Sampler 3000 0 0 1 0.25059839495805947 0.0 10.001133461792335 0.0 0.4102027396438263 0.0 subscribe connect - WebSocket Single Write Sampler 3000 0 0 1 0.1768838287941803 0.0 10.001133461792335 0.0 1.2110747551389156 0.0 subscribe send - WebSocket Single Write Sampler 3000 0 0 1 0.16110727964792765 0.0 10.001133461792335 0.0 1.181774559450071 0.0 subscribe disconnect - WebSocket Single Write Sampler 3000 0 0 1 0.145592658545073 0.0 10.001133461792335 0.0 1.2403749508277604 0.0 채팅방 입장 - WebSocket Single Write Sampler 3000 0 0 1 0.16401592063644987 0.0 10.001133461792335 0.0 3.613690801624184 0.0 채팅방 message 보내기 - WebSocket Single Write Sampler 3000 0 0 1 0.2702583126483912 0.0 10.001200144017282 0.0 3.652782083850062 0.0 채팅방 퇴장 - WebSocket Single Write Sampler 3000 0 0 1 0.2828095157914992 0.0 10.001200144017282 0.0 3.6918492719126297 0.0 TOTAL 33000 9 0 260 28.878759653965666 0.0 109.96261271167803 10.112492742051037 21.26230206729712 94.17012121212122 성능 차이가 크게 나지 않는 이유에 대해서 분석해본다. Overhead 및 Latency: 사용자 수가 증가하고 Ramp-Up 기간이 길어질수록 RabbitMQ는 네트워크 트래픽과 메시지 브로커에서의 처리에 더 많은 오버헤드를 발생시킬 수 있다. 이로 인해 RabbitMQ의 성능이 감소할 수 있다. 반면에 Simple In-Memory Broker는 네트워크 오버헤드가 없으며 메모리 내에서 메시지를 처리하므로 이러한 성능 저하가 없을 수 있다. 리소스 활용 RabbitMQ는 메시지를 브로커로 전송하고 처리하기 위해 시스템 리소스를 사용한다. 따라서 더 많은 사용자 및 스레드가 활성화되면 RabbitMQ의 리소스 사용량이 증가하여 성능에 영향을 줄 수 있다. Simple In-Memory Broker는 메모리 내에서만 작동하므로 리소스 사용량이 상대적으로 적고, 따라서 더 많은 사용자 및 스레드를 다룰 때에도 성능이 유지될 수 있다. 최적화: Simple In-Memory Broker는 단순하고 경량화되어 있어서 작은 규모의 테스트에서는 RabbitMQ보다 효율적일 수 있다. 특히 사용자 수가 적고 메시지 처리가 빈번하지 않은 경우에는 Simple In-Memory Broker가 더 나은 성능을 보일 수 있다. 이러한 이유로 인해 특정 조건에서는 Simple In-Memory Broker가 RabbitMQ보다 성능이 우수하게 나타날 수 있다.그러나 대규모 및 분산 환경에서는 RabbitMQ의 더 나은 확장성과 성능이 더 중요해질 수 있다.오버헤드(Overhead)란 어떤 작업을 수행하기 위해 필요한 추가적인 자원 또는 처리 과정을 말한다.ex) 편지를 보내는 상황내가 직접 친구에게 전달하는 경우 :추가 비용이 발생하지 않는다. → 오버헤드 x편지를 우편 서비스를 통해 보내는 경우 : 우편 봉투를 작성하고 우편 배달 서비스를 이용하는데 소요되는 시간과 비용이 추가된다 → 오버헤드직접 친구에게 보내는 과정에서 1시간이 소요되었는데우편 서비스를 이용해 보내게 되면서 24시간이 소요되었다면오버헤드는 24-1인 23시간이라고 보면 된다.성능 테스트 2login 후 → 채팅(conncet → send → disconnect)의 흐름을 순서대로 진행시키다 보니 큰 차이를 느끼지 못해서이번에는 채팅 메시지를 보내는 SEND 과정만 loop로 돌리고 차이를 비교해봤다.Number of Threads (users) : 1Ramp-Up Period (in seconds) : 1 Loop Count : 1☑️ Same user on each iteration☑️ Delay Thread creation until needed- Loop Controller의 Loop Count : 30Simple In-Memory Broker 적용 Label Samples Average Min Max Std.Dev. Error% Throughput Received KB/sec Sent KB/sec Avg.Bytes JSR223 Sampler 1 14 14 14 0.0 0.0 71.42857142857143 0.0 0.0 0.0 login 1 91 91 91 0.0 0.0 10.989010989010989 4.657451923076923 2.5218921703296706 434.0 WebSocket Open Connection 1 4 4 4 0.0 0.0 250.0 57.6171875 99.365234375 236.0 send connect - WebSocket Single Write Sampler 1 0 0 0 0.0 0.0 0.0 0.0 0.0 0.0 subscribe - WebSocket Single Write Sampler 1 0 0 0 0.0 0.0 0.0 0.0 0.0 0.0 채팅방 입장 - WebSocket Single Write Sampler 1 0 0 0 0.0 0.0 0.0 0.0 0.0 0.0 채팅방 message 보내기 - WebSocket Single Write Sampler 30 0 0 1 0.24944382578492943 0.0 15000.0 0.0 5478.515625 0.0 채팅방 퇴장 - WebSocket Single Write Sampler 1 0 0 0 0.0 0.0 0.0 0.0 0.0 0.0 TOTAL 37 3 0 91 14.852427229062412 0.0 327.43362831858406 5.790237831858407 110.2997096238938 18.10810810810811 RabbitMQ 적용 Label Samples Average Min Max Std.Dev. Error% Throughput Received KB/sec Sent KB/sec Avg.Bytes JSR223 Sampler 1 13 13 13 0.0 0.0 76.92307692307692 0.0 0.0 0.0 login 1 88 88 88 0.0 0.0 11.363636363636365 4.816228693181818 2.6078657670454546 434.0 WebSocket Open Connection 1 1 1 1 0.0 0.0 1000.0 230.46875 397.4609375 236.0 send connect - WebSocket Single Write Sampler 1 0 0 0 0.0 0.0 0.0 0.0 0.0 0.0 subscribe connect - WebSocket Single Write Sampler 1 0 0 0 0.0 0.0 0.0 0.0 0.0 0.0 subscribe send - WebSocket Single Write Sampler 1 0 0 0 0.0 0.0 0.0 0.0 0.0 0.0 subscribe disconnect - WebSocket Single Write Sampler 1 1 1 1 0.0 0.0 1000.0 0.0 124.0234375 0.0 채팅방 입장 - WebSocket Single Write Sampler 1 0 0 0 0.0 0.0 0.0 0.0 0.0 0.0 채팅방 message 보내기 - WebSocket Single Write Sampler 30 0 0 0 0.0 0.0 30000.0 0.0 10957.03125 0.0 채팅방 퇴장 - WebSocket Single Write Sampler 1 0 0 0 0.0 0.0 0.0 0.0 0.0 0.0 TOTAL 39 2 0 88 13.999060736783845 0.0 364.4859813084112 6.114924065420561 118.86682242990655 17.17948717948718 Simple In-Memory Broker 적용 채팅 메시지를 보내는 과정에서 평균적으로 15,000개의 메시지가 전송되었다. 채팅방 메시지 최대 응답 시간은 1ms다. 전체 평균 응답 시간은 약 3ms이며, 최대 응답 시간은 91ms다. RabbitMQ 적용 채팅 메시지를 보내는 과정에서 평균적으로 30,000개의 메시지가 전송되었다. 채팅방 메시지 최대 응답 시간은 0ms다. 전체 평균 응답 시간은 약 2ms로 더 줄어들었고, 최대 응답 시간은 88ms다. 결과 분석: RabbitMQ를 사용한 경우에는 채팅방 메시지 평균 전송량이 두 배 이상으로 매우 높은 처리량을 보였다. RabbitMQ를 사용한 경우에는 전체 평균 응답 시간이 더 짧았으며, 최대 응답 시간도 감소하여 효율성이 향상되었다. 또한, RabbitMQ를 사용한 경우 채팅방 메시지의 평균 전송량이 약 5478에서 10957로 상당히 높아졌으며, 채팅방 메시지의 응답 시간도 유의미하게 낮아졌다. 따라서 RabbitMQ가 더 많은 부하를 처리하는 동시에 효율적으로 동작하는 것으로 나타났다. 성능 테스트 3이번 성능 테스트에서는 성능 테스트 2에 비해 Number of Threads와 Ramp-Up Period를 늘려 테스트를 진행했다.Number of Threads (users) : 5000Ramp-Up Period (in seconds) : 600 Loop Count : 1☑️ Same user on each iteration☑️ Delay Thread creation until needed- Loop Controller의 Loop Count : 30Simple In-Memory Broker 적용 Label Samples Average Min Max Std.Dev. Error% Throughput Received KB/sec Sent KB/sec Avg.Bytes JSR223 Sampler 5000 0 0 32 0.6140978423671589 0.0 8.333444445925947 0.0 0.0 0.0 login 5000 115 73 307 24.93694980465733 0.0 8.332111290344084 3.5313831054778633 1.9121544465145113 434.0 WebSocket Open Connection 5000 1 0 51 1.062801129092362 0.0 8.333847253913993 1.9206913593004904 3.312378742522456 236.0 send connect - WebSocket Single Write Sampler 5000 0 0 1 0.21503032344299722 0.0 8.333888925928395 0.0 0.3418196629775318 0.0 subscribe - WebSocket Single Write Sampler 5000 0 0 1 0.1689249537516586 0.0 8.333888925928395 0.0 0.9033805378691913 0.0 채팅방 입장 - WebSocket Single Write Sampler 5000 0 0 1 0.1661127328051646 0.0 8.333888925928395 0.0 3.0112684595639707 0.0 채팅방 message 보내기 - WebSocket Single Write Sampler 150000 0 0 6 0.17640824571304925 0.0 250.01625105631865 0.0 91.31452919439764 0.0 채팅방 퇴장 - WebSocket Single Write Sampler 5000 0 0 1 0.17168529348782324 0.0 8.333902816692476 0.0 3.0763820944431206 0.0 TOTAL 185000 3 0 307 19.210549311790775 0.0 308.2685969279785 5.4513291792057 103.84375270776471 18.10810810810811 RabbitMQ 적용 Label Samples Average Min Max Std.Dev. Error% Throughput Received KB/sec Sent KB/sec Avg.Bytes JSR223 Sampler 5000 0 0 15 0.4409152299478892 0.0 8.33334722224537 0.0 0.0 0.0 login 5000 107 72 192 24.733399176821592 0.0 8.332291796858726 3.5314596092155144 1.9121958713494145 434.0 WebSocket Open Connection 5000 1 0 18 0.6217837566228308 0.0 8.333361111203704 1.9205793185977285 3.3121855197850656 236.0 send connect - WebSocket Single Write Sampler 5000 0 0 1 0.21249291752903202 0.0 8.333361111203704 0.0 0.3417980143267144 0.0 subscribe connect - WebSocket Single Write Sampler 5000 0 0 1 0.16948109039063916 0.0 8.333361111203704 0.0 1.0091179470598235 0.0 subscribe send - WebSocket Single Write Sampler 5000 0 0 1 0.1638238077936171 0.0 8.333361111203704 0.0 0.9847038031793438 0.0 subscribe disconnect - WebSocket Single Write Sampler 5000 0 0 1 0.15242558840299747 0.0 8.333361111203704 0.0 1.033532090940303 0.0 채팅방 입장 - WebSocket Single Write Sampler 5000 0 0 5 0.182449883529697 0.0 8.333361111203704 0.0 3.0110777452591506 0.0 채팅방 message 보내기 - WebSocket Single Write Sampler 150000 0 0 6 0.179258048137935 0.0 250.0 0.0 91.30859375 0.0 채팅방 퇴장 - WebSocket Single Write Sampler 5000 0 0 1 0.1770599898339543 0.0 8.333361111203704 0.0 3.0761821289404296 0.0 TOTAL 195000 2 0 192 17.48832577918017 0.0 324.9485498129463 5.451610786625451 105.97280430598488 17.17948717948718 RabbitMQ를 사용한 경우와 Simple In-Memory Broker를 사용한 경우 모두 비슷한 결과가 나타났다.전반적으로 동일한 성능을 보여주었으며, 특별히 큰 차이를 보이지 않았다.성능 테스트 4이번 테스트에서는 성능 테스트 2의 Loop Count를 3배로 증가시켰다.Number of Threads (users) : 1Ramp-Up Period (in seconds) : 1 Loop Count : 1☑️ Same user on each iteration☑️ Delay Thread creation until needed- Loop Controller의 Loop Count : 90Simple In-Memory Broker 적용 Label Samples Average Min Max Std.Dev. Error% Throughput Received KB/sec Sent KB/sec Avg.Bytes JSR223 Sampler 1 20 20 20 0.0 0.0 50.0 0.0 0.0 0.0 login 1 93 93 93 0.0 0.0 10.75268817204301 4.557291666666667 2.467657930107527 434.0 WebSocket Open Connection 1 1 1 1 0.0 0.0 1000.0 230.46875 397.4609375 236.0 send connect - WebSocket Single Write Sampler 1 0 0 0 0.0 0.0 0.0 0.0 0.0 0.0 subscribe - WebSocket Single Write Sampler 1 0 0 0 0.0 0.0 0.0 0.0 0.0 0.0 채팅방 입장 - WebSocket Single Write Sampler 1 0 0 0 0.0 0.0 0.0 0.0 0.0 0.0 채팅방 message 보내기 - WebSocket Single Write Sampler 90 0 0 1 0.17950549357115014 0.0 12857.142857142857 0.0 4695.870535714285 0.0 채팅방 퇴장 - WebSocket Single Write Sampler 1 0 0 0 0.0 0.0 0.0 0.0 0.0 0.0 TOTAL 97 1 0 93 9.585145449347783 0.0 782.258064516129 5.276587701612903 277.24136844758067 6.907216494845361 RabbitMQ 적용 Label Samples Average Min Max Std.Dev. Error% Throughput Received KB/sec Sent KB/sec Avg.Bytes JSR223 Sampler 1 19 19 19 0.0 0.0 52.631578947368425 0.0 0.0 0.0 login 1 126 126 126 0.0 0.0 7.936507936507937 3.3637152777777777 1.8213665674603174 434.0 WebSocket Open Connection 1 4 4 4 0.0 0.0 250.0 57.6171875 99.365234375 236.0 send connect - WebSocket Single Write Sampler 1 1 1 1 0.0 0.0 1000.0 0.0 41.015625 0.0 subscribe connect - WebSocket Single Write Sampler 1 0 0 0 0.0 0.0 0.0 0.0 0.0 0.0 subscribe send - WebSocket Single Write Sampler 1 0 0 0 0.0 0.0 0.0 0.0 0.0 0.0 subscribe disconnect - WebSocket Single Write Sampler 1 0 0 0 0.0 0.0 0.0 0.0 0.0 0.0 채팅방 입장 - WebSocket Single Write Sampler 1 0 0 0 0.0 0.0 0.0 0.0 0.0 0.0 채팅방 message 보내기 - WebSocket Single Write Sampler 90 0 0 1 0.17950549357115014 0.0 15000.0 0.0 5463.8671875 0.0 채팅방 퇴장 - WebSocket Single Write Sampler 1 0 0 0 0.0 0.0 0.0 0.0 0.0 0.0 TOTAL 99 1 0 126 12.720994122318237 0.0 626.5822784810126 4.1411194620253164 218.62638449367088 6.767676767676767 Simple In-Memory Broker 적용 채팅 메시지를 보내는 과정에서 평균적으로 약 12,857.14 샘플/초의 메시지가 전송되었다. 채팅방 메시지의 최대 응답 시간은 1ms로 매우 빠른 응답 속도를 보였다. 전송 속도는 약 4,695.87 KB/sec이다. RabbitMQ 적용 채팅 메시지를 보내는 과정에서 평균적으로 약 약 15,000 샘플/초의 메시지가 전송되었다. 채팅방 메시지의 최대 응답 시간은 0ms로 매우 빠른 응답 속도를 보였다. 전송 속도는 약 5,463.87 KB/sec이다. 결과 분석 RabbitMQ를 사용한 경우에는 채팅 메시지 전송량이 증가했다. 이는 RabbitMQ가 더 많은 부하를 처리할 수 있다는 것을 시사한다. Sent KB/sec는 시스템이 단위 시간당 전송하는 데이터 양을 나타낸다.RabbitMQ의 Sent KB/sec 값이 더 높게 나타나면서 채팅 메시지를 더 빠르게 처리하고 전송한다는 것을 시사한다. RabbitMQ를 사용한 경우에는 평균 응답 시간이 더 짧았고, 최대 응답 시간도 감소하여 효율성이 향상되었다. 따라서, RabbitMQ가 채팅 시스템의 성능과 안정성을 향상시킬 수 있는 좋은 대안이 될 수 있음을 시사한다. 결론Simple In-Memory Broker 적용 vs. RabbitMQ 적용Throughput은 시스템이 단위 시간당 처리할 수 있는 작업의 양을 나타낸다.RabbitMQ를 사용한 경우에는 채팅 메시지 전송량이 두 배 이상으로 증가했다.이는 RabbitMQ가 더 많은 부하를 처리할 수 있다는 것을 시사한다.또한, RabbitMQ를 사용한 경우에는 평균 응답 시간이 더 짧아지고, 최대 응답 시간도 감소하여 효율성이 향상되었다.Sent KB/sec를 보면서 RabbitMQ를 사용한 경우에는 데이터 전송 속도가 더 빠르다는 것을 알 수 있다.높은 Sent KB/sec는 시스템이 단위 시간당 더 많은 데이터를 처리하고 전송한다는 것을 의미하므로,RabbitMQ를 사용한 경우에는 데이터가 더 빠르게 전송되며, 따라서 시스템의 성능이 향상되었다고 볼 수 있다.성능 테스트 2 vs. 성능 테스트 3:성능 테스트 3에서는 더 많은 사용자를 시뮬레이션하고, 더 긴 Ramp-Up Period를 사용하여 테스트를 진행했다.전반적으로 동일한 성능을 보여주었으며, 특별히 큰 차이를 보이지 않았다.성능 테스트 2 vs. 성능 테스트 4:성능 테스트 4에서는 Loop Count를 3배로 늘려서 테스트를 진행했다.이 결과, RabbitMQ를 사용한 경우에는 평균 응답 시간이 더 짧아지고, 최대 응답 시간도 감소하는 것을 확인할 수 있었다.JMeter를 적용하면서 수정한 코드roomId를 갖고오는 메소드와 권한 갖고오는 메소드의 key가 같아서roomId를 갖고오려고 실행했으나 권한이 출력되는 경우가 생겼다.따라서 key값을 다르게 적용해야한다.변경 전public void addRedis(ChatMessage chatMessage) { long expireTimeInSeconds = 24 * 60 * 60; long creationTimeInMillis = System.currentTimeMillis(); long remainingTimeInSeconds = expireTimeInSeconds - ((System.currentTimeMillis() - creationTimeInMillis) / 1000); redisTemplate.opsForValue().set(chatMessage.getSender(), chatMessage.getRoomId(), remainingTimeInSeconds, TimeUnit.SECONDS);}public String getRedis(String nickname) { return redisTemplate.opsForValue().get(nickname);}public void deleteRedis(String nickname) { redisTemplate.delete(nickname);}public void addAuth(ChatMessage chatMessage){ long expireTimeInSeconds = 24 * 60 * 60; long creationTimeInMillis = System.currentTimeMillis(); long remainingTimeInSeconds = expireTimeInSeconds - ((System.currentTimeMillis() - creationTimeInMillis) / 1000); redisTemplate.opsForValue().set(chatMessage.getSender(), chatMessage.getAuth(), remainingTimeInSeconds, TimeUnit.SECONDS);}public String getAuth(String nickname){ return redisTemplate.opsForValue().get(nickname);}변경 후public void addRoomId(ChatMessage chatMessage) { long expireTimeInSeconds = 24 * 60 * 60; long creationTimeInMillis = System.currentTimeMillis(); long remainingTimeInSeconds = expireTimeInSeconds - ((System.currentTimeMillis() - creationTimeInMillis) / 1000); redisTemplate.opsForValue().set(\"getRoomId - \" + chatMessage.getSender(), chatMessage.getRoomId(), remainingTimeInSeconds, TimeUnit.SECONDS);}public String getRoomId(String nickname) { return redisTemplate.opsForValue().get(\"getRoomId - \" + nickname);}public void deleteRoomId(String nickname) { redisTemplate.delete(\"getRoomId - \" + nickname);}public void addAuth(ChatMessage chatMessage){ long expireTimeInSeconds = 24 * 60 * 60; long creationTimeInMillis = System.currentTimeMillis(); long remainingTimeInSeconds = expireTimeInSeconds - ((System.currentTimeMillis() - creationTimeInMillis) / 1000); redisTemplate.opsForValue().set(\"auth - \" + chatMessage.getSender(), chatMessage.getAuth(), remainingTimeInSeconds, TimeUnit.SECONDS);}public String getAuth(String nickname){ return redisTemplate.opsForValue().get(\"auth - \" + nickname);} " }, { "title": "상속과 컴포지션", "url": "/posts/%EC%83%81%EC%86%8D%EA%B3%BC-%EC%BB%B4%ED%8F%AC%EC%A7%80%EC%85%98/", "categories": "Project", "tags": "refactoring, Java, 디자인 패턴", "date": "2024-04-12 00:00:00 +0900", "snippet": "상속 (Inheritance)상속은 객체 지향 프로그래밍에서 기존 클래스의 특성과 기능을 그대로 물려받아 새로운 클래스를 정의하는 것이다.이는 클래스 간의 “is-a” 관계를 표현하며, 코드를 재사용하고 클래스 간의 관계를 명확히 할 수 있다.ex. 동물 클래스가 있고, 이를 상속받은 고양이, 개 클래스가 있을 때, 고양이와 개는 모두 동물이라는 공통 특성을 갖는다.장점코드 재사용성부모 클래스의 기능을 자식 클래스가 그대로 이용할 수 있다.다형성 구현다형성이란 한 가지 인터페이스나 기능을 여러 방식으로 구현할 수 있는 것을 의미한다.부모 클래스의 메서드를 자식 클래스에서 오버라이딩하여 다른 동작을 구현할 수 있다.*다형성의 대표적인 예시로는 오버로딩(Overloading)과 오버라이딩(Overriding)이 있다.Overloading// 같은 이름의 메서드를 여러 개 정의하되 매개변수의 타입, 개수, 순서가 다른 경우public class Example { public void print(int num) { System.out.println(\"정수: \" + num); } public void print(double num) { System.out.println(\"실수: \" + num); } public void print(String str) { System.out.println(\"문자열: \" + str); }}Overriding// 상속 관계에서 부모 클래스의 메서드를 자식 클래스에서 재정의하여 사용class Animal { public void makeSound() { System.out.println(\"Animal\"); }}class Dog extends Animal { @Override public void makeSound() { System.out.println(\"Dog\"); }}class Cat extends Animal { @Override public void makeSound() { System.out.println(\"Cat\"); }}단점캡슐화 위반자식 클래스에서 부모 클래스의 메서드를 오버라이딩하면, 부모 클래스의 의도와 다른 동작이 수행될 수 있다.캡슐화, 즉 정보 은닉은 객체가 내부적으로 기능을 어떻게 구현하는지를 감추는 것을 의미한다.이를 통해 우리는 클래스의 기능을 사용할 때 내부 동작을 알 필요없이 단순히 메서드만 호출할 수 있다.단, 내부 동작을 알 필요가 없다는 말은 신뢰성이 보장되어야 한다는 말이기도 하다.따라서 캡슐화가 위반된다면 이는 신뢰성이 깨진 것으로 볼 수 있다.아래의 예시 코드에서 Dog 클래스가 Animal 클래스의 makeSound 메서드를 오버라이딩하여 동작을 변경한다.이렇게 부모 클래스의 동작을 변경함으로써 캡슐화가 위반된다고 볼 수 있다.class Dog extends Animal { @Override public void makeSound() { System.out.println(\"Cat meows\"); }}결국, 상속 후에 진행된 오버라이딩은 캡슐화를 위반할 수 있다는 것을 염두에 두어야 한다.결합도 증가결합도는 하나의 모듈이 다른 모듈에 대해 얼마나 많은 지식을 갖고 있는지를 나타내는 의존 정도를 말한다.객체지향 프로그래밍에서는 결합도는 낮을수록, 응집도는 높을수록 좋다.그래서 추상화에 의존함으로써 다른 객체에 대한 결합도는 최소화하고 응집도를 최대화하여 변경 가능성을 최소화 할 수 있다.여기서 상속을 하게 되면 부모 클래스의 내부 구현에 의존하기 때문에부모 클래스를 변경할 때 자식 클래스도 함께 변경해야 한다.아래와 같이 코드에서 Food 부모 클래스에 count 필드를 하나 추가해버리면,자식클래스는 물론 클래스 호출 부분 까지 전부 수정해주어야 한다.class Food { final int price; final int count; // 코드 추가 Food(int price, int count) { this.price = price; this.count = count; // 코드 추가 }}class Bread extends Food { public Bread(int price, int count) { super(price, count); // 코드 수정 }}public class Main { public static void main(String[] args) { Food bread = new Bread(1000, 5); // 코드 수정 }}불필요한 기능 상속부모 클래스에 추가된 메서드가 자식 클래스에 적합하지 않는 경우도 있다.Animal 클래스에 fly() 라는 메서드를 추가했을때, Tiger 자식 클래스에서는 동작하지 않는 메서드가 되어 버린다.상속을 사용하는 경우는 명확한 is - a 관계에 있는 경우,상위 클래스가 확장할 목적으로 설게되었고 문서화도 잘되어 있는 경우에 사용하면 좋다.컴포지션 (Composition)컴포지션은 한 클래스가 다른 클래스의 인스턴스를 포함하는 것이다.포함된 객체의 기능을 사용하여 클래스의 기능을 확장하거나 구현한다. “has-a” 관계를 나타낸다.ex. 자동차 클래스가 엔진 클래스의 인스턴스를 포함하여 자동차가 엔진을 가지고 있다.낮은 결합도컴포지션을 사용하면 클래스 간의 결합도가 낮아진다.각 클래스는 독립적으로 존재할 수 있으며, 변경 사항이 다른 클래스에 영향을 미치지 않는다.유연성컴포지션을 사용하면 클래스를 구성하는 객체를 동적으로 변경할 수 있다.즉, 클래스의 기능을 유연하게 확장하거나 수정할 수 있다.REFACTORING내가 수정할 부분은 LastMessage와 ChatRoomDto다.이 두 개의 dto에는 중복된 변수들이 많고 LastMessage에는 nickname 필드만 존재하지 않는다.@Getter@Setter@ToString@Builder@AllArgsConstructorpublic class ChatRoomDto implements Serializable { private String roomId; private String nickname; private Integer adminChat; private Integer userChat; private String message; private String day; private String time; public ChatRoomDto() { } public static ChatRoomDto create() { ChatRoomDto room = new ChatRoomDto(); room.roomId = UUID.randomUUID().toString(); return room; } public static ChatRoomDto of(String roomId, User user, LastMessage lastMessage) { return ChatRoomDto.builder() .roomId(roomId) .nickname(user.getNickname()) .adminChat(lastMessage.getAdminChat()) .userChat(lastMessage.getUserChat()) .message(lastMessage.getMessage()) .day(lastMessage.getDay()) .time(lastMessage.getTime()) .build(); }}@Getter@Builderpublic class LastMessage { private String roomId; private int adminChat; private int userChat; private String message; private String day; private String time; public static LastMessage of(ChatMessage chatMessage, int adminChat, int userChat, String day, String time){ return LastMessage.builder() .roomId(chatMessage.getRoomId()) .adminChat(adminChat) .userChat(userChat) .message(chatMessage.getMessage()) .day(day) .time(time) .build(); }}중복 제거와 Composition 활용내가 수정하는 DTO 는 명확한 is-a 관계는 아니지만, 완전히 관계가 없는 것은 아니다.또한 메서드 안에서 두 객체가 함께 사용되기 때문에 중복을 최대한 제거하고자 했다.중복 제거와 유연성을 위해 Composition을 활용하여 refactoring을 진행했다.따라서 ChatRoomDto가 LastMessage를 포함함으로써, ChatRoomDto에서는 LastMessage의 일부 기능을 사용할 수 있다.@Getter@Setter@Builder@AllArgsConstructorpublic class ChatRoomDto implements Serializable { private String roomId; private String nickname; private LastMessage lastMessage;// Composition(has-a 관계) public ChatRoomDto() { } public static ChatRoomDto create() { ChatRoomDto room = new ChatRoomDto(); room.roomId = UUID.randomUUID().toString(); return room; } public static ChatRoomDto of(User user, LastMessage lastMessage) { return ChatRoomDto.builder() .nickname(user.getNickname()) .lastMessage(lastMessage) .build(); }}Service에서는 ChatRoomDto.of(roomId, user, lastLine); → ChatRoomDto.of(user, lastLine);와 같이 수정했다.컴포지션을 사용하면 클래스 간의 결합도가 낮아져 클래스를 구성하는 객체를 동적으로 변경할 수 있다.이는 코드의 수정 없이도 ChatRoomDto의 기능을 유연하게 확장할 수 있다는 것을 의미한다.예를 들어 ChatRoomDto의 기능을 확장하기 위해 LastMessage에 새로운 변수나 메서드를 추가해야 할 수 있다.@Getter@Builderpublic class LastMessage { private String roomId; private int adminChat; private int userChat; private String message; private String day; private String time; // 새로운 변수나 메서드 추가 private boolean hasAttachment; private String attachmentUrl; }이렇게 LastMessage에 새로운 기능을 추가하면, ChatRoomDto에서는 별도의 수정 없이도 이를 활용할 수 있다.이는 클래스 간의 결합도가 낮아서 발생하는 유연성의 장점이다.따라서 코드의 수정 없이도 ChatRoomDto의 기능을 유연하게 확장할 수 있다는 것을 의미한다.중복된 변수를 최소화하여 코드를 개선하고, 컴포지션을 통해 클래스 간의 결합도를 낮췄다.이를 통해 코드의 유지보수성을 높일 수 있고, 더욱 유연하고 확장 가능한 구조를 만들 수 있다.REFERENCE 상속을 자제하고 합성(Composition)을 이용하자 상속보다는 컴포지션을 사용하자 상속이 캡슐화를 깬다?" }, { "title": "Rabbitmq 적용", "url": "/posts/RabbitMQ-%EC%A0%81%EC%9A%A9/", "categories": "Project, RabbitMQ", "tags": "Chat", "date": "2024-04-05 00:00:00 +0900", "snippet": "RabbitMQ 적용이 전에 어떻게 적용을 해야하는지 파악했으니 이제 본 코드에 적용해보기로 했다.적용할 부분 1:1 채팅 현재 나는 1:n 채팅은 존재하지 않는다. 따라서 “topic”은 지운다. topic과 queue에 대한 stackoverflow 글 MessageType에 따른 Queue 설정 Connect, Send, Disconnect에 대한 별도의 Queue를 설정하여 처리를 분산시킨다. 사용자마다 Queue를 생성하는 것보다 효율적으로 처리할 수 있을 것 같았다.Code 수정application.propertiesrabbitmq.connect.queue = connect.queuerabbitmq.send.queue = send.queuerabbitmq.disconnect.queue = disconnect.queuerabbitmq.connect.exchange = connect.exchangerabbitmq.send.exchange = send.exchangerabbitmq.disconnect.exchange = disconnect.exchangerabbitmq.routing.key = room.*Stomp Config@Configuration@EnableWebSocketMessageBroker@RequiredArgsConstructorpublic class StompWebSocketConfig implements WebSocketMessageBrokerConfigurer { private final StompHandler stompHandler; @Override public void configureMessageBroker(MessageBrokerRegistry config) { config.setApplicationDestinationPrefixes(\"/app\"); config.setPathMatcher(new AntPathMatcher(\".\")); config.enableStompBrokerRelay(\"/exchange\"); // custom exchange 사용 } @Override public void registerStompEndpoints(StompEndpointRegistry registry) { registry.addEndpoint(\"/coco\").setAllowedOriginPatterns(\"*\").withSockJS(); } @Override public void configureClientInboundChannel(ChannelRegistration registration) { registration.interceptors(stompHandler); }}custom exchange만을 사용하여 message routing을 처리하기 때문에 “/exchange”만 추가했다.RabbitMQConfigMessageType(connect, send, disconnect)에 따라 exchange, queue 분리@Configurationpublic class RabbitMQConfig { @Value(\"${spring.rabbitmq.host}\") private String host; @Value(\"${spring.rabbitmq.port}\") private int port; @Value(\"${spring.rabbitmq.username}\") private String username; @Value(\"${spring.rabbitmq.password}\") private String password; @Value(\"${rabbitmq.connect.queue}\") private String connectQueue; @Value(\"${rabbitmq.send.queue}\") private String sendQueue; @Value(\"${rabbitmq.disconnect.queue}\") private String disconnectQueue; @Value(\"${rabbitmq.connect.exchange}\") private String connectExchange; @Value(\"${rabbitmq.send.exchange}\") private String sendExchange; @Value(\"${rabbitmq.disconnect.exchange}\") private String disconnectExchange; @Value(\"${rabbitmq.routing.key}\") private String routingKey; @Bean public Queue connectQueue() { return new Queue(connectQueue, true); } @Bean public Queue sendQueue() { return new Queue(sendQueue, true); } @Bean public Queue disconnectQueue() { return new Queue(disconnectQueue, true); } @Bean public TopicExchange connectExchange() { return new TopicExchange(connectExchange); } @Bean public TopicExchange sendExchange() { return new TopicExchange(sendExchange); } @Bean public TopicExchange disconnectExchange() { return new TopicExchange(disconnectExchange); } @Bean public Binding connectBinding() { return BindingBuilder .bind(connectQueue()) .to(connectExchange()) .with(routingKey); } @Bean public Binding sendBinding() { return BindingBuilder .bind(sendQueue()) .to(sendExchange()) .with(routingKey); } @Bean public Binding disconnectBinding() { return BindingBuilder .bind(disconnectQueue()) .to(disconnectExchange()) .with(routingKey); } @Bean public ConnectionFactory connectionFactory() { CachingConnectionFactory connectionFactory = new CachingConnectionFactory(host); connectionFactory.setHost(host); connectionFactory.setPort(port); connectionFactory.setVirtualHost(\"/\"); connectionFactory.setUsername(username); connectionFactory.setPassword(password); return connectionFactory; } @Bean public RabbitTemplate rabbitTemplate(ConnectionFactory connectionFactory) { RabbitTemplate rabbitTemplate = new RabbitTemplate(connectionFactory); rabbitTemplate.setMessageConverter(jackson2JsonMessageConverter()); rabbitTemplate.setRoutingKey(routingKey); return rabbitTemplate; } @Bean public MessageConverter jackson2JsonMessageConverter() { return new Jackson2JsonMessageConverter(); } @Bean public SimpleMessageListenerContainer container(ConnectionFactory connectionFactory) { SimpleMessageListenerContainer container = new SimpleMessageListenerContainer(); container.setConnectionFactory(connectionFactory); return container; }}connectExchange, sendExchange, disconnectExchange: 각각 연결, 전송, 연결 끊기와 관련된 Exchange를 정의했다.connectQueue, sendQueue, disconnectQueue: 위와 동일하게 연결, 전송, 연결 끊기와 관련된 Queue를 정의했다.그리고 Exchange와 Queue를 연결하는 Binding을 설정했다:각각의 RabbitTemplate과 container 빈에 Exchange와 Queue 이름을 설정하지 않은 이유는Exchange와 Queue가 각각 1개씩 있는 것이 아니라 여러 개 있기 때문이다.RabbitTemplate과 container는 모든 Exchange와 Queue에 대해메시지 전송 및 수신을 담당하는 역할을 하기 때문에 공통적인 설정만을 추가했다.Controller@Controller@RequiredArgsConstructor@Slf4jpublic class ChatController { private final ChatServiceImpl chatService; private final JwtTokenProvider jwtTokenProvider; private final RedisService redisService; private final RabbitTemplate rabbitTemplate; @Value(\"${rabbitmq.connect.exchange}\") private String connectExchange; @Value(\"${rabbitmq.send.exchange}\") private String sendExchange; @MessageMapping(\"chat.sendMessage\") public void sendMessage(@Payload ChatMessage chatMessage) { String roomId = chatMessage.getRoomId(); rabbitTemplate.convertAndSend(sendExchange, \"room.\" + roomId, chatMessage); } @MessageMapping(\"chat.addUser\") public void addUser(@Payload ChatMessage chatMessage, SimpMessageHeaderAccessor headerAccessor) { String token = headerAccessor.getFirstNativeHeader(\"Authorization\"); User user = jwtTokenProvider.getUserFromToken(token); String roomId = chatMessage.getRoomId(); chatMessage.setSender(user.getNickname()); chatMessage.setType(MessageType.JOIN); chatMessage.setAuth(user.getRole().name()); rabbitTemplate.convertAndSend(connectExchange, \"room.\" + roomId, chatMessage); } @EventListener public void handleWebSocketDisconnectListener(SessionDisconnectEvent event) { StompHeaderAccessor headerAccessor = StompHeaderAccessor.wrap(event.getMessage()); String sessionId = (String) headerAccessor.getHeader(\"simpSessionId\"); String token = redisService.getSession(sessionId); User user = jwtProvider.getUserFromToken(token); String nickname = user.getNickname(); String roomId = redisService.getRoomId(nickname); ChatMessage chatMessage = new ChatMessage(); chatMessage.setType(MessageType.LEAVE); chatMessage.setSender(nickname); chatMessage.setRoomId(roomId); rabbitTemplate.convertAndSend(disconnectExchange, \"room.\" + roomId, chatMessage); }}clientstompClient.subscribe('/exchange/' + connectEx +'/room.' + roomId, message);stompClient.subscribe('/exchange/' + sendEx +'/room.' + roomId, message);stompClient.subscribe('/exchange/' + disconEx +'/room.' + roomId, message);전체적인 흐름을 그림으로 보면 아래와 같다.RabbitMQ 페이지설정한 connect.exchange, send.exchange, disconnect.exchange가 포함되어있는걸 볼 수 있다.Exchange이 중에 connect.exchange를 클릭해보면 아래와 같이 띄워진다.Publish (in): 해당 exchange로 메시지가 도착하는 속도Publish (out): 해당 exchange에서 메시지가 발송되는 속도connect.exchange에 바인딩된 queue는 connect.queue다.Queue각 exchange에 바인딩 된 queue는 아래와 같다.connect Queue채팅방에 입장을 하면 서버에서 message를 보낸다.해당 message를 Get Message 버튼을 클릭하면 볼 수 있다.send Queue채팅방에서 메세지를 보내고 관리자 페이지를 확인했다.   Total Ready Unacked In memory Persistent Transient, Paged Out Messages 1 1 0 1 1 0 Message body bytes 139 B 139 B 0 B 139 B 139 B 0 B Process memory 13 KiB           Total Messages: 현재 시스템에 총 메시지 수 Ready Messages: 대기열에 있는 메시지 수. consumer에게 전달 될 message Unacked Messages: 소비자가 메시지를 처리하려고 했지만 처리가 완료되지 않은 상태 소비자가 처리를 완료하고 메시지를 확인(acknowledge)하면 해당 메시지는 “Unacked” 상태에서 제거되고, “Ready” 상태로 전환된다. ex) 서버 부하가 증가하거나 사용자가 많아져서 큐에 메시지가 쌓이는 경우 발생 할 수 있다. In Memory Messages: 메시지 큐에 현재 메모리에 저장된 메시지 수 Persistent Messages: 디스크에 저장된 메시지 수 메모리에 저장되는 대신 디스크에 지속적으로 저장되는 메시지는 지속적(persistent) 메시지다. *durable queue를 사용하는 경우 메시지가 디스크에 저장된다. Transient Messages, Paged Out: 메시지 큐에서 메모리에서 페이지 아웃(메시지가 메모리에서 디스크로 이동)된 메시지 수 Message Body Bytes: 메시지들의 총 바이트 크기 Process Memory: RabbitMQ 프로세스가 사용하는 메모리 양 메시지를 한 번 처리할 때 사용 가능한 메모리 공간의 한계 여기서 한 번에 100개의 메시지를 보내면 어떻게 될까?메시지를 보내는 과정중에 Process memory가 일시적으로 증가한다.메시지를 더 이상 보내지 않았더니 메모리 양이 기존으로 다시 돌아왔다.이를 통해 메시지의 전달과 소비에 따라 메모리의 사용량이 동적으로 변동하면서메모리가 적절하게 관리되어 시스템의 안정성을 유지하고 성능을 최적화하는 것을 파악할 수 있다." }, { "title": "Rabbitmq", "url": "/posts/RabbitMQ/", "categories": "Project, RabbitMQ", "tags": "Chat", "date": "2024-04-01 00:00:00 +0900", "snippet": "RabbitMQMessage Broker는 실시간 채팅 서비스를 구현하는 데 핵심적인 부분이다.Message Broker를 적용하는 과정에 대해서 정리했다.WebSocket과 Stomp의 차이점에 대해서 살펴보면WebSocket은 클라이언트와 서버 간 양방향 실시간 통신을 가능하게 하는 프로토콜이다.별도의 메시지 브로커 없이도 클라이언트와 서버 간의 통신을 구현할 수 있다.Stomp는 메시지 브로커와 클라이언트 간 상호작용을 위한 프로토콜이다.메시지 큐나 브로커와의 통신을 추상화하여 클라이언트가 메시지를 보내고 받을 때의 프로토콜을 통일한다. (일관된 방식)따라서 보안 토큰과 같은 정보를 헤더와 바디를 가진 메시지로 전달할 수 있다.나는 Stomp 프로토콜을 선택하여 보안을 강화하고 메시지의 타입에 따라 컨트롤러를 분리하기로 했다.따라서 나는 header의 token을 담아 보안을 높이고 메세지 타입에 따른 controller를 분리 시키기 위해 Stomp을 사용했었다.In Memory Broker의 문제점Stomp 프로토콜을 사용할 때는 기본적으로 In-Memory Message Broker를 사용하게된다.In Memory Broker를 사용하는 경우 몇 가지 문제점이 있다. 용량 제한: 세션을 수용할 수 있는 크기가 제한되어 있어서, 사용자 수가 증가할수록 서버 부하와 처리량이 감소한다. 장애 발생 시 메시지 유실 가능성: 장애가 발생하면 메시지가 메모리에만 저장되어 있기 때문에 메시지 유실 가능성이 높아진다. 모니터링 어려움: 메모리 기반 브로커의 경우 모니터링 도구나 기능이 제한되어 있어 시스템 상태를 파악하기 어렵다. 이러한 문제점을 해결하기 위해 외부 브로커인 RabbitMQ, Kafka, Active MQ 등을 사용할 수 있다.Redis의 적용과 문제점문제를 해결하기 위해 Redis를 사용하여 메시지를 빠르게 처리할 수 있도록 적용했었다.그러나 Redis는 STOMP 프로토콜을 지원하지 않았다.따라서 front에서 사용 중인 STOMP 프로토콜과의 호환성 문제가 발생했다.현재 채팅은 front에서 STOMP 프로토콜을 사용하고 있기 때문에Redis broker를 사용해서 채팅을 진행하려면 websocket을 사용해야하고front를 수정하지 않고 동작시키기 위해서는STOMP 프로토콜의 Message Broker 기능을 제공하는 RabbitMQ, ActiveMQ 등을 사용해야했다.RabbitMQ와 ActiveMQ 비교RabbitMQ와 ActiveMQ는 메시지를 수신한 구독자가 해당 메시지를 명시적으로 확인하기 전까지는 메시지를 보관하고 유지한다.이러한 방식을 메시지 액키스(Acknowledgement) 또는 컨슈머의 확인(Consumer Acknowledgement)이라고 한다.따라서 메시지를 받기 전까지 삭제하지 않으며, 이는 메시지 손실을 방지하는 데 도움이 된다.비교적으로 RabbitMQ는 더 높은 성능과 안정성을 제공하며, 더 많은 정보를 얻을 수 있다.또한, 단순하고 쉽게 설정하고 관리할 수 있는 특성을 가지고 있다.위와 같은 이유로, RabbitMQ와 ActiveMQ 중에서는 RabbitMQ를 선택했다.남은 RabbitMQ와 Kafka를 후보로 두고 내가 정한 기준에 따라 결정했다.1. 문제가 발생했을 시 재시도 가능2. Stomp 프로토콜을 지원RabbitMQ와 Kafka의 특징RabbitMQ는 AMQP 프로토콜을 지원하여 다양한 클라이언트 언어와 플랫폼에서 사용할 수 있다.또한 메시지 지속성을 통해 메시지 손실을 방지하고 유연한 메시지 라우팅 기능을 제공한다.이는 비동기 및 분산 시스템에 적합하다.반면 Kafka는 로그 기반 아키텍처를 통해 대량의 데이터를 신속하게 처리할 수 있으며,분산 및 확장성을 갖춘 클러스터 구성으로 대규모 데이터 처리가 가능하다.또한 파티션 단위로 데이터를 저장하여 순서를 보장한다.RabbitMQ와 Kafka의 재시도 메커니즘RabbitMQ는 메시지 처리 실패 시 재시도가 가능한 내장된 메커니즘을 제공한다.이를 통해 다른 소비자가 해당 메시지를 처리할 수 있으며, 재시도 동안 다른 메시지의 처리가 중단되지 않는다.반면 Kafka는 내장된 재시도 메커니즘이 없기 때문에 소비자 애플리케이션에서 메시지 재시도 로직을 직접 구현해야 한다.또한 파티션 내에서 순서가 보장되므로 메시지 처리 중에 다른 메시지 처리가 대기해야 한다.이러한 특징을 고려하여 RabbitMQ가 메시지의 안정적인 전달을 보장하고 실시간 채팅 서비스에 적합하다고 판단했다.RabbitMQ flow공식 문서단순 내장 메시지 브로커가 활성화될 때 사용되는 구성 요소외부 브로커(RabbitMQ)를 구성할 때 사용되는 구성 요소두 다이어그램 사이의 차이점은 메시지를 TCP를 통해 외부 STOMP broker까지 전달하고broker에서 가입된 client로 메시지를 전달하기 위해 “broker relay”를 사용한다는 것이다.message는 Producer에서 시작하여 Exchange를 거쳐 Binding된 Queue로 이동하고, 최종적으로 Consumer에게 전달된다. +----------+ +------------+ +----------+ +------+ | Producer | --&gt; | Exchange | --&gt; | Binding | --&gt; | Queue| --&gt; Consumer +----------+ +------------+ +----------+ +------+ | Routing | | Rules | +--------------+ Producer(프로듀서): Producer는 메시지를 생성하고 Message Broker(RabbitMQ)에 전송한다. Exchange(익스체인지): Exchange는 Producer로부터 받은 메시지를 수신하고 라우팅한다. Exchange는 설정된 라우팅 규칙(route key)에 따라 메시지를 하나 이상의 Queue로 라우팅한다. Binding(바인딩): Binding은 Exchange와 Queue 간의 연결을 말한다. Binding을 통해 Exchange는 어떤 Queue로 메시지를 전달할지 결정한다. Queue(큐): Queue는 Exchange로부터 메시지를 수신하여 저장한다. Binding된 Queue 중 하나에 메시지가 전달된다. Consumer(컨슈머): Consumer는 Queue에 쌓인 메시지를 소비하고 처리한다. Consumer는 Queue에 새로운 메시지가 도착할 때마다 해당 메시지를 받아 처리한다. Code 작성공식 문서공식 문서 guide의존성 주입implementation 'org.springframework.boot:spring-boot-starter-reactor-netty'implementation 'org.springframework.boot:spring-boot-starter-amqp'stompBrokerRelayMessageHandler는 Spring Framework의 WebSocket 모듈에서STOMP 메시징 프로토콜을 사용하여 메시지 브로커와 통신하기 위한 핸들러다.이 핸들러를 사용하려면 STOMP 메시지 브로커와의 통신을 지원하는 라이브러리가 필요하다.Reactor Netty를 백엔드로 사용하기 때문에 관련 설정을 추가해준다.# application.propertiesspring.rabbitmq.host=localhostspring.rabbitmq.port=5672spring.rabbitmq.username=guestspring.rabbitmq.password=guest# RabbitMQ queue, exchange, routing-key inforabbitmq.queue.name = adme.queuerabbitmq.exchange.name = adme.exchangerabbitmq.routing.key = room.*routing key는 사용자 별로 채팅방 id가 다르기 때문에 와일드 카드를 사용했다.. * : 한 단어만을 대신 # : 한 단어 이상을 대신ex) room.*일 때, “room.hello”와 “room.hi”는 인식하지만 “room.hello.hi”는 인식하지 못한다.이럴 때 room.#을 사용해야한다.room.* 패턴은 “room.” 다음에 딱 하나의 단어가, room.# 패턴은 “room.” 다음에 하나 이상의 단어가 나온다고 보면 된다.RabbitMQ tutorial - Topicsstomp@Configuration@EnableWebSocketMessageBroker@RequiredArgsConstructorpublic class StompWebSocketConfig implements WebSocketMessageBrokerConfigurer { private final StompHandler stompHandler; @Override public void configureMessageBroker(MessageBrokerRegistry config) { config.setApplicationDestinationPrefixes(\"/app\"); // pub config.setPathMatcher(new AntPathMatcher(\".\")); // URL을 / → .으로 config.enableStompBrokerRelay( \"/queue\", \"/topic\", \"/exchange\", \"/amq/queue\");// stompBrokerRelayMessageHandler는 외부 메시지 브로커와 통신하기 위한 설정이다. @Override public void registerStompEndpoints(StompEndpointRegistry registry) { //소켓에 연결하기 위한 엔드 포인트를 지정 registry.addEndpoint(\"/coco\").setAllowedOriginPatterns(\"*\").withSockJS(); } @Override public void configureClientInboundChannel(ChannelRegistration registration) { // jwt 토큰 검증을 위해 생성한 stompHandler를 인터셉터로 지정해준다. registration.interceptors(stompHandler); }}RabbitMQ에서는 점(.)을 사용하여 경로를 구분한다.예를 들어, “/room”과 같은 주제를 구독할 때, RabbitMQ에서는 “/room” 대신에 “.room”으로 사용된다.따라서 Spring의 configureMessageBroker()에서 config.setPathMatcher(new AntPathMatcher(\".\"))를 사용한다.ConfigExchage 유형은 4가지가 있다. (Direct Exchange, Fanout Exchange, Topic Exchange, Headers Exchange)고객센터의 채팅을 구현했기 때문에 1:1 통신에 적합한 방식인 direct를 사용하려고 했으나routing Key와 큐의 binding key가 정확히 일치하는 경우에만 메시지를 전달하기 때문에와일드 카드(*, #)를 사용할 수가 없다.사용자 별로 채팅방 id를 구분하기 때문에 와일드 카드를 사용해야해서 TopicExchange을 사용했다.TopicExchange는 pub/sub에 적합하다.@Configurationpublic class RabbitMQConfig { @Value(\"${spring.rabbitmq.host}\") private String host; @Value(\"${spring.rabbitmq.port}\") private int port; @Value(\"${spring.rabbitmq.username}\") private String username; @Value(\"${spring.rabbitmq.password}\") private String password; @Value(\"${rabbitmq.queue.name}\") private String queueName; @Value(\"${rabbitmq.exchange.name}\") private String exchange; @Value(\"${rabbitmq.routing.key}\") private String routingKey; /** * 지정된 큐 이름으로 Queue 빈을 생성 * @return Queue 빈 객체 */ @Bean public Queue queue() { return new Queue(queueName, true); } /** * routing Key와 일치하는 Queue로 메시지를 전송하기 위한 TopicExchange 빈 생성 * @return TopicExchange 빈 객체 */ @Bean public TopicExchange exchange() { return new TopicExchange(exchange); } /** * Exchange와 Queue를 바인딩하기 위한 Binding 빈 생성 * @param queue Queue 빈 객체 * @param exchange TopicExchange 빈 객체 * @return Binding 빈 객체 */ @Bean public Binding binding(Queue queue, TopicExchange exchange) { // 라우팅 키를 사용하여 Exchange와 Queue를 바인딩 return BindingBuilder .bind(queue) .to(exchange) .with(routingKey); } /** * RabbitMQ와의 연결을 관리하는 클래스 * @return ConnectionFactory 빈 객체 */ @Bean public ConnectionFactory connectionFactory() { // RabbitMQ와의 연결을 설정 CachingConnectionFactory connectionFactory = new CachingConnectionFactory(host); connectionFactory.setPort(port); connectionFactory.setUsername(username); connectionFactory.setPassword(password); return connectionFactory; } /** * RabbitMQ와의 메시지 통신을 담당하는 클래스 * @param connectionFactory ConnectionFactory 빈 객체 * @return RabbitTemplate 빈 객체 */ @Bean public RabbitTemplate rabbitTemplate(ConnectionFactory connectionFactory) { // RabbitMQ와의 메시지 통신을 설정 RabbitTemplate rabbitTemplate = new RabbitTemplate(connectionFactory); rabbitTemplate.setMessageConverter(jackson2JsonMessageConverter()); rabbitTemplate.setExchange(exchange); rabbitTemplate.setRoutingKey(routingKey); return rabbitTemplate; } @Bean public SimpleMessageListenerContainer container(ConnectionFactory connectionFactory) { // RabbitMQ 메시지 리스너 컨테이너 설정 SimpleMessageListenerContainer container = new SimpleMessageListenerContainer(); container.setConnectionFactory(connectionFactory); container.setQueueNames(queueName); return container; } /** * Jackson library를 사용해서 메시지를 JSON 형식으로 변환하는 BEAN 생성 * @return MessageConverter 빈 객체 */ @Bean public MessageConverter jackson2JsonMessageConverter() { return new Jackson2JsonMessageConverter(); }}new Queue(queueName, true);boolean durable 매개변수는 큐의 지속성(durability)을 나타낸다.true로 설정하면, 큐가 지속되어 RabbitMQ 서버가 다시 시작되어도 유지된다.이는 큐에 저장된 메시지가 손실되지 않고 유지되는 것을 의미한다.false로 설정하면, 큐가 비지속적(non-durable)이며, RabbitMQ 서버가 다시 시작될 때 해당 큐가 삭제된다.이 경우 큐에 저장된 메시지는 유실될 수 있다.ProducerRedis의 Publisher-Subscriber 모델은 RabbitMQ의 Producer-Consumer 모델과 유사한 메시지 전달 패턴을 가지고 있다.@Service@RequiredArgsConstructor@Slf4jpublic class ChatMessageProducer { private final RabbitTemplate rabbitTemplate; @Value(\"${rabbitmq.queue.name}\") private String queue; @Value(\"${rabbitmq.exchange.name}\") private String exchange; @Value(\"${rabbitmq.routing.key}\") private String routingKey; public void sendMessage(ChatMessage message, String roomId) { log.info(\"message send : {}\", message); rabbitTemplate.convertAndSend(exchange, roomId, message); }}ConsumerRedis의 경우 MessageListener를 구현하는 방식으로 메시지를 구독했었다.RabbitMQ에서는 메시지를 소비하고 처리하기 위해 @RabbitListener을 사용하면 된다.@Component@Slf4jpublic class ChatMessageConsumer{ @RabbitListener(queues = \"${rabbitmq.queue.name}\") public void onMessage(Message message) { // Queue에서 message를 구독 try { log.info(\"Received message: \" + new String(message.getBody())); } catch (Exception e) { log.error(\"Error processing message: \" + e.getMessage()); } }}ControllerRedis에서는 메시지를 수신하기 위해 Channel을 구독하고, 이를 수신하는 MessageListener를 등록했었다.하지만 RabbitMQ에서는 메시지를 수신하기 위해 명시적인 구독이 필요하지 않았다.Producer가 메시지를 보내면 해당 Exchange에 메시지가 전달되고,이를 구독하는 Consumer는 큐로부터 메시지를 받아 처리한다.@Controller@RequiredArgsConstructor@Slf4jpublic class ChatController { private final ChatServiceImpl chatService; private final JwtTokenProvider jwtTokenProvider; private final RedisService redisService; private final ChatMessageProducer producer; @MessageMapping(\"chat.sendMessage\") public void sendMessage(@Payload ChatMessage chatMessage) { producer.sendMessage(chatMessage, \"room.\" + chatMessage.getRoomId()); } @MessageMapping(\"chat.addUser\") public void addUser(@Payload ChatMessage chatMessage, SimpMessageHeaderAccessor headerAccessor) { chatMessage.setType(MessageType.JOIN); redisService.addRedis(chatMessage); chatService.countUser(\"Connect\", roomId, chatMessage); producer.sendMessage(chatMessage, \"room.\" + chatMessage.getRoomId()); }}Dockerdocker run -d --name rabbitmq -p 5672:5672 -p 15672:15672 -p 61613:61613 rabbitmq:managementRabbitMQ의 AMQP port : 5672관리자 웹 인터페이스 port : 15672RabbitMQ의 STOMP port : 61613RabbitMQ STOMP plug-in 활성화$ rabbitmq-plugins enable rabbitmq_web_stomp$ rabbitmq-plugins enable rabbitmq_web_stomp_examplesRabbitMQ 관리자 페이지application을 실행하면 아래 로그가 뜬다.RabbitMQ 서버와 Connection이 정상적으로 동작하는 것을 확인할 수 있다.http://localhost:15672로 들어가서 로그인을 한다.ConnectionsConnections 탭에서 연결이 되었는지 확인한다.Exchange 확인adme.exchange를 클릭해서 binding 탭을 보면application.properties에 설정한 값 그대로 들어가 있는 것을 볼 수 있다.Listener testConsumer 쪽으로 메세지가 잘 들어가는지 테스트 해본다.RabbitMQ management 에서 자체적으로 테스트를 할 수 있다.Queues &gt; adme.queue(각자 설정한 queueName)의 상세 화면을 보면 Publish message 토글이 있다.Payload에 아무 글이나 작성하고 Pulbish message를 클릭한다.메세지가 발행이 되었다고 alert창이 뜬다. 서버 log를 확인해본다.code testdestination을 /queue/&lt;name&gt;으로 설정하면 메세지는 default exchange로 발행된다.destination을 /topic/&lt;routing_key&gt;로 설정하면 메세지는 amq.topic 이라는 exchange로 발행된다.나머지 destination에 대해 /exchange/&lt;exchange_name&gt;/[routing_key] 의 exchange로 메세지가 발행된다.exchanges 탭을 보면 아래와 같이 보여지는데 adme.exchange는 직접 만든 것이고나머지는 RabbitMQ에서 기본으로 만들어 준 것이다.custom exchangestompClient.subscribe('/exchange/adme.exchange/room.' + roomId, onMessageReceived);private final static String CHAT_EXCHANGE_NAME = \"adme.exchange\";@MessageMapping(\"chat.addUser\")public void addUser(@Payload ChatMessage chatMessage, SimpMessageHeaderAccessor headerAccessor) { rabbitTemplate.convertAndSend(CHAT_EXCHANGE_NAME, \"room.\" + chatMessage.getRoomId(), chatMessage);}queue(default exchange)stompClient.subscribe('/queue/room.' + roomId, onMessageReceived);private final static String CHAT_EXCHANGE_NAME = \"adme.exchange\";@MessageMapping(\"chat.addUser\")public void addUser(@Payload ChatMessage chatMessage, SimpMessageHeaderAccessor headerAccessor) { rabbitTemplate.convertAndSend(C\"room.\" + chatMessage.getRoomId(), chatMessage);}topic(amq.topic)let exchanstompClient.subscribe('/topic/room.' + roomId, onMessageReceived);private final static String CHAT_EXCHANGE_NAME = \"adme.exchange\";@MessageMapping(\"chat.addUser\")public void addUser(@Payload ChatMessage chatMessage, SimpMessageHeaderAccessor headerAccessor) { rabbitTemplate.convertAndSend(\"amq.topic\", \"room.\" + chatMessage.getRoomId(), chatMessage);}*RabbitMQ 관리 페이지와 관련된 글은 Rabbitmq 적용에서 더 볼 수 있다.ERROR 모음집Connection refusedio.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: no further information:해결방법RabbitMQ의 STOMP 포트인 61613 포트를 매핑시킨다.docker run -d --name rabbitmq -p 5672:5672 -p 15672:15672 -p 61613:61613 rabbitmq:managementREFERENCE Stomp + Kafka를 이용한 채팅 기능 개발하기 - (with Spring Boot) #1 (Kafka와 Stomp는 무엇일까?) [36] WebSocket - In Memory 대신 외부 브로커 사용하는 이유= = = = = = = = = = = = = = = = = = = = = = = = = = = WebSocket - RabbitMQ Springboot + RabbitMQ 연동 및 초간단 샘플 프로젝트 만들기 STOMP에 RabbitMQ를 추가해보았다." }, { "title": "Apache jmeter", "url": "/posts/Apache-Jmeter/", "categories": "Project, 성능테스트", "tags": "Monitoring", "date": "2024-03-25 00:00:00 +0900", "snippet": "Apache JmeterDownload Release 클릭 후 나는 apache-jmeter-5.6.3.zip 다운받았다.파일 압축을 해제 한 후 bin 파일에 들어가서ApacheJMeter.jar 파일을 실행하면 jmeter가 실행된다.window인 나는 jmeter.bat을 실행했다.JMeter pluginlink이렇게 검색해도 된다.해당 이미지처럼 클릭해서 플러그인 매니저를 다운받는다.jmeter 압축해제 한 뒤 해당 파일을 jmeter 폴더의 lib/ext 안에 넣어준다.JMeter를 재시작 하면 아래와 같이 플러그인을 설치할 수 있게 메뉴가 생겼다.Http TestThread 설정JMeter에서 Test Plan 우클릭 → add → Thread(Users) → Thread Group을 하여 Thread Group을 생성한다.1) Number of Threads (users) : 쓰레드 개수 → 사용자 수2) Ramp-Up Period (in seconds) : 쓰레드 당 생성시간Number of Threads = 1000이고 Ramp-up = 10 일 때, 1000명의 유저를 생성하는데 10초가 걸린다.→ 1초 동안 100명의 유저가 요청을 한다Ramp-up = 0 으로 설정하면, 동시 접속 자 수는 1000명이 된다.3) Loop Count : Thread당 수행할 테스트 횟수Number of Threads = 1000 이고 Loop Count = 10 일 때, 1000명의 유저는 동일한 작업을 10번 수행하게 된다.따라서 총 1000 * 10 = 10000 번 수행되고, 총 요청 횟수로 생각할 수 있다.WebSocket TestWebSockeet Sampler 플러그인을 설치한다.options 탭 → Plugins Manager → Available Plugins 탭 클릭 → WebSocket Sampler by Peter Doornbosch를 체크우측 하단의 Apply Changes and Restart JMeter버튼 클릭WebSocket Close: WebSocket 연결을 닫는 작업을 테스트한다. → WebSocket 연결의 안정성과 정상적인 종료 상황을 확인WebSocket Open Connection: WebSocket 서버에 연결을 연다. → WebSocket 연결 설정이 올바른지 확인하고, 연결이 성공적으로 이루어지는지 확인WebSocket Ping/Pong: WebSocket 통신 중에 Heartbeat 메시지를 보내고 받아서 연결의 활성 상태를 유지하는지 테스트한다. → 서버와의 연결 유지 여부를 확인WebSocket Single Read Sampler: WebSocket에서 메시지를 읽어오는 작업을 테스트한다. → 서버로부터의 응답을 확인하거나 특정 이벤트를 감지WebSocket Single Write Sampler: WebSocket으로 메시지를 전송하는 작업을 테스트한다. ex) 채팅 메시지를 보내는 등의 작업 테스트WebSocket Request-Response Sampler: WebSocket을 통해 요청을 보내고, 서버로부터의 응답을 받는 작업을 테스트한다. → 요청과 응답 간의 시간을 측정하고, 성능을 평가MessageMapping으로 채팅 메시지를 보내는 경우에는 WebSocket Single Write Sampler를 사용하면 될 것 같고EventListener를 통해 연결 및 종료 이벤트를 감지하는 경우에는각각 WebSocket Open Connection 및 WebSocket Close Sampler를 사용하면 될 것 같다.testlogin채팅을 하기 전 header에 token을 담기 위해서 login 먼저 진행했다.Thread Group Thread Group 안에 HTTP Request, Debug Sampler, View Results Tree 추가 Thread Group &gt; Add &gt; Sampler &gt; HTTP Request Thread Group &gt; Add &gt; Listener &gt; View Results Tree Thread Group &gt; Sampler &gt; Debug SamplerHTTP RequestBody Data에 json형식으로 nickname과 password를 작성한다.{ \"nickname\" : \"nick.123\", \"password\" : \"nick.123\"}HTTP Header Manager HTTP request &gt; Add &gt; Config Element &gt; HTTP Header ManagerHTTP Header Manager에 Name = Content-type, Value = application/json를 추가한다.View Results TreeResponse data &gt; Response Body로 보면 아래와 같은 형식으로 응답이 온다.{\"success\":true, \"role_check\":\"사용자\",\"token\":\"token1234\",\"username\":\"nick.123\"}Regular Expression Extractor HTTP request &gt; Add &gt; Post Processor &gt; Regular Expression Extractor응답이 온 값들 중 token만 값을 저장하려고 한다. Name of created variable : token Regular Excpression : \"token\":\"([^\"]+)\" Template : $1$ Match No. : 1token이 추출 된 것을 볼 수 있다.BeanShell PostProcessor HTTP request &gt; Add &gt; Post Processor &gt; BeanShell PostProcessorDebug Sampler에서 추출한 token 값을 넣었다.import org.apache.jmeter.protocol.http.control.Header;sampler.getHeaderManager().add(new Header(\"Authorization\",vars.get(\"token\")));로그인 후의 http request게시글 조회로 test를 해봤다. HTTP Request를 만들고 HTTP Header Manager에 token을 넣어준다.Chat전체 보기참고로 모든 요청에 HTTP Header Manager를 생성하여 아래와 같이 작성했다.*simpSessionId는 아래에서 설명 예정WebSocket Open Connection Thread Group &gt; Add &gt; Sampler &gt; WebSocket Open ConnectionStomp 프로토콜을 사용하여 통신하는 엔드포인트는 /ws 다.채팅을 할 때 network로 해당 url을 살펴보면 아래와 같이 보여진다.ws://localhost:8080/ws/${유저 번호}/${세션 식별자}/websocket이를 Server URL에 작성하면 ws, localhost, 8080으로 작성할 수 있다.여기서 Path는 ws/${유저 번호}/${세션 식별자}/websocket인데유저번호를 3자릿수로, 세션 식별자를 8자릿수로 설정했다.변수 추가user number Thread Group &gt; HTTP Request &gt; Add &gt; Config Element &gt; Random Variable100~999 랜덤 숫자session Thread Group &gt; HTTP Request &gt; Add &gt; Config Element &gt; User Defined Variablesa~z 중 랜덤 8자리Name = sessionId, Value = ${__RandomString(8,abcdefghijklmnopqrstuvwxyz)}따라서 path는 /ws/${num}/${sessionId}/websocket로 설정할 수 있다.작성 후에 실행하면 성공적으로 띄워지는 것을 볼 수 있다.이제 채팅을 연결 시켜봤으니 사용자가 해당 채팅을 연결 시켜보는 작업을 진행한다.Send Connect : WebSocket Single Write Sampler Thread Group &gt; Add &gt; Sampler &gt; WebSocket Single Write SamplerWebSocket Open Connection”으로 연결을 열어둔 상태에서“WebSocket Single Write Sampler”로 메시지를 보내기 때문에 use existing connection 적용Request data :[\"CONNECTED\\nversion:1.2\\n\\n\\u0000\"]만약 config에서 heart-beat를 설정했다면 [\"CONNECTED\\nversion:1.2\\nheart-beat:0,0\\n\\n\\u0000\"]와 같이 작성SEND SUBSCRIBE : WebSocket Single Write Sampler Thread Group &gt; Add &gt; Sampler &gt; WebSocket Single Write Sampler구독하는 url : /topic/public/${roomId}Request data : [\"SUBSCRIBE\\ndestination:/topic/public/room/'${roomId}'\\nid:sub-0\\n\\n\\u0000\"] \\n\\n: STOMP 프로토콜에서는 헤더와 본문을 구분하기 위해 빈 줄 (두 개의 연속된 개행 문자)을 사용 \\u0000: 이는 STOMP 프레임의 끝을 나타내는 NULL 문자 만약 id 값을 넣지 않고 [\"SUBSCRIBE\\ndestination:/topic/public/room/'${roomId}'\\n\\n\\u0000\"] 와 같이 작성했다면No subscriptionId in GenericMessage 라는 에러가 뜬다.STOMP 프로토콜에서는 클라이언트가 구독(subscribe) 요청을 할 때 필수정인 정보를 전달한다. destination : 구독할 대상의 목적지를 지정한다. (topic이나 queue의 이름) id : 클라이언트가 메시지를 수신할 때 사용할 subscriptionId를 지정한다. 서버가 클라이언트에게 할당하는 고유한 식별자로써 클라이언트는 이 subscriptionId를 통해 메시지를 구독하고, 서버는 해당 subscriptionId를 통해 메시지를 전송한다. &gt;&gt;&gt; SUBSCRIBEid:sub-0destination:/topic/public/3d41c3ed-8ddb-458dWebsocket 정리 글을 참고한다.채팅방 입장(code)// ChatController@MessageMapping(\"/chat/addUser\")public void addUser(@Payload ChatMessage chatMessage, SimpMessageHeaderAccessor headerAccessor) { // 일부 코드 생략 String sessionId = (String) headerAccessor.getHeader(\"simpSessionId\"); String token = headerAccessor.getFirstNativeHeader(\"Authorization\"); redisService.addSession(sessionId, token); log.info(\"[chat] addUser token 검사: \" + user.getNickname()); template.convertAndSend(\"/topic/public/\" + roomId, chatMessage);}// WebSocketConfig @Overridepublic void configureMessageBroker(MessageBrokerRegistry config) { config.enableSimpleBroker(\"/topic\"); config.setApplicationDestinationPrefixes(\"/app\");}작성해야 할 정보 : token, sessionId, roomId, MessageType, day, time위 정보들을 request data에 담기 위해서 JSR223 Sampler를 사용했다. Thread Group &gt; Add &gt; Sampler &gt; JSR223 Sampler*만약 JSR223 Sampler가 존재하지 않을 경우 Options의 Plugins Manager에서 설치하면 된다.import java.util.UUID;import java.util.Calendar;import java.text.SimpleDateFormat;// 현재 시간을 가져오기 위해 Calendar 객체 생성Calendar cal = Calendar.getInstance();// 월과 일을 가져옴 (월은 0부터 시작하므로 1을 더해줌)int month = cal.get(Calendar.MONTH) + 1;int day = cal.get(Calendar.DAY_OF_MONTH);// SimpleDateFormat을 사용하여 원하는 형식으로 날짜를 포맷SimpleDateFormat dateFormat = new SimpleDateFormat(\"MM/dd\");String formattedDate = dateFormat.format(cal.getTime());// 시간과 분을 가져옴int hour = cal.get(Calendar.HOUR_OF_DAY);int minute = cal.get(Calendar.MINUTE);// roomId 생성String roomId = UUID.randomUUID().toString();// 생성된 roomId를 JMeter 변수에 할당vars.put(\"roomId\", roomId);// 가져온 월과 일을 JMeter 변수에 할당vars.put(\"date\", formattedDate); // 가져온 시간과 분을 JMeter 변수에 할당vars.put(\"time\", String.valueOf(hour) + \":\" + String.valueOf(minute));Request data :[\"SEND\\ndestination:/app/chat/addUser\\nAuthorization:${token}\\ncontent-type:application/json\\n\\n{\\\"roomId\\\":\\\"${roomId}\\\",\\\"type\\\":\\\"JOIN\\\",\\\"day\\\":\\\"${date}\\\",\\\"time\\\":\\\"${time}\\\"}\\n\\u0000\"]@MessageMapping(\"/chat/addUser\")public void addUser(@Payload ChatMessage chatMessage, SimpMessageHeaderAccessor headerAccessor) { // 코드 생략 log.info(\"[chat] addUser token 검사: \" + user.getNickname());}사용자가 채팅방에 접속했을 때 띄워지는 log가 출력되었다.REFERENCE [JMeter] JMeter를 이용한 성능 테스트 Apache JMeter란 무엇인가? (+ 사용 방법 with 성능 및 부하 테스트) JMeter을 이용해서 웹서버 성능 테스트하기 JMeter 플러그인 설치 및 활용 🙈Apache JMeter - HTTP, WebSocket 성능 테스트🐵 Jmeter jwt 동적으로 받기 (1탄) [Spring Boot] Jmeter로 STOMP 부하 테스트 하기" }, { "title": "Ngrinder", "url": "/posts/nGrinder/", "categories": "Project, 성능테스트", "tags": "Monitoring", "date": "2024-03-21 00:00:00 +0900", "snippet": "nGrindernGrinder는 성능 테스트를 위한 오픈 소스 플랫폼으로, Controller와 에이전트(Agent)로 구성된다. 컨트롤러 (Controller)nGrinder 성능 테스트를 관리하고 조정하는 중앙 집중형 서버다.사용자는 웹 인터페이스를 통해 컨트롤러에 접속하여 테스트를 설정하고 실행할 수 있다.컨트롤러는 테스트를 위해 Agent들을 관리하고, 테스트 결과를 수집하여 보고서를 생성한다. 에이전트 (Agent)Controller에서 지시를 받아 성능 테스트를 수행하는 노드다.여러 대의 Agent가 동시에 여러 서버에 분산되어 실행될 수 있다.Agent는 실제 테스트 대상 시스템에 부하를 가해 성능을 측정하고, 이러한 결과를 Controller에 보고한다.먼저 Controller를 설정하고 실행하여 웹 인터페이스를 통해 성능 테스트를 관리한다.그런 다음, 테스트를 실행하기 위해 하나 이상의 에이전트를 준비하고 컨트롤러에 연결한다.Controller에서 성능 테스트를 설정하고 실행하면, 에이전트들이 테스트를 수행하고 결과를 컨트롤러에 제공한다.설치 (3가지 방법 중 1개 선택)1. war 파일 다운설치 링크ngrinder-controller-3.5.9.war 다운$ java -jar ngrinder-controller-3.5.9-p1.war --port=8300Tomcat과 충돌하지 않는 포트 번호를 선택하여 사용했다.(충돌하지 않는 포트번호면 어떠한 것도 상관없음)2. DockerController 설치 및 실행$ docker pull ngrinder/controller$ docker run -d -v ~/ngrinder-controller:/opt/ngrinder-controller --name controller -p 80:80 -p 16001:16001 -p 12000-12009:12000-12009 ngrinder/controller --name controller : 컨테이너의 이름을 controller로 지정 -p 80:80 : 호스트의 80번 포트와 컨테이너의 80번 포트를 연결 -p 16001:16001 : 호스트의 16001번 포트와 컨테이너의 16001번 포트를 연결 -p 12000-12009:12000-12009 : 호스트의 12000부터 12009까지의 포트와 컨테이너의 동일한 범위의 포트를 연결 호스트의 8081번 포트를 컨테이너의 80번 포트로 사용하고 싶다면 -p 8081:80 으로 수정할 수 있디. Agent 설치 및 실행$ docker pull ngrinder/agent$ docker run -d --name agent --link controller:controller ngrinder/agent --name agent : 컨테이너의 이름을 agent로 지정 --link controller:controller : 다른 컨테이너인 controller와 agent를 연결 ngrinder/agent: 이 컨테이너의 이미지로 ngrinder/agent를 사용 참고로 로컬에서 간단하게 테스트 하는 것이 아니라면 controller 와 agent 는 물리적으로 다른 서버에 두는 것이 좋다.성능이 나오지 않아 원하는 만큼의 부하를 줄 수 가 없기 때문이다.controller 와 agent 중 agent 서버의 성능이 더 중요하다.3. Docker Composeversion: '3.9'services: controller: image: ngrinder/controller restart: always ports: - \"80:80\" - \"16001:16001\" - \"12000-12009:12000-12009\" volumes: - ./ngrinder-controller:/opt/ngrinder-controller agent: image: ngrinder/agent restart: always links: - controllerversion: '3.9' : Docker Compose 파일의 버전restart: always : 컨테이너가 종료되었을 때 자동으로 다시 시작하도록 지정docker-compose.yml 파일 실행$ docker-compose up만약 docker-com.yml과 같이 파일 명이 다를 경우 docker-compose -f docker-com.yml up사이트 확인Controller를 실행한 포트 번호로 브라우저 주소창에 http://localhost:[포트번호]/login을 입력하면아래와 같은 화면을 확인할 수 있다.ex) http://localhost:80/login초기 아이디와 패스워드는 모두 admin메인 화면에서 오른쪽 상단 admin → Agent Management에 Agent 서버가 Controller에 정상적으로 적용되었는지 확인한다.API 호출 테스트API 호출을 테스트하기 위해서는 Script를 작성해야한다. 어떤 REST API로 요청을 보낼 것인지 설정해준다.정상적으로 Agent가 동작중이라면 화면 상단에 위치한 탭에서 Script를 클릭하여 스크립트 화면으로 이동한 뒤,테스트를 위해 + Create 버튼을 누르고, Create a script를 선택한다.Script Name : 아무거나 작성여기서 주의할 점은 URL에 ‘localhost, 127.0.0.1’로는 테스트가 불가능하다.http://12.34.45.56:8080 과 같이 12.34.45.56 를 본인 ip 주소를 작성하면 된다.스크립트 생성 후, 우측 상단의 ‘Validate’ 버튼을 누르면 스크립트가 정상적으로 동작하는 지 검증할 수 있다.상단의 Performance Test를 눌러서 실제 성능테스트를 진행한다. Agent: 방금 생성한 한 개의 script가 있기 때문에 1 입력 Vuser per agent: 테스트할 사용자 수 입력 Duration: 테스트할 시간을 지정한다. Save and Start: 오른쪽 위 파란 버튼 클릭 후 실행 테스트 결과 확인하기Total Vusers (Virtual Users): 테스트에서 사용된 가상 사용자의 총 수Agent: 테스트를 수행하는 데 사용된 ngrinder 에이전트의 수Processes: 테스트 동안 실행된 프로세스의 수Threads: 테스트 동안 사용된 스레드의 수Sample Ignore: 무시된 샘플의 수TPS (Transactions per Second): 초당 처리되는 트랜잭션의 수Peak TPS (Peak Transactions per Second): 테스트 중 최고로 높았던 TPS 값Mean Test Time: 평균 테스트 시간Executed Tests: 실행된 테스트 케이스의 총 수Successful Tests: 성공적으로 완료된 테스트 케이스의 수Errors: 발생한 오류의 수 Total Vusers 99 → 99명의 가상 사용자가 사용 Agent 1 → 1개의 에이전트가 사용 Processes Threads 3 / 33 → 총 33개의 스레드 중에 3개의 스레드가 사용 Sample Ignore 0 → 0개의 샘플이 무시 TPS 102.2 → 평균 102.2개의 트랜잭션이 처리 Peak TPS 179 → 179개의 트랜잭션을 초당 가장 많이 처리 Mean Test Time 998.92 ms → 평균적으로 998.92밀리초가 소요 Executed Tests 5,449 → 총 5,449개의 테스트 케이스가 실행 Successful Tests 5,449 → 5,449개의 테스트 케이스가 성공적으로 완료 Errors 0 → 오류가 발생하지 않음로그인 후 test주된 api는 대부분 로그인 한 후 token을 header에 담아서 진행되기 때문에 로그인 인증 정보를 제공해야했다.위와 같이 header와 param을 입력해도 되고 아래 주석으로 작성한 것과 같이 직접 넣을 수 있다.@RunWith(GrinderRunner)class TestRunner { public static GTest test public static HTTPRequest request public static Map&lt;String, String&gt; headers = [:] public static Map&lt;String, Object&gt; params = [:] public static List&lt;Cookie&gt; cookies = []/* public static Map&lt;String, String&gt; headers = [\"Content-Type\" : \"application/json\"] public static Map&lt;String, Object&gt; params = [\"nickname\" : \"hello\"]*/ @BeforeProcess // 프로세스가 호출되기 전 처리할 동작 정의 public static void beforeProcess() { HTTPRequestControl.setConnectionTimeout(300000) test = new GTest(1, \"{ip 주소}\") request = new HTTPRequest() // Set header data headers.put(\"Content-Type\", \"application/x-www-form-urlencoded\") grinder.logger.info(\"before process.\") } @BeforeThread // 각 쓰레드가 실행되기 전 처리할 동작 정의 public void beforeThread() { test.record(this, \"test\") grinder.statistics.delayReports = true grinder.logger.info(\"before thread.\") } @Before // @Test 가 수행되기 전 처리할 동작 정의 public void before() { request.setHeaders(headers) CookieManager.addCookies(cookies) grinder.logger.info(\"before. init headers and cookies\") } @Test // 테스트할 동작 정의 public void test() { HTTPResponse response = request.POST(\"https://{ip주소}:8080/{test할 url}\", params) if (response.statusCode == 301 || response.statusCode == 302) { grinder.logger.warn(\"Warning. The response may not be correct. The response code was {}.\", response.statusCode) } else { assertThat(response.statusCode, is(200)) } }}위를 통해 아래와 같이 코드를 적용한 후 실행시켰다. 수정한 부분은 ⭐로 체크했다.import org.json.JSONObject;import groovy.json.JsonOutput@RunWith(GrinderRunner)class TestRunner { public static GTest test public static HTTPRequest request public static Map&lt;String, String&gt; headers = [:] public static Map&lt;String, Object&gt; params = [:] public static List&lt;Cookie&gt; cookies = [] public static String user = \"{\\\"nickname\\\": \\\"nickname\\\", \\\"password\\\": \\\"password\\\"}\" // ⭐ public static String nickname = \"{\\\"nickname\\\": \\\"nickname\\\"}\" // ⭐ private String token // ⭐ @BeforeProcess public static void beforeProcess() { HTTPRequestControl.setConnectionTimeout(300000) test = new GTest(1, \"{ip 주소}\") request = new HTTPRequest() // Set header data headers.put(\"Content-Type\", \"application/json; charset=utf-8\") // ⭐ grinder.logger.info(\"before process.\") } @BeforeThread public void beforeThread() { test.record(this, \"test\") grinder.statistics.delayReports = true grinder.logger.info(\"before thread.\") } @Before public void before() { request.setHeaders(headers) CookieManager.addCookies(cookies) grinder.logger.info(\"before. init headers and cookies\") } @Test public void test1() { // ⭐ HTTPResponse response = request.POST(\"https://{ip 주소}:8080/sign-in\", user.getBytes()) def loginInfo = response.getBodyText() JSONObject jsonObject = new JSONObject(loginInfo) token = jsonObject.getString(\"token\") headers.put(\"Authorization\", token) grinder.logger.info(\"token : {}\", token) if (response.statusCode == 301 || response.statusCode == 302) { grinder.logger.warn(\"Warning. The response may not be correct. The response code was {}.\", response.statusCode) } else { assertThat(response.statusCode, is(200)) } } @Test public void test2() { // ⭐ request.setHeaders(headers) HTTPResponse response = request.POST(\"https://{ip 주소}:8080/room\", nickname.getBytes()) if (response.statusCode == 301 || response.statusCode == 302) { grinder.logger.warn(\"Warning. The response may not be correct. The response code was {}.\", response.statusCode) } else { assertThat(response.statusCode, is(200)) } }}정상적으로 로그인 동작 후 해당 token을 header에 담아서 로그인 후의 api도 동작하는 것을 확인할 수 있다.서버 log에서도 해당 header의 token 검증을 완료한 것을 확인할 수 있다.로그인 한번만 진행 후 api test위에서 작성한 코드대로 하면 로그인 한번 후 test를 한 다음 다시 로그인을 하게 된다.그래서 로그인을 한번만 진행한 후에 test를 진행하기 위해 수정했다.동일한 아이디로 로그인한 후 특정 API를 테스트하기 때문에 @BeforeProcess에 작성했다.@BeforeProcess는 모든 쓰레드가 공유하는 공통된 상태를 설정하는 데 유용하고,@BeforeThread는 각 쓰레드가 독립된 상태를 설정하는 데 유용하다.import static net.grinder.script.Grinder.grinderimport static org.junit.Assert.*import static org.hamcrest.Matchers.*import net.grinder.script.GTestimport net.grinder.script.Grinderimport net.grinder.scriptengine.groovy.junit.GrinderRunnerimport net.grinder.scriptengine.groovy.junit.annotation.BeforeProcessimport net.grinder.scriptengine.groovy.junit.annotation.BeforeThread// import static net.grinder.util.GrinderUtils.* // You can use this if you're using nGrinder after 3.2.3import org.junit.Beforeimport org.junit.BeforeClassimport org.junit.Testimport org.junit.runner.RunWith// import 추가import groovy.json.JsonOutputimport groovy.json.JsonSlurper import org.ngrinder.http.HTTPRequestimport org.ngrinder.http.HTTPRequestControlimport org.ngrinder.http.HTTPResponseimport org.ngrinder.http.cookie.Cookieimport org.ngrinder.http.cookie.CookieManager/*** A simple example using the HTTP plugin that shows the retrieval of a single page via HTTP.** This script is automatically generated by ngrinder.** @author admin*/@RunWith(GrinderRunner)class TestRunner { public static GTest test public static HTTPRequest request public static Map&lt;String, String&gt; headers = [:] public static Map&lt;String, Object&gt; params = [:] public static List&lt;Cookie&gt; cookies = [] public static String token @BeforeProcess public static void beforeProcess() { HTTPRequestControl.setConnectionTimeout(300000) test = new GTest(1, \"{ip 주소}\") request = new HTTPRequest() // Set header data //headers.put(\"Content-Type\", \"application/json; charset=utf-8\"); grinder.logger.info(\"before process.\") // login HTTPResponse response = request.POST(\"https://{ip 주소}:8080/sign-in\", [nickname: \"nickname\", password: \"password\"]) def responseBody = response.getBodyText() def jsonResponse = new JsonSlurper().parseText(responseBody) token = jsonResponse.token headers.put(\"Authorization\", token) grinder.logger.info(\"token : {}\", token) } @BeforeThread public void beforeThread() { test.record(this, \"test\") grinder.statistics.delayReports = true grinder.logger.info(\"before thread.\") } @Before public void before() { request.setHeaders(headers) CookieManager.addCookies(cookies) grinder.logger.info(\"before. init headers and cookies\") } @Test public void test() { // login 후 request.setHeaders(headers) HTTPResponse response = request.POST(\"https://{ip 주소}:8080/room\", [nickname: \"nickname\"]) if (response.statusCode == 301 || response.statusCode == 302) { grinder.logger.warn(\"Warning. The response may not be correct. The response code was {}.\", response.statusCode) } else { assertThat(response.statusCode, is(200)) } }}script를 작성하고 performance test를 진행했다.해당 /room이 동작하는 방법에 대해서 설명하자면 채팅방 버튼을 누르면 실행이 된다.채팅 repository에서 user가 있는지 확인을 하고 없다면 채팅방을 생성한다.만약 user가 있다면 해당 roomId를 db에서 가져온 다음 가장 마지막에 작성된 글을 가져온다.마지막 글이 null일 경우(채팅방 개설만 하고 채팅을 하지 않은 경우) 임의로 지정한 글을 넘겨주고만약 마지막 글이 있을 경우 해당 글을 가져오는데 Map을 활용하여roomId에 해당하는 Map이 있을 경우 Map에 있는 값을 가져오고 아닐 경우 file에서 마지막 글을 조회한다.여기서 redis로 cache를 적용했는데 차이가 있는지 비교해봤다.&lt; Redis Cache 적용 ⭕ &gt; Total Vusers 500 Agent 1 Processes Threads 10 / 50 Sample Ignore 0 TPS 139.1 Peak TPS 342 Mean Test Time 3,586.78 ms Executed Tests 247,650 Successful Tests 247,648 Errors 2 &lt; Redis Cache 적용 ❌ &gt; Total Vusers 500 Agent 1 Processes Threads 10 / 50 Sample Ignore 0 TPS 111.5 Peak TPS 344 Mean Test Time 4,476.48 ms Executed Tests 198,007 Successful Tests 197,864 Errors 143 TPS (초당 트랜잭션) 비교 Redis를 사용한 경우: 139.1 Redis를 사용하지 않은 경우: 111.5 Redis를 사용한 경우 TPS가 약 24.9% 더 높다. Mean Test Time (평균 테스트 시간) 비교 Redis를 사용한 경우: 3,586.78 ms Redis를 사용하지 않은 경우: 4,476.48 ms Redis를 사용한 경우 평균 테스트 시간이 약 20.0% 감소했다. 에러 수 비교 Redis를 사용한 경우: 2 Redis를 사용하지 않은 경우: 143 Redis를 사용한 경우에는 에러가 거의 발생하지 않았다. 따라서 Redis를 사용하는 것이 성능 및 안정성 면에서 더 효율적임을 알 수 있다.특히 평균 테스트 시간의 감소로 인해 사용자는 빠른 응답 속도를 경험할 수 있으며,에러 수의 감소로 시스템 안정성이 향상된다.게시글 curd scriptformData 작성(post)방법 1. public static Long idx; @BeforeProcess public static void beforeProcess() { headers.put(\"Content-Type\", \"application/x-www-form-urlencoded\") } @Test public void test() { request.setHeaders(headers) HTTPResponse response = request.POST(\"http://{ip 주소}:8080/registry\", [title: \"title\", main: \"main\"]) // 참고. id값만 저장하기 byte[] contentBytes = response.getBodyText(); String content = new String(contentBytes, \"UTF-8\"); def jsonObject = new JSONObject(content); idx = jsonObject[\"idx\"] }방법 2.import HTTPClient.NVPair @Test public void test() { request.setHeaders(headers) // token 저장 NVPair param1 = new NVPair(\"title\", \"title\"); NVPair param2 = new NVPair(\"main\", \"main\"); NVPair[] params = [param1, param2] HTTPResponse response = request.POST(\"http://{ip 주소}:8080/registry\", params) }최종 전체 코드import static net.grinder.script.Grinder.grinderimport static org.junit.Assert.*import static org.hamcrest.Matchers.*import net.grinder.script.GTestimport net.grinder.script.Grinderimport net.grinder.scriptengine.groovy.junit.GrinderRunnerimport net.grinder.scriptengine.groovy.junit.annotation.BeforeProcessimport net.grinder.scriptengine.groovy.junit.annotation.BeforeThread// import static net.grinder.util.GrinderUtils.* // You can use this if you're using nGrinder after 3.2.3import org.junit.Beforeimport org.junit.BeforeClassimport org.junit.Testimport org.junit.runner.RunWithimport org.ngrinder.http.HTTPRequestimport org.ngrinder.http.HTTPRequestControlimport org.ngrinder.http.HTTPResponseimport org.ngrinder.http.cookie.Cookieimport org.ngrinder.http.cookie.CookieManagerimport groovy.json.JsonOutputimport groovy.json.JsonSlurperimport org.json.JSONObject;/*** A simple example using the HTTP plugin that shows the retrieval of a single page via HTTP.** This script is automatically generated by ngrinder.** @author admin*/@RunWith(GrinderRunner)class TestRunner { public static GTest test public static HTTPRequest request public static Map&lt;String, String&gt; headers = [:] public static Map&lt;String, Object&gt; params = [:] public static List&lt;Cookie&gt; cookies = [] public static token public static Long idx @BeforeProcess public static void beforeProcess() { HTTPRequestControl.setConnectionTimeout(300000) test = new GTest(1, \"{ip 주소}\") request = new HTTPRequest() // login HTTPResponse response = request.POST(\"http://{ip 주소}:8080/sign-in\", [nickname: \"nick.123\", password: \"nick.123\"]) def responseBody = response.getBodyText() def jsonResponse = new JsonSlurper().parseText(responseBody) token = jsonResponse.token headers.put(\"Authorization\", token) } @BeforeThread public void beforeThread() { test.record(this, \"test\") grinder.statistics.delayReports = true grinder.logger.info(\"before thread.\") } @Before public void before() { request.setHeaders(headers) CookieManager.addCookies(cookies) grinder.logger.info(\"before. init headers and cookies\") } @Test public void test() { // 게시글 저장 headers.put(\"Content-Type\", \"application/x-www-form-urlencoded\") request.setHeaders(headers) HTTPResponse response = request.POST(\"http://{ip 주소}:8080/registry\", [title: \"nick.123\", main: \"nick.123\"]) byte[] contentBytes = response.getBodyText(); String content = new String(contentBytes, \"UTF-8\"); def jsonObject = new JSONObject(content); grinder.logger.info(\"response : {} \" , jsonObject) idx = jsonObject[\"idx\"] if (response.statusCode == 301 || response.statusCode == 302) { grinder.logger.warn(\"Warning. The response may not be correct. The response code was {}.\", response.statusCode) } else { assertThat(response.statusCode, is(200)) } } @Test public void test2() { // 게시글 수정 headers.put(\"Content-Type\", \"application/json\") request.setHeaders(headers) HTTPResponse response = request.PUT(\"http://{ip 주소}:8080/registry/\"+ idx, [title : \"title1\", main : \"main1\"] ) byte[] contentBytes = response.getBodyText() String content = new String(contentBytes, \"UTF-8\"); def jsonObject = new JSONObject(content) grinder.logger.info(\"response : {} \" , jsonObject) if (response.statusCode == 301 || response.statusCode == 302) { grinder.logger.warn(\"Warning. The response may not be correct. The response code was {}.\", response.statusCode) } else { assertThat(response.statusCode, is(200)) } } @Test public void test3() { grinder.logger.info(\"게시글 조회\") request.setHeaders(headers) HTTPResponse response = request.GET(\"http://{ip 주소}:8080/registry?idx=\"+idx) byte[] contentBytes = response.getBodyText() String content = new String(contentBytes, \"UTF-8\"); def jsonObject = new JSONObject(content) grinder.logger.info(\"response : {} \" , jsonObject) if (response.statusCode == 301 || response.statusCode == 302) { grinder.logger.warn(\"Warning. The response may not be correct. The response code was {}.\", response.statusCode) } else { assertThat(response.statusCode, is(200)) } } @Test public void test4() { grinder.logger.info(\"게시글 삭제\") request.setHeaders(headers) HTTPResponse response = request.DELETE(\"http://{ip 주소}:8080/registry/\"+idx) if (response.statusCode == 301 || response.statusCode == 302) { grinder.logger.warn(\"Warning. The response may not be correct. The response code was {}.\", response.statusCode) } else { assertThat(response.statusCode, is(200)) } }}REFERENCE nGrinder을 이용한 Spring Boot 부하 테스트 nGridner 소개와 설치 방법, 간단 테스트 nGrinder + Springboot 부하 테스트 튜토리얼 [nGrinder ] Docker를 이용한 nGrinder 설치하기 [ETC] 성능 테스트를 위한 nGrinder 설치 및 사용해보기 (Docker) docker를 이용한 Ngrinder 성능 테스트 환경 세팅 nGrinder를 이용한 api 성능테스트 후기" }, { "title": "Spring security의 jwt 토큰 관리와 보안 필터 처리", "url": "/posts/Spring-Security%EC%9D%98-JWT-%ED%86%A0%ED%81%B0-%EA%B4%80%EB%A6%AC%EC%99%80-%EB%B3%B4%EC%95%88-%ED%95%84%ED%84%B0-%EC%B2%98%EB%A6%AC/", "categories": "Project", "tags": "spring, Security", "date": "2024-03-18 00:00:00 +0900", "snippet": "Spring Security의 JWT 토큰 관리와 보안 필터 처리log에 [doFilterInternal] 유효한 JWT 토큰이 없습니다, uri: 라는 메시지가 표시되어해당 인증이 필요없는 CSS 및 JavaScript 파일에도 이 메시지가 표시되는 문제가 생겼다.public class JwtAuthenticationFilter extends OncePerRequestFilter { @Override protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain filterChain) throws ServletException, IOException { }}back과 front를 분리할 경우, 각각의 서버는 독립적으로 동작하며 API 요청만을 처리하기 때문에 보안 필터를 적용할 필요가 없다.이로 인해 log에는 해당 메시지가 표시되지 않는다.그러나 back과 front를 결합하여 하나의 서버로 실행할 경우, 보안 필터가 모든 요청에 대해 작동하게 된다.이로 인해 CSS 및 JavaScript 파일과 같이 인증이 필요 없는 자원에 대해서도 보안 필터가 적용되어 해당 메시지가 log에 표시된다.해당 메시지가 나타나는 경우는 두 가지다. 현재 사용자의 인증 정보가 없을 때(SecurityContextHolder.getContext().getAuthentication()) client에서 전송한 token이 없을 때 (HttpServletRequest.getHeader(\"Authorization\")) 문제는 해당 인증이 필요없는 css, js까지 해당 log가 뜬다는 점이었다.public static final String[] VIEW_LIST = { \"/css/**\", \"/js/**\"};@Beanpublic SecurityFilterChain filterChain(HttpSecurity http) throws Exception { http.authorizeRequests() .requestMatchers(VIEW_LIST).permitAll()}인증 여부와 관계 없이 접근을 허용 하는 permitAll()을 사용했는데도 css와 js에 인증을 요구하고 있었다.코드 살펴보기Spring Security에서는 기본적으로 세션 기반의 인증 방식을 사용하지만,여기서는 JWT(Json Web Token)를 사용한 인증 방식을 사용했다.이를 위해 기본적으로 제공되는 UsernamePasswordAuthenticationFilter를 사용하지 않고,커스텀 필터인 JwtAuthenticationFilter를 사용했다.http.addFilterBefore(new JwtAuthenticationFilter(jwtTokenProvider), UsernamePasswordAuthenticationFilter.class);JwtAuthenticationFilter는 인증 과정에서 JWT token을 검증하며,인증에 실패할 경우 JwtAuthenticationEntryPoint가 호출되어 일관된 인증 예외 응답을 반환한다.이를 통해 클라이언트에게 인증 실패에 대한 적절한 응답을 제공할 수 있다.// SecurityConfighttp.exceptionHandling() .authenticationEntryPoint(customAuthenticationEntryPoint)// CustomAuthenticationEntryPoint@Overridepublic void commence(HttpServletRequest request, HttpServletResponse response, AuthenticationException authException) throws IOException, ServletException { log.info(\"[ commence ] : \" + \"인증 실패\");}JwtAuthenticationFilter에서 JWT 인증이 실패할 경우,JwtAuthenticationEntryPoint가 동작하여 클라이언트에게 401 에러를 반환하게 된다.해결 방법permitAll() 을 적용하면 CSS 및 JavaScript 파일에 대한 접근을 허용했지만,Spring Security의 필터 체인이 동작한다.URL에 대한 모든 사용자의 요청을 허용하는 메소드로써 인증 처리 결과를 무시하는 것이지만Spring Security 의 필터 체인은 동작한다는 얘기다.→ permitAll() 을 적용해도, 구성된 Spring Security의 필터 체인을 거친다.따라서 필터 체인을 거치지 않게 하기 위해 ignoring을 작성했다.@Beanpublic WebSecurityCustomizer webSecurityCustomizer() { return web -&gt; { web.ignoring() .antMatchers( \"/css/**\", \"/js/**\" ); }; }WebSecurity 는 HttpSecurity 상위에 존재하며 WebSecurity의 ignoring에 API를 등록하면,Spring Security의 필터 체인을 무시하고 해당 URL에 대한 접근을 허용한다.하지만 이경우, Cross-Site Scripting,XSS 공격 등에 취약해진다.HttpSecurity 에서 permitAll() 은 인증 처리 결과을 무시하는 것이지Spring Security의 필터 체인이 적용은 정상적으로 된다.그래서 WebSecurity는 보안과 전혀 상관없는 로그인 페이지, 공개 페이지(어플리캐이션 소개 페이지 등),application의 health 체크를 하기위한 API에 사용하고, 그 이외에는 HttpSecurity의 permitAll() 을 사용하는 것이 좋다.REFERENCE [Spring Security] - SecurityConfig 클래스의 permitAll() 이 적용되지 않았던 이유" }, { "title": "Spring security: 인증과 권한 관리", "url": "/posts/Spring-Security-%EC%9D%B8%EC%A6%9D%EA%B3%BC-%EA%B6%8C%ED%95%9C-%EA%B4%80%EB%A6%AC/", "categories": "Project", "tags": "spring, Security", "date": "2024-03-17 00:00:00 +0900", "snippet": "Spring Security: 인증과 권한 관리back과 front를 분리하면서 해당 권한에 해당하는 api 주소를 back에 맞게 변경했다.그리고 해당 주소 중 관리자만 사용할 수 있게 권한을 Security에 설정했다.문득 이 권한은 로그인한 사용자 정보를 얻기 위해SecurityContextHolder.getContext().setAuthentication(authentication);로 값을 저장하면@AuthenticationPrincipal UserDetails userDetails를 작성했을 때 값을 가져오는 것처럼SecurityContextHolder에 저장된 사용자 정보를 사용하는걸까 생각이 들었다.Spring SecuritySpring Security는 Java 기반의 애플리케이션에서 보안과 인증을 처리하기 위한 프레임워크로REST API 및 서비스를 보호하기 위한 다양한 보안 기능을 제공하며주요 기능으로 인증(Authentication)과 인가(Authorization)가 있다. 인증(Authentication) : 해당 사용자가 본인이 맞는지 확인하는 과정 인증은 사용자의 신원을 확인하는 과정으로, 사용자가 제공한 자격 증명(예: id와 pw)을 검증하여 사용자를 식별한다. 인가(Authorization) : 해당 사용자가 요청하는 자원을 실행할 수 있는 권한이 있는가를 확인하는 과정 인가는 인증된 사용자에게 특정 리소스 또는 기능에 대한 액세스 권한을 부여하는 과정이다. Spring Security는 기본적으로 인증 절차를 거친 후에 인가 절차를 진행하며,인가 과정에서 해당 리소스에 접근 권한이 있는지 확인하게 된다Spring Security는 세분화된 권한 관리를 지원하여, 역할 기반의 접근 제어를 구현할 수 있다.이를 통해 애플리케이션의 리소스에 대한 접근 제한을 설정할 수 있다.Spring Security는 ‘인증’과 ‘권한’에 대한 부분을 Filter 흐름에 따라 처리하고 있다.Filter는 Dispatcher Servlet으로 가기 전에 적용되므로 가장 먼저 URL 요청을 받지만, (웹 컨테이너에서 관리)Interceptor는 Dispatcher와 Controller 사이에 위치한다는 점에서 적용 시기의 차이가 있다. (스프링 컨테이너에서 관리) Client (request) → Filter → DispatcherServlet → Interceptor → Controller(실제로 Interceptor가 Controller로 요청을 위임하는 것은 아님, Interceptor를 거쳐서 가는 것)Spring Security 설정Spring Security 설정은 주로 configure() 메소드를 사용하여 이루어진다.여기서 URL 경로에 대한 인가 규칙을 설정하고, 특정 URL 경로를 허용하거나 인증을 요구하는 설정을 할 수 있다. 설정 설명 http.authorizeRequests() URL 경로에 대한 인가 규칙을 설정한다. .antMatchers().permitAll() 특정 URL 경로를 인증 없이 허용한다. .anyRequest().authenticated() 모든 요청에 대해 인증을 요구한다. .hasRole() 특정 역할을 가진 사용자만 접근을 허용한다. .formLogin() 폼 기반 로그인을 활성화한다. .loginPage() 로그인 페이지의 경로를 지정한다. .defaultSuccessUrl() 로그인 성공 후 이동할 기본 URL을 설정한다. .logout() 로그아웃을 처리하는 설정을 추가한다. .logoutUrl() 로그아웃 URL을 지정한다. .logoutSuccessUrl() 로그아웃 성공 후 이동할 URL을 설정한다. .csrf() CSRF(Cross-Site Request Forgery) 공격 방어 설정을 활성화한다. .sessionManagement() 세션 관리를 설정한다. .sessionCreationPolicy() 세션 생성 정책을 설정한다. ROLE http.authorizeRequests() .antMatchers(\"/hello\").hasAuthority(UserRole.ADMIN.name())hasRole을 사용하게 된다면 UserRole 클래스에 USER 대신 ROLE_USER로 저장을 하고.antMatchers(\"/hello\").hasRole(hasRole(\"USER\")) 로 작성해야한다.hasRole을 찾아보면 prefix가 붙어있다.별도로 설정을 하지 않는이상 prefix는 “ROLE_” 이라는 것을 알 수 있다.hasAuthority(\"ROLE_USER\") == hasRole(\"USER\")참고로 더 디테일하고 좁은 범위의 url이 위에 오고 넓은 범위의 url이 아래(하단)에 위치해야한다. http.authorizeRequests() .antMatchers(\"/hello/morning\").hasAuthority(UserRole.ADMIN.name()) .antMatchers(\"/hello/**\").hasAuthority(UserRole.ADMIN.name())UserDetailsService(사용자 정보 조회)Spring Security는 사용자 정보를 조회하기 위해 UserDetailsService를 제공한다.이 Interface는 사용자의 username을 기반으로 사용자 정보를 조회하고, UserDetails 객체를 반환한다.public class CustomUserService implements UserDetailsService { @Override public UserDetails loadUserByUsername(String nickname) throws UsernameNotFoundException { return userRepository.findByNickname(nickname) .map(this::buildUserDetails) .orElseThrow(() -&gt; new UsernameNotFoundException(\"User not found with username: \" + nickname)); }}nickname과 pw로 로그인하기 때문에 파라미터에 nickname을 작성했다.loadUserByUsername()에서 하는 일 nickname을 가지고 사용자 정보를 조회하여 UserDetails 객체로 변환하여 반환 사용자의 Role과 권한(Privilege)을 조회하여, SimpleGrantedAuthority 목록을 authorities에 세팅한다. Authentication 내부 principal 객체에 UserDetails 객체가 저장된다. Authentication 내부 authorities 객체에 사용자의 Role과 권한(Privilege) 정보가 저장된다. UserDetails에 authorities가 세팅되어 있어야, API별 role이나 권한 체크를 진행할 수 있다. GrantedAuthority(권한 관리) USER : 사용자 정보를 포함하는 entity 객체로 UserDetails의 구현체 UserDetails : 인증된 핵심 사용자 정보 (권한, 비밀번호, 사용자명, 각종 상태)를 제공하기 위한 interface이다. Spring Security는 사용자의 권한을 GrantedAuthority를 통해 관리한다.이는 현재 사용자(Principal)가 가지고 있는 권한을 의미하며, 사용자의 Role과 권한(Privilege) 정보를 제공한다.public class User implements UserDetails { Collection&lt;? extends GrantedAuthority&gt; getAuthorities()}Authentication 클래스에 getAuthorities() 메소드를 통하여, 인증받은 사용자의 authorities를 조회할 수 있다.도메인 별로 구체적인 권한 체크가 필요한 경우에는 GrantedAuthority로 관리하지 않고,각 API 별로 비지니스 권한을 체크한다.SecurityContextHolderSecurityContextHolder는 SecurityContext를 보관하는 저장소다.이를 통해 현재 사용자의 인증 정보를 관리하고, Authentication 인스턴스를 저장한다.*Authentication에는 principal, credentials, authorities가 저장된다.따라서 getAuthorities() 메소드를 통하여 가져오는 권한은SecurityContextHolder에 저장된 사용자 정보를 활용하여 가져오는 것과 동일한 공간에서 가져온다고 볼 수 있다.REFERENCE [Spring Boot] Spring Security 권한 설정 및 사용 방법 Spring Security - 2. Role과 권한(Privilege) Spring Security의 구조(Architecture) 및 처리 과정 알아보기" }, { "title": "Cors", "url": "/posts/CORS/", "categories": "Project", "tags": "Network, Security", "date": "2024-02-29 00:00:00 +0900", "snippet": "CORS기존 브라우저 정책은 서로 다른 도메인으로부터 리소스가 필요한 경우,보안상의 이유로 다른 도메인의 리소스를 가져오는 것이 불가능했다. (SOP : Single-Origin-Policy)하지만 어플리케이션을 개선하고 쉽게 개발하기 위해선 다른 도메인에 요청을 보내는 일은 필연적이다.이를 해결하고자 등장한 표준 기술이 CORS이다.CORS란 Cross Origin Resource Sharing의 약자로 도메인이 다른 자원에 리소스를 요청할 때 접근 권한을 부여하는 메커니즘이다.URL 구조 Protocol(Scheme) : http, https Host : 사이트 도메인 Port : 포트 번호 Path : 사이트 내부 경로 Query string : 요청의 key와 value값 Fragment : 해시 태그https://localhost:8080/board?page=1Protocol : httpsHost : localhostPort : 8080Path : boardQuery String : ?page=1Origin란 URL 구조에서 살펴본 Protocol, Host, Port를 합친 것을 말한다.Origin이 다르다는 말은, HTTP, HTTPS 프로토콜이 다르거나, 주소가 다르거나, 포트번호가 다르다는 말이다.Same Origin Policy(SOP) : 동일 출처 정책동일 출처(Same-Origin) 서버에 있는 리소스는 자유로이 가져올수 있지만,다른 출처(Cross-Origin) 서버에 있는 이미지나 유튜브 영상 같은 리소스는 상호작용이 불가능하다.동일 출처가 아닌 경우 접근을 차단하는 이유는해커가 CSRF(Cross-Site Request Forgery)나 XSS(Cross-Site Scripting) 등의 방법을 이용해서우리가 만든 어플리케이션에서 해커가 심어놓은 코드가 실행하여 개인 정보를 가로챌 수 있다.이러한 악의적인 경우를 방지하기 위해 SOP 정책으로 동일하지 않는 다른 출처의 스크립트가 실행되지 않도록브라우저에서 사전에 방지하는 것이다.→ 출처를 비교하는 로직은 서버에 구현된 스펙이 아닌 브라우저에 구현된 스펙이다.브라우저의 CORS 기본 동작1. 클라이언트에서 HTTP요청의 헤더에 Origin을 담아 전달(ex. Origin: http://localhost:8080)2. 서버는 응답헤더에 Access-Control-Allow-Origin을 담아 클라이언트로 전달한다.(ex.Acess-Control-Allow-Origin: http://localhost:8080)3. 클라이언트에서 Origin과 서버가 보내준 Access-Control-Allow-Origin을 비교한다.이후 응답을 받은 브라우저는 자신이 보냈던 요청의 Origin과서버가 보내준 응답의 Access-Control-Allow-Origin을 비교해본 후 차단할지 말지를 결정한다.만약 유효하지 않다면 그 응답을 사용하지 않고 버린다. 👉🏻 CORS 에러결국 CORS 해결책은 서버의 허용이 필요하다.CORS 동작 방식CORS가 동작하는 방식은 3가지가 있다고 한다.1. 예비 요청 (Preflight Request)클라이언트에서 요청하려는 URL이 외부 도메인일 경우, 웹브라우저에서 자체적으로 실행된다.브라우저는 요청을 보낼 때 한번에 바로 보내지않고 먼저 예비 요청을 보내 서버와 잘 통신되는지 확인한 후 본 요청을 보낸다.예비 요청의 역할은 본 요청을 보내기 전에 브라우저 스스로 안전한 요청인지 미리 확인하는 것이다.이때, 브라우저가 예비요청을 보내는 것을 Preflight라고 부르며이 예비요청의 HTTP 메소드를 GET이나 POST가 아닌 OPTIONS라는 요청이 사용된다는 것이 특징이다.js에서 api 요청 예시🔷 js에서 start()를 통해 resource를 받아오려고 한다.🔷 브라우저는 서버로 HTTP OPTIONS를 통해 예비 요청(Preflight)을 먼저 보낸다.🔷 서버는 예비 요청에 대한 응답으로 어떤 것을 허용하고 금지하고 있는지에 대한 header 정보를 담아서 브라우저로 보낸다.🔷 브라우저는 보낸 요청과 서버가 응답해준 정책을 비교하여 해당 요청이 안전한지 확인하고 본 요청을 보낸다.🔷 서버가 본 요청에 대한응답을 하면 최종적으로 응답 데이터를 js로 넘겨준다.실제 api 요청을 보내면 chrome에서 client와 server가 본 요청을 보내기 전에예비 요청(preflight) 통신을 하고 있는 것을 볼 수 있다.예비 요청은 GET이나 POST가 아닌 OPTIONS라는 독립적인 요청 메소드로 보내진다.Request header의 Origin과 Response header의 Access-Control-Allow-Origin의 출처를 비교한다.만약 둘이 다르게되면 브라우저는 이 요청이 CORS 정책을 위반했다고 판단하고 에러를 내보낸다.Requset headers (클라이언트 요청 헤더) Origin: 요청을 보내는 페이지의 출처 (도메인) Access-Content-Request-Method: 실제 요청하려는 메소드 Access-Content-Request-Headers: 실제 요청에 포함되어 있는 헤더 이름 Response headers (서버 응답 헤더) Access-Control-Allow-Origin: 요청을 허용하는 출처 ( * 와일드 카드이면 모든 곳에서 허용, 특정하려면 Protocol + Host + Port 입력) Access-Control-Allow-Credentials: 클라이언트 요청이 쿠키를 통해서 자격 증명을 하는 경우에 true true를 응답받은 클라이언트는 실제 요청 시 서버에서 정의된 규격의 인증값이 담긴 쿠키를 같이 보내야 한다. Access-Control-Expose-Headers: 클라이언트 요청에 포함되어도 되는 사용자 정의 헤더 Access-Control-Max-Age: 클라이언트에서 Preflight 의 요청 결과를 저장할 기간을 지정한다. 클라이언트에서 Preflight 요청의 결과를 저장하고 있을 시간이다. 해당 시간 동안은 Preflight 요청을 다시 하지 않게된다. Access-Control-Allow-Methods: 요청을 허용하는 메서드, 기본값은 GET, POST라고 보면된다. 이 헤더가 없으면 GET과 POST요청만 가능하다. 만약 이 헤더가 지정되어 있으면 클라이언는 헤더 값에 해당하는 메서드일 경우에만 실제 요청을 시도한다. Access-Control-Allow-Headers: 요청을 허용하는 헤더 요청을 보내기 전에 예비요청을 보낸다면실제 요청에 걸리는 시간이 늘어나게 되어 어플리케이션 성능에 영향을 미치기 때문에브라우저 캐시를 이용해 Access-Control-Max-Age를 활용하면 Preflight 요청을 캐싱시켜 최적화를 시켜줄 수 있다.3600초 → 1시간예비 요청 캐싱 기간에 대해서는, 파이어폭스 브라우저는 86400초(24시간) 까지 가능하지만크로미움 기반 브라우저는 7200초(2시간)이 최대이다.예비 요청 캐시 동작과정🔷 브라우저는 예비(Preflight) 요청을 할 때마다 먼저 Preflight 캐시를 확인하여 해당 요청에 대한 응답이 있는지 확인한다.🔷 만일 응답이 캐싱 되어 있지 않다면,  서버에 예비 요청을 보내 인증 절차를 밟는다.🔷 만일 서버로 부터 Access-Control-Max-Age 응답 헤더를 받는다면 그 기간 동안 브라우저 캐시에 결과를 저장한다.🔷 다시 요청을 보내고 만일 응답이 캐싱 되어 있다면 예비 요청을 서버로 보내지 않고 대신 캐시된 응답을 사용한다.2. 단순 요청 (Simple Request)예비 요청(Prefilght)을 생략하고 바로 서버에 직행으로 본 요청을 보낸 후서버가 이에 대한 응답의 헤더에 Access-Control-Allow-Origin 헤더를 보내주면브라우저가 CORS정책 위반 여부를 검사하는 방식이다.but, 아래 3가지 경우를 만족 할 때만 가능하다.1. 요청의 메소드는 GET, HEAD, POST 중 하나여야 한다.2. Accept, Accept-Language, Content-Language, Content-Type, DPR, Downlink, Save-Data, Viewport-Width, Width 헤더일 경우에만 적용된다.3. Content-Type 헤더가 application/x-www-form-urlencoded, multipart/form-data, text/plain중 하나여야한다. 아닐 경우 예비 요청으로 동작된다.위 조건을 모두 만족되어 단순 요청이 일어나는 상황은 드물다.대부분 HTTP API 요청은 text/xml 이나 application/json 으로 통신하기 때문에3번째 Content-Type이 위반되기 때문이다.따라서 대부분의 API 요청은 예비 요청(preflight)으로 이루어진다 라고 이해하면 된다.3. 인증된 요청 (Credentialed Request)인증된 요청은 클라이언트에서 서버에게 자격 인증 정보(Credential)를 실어 요청할 때 사용되는 요청이다.여기서 말하는 자격 인증 정보란 세션 ID가 저장되어있는 쿠키(Cookie) 혹은Authorization 헤더에 설정하는 토큰 값 등을 일컫는다.즉, 클라이언트에서 일반적인 JSON 데이터 외에도 쿠키 같은 인증 정보를 포함해서다른 출처의 서버로 전달할 때 CORS의 세가지 요청 중 하나인 인증된 요청으로 동작된다1. 클라이언트에서 인증 정보를 보내도록 설정하기기본적으로 브라우저가 제공하는 요청 API 들은 별도의 옵션 없이브라우저의 쿠키와 같은 인증과 관련된 데이터를 함부로 요청 데이터에 담지 않도록 되어있다. same-origin(기본값) : 같은 출처 간 요청에만 인증 정보를 담을 수 있다. include : 모든 요청에 인증 정보를 담을 수 있다. omit : 모든 요청에 인증 정보를 담지 않는다. 이때 요청에 인증과 관련된 정보를 담을 수 있게 해주는 옵션이 바로 credentials 옵션이다.만일 이러한 별도의 설정을 해주지 않으면 쿠키 등의 인증 정보는 절대로 자동으로 서버에게 전송되지 않는다.2. 서버에서 Access-Control-Allow-Origin 헤더 설정하기 응답 헤더의 Access-Control-Allow-Credentials 항목을 true로 설정해야 한다. 응답 헤더의 Access-Control-Allow-Origin 의 값에 와일드카드 문자(*)는 사용할 수 없다. 응답 헤더의 Access-Control-Allow-Methods 의 값에 와일드카드 문자(*)는 사용할 수 없다. 응답 헤더의 Access-Control-Allow-Headers 의 값에 와일드카드 문자(*)는 사용할 수 없다. 응답의 Access-Control-Allow-Origin 헤더가 와일드카드(*)가 아닌 분명한 Origin으로 설정되어야 하고Access-Control-Allow-Credentials 헤더는 true로 설정되어야 한다.그렇지 않으면 브라우저의 CORS 정책에 의해 응답이 거부된다.(인증 정보는 민감한 정보이기 때문에 출처를 정확하게 설정해주어야 한다)직접 서버에서 HTTP 헤더 설정을 통해 출처를 허용하게 설정하는 가장 정석적인 해결책이다.@CrossOrigin가장 단순한 해결책은 @CrossOrigin 을 사용하는 것이다.@CrossOrigin을 사용하면 다른 도메인의 클라이언트가 나의 서버에 요청 보내는 것을 허용한다.ex) 서버 : http://localhost:8080, 클라이언트 : http://localhost:8081@RestControllerpublic class Controller { @CrossOrigin(\"http://localhost:8081\") @GetMapping(\"/hello\") public String say() { return \"hello-world\"; }}@RestController@CrossOrigin(origins = \"http://localhost:8081\", allowedHeaders = \"GET\")public class Controller {}하지만 위처럼 작성한다면 수 많은 Controller에 일일히 작성해야한다.Filter*Filter 는 꼭 javax.servlet 의 Filter를 사용해야 한다.import javax.servlet.*;@Component@Order(Ordered.HIGHEST_PRECEDENCE)public class CorsFilter implements Filter { private static final String[] allowedOrigins = { \"http://localhost:8080\", \"http://localhost:8081\" }; @Override public void init(FilterConfig filterConfig) throws ServletException { } @Override public void doFilter(ServletRequest req, ServletResponse res, FilterChain chain) throws IOException, ServletException { HttpServletRequest request = (HttpServletRequest) req; HttpServletResponse response = (HttpServletResponse) res; response.setHeader(\"Access-Control-Allow-Origin\", allowedOrigins); response.setHeader(\"Access-Control-Allow-Credentials\", \"true\"); response.setHeader(\"Access-Control-Allow-Methods\", \"GET, OPTIONS, PUT, POST, DELETE\"); response.setHeader(\"Access-Control-Max-Age\", \"3600\"); response.setHeader(\"Access-Control-Allow-Headers\", \"Origin, X-Requested-With, Content-Type, Accept, Authorization\"); if(\"OPTIONS\".equalsIgnoreCase(request.getMethod())) { response.setStatus(HttpServletResponse.SC_OK); }else { chain.doFilter(req, res); } } @Override public void destroy() { }}Configurationhttp.authorizeRequests() .requestMatchers(CorsUtils::isPreFlightRequest).permitAll()/*CORS preflight 요청에 대해 모든 경로에서 접근을 허용→ CORS preflight 요청은 인증처리를 하지 않겠다CORS semantic 상으로 CORS prefight에는 Authorization 헤더를 줄 이유가 없으므로CORS preflight 요청에 대해서는 401 응답(Unauthorized→ 인증이 필요함) 을 하면 안된다. */@Beanpublic CorsConfigurationSource corsConfigurationSource() { CorsConfiguration configuration = new CorsConfiguration(); configuration.setAllowedOriginPatterns(List.of(\"https://www.domain.com\")); configuration.setAllowedHeaders(List.of(\"Authorization\", \"Content-Type\")); configuration.setAllowedMethods(Arrays.asList(\"GET\", \"POST\", \"PUT\", \"DELETE\", \"OPTIONS\")); configuration.setMaxAge(3600L); // 1 HOUR configuration.setAllowCredentials(true); UrlBasedCorsConfigurationSource source = new UrlBasedCorsConfigurationSource(); source.registerCorsConfiguration(\"/**\", configuration); return source;}CorsConfiguration : CORS 정책을 정의UrlBasedCorsConfigurationSource : CORS 구성을 URL 패턴에 기반하여 설정source.registerCorsConfiguration(\"/**\", configuration); : 모든 URL에 대해 CORS 구성을 적용setAllowedOrigins(\"*\")와 setAllowedOriginPatterns(\"*\")위에서 설명했듯이setAllowedOrigins(\"*\")를 적용하면 setAllowCredentials(true)는 사용할 수 없고setAllowedOriginPatterns(\"*\")를 적용해야 했다. 정확히 말하자면 와일드카드를 사용할 수 없다.더 유연한 Origin 지정이 필요한 경우에는 setAllowedOriginPatterns를 사용하고,(ex.https://*.domain.com)명시적인 Origin을 지정하는 경우에는 setAllowedOrigins를 사용하는데 (ex.https://domain.com)문제는 명시적으로 작성해도 잘 동작하지 않아 setAllowedOriginPatterns를 사용하게 되었다.setAllowCredentials(true)는 CORS(Cross-Origin Resource Sharing) 관련 설정 중 하나로,브라우저 간의 요청에서 인증 정보를 포함하도록 허용하는 옵션이다.S3S3 CORS(Cross-origin 리소스 공유)Amazon S3 &gt; 버킷 &gt; ${버킷 이름} &gt; 권한 탭제일 하단으로 내리면 CORS(Cross-origin 리소스 공유)가 보인다.편집을 누르고 아래를 붙여넣으면 된다.[ { \"AllowedHeaders\": [ \"Authorization\" ], \"AllowedMethods\": [ \"GET\", \"HEAD\" ], \"AllowedOrigins\": [ \"https://www.domain.com\" ], \"ExposeHeaders\": [ \"Access-Control-Allow-Origin\" ] }]CORS 에러 CODE이 글에서 cors 에러가 떠서 security를 수정했는데 남은 기능을 test 해보니 전부 CORS 에러가 떴다.문제는 모든 api에 .antMatchers(\"/ws/**\").permitAll()와 같이.permitAll()을 해버리면 인증 없이도 접근 가능한 페이지가 많아진다.따라서 cors 에러를 해결했다고 볼 수가 없다.글 하단에 있는 REFERENCE들을 참고하여 수정했다. Class CorsConfigurationaddAllowedOrigin()과 setAllowedOrigins()의 차이는addAllowedOrigin은 허용된 origin을 하나씩 추가하는 것이고setAllowedOrigins은 list 형태로 여러 개를 한번에 추가할 수 있다.setAllowedOrigins()을 활용해 origin을 추가했다.REFERENCE CORS 란 CORS(Cross-Origin-Resource Sharing) 란? [[Web CORS 이슈 setAllowOrigins Preflight Request](https://pearlluck.tistory.com/360) [CORS] CORS란? CORS 에러 해결하기 CORS란? 🌐 악명 높은 CORS 개념 &amp; 해결법 - 정리 끝판왕 👏 [네트워크/HTTP] OPTIONS 메소드를 쓰는 이유와 CORS란? [Spring Boot] CORS 를 해결하는 3가지 방법 (Filter, @CrossOrigin, WebMvcConfigurer) [Spring Boot] CORS 설정하기 CORS 설정과 Spring Security CORS 에러 관련 해결 [Cors] Cors 에러 삽질 기록 [SpringBoot] CORS 에러 백 &amp; 프론트 협업시 발생하는 CORS에러 해결 방법. " }, { "title": "Authenticationprincipal null 값", "url": "/posts/AuthenticationPrincipal-null-%EA%B0%92/", "categories": "Error", "tags": "Security, error", "date": "2024-02-25 00:00:00 +0900", "snippet": "@AuthenticationPrincipal을 활용한 사용자 정보 주입@AuthenticationPrincipal은 Spring Security에서 현재 인증된(principal) 사용자의 정보를 주입받을 때 사용하는 어노테이션이다.이를 통해 컨트롤러나 서비스에서 현재 사용자의 정보에 쉽게 접근할 수 있다.문제User가 UserDetails를 상속받은 엔티티에서 권한과 userName을 Override 했고getUsername()을 통해 nickname을 반환하는 것으로 설정했다.@Overridepublic Collection&lt;? extends GrantedAuthority&gt; getAuthorities() { List&lt;GrantedAuthority&gt; authorities = new ArrayList&lt;&gt;(); authorities.add(new SimpleGrantedAuthority(this.role.name())); return authorities;}@JsonProperty(access = JsonProperty.Access.WRITE_ONLY)@Overridepublic String getUsername() { return this.nickname;}front에서 받아오는 nickname이 만약 사용자가 임의로 변경할 수 있다는 가정하에back에서 로그인한 정보를 가지고 해당 nickname을 통해 채팅방을 만드는 코드다.@PostMapping(\"/chat\")public ChatRoomDto createRoom(@RequestBody String nickname, @AuthenticationPrincipal UserDetails userDetails) { if(nickname.equals(userDetails.getUsername())){ return chatService.createRoom(nickname); }else{ return chatService.createRoom(userDetails.getUsername()); }}여기서 UserDetails 값이 null로 떠서 500 (Internal Server Error) 오류가 떴다.문제 해결하기@AuthenticationPrincipal는Spring Security의 AuthenticationPrincipalArgumentResolver 클래스를 통해 동작하며,SecurityContextHolder에 접근해서 값을 반환한다.// AuthenticationPrincipalArgumentResolver.class public Object resolveArgument(MethodParameter parameter, ModelAndViewContainer mavContainer, NativeWebRequest webRequest, WebDataBinderFactory binderFactory) { // SecurityContextHolder에서 Authentication 객체를 가져온다. Authentication authentication = this.securityContextHolderStrategy.getContext().getAuthentication(); if (authentication == null) { return null; } else { // 구현한 principal 객체가 각각 다르기 때문에 authentication.getPrincipal()를 사용하여 Object타입으로 받아준다. Object principal = authentication.getPrincipal(); /* AuthenticationPrincipal 어노테이션에 사용한 parameter를 얻어내 exprsssion 메서드를 통해 String으로 사용자가 인증에 사용하는 클래스의 이름을 알아낸다(ex. UserDetails) */ AuthenticationPrincipal annotation = (AuthenticationPrincipal)this.findMethodAnnotation(AuthenticationPrincipal.class, parameter); String expressionToParse = annotation.expression(); if (StringUtils.hasLength(expressionToParse)) { /* 알아낸 클래스 이름과 스프링 컨테이너에서 Bean을 찾아주는 beanResolver, context에 설정한 값을 가지고 인증시에 사용했던 클래스의 인스턴스를 만들어낸다.*/ StandardEvaluationContext context = new StandardEvaluationContext(); context.setRootObject(principal); context.setVariable(\"this\", principal); context.setBeanResolver(this.beanResolver); Expression expression = this.parser.parseExpression(expressionToParse); principal = expression.getValue(context); } if (principal != null &amp;&amp; !ClassUtils.isAssignable(parameter.getParameterType(), principal.getClass())) { if (annotation.errorOnInvalidType()) { throw new ClassCastException(\"\" + principal + \" is not assignable to \" + parameter.getParameterType()); } else { return null; } } else { return principal; } }}AuthenticationPrincipalArgumentResolver 클래스를 보면1. supportsParameter()를 통해 @AuthenticationPrincipal 이 있는지 체크2. supportsParameter()의 값이 true라면 resolveArgument()에서 파라미터에 값을 주입한다.여기서 resolveArgument()의 반환값은 Authentication이다.Authentication 인터페이스는 Spring Security에서 인증 객체를 나타내는 인터페이스다.Spring Security에서 AuthenticationFilter를 거쳐 사용자의 인증을 완료하면SecurityContextHolder에는 Authentication 인터페이스를 구현한 객체가 저장된다.대표적으로 사용되는 클래스는 UsernamePasswordAuthenticationToken다.따라서 사용자 정보를 가져오기 위해 @AuthenticationPrincipal을 사용할 때는UsernamePasswordAuthenticationToken을 사용하여 Authentication 객체를 설정해야 한다.UsernamePasswordAuthenticationToken은 Authentication 인터페이스를 구현한 클래스다.따라서 SecurityContextHolder에 저장되는 것은 Authentication 인터페이스를 상속받은 객체다.문제 해결UserDetails userDetails = userDetailService.loadUserByUsername(jwtProvider.getNickname(token));UsernamePasswordAuthenticationToken auth = new UsernamePasswordAuthenticationToken(userDetails.getUsername(), null, userDetails.getAuthorities());SecurityContextHolder.getContext().setAuthentication(auth);UsernamePasswordAuthenticationToken의 첫 번째 매개변수는 principal을 나타내는데@AuthenticationPrincipal을 받는 객체가 UserDetails를 구현한 객체이므로 userDetails를 넣었어야 했다.UsernamePasswordAuthenticationToken은 사용자의 인증 정보를 생성하고 설정하는 데 사용하고,SecurityContextHolder는 이를 저장하고 관리하는 역할을 한다.결론인증 객체를 저장하는 과정에서 username 정보만 포함시킨 문제를 수정했다.@AuthenticationPrincipal을 사용하여 Principal 정보를 가져올 때,UsernamePasswordAuthenticationToken의 Principal로 설정된 객체를 얻을 수 있다.UserDetails userDetails = userDetailService.loadUserByUsername(jwtProvider.getNickname(token));UsernamePasswordAuthenticationToken auth = new UsernamePasswordAuthenticationToken(userDetails, null, userDetails.getAuthorities());SecurityContextHolder.getContext().setAuthentication(auth);@AuthenticationPrincipal 을 사용하여 UserDetails 값을 가져올 때는 UserDetails 객체를 Principal로 설정해야 하므로userDetails.getUsername() 대신 userDetails로 수정했다.참고로 SecurityContextHolder.getContext().getAuthentication()의 값을 출력시켜도 알 수 있다.수정 전) UsernamePasswordAuthenticationToken [Principal=nickname, ~ // 이하 생략 ]수정 후) UsernamePasswordAuthenticationToken [Principal=org.springframework.security.core.userdetails.User [Username=nickname, ~ // 이하 생략]REFERENCE @AuthenticationPrincipal 어노테이션 [프로젝트] @AuthenticationPrincipal에 null값 들어오는 문제 해결" }, { "title": "동시성을 통한 다중 접속자 관리", "url": "/posts/%EB%8F%99%EC%8B%9C%EC%84%B1%EC%9D%84-%ED%86%B5%ED%95%9C-%EB%8B%A4%EC%A4%91-%EC%A0%91%EC%86%8D%EC%9E%90-%EA%B4%80%EB%A6%AC/", "categories": "Project, Chat", "tags": "Java, Chat", "date": "2024-02-22 00:00:00 +0900", "snippet": "동시성을 통한 다중 접속자 관리동시성(Concurrency)은 단일 코어에서 여러 스레드가 번갈아가면서 실행되는 것처럼 보이는 개념이다.이는 실제로는 하나의 코어에서 각 스레드가 번갈아가면서 실행되기 때문에 동시에 실행되는 것은 아니다.이때 thread들은 작업을 진행하다가 일시적으로 중단되고 다른 스레드가 실행되는 형태로 동작한다.이런 상황에서 Context Switching이 발생하여 thread 간 전환되어 작업을 수행한다.접속자 수private Map&lt;String, Integer&gt; connectUsers;@PostConstructprivate void setUp() { this.connectUsers = new HashMap&lt;&gt;();}public void connectUser(String status, String roomId, ChatMessage chatMessage) { if (Objects.equals(status, \"Connect\")) { connectUsers.putIfAbsent(roomId, 0); int num = connectUsers.get(roomId); connectUsers.put(roomId, (num + 1)); saveFile(chatMessage); } else if (Objects.equals(status, \"Disconnect\")) { int num = connectUsers.get(roomId); connectUsers.put(roomId, (num - 1)); } log.info(\"현재 인원 : \" + connectUsers.get(roomId));}많은 사람이 채팅을 시작하고 종료하면서 접속자 수가 제대로 count 되지 않는 문제가 생겼다.여러 사용자가 동시에 접속 및 접속 해제하게 되면서 문제가 발생한 것 같다.여러 스레드가 동시에 connectUser()를 호출하면 접속자 수가 정확히 유지되지 않고 오류가 발생할 수 있다.이로 인해 Map(connectUsers)에 대한 동기화가 보장되지 않고,여러 스레드에서 동시에 맵을 수정하면 예기치 않은 결과가 발생할 수 있다.코드 수정현재 로직은 사용자 A와 사용자 B가 각각 다른 roomId를 가지고 ConcurrentHashMap에 저장이 된다.같은 ConcurrentHashMap에는 관리자와 사용자 A, 혹은 사용자 B와 관리자로 저장된다.1. 동기화된 맵 사용private Map&lt;String, Integer&gt; connectUsers;@PostConstructprivate void setUp() { this.connectUsers = new HashMap&lt;&gt;();}public void connectUser(String status, String roomId, ChatMessage chatMessage) { int num = 0; log.info(\"[ ConnectUser ] roomId : \" + roomId); if (Objects.equals(status, \"Connect\")) { num = connectUsers.getOrDefault(roomId, 0); connectUsers.put(roomId, (num + 1)); saveFile(chatMessage); } else if (Objects.equals(status, \"Disconnect\")) { log.info(\"[ DisconnectUser ] roomId : \" + roomId); num = connectUsers.get(roomId); connectUsers.put(roomId, (num - 1)); } log.info(\"현재 인원 : \" + connectUsers.get(roomId));}Java에서는 ConcurrentHashMap 클래스를 사용하여 동시성 문제를 해결할 수 있다.Hashtable 클래스의 대부분의 API를 보면 메소드 전체에 synchronized가 존재하여동시에 여러 작업을 해야할 때 병목현상이 발생할 수 밖에 없다.Thread-safe 하다는 특징이 있지만, Multi-Thread 환경에서 사용하기에 살짝 느리다는 단점이 있다.HashMap 클래스를 보면 synchronized가 존재하지 않기 때문에 단일 스레드 환경에서는 성능이 우수히디.하지만 synchronized가 존재하지 않기 때문에 Multi-Thread 환경에서 동시성 문제가 발생할 수 있다.Hashtable 클래스의 단점을 보완하면서 Multi-Thread 환경에서 사용할 수 있도록 나온 클래스가 바로 ConcurrentHashMap이다.ConcurrentHashMap은 get()은 여러 thread가 동시에 읽을 수 있지만,put()은 일부 세그먼트 or 버킷에 대한 Lock을 사용하여 동시성을 제어한다.get()에는 synchronized가 존재하지 않고, put()에는 중간에 synchronized가 존재하는 것을 볼 수 있다.읽기 작업에는 병렬적인 액세스가 허용되므로 읽기 작업의 성능이 향상된다.쓰기 작업에는 일부 세그먼트 또는 버킷에 대해 lock을 사용하여 동시성을 제어하므로여러 thread가 동시에 쓰기 작업을 시도할 때 성능이 저하되는 것을 방지한다.ConcurrentHashMap 클래스를 보면 위와 같이 DEFAULT_CAPACITY, DEFAULT_CONCURRENCY_LEVEL이 16으로 설정되어 있다.DEFAULT_CAPACITY는 HashMap 및 ConcurrentHashMap에서 사용되는 초기 용량(capacity)을 나타낸다.DEFAULT_CONCURRENCY_LEVEL는 동시성 수준을 나타내며 동시에 작업 가능한 스레드 수를 말한다.ConcurrentHashMap은 버킷 단위로 lock을 사용하기 때문에 같은 버킷만 아니라면 Lock을 기다릴 필요가 없다는 특징이 있다.(버킷당 하나의 Lock을 가지고 있다라고 생각하면 된다.)코드로 예를 들자면ConcurrentHashMap에 두 개의 키가 저장되어 있다면, 일반적으로 내부적으로는 두 개의 버킷이 있을 것이다.a 사용자와 관리자가 한 버킷에 접근하고 b 사용자와 관리자가 다른 버킷에 접근하는 상황에서a 사용자와 b 사용자가 동시에 접근해도 서로 다른 버킷에 접근하므로 lock을 기다릴 필요가 없다→ 여러 thread에서 ConcurrentHashMap 객체에 동시에 데이터를 삽입, 참조하더라도그 데이터가 다른 세그먼트에 위치하면 서로 락을 얻기 위해 경쟁하지 않는다.따라서 ConcurrentHashMap은 여러 thread가 안전하게 동시에 Map을 수정할 수 있도록 지원한다.2. 동기화 블록 사용synchronized를 적용하는 방법에는 4가지가 있다. synchronized method synchronized block static synchronized method static synchronized blockSynchronized 이해public class Prac { private String msg; public static void main(String[] agrs) { BasicSynchronization temp = new BasicSynchronization(); System.out.println(\"Test start!\"); new Thread(() -&gt; { for (int i = 0; i &lt; 10; i++) { temp.callMe(\"Thread1\"); } }).start(); new Thread(() -&gt; { for (int i = 0; i &lt; 10; i++) { temp.callMe(\"Thread2\"); } }).start(); System.out.println(\"Test end!\"); } public synchronized void callMe(String name) { msg = name; try { long sleep = (long) (Math.random() * 100); Thread.sleep(sleep); } catch (InterruptedException e) { e.printStackTrace(); } if (!msg.equals(name)) { System.out.println(name + \" : \" + msg); } }}위 코드를 실행시키면 로그가 찍히지 않는다.즉, 함수에 synchronized를 걸면 그 함수가 포함된 해당 객체(this)에 lock을 거는것과 같다.그래서 synchronized block이 존재한다.Java에서는 thread를 동기화 하기 위해서 synchronized를 제공한다.thread는 synchronized()에 들어가기 위해 lock을 얻고 메소드가 끝나면 lock을 반환한다.어떠한 thread가 lock을 얻어 synchronized()를 사용중이면 다른 메소드는 lock이 없으므로synchronized에 접근할 수 없고 다른 thread가 lock을 반환할 때까지 기다려야 한다.ex) synchronized → 🏠 , lock → 🗝️synchronized(🏠)에 들어가기 위해서는 lock(🗝️)이 필요한데 lock(🗝️)은 단 1개만 존재한다.A가 synchronized(🏠)에 lock(🗝️)을 들고 들어가면B는 synchronized(🏠)에 들어갈 lock(🗝️)이 없기 때문에 A가 synchronized(🏠)에 나올 때까지 기다려야 한다.private Map&lt;String, Integer&gt; connectUsers;@PostConstructprivate void setUp() { this.connectUsers = new HashMap&lt;&gt;();}public void connectUser(String status, String roomId, ChatMessage chatMessage) { log.info(\"[ connectUser ] roomId : \" + roomId); int num = 0; synchronized (lock) { if (Objects.equals(status, \"Connect\")) { connectUsers.putIfAbsent(roomId, 0); num = connectUsers.get(roomId); connectUsers.put(roomId, (num + 1)); saveFile(chatMessage); } else if (Objects.equals(status, \"Disconnect\")) { num = connectUsers.get(roomId); connectUsers.put(roomId, (num - 1)); } log.info(\"현재 인원 : \" + connectUsers.get(roomId)); }}위 코드는 block이 method 전체에 적용되어있기 때문에 mehtod 단위로 lock을 거는 것과 같다.참고로 synchronized는 임계 영역에 접근하는 모든 요청(Thread)들을 동기화하기 때문에같은 roomId가 아닌 다른 roomId라도 Blocking이 발생해서 성능 저하로 이어질 수 있다고 한다.→ 사용자 A, B가 동시에 채팅을 접속한다면 Blocking이 발생할 수 있다.동시성을 적용하고 나서 여러 사용자가 동시에 같은 자원(예: 데이터베이스의 특정 레코드)을 추가하려고 할 때 동시성을 사용하여 한 번에 한 사용자만 해당 자원에 접근하도록 제어할 수 있다. 이렇게 하면 다중 사용자 간의 충돌을 방지하고 데이터의 일관성을 유지할 수 있다. 한 사용자가 여러 번 추가되는 것을 방지 사용자가 동시에 같은 작업을 실행하더라도 해당 작업을 한 번만 실행하도록 보장해서 한 사용자가 여러 번 추가되는 것을 방지할 수 있다. 처음 동시성을 적용할 때는 synchronized와 ConcurrentHashMap을 둘 다 적용했었다.이후, ConcurrentHashMap을 알아보게 되면서ConcurrentHashMap은 동시에 다른 버킷에 접근하는 경우별도의 lock 경합이 발생하지 않기 때문에 lock을 기다릴 필요가 없지만synchronized은 동시에 여러 스레드가 접근하는 경우 lock을 기다려야하는 상황이 생기기 때문에synchronized와 같이 사용하게 된다면 ConcurrentHashMap을 활용하지 못한다고 생각이 들어서2개 중에 하나를 적용하려고 했고나는 사용자들끼리 동시에 접속하는 횟수가 많을 것이라고 판단하여 ConcurrentHashMap을 적용했다.REFERENCE 동시성이 무엇일까 [Java] ConcurrentHashMap 이란 무엇일까? [Java] 혼동되는 synchronized 동기화 정리 Java Synchronized (자바 동기화) 안드로이드 개발 네트워크 개발 등등 Java의 동기화 Synchronized 개념 정리#1 예약 시스템에서 동시성 제어와 더블부킹(중복요청)은 어떻게 막을까?" }, { "title": "Https 기본", "url": "/posts/HTTPS-%EA%B8%B0%EB%B3%B8/", "categories": "Project, Cloud", "tags": "AWS", "date": "2024-02-04 00:00:00 +0900", "snippet": "HTTPS 적용 사전 지식HTTPS를 적용하면서 적용과정만 작성했기 때문에 이곳에 관련 지식들을 정리해봤다.HTTPS란HTTPS는 HTTP 프로토콜에 SSL 기술이 더하여 전달되는 데이터를 SSL 암호화하여 보안성을 더 높였다.간단히 말하자면 HTTPS(Hypertext Transfer Protocol Secure)는 이름처럼 HTTP 프로토콜보다 보안성이 뛰어난 프로토콜이다.HTTPS를 사용하려면 일반적으로 관련 인증서가 필요하다. 이 인증서를 발급받는데도 비용이 든다.그리고 그 인증서를 적용하려는 웹서버에 올려 적용하고, HTTP &gt; HTTPS 리다이렉션 등을 해야 한다.AWS 클라우드는 CloudFront와 함께 이것을 쉽게 처리할 수 있다CloudFront를 이용한 HTTPS 구성Client는 뒷단 서버에 HTTPS 프로토콜로 요청을 보낼 것이다.여기서 point는 CloudFront 뒤로는 HTTP 통신을 한다는 것이다.외부 인터넷을 통해오는 요청만 HTTPS 프로토콜을 이용하고 이후 뒷단에 Private 한 공간은 HTTP 프로토콜을 이용함으로써EC2서버나 S3는 HTTPS 프로토콜을 위한 별도의 작업이 필요하지 않다는 것이다.위 그림에는 없지만, 필요하다면 CloudFront와 ALB를 연결해 뒷단(S3, EC2 etc…)까지 HTTPS 요청 전달도 고려할 수 있다.HTTPS통신은 SSL 인증서가 필요하다고 했었다.AWS에서 인증서는 ACM 서비스가 담당하며 HTTPS 연동을 위해 사용되는 것이라면 무료로 무한정 제공된다.DNS도메인 이름 시스템(DNS)은 사람이 읽을 수 있는 도메인 이름(예: www.amazon.com)을머신이 읽을 수 있는 IP 주소(예: 192.0.2.44)로 변환하는 시스템을 말한다.인터넷을 구성하고 있는 IP 주소는 IPv4의 경우 192.168.0.1 같이 숫자로 구성된다.실제 컴퓨터 통신에서는 naver.com이라는 문자열 주소를 192.168.0.1 같은 IPv4 주소로 변환해주는 서비스가 필요하다.이런 서비스를 DNS 서비스라고 한다.1. USER가 브라우저에 ‘haedal.com’ 라는 도메인을 입력하면 도메인 주소들을 가지고 있는 네임서버(DNS 서버)에 접속한다.2. 네임서버에 접속한 도메인(haedal.com)과 연결된 IP 정보(123.456.789)를 확인하고 IP를 사용자 PC에게 전달한다.3. 사용자 PC는 전달 받은 서버의 IP 주소로 접속한다.4. 서버의 IP로 연결된 브라우저에 서버의 내용(홈페이지)을 출력한다.DNS 동작 순서1. 웹 브라우저에 www.naver.com을 입력하면먼저 PC에 저장된 Local DNS(기지국 DNS 서버)에게 www.naver.com 이라는 hostname에 대한 IP 주소를 요청한다.Local DNS에는 www.naver.com 의 IP 주소가 있을 수도 없을 수도 있다.(여기서는 Local DNS에 www.naver.com 의 IP 주소가 없다고 가정)만일 네이버에 접속했던 전적이 있다면, Local DNS에 접속정보가 캐싱이 되어있어서 바로 PC에 IP 주소를 주고 끝난다.(1번 → 8번으로 넘어가 빠르게 웹페이지에 접속할 수 있다.)Local DNS(기지국 DNS 서버) 란?기본적으로 인터넷을 사용하기 위해선 IP를 할당해주는 통신사(KT, SK, LG 등…)에 등록하게 된다.컴퓨터의 LAN선을 통해 인터넷이 연결되면, 가입했던 각 통신사의 기지국 DNS 서버가 등록되게 된다.KT를 사용하는 집이면 KT DNS가 되고, SK 사용하는 집이면 SK DNS가 자동으로 셋팅 된다.2. Local DNS는 이제 www.naver.com 의 IP 주소를 찾아내기 위해 다른 DNS 서버들과 통신(DNS 쿼리)을 시작한다.먼저 Root DNS 서버에게 www.naver.com 의 IP 주소를 요청한다.Root DNS(루트 네임서버) 란?Root DNS는 인터넷의 도메인 네임 시스템의 루트 존이다.ICANN이 직접 관리하는 절대 존엄 서버로, TLD DNS 서버 IP들을 저장해두고 안내하는 역할을 한다.전세계에 961개의 루트 DNS가 운영되고 있다.3. Root DNS 서버는 Root DNS 서버 는 www.naver.com 의 IP 주소 를 찾을 수 없어com 도메인을 관리하는 TLD DNS 서버로 가라고 응답한다.4. Local DNS 서버는 com 도메인을 관리하는 TLD DNS 서버(최상위 도메인 서버)에 www.naver.com에 대한 IP 주소를 요청한다.TLD(Top-Level Domain, 최상위 도메인) DNS Server 란?TLD는 도메인 등록 기관(Registry)이 관리하는 서버로, 도메인 네미의 가장 마지막 부분을 말한다..com 이나 co.kr 같은 도메인들을 관리하고 부여하는 서버이다.Authoritative DNS 서버 주소를 저장해두고 안내하는 역할을 한다.5. com 도메인을 관리하는 DNS 서버에도 해당 정보가 없으면,Local DNS 서버에게 www.naver.com 의 IP 주소 찾을 수 없음. 다른 DNS 서버에게 물어봐 라고 응답을 한다.6. Local DNS 서버는 naver.com DNS 서버(Authoritative DNS 서버)에게 다시 www.naver.com 의 IP 주소 를 요청한다.Authoritative DNS Server 란?실제 개인 도메인과 IP 주소의 관계가 기록/저장/변경되는 서버다.그래서 권한의 의미인 Authoritative가 붙는다. (가비아에서 직접 입력)일반적으로 도메인/호스팅 업체의 ‘네임서버’를 말하지만, 개인이나 회사 DNS 서버 구축을 한 경우에도 해당된다.7. naver.com DNS 서버 에는 www.naver.com 의 IP 주소 가 있다.그래서 Local DNS 서버에게 www.naver.com에 대한 IP 주소는 222.122.195.6 라는 응답을 한다.8. 이를 수신한 Local DNS는 www.naver.com 의 IP 주소를 캐싱을 하고 이후다른 요청이 있을시 응답할 수 있도록 IP 주소 정보를 단말(PC)에 전달해 준다.Recursive Query이렇게 Local DNS 서버가 여러 DNS 서버에 차례대로Root DNS 서버 → TLD DNS 서버(.com) → Authoritative DNS 서버(naver.com) 요청하여그 답을 찾는 과정을 재귀적 쿼리 Recursive Query 라고 부른다.→ 결과물(IP 주소)를 돌려주는 작업Iterative Query (반복적 질의)Recursive DNS 서버가 다른 DNS 서버에게 쿼리를 보내어 응답을 요청하는 작업이다.Recursive 서버가 권한 있는 네임 서버들에게 반복적으로 쿼리를 보내서 결과물(IP 주소)를 알아낸다.Recursive 서버에 이미 IP 주소가 캐시 되어있다면 이 과정은 건너 뛴다.DNS 구성 요소Route 53을 적용하다보면 레코드 종류가 여러가지가 있는 것을 확인할 수 있다.해당 링크를 통해 구글 관리 콘솔 도구 상자를 통해서 조회할 수 있다.DNS RecordDNS Record는 DNS 서버가 해당 패킷을 받았을 때 어떤 식으로 처리할지를 나타내는 지침을 말한다.→ DNS 상에서 도메인에 관한 설정을 하기 위해 사용되는 일련의 설정 문자DNS 레코드 종류 종류 설명 A 해당 도메인 주소가 가지는 IP(1:1) CNAME 별칭을 부여한 특정 도메인 주소 NS 영역을 풀이할 수 있는 DNS 서버 목록 SOA 도메인의 시작점(Start Of Authority) AA 레코드는 DNS에 저장되는 정보의 타입으로 도메인 주소와 서버의 IP 주소가 직접 매핑 시키는 방법이다.ex) 도메인 이름 : domain.com - 맵핑된 주소 : 111.222.333.444→ A 레코드는 domain 도메인은 IP 주소 111.222.333.444에 연결 되어있다 라고 말하는 역할A 레코드는 반드시 도메인과 IP간의 1:1 매칭이 될 필요는 없다.도메인 매핑 설정에 따라서 1:N, N:1이 될 수도 있다.CNAME (Canonical Name record)CName 레코드는 도메인 별명 레코드라고 부르며,도메인 주소를 또 다른 도메인 주소로 이중 매핑 시키는 형태의 DNS 레코드 타입이다.→ 도메인 주소로 연결한 부분에 다시 한번 도메인 주소로 연결하는 방식이다. CNAME 레코드는 무조건 다른 도메인 주소를 등록해야 하며 A 레코드처럼 직접 IP 주소를 등록해서는 안 된다.ex) domain.com 도메인이 있을 때, 이 도메인의 CNAME을 domain22.com으로 정해서domain22.com을 입력하면 domain.com으로 접근되는 형식이다.그 다음 domain.com에 매핑된(A 레코드) IP 주소 111.222.333.444 을 얻어최종적으로 서비스에 접속하게 되는 방식이다. 서비스 도메인 주소 등록 주소 Type(형식) domain domain.com 111.222.333.444 A domain2 domain22.com domain.com CNAME A vs CNAMEDNS는 Domain Name System의 약자로 naver.com 같은 문자열 주소를 IP 주소로 해석해주는 네트워크 서비스를 말한다.DNS 서버에는 도메인 주소와 IP 주소의 쌍(Pair)이 저장된다.예를 들어, . . naver.com 192.168.0.1 google.com 172,17.0.1 plusblog.co.kr 10.234.34.12 이런 정보가 DNS 서버에 저장되고 사용자가 웹 브라우저나 프로그램에서 naver.com을 요청하면이 테이블에서 naver.com을 찾아 192.168.0.1 을 응답해준다.사용자의 웹 브라우저나 프로그램은 이 IP 주소를 이용해서 통신하게 된다.결국 위 테이블에서 하나의 행(Row)를 ‘레코드(Record)’라고 하며, 저장되는 타입에 따라 A Record와 CNAME으로 구분할 수 있다.A 레코드의 장점은 한번의 요청으로 찾아갈 서버의 IP 주소를 한번에 알 수 있다. (= 빠르다)단점은 IP 주소가 자주 바뀌는 환경에서는 조금 번거로울 수 있다.예를 들어 coco.site에서 A레코드로 IP 주소 1.0.11.111을 매핑했다고 가정한다.그러다가 IP 주소를 2.55.3.333으로 변경되었다고 한다면실 서버주소와 도메인에 맵핑된 주소가 달라 접속이 불가능해질 것이다.따라서 도메인의 A레코드를 변경해줘야 한다.도메인을 수십 개 관리하고 있는 환경에서는 번거로워지게 된다.NAME 레코드의 장점은 IP 주소가 자주 변경되는 환경에서 유연하게 대응할 수 있다.예를 들어, haedal.com 와 dal.com 두 개의 서브 도메인을 메인 도메인인 coco.site 로 매핑시키는 CNAME 레코드로 저장하고,coco.site 라는 주소를 서버 IP 1.0.11.111 주소로 매핑시키는 A 레코드로 저장했다면,서버의 IP 주소가 바뀌었을 때 main.co.kr의 A 레코드 정보만 변경시키면 된다.그러나 CNAME 레코드의 단점은맵핑을 중복으로 연달아 해서 실제 IP 주소를 얻을 때까지 여러번 DNS 정보를 요청해야 한다는 점이다.DNS 정보를 해석하는데 경우에 따라서 성능저하를 유발할 수 있게 된다.정리 하자면, A레코드와 CNAME은 장점과 단점이 서로 상반되어 있다고 보면 된다. Type 장점 단점 A 도메인이 바뀌어도 IP는 그대로 이므로 유지가 된다. 서버 이전등의 문제로 IP가 변동될시에 일일히 변경해야 한다. CNAME 서버 이전등의 문제로 IP가 변동될시에 변경하지 않아도 된다. 도메인이 바뀌면 변경해야 한다. 여러 번 요청이 될 경우 성능 저하가 일어날 수가 있다. NS (Name Server)NS 레코드는 네임 서버 레코드로 도메인에 대한 네임서버의 권한을 누가 관리하고 있는지 알려주는 레코드다.쉽게 말해, 내가 dal.site 라는 도메인을 gabia에서 구입해서 사용하고 있다고 하면,dal.site 도메인을 관리하는 네임 서버는 당연히 gabia가 되게 된다.즉 NS 레코드는 어떤 도메인에 대한 처리를 다른 도메인 네임 서버에게 위임하는 기능을 가진 레코드이다.ex) dal.site의 네임서버 ns1.dal.site ns2.dal.site ns3.dal.site ns4.dal.siteDNS 서버 자신에서 domain name에 대한 주소를 알아내지 못할 때, 이 NS 레코드에 정의된 서버로 가서 주소를 알아오게 된다.TTL(Time To Live)라는 값은 DNS서버나 사용자 PC의 캐쉬(메모리)에 저장되는 시간을 말한다.SOA (Start of Authority)SOA레코드는 네임서버가 해당 도메인에 관하여 인증된 데이터를 가지고 있음을 증명하는 레코드이다.이 레코드는 기본 이름 서버, 도메인 관리자의 전자 메일, 도메인 일련 번호 및 영역 새로 고침과 관련된 여러 타이머를 포함하여DNS 영역에 대한 핵심 정보를 지정한다.즉, SOA레코드가 없는 도메인은 네임서버에서 정상적으로 동작하지 않게 되는 것이다.SOA레코드는 도메인당 1개이다.하늘색과 주황색 표시된 부분은 같은 내용이며 하늘색을 풀어쓴 것이 주황색이며 하늘색의 시간은 초단위이다.◼️ Mname / primary name : 도메인에 대한 기본 호스트네임◼️ RName / mail addr : 관리자의 이메일 주소. 일반적인 이메일 형식인 @가 아니라 마침표가 들어있음.◼️ Serial : 도메인의 갱신 버전 번호. 일반적으로 날짜(YYYYMMDD)형식.◼️ Refresh : 도메인 영역의 데이터 갱신 여부를 체크하는 주기(초 단위)◼️ Retry : (장애 등의 이유로)refresh 주기로 체크하지 못했을 경우, 체크를 재시도하는 주기(초 단위)◼️ Expire : retry의 주기로 체크를 수차례 반복하다가, 도메인을 더이상 신뢰할 수 있는 영역이라고 간주하지 않아 서비스를 중단하는 최대 기한. ◼️ minimum : 도메인을 찾을 수 없는 경우, 네임 서버가 도메인의 부재정보를 캐싱하는 시간즉, Refresh 시간만큼 기다렸다가 Secondary Name Server는 Primary Name Server에 DNS 정보를 물어본다.DNS 정보는 SOA 레코드가 가장 먼저 전달되는데, SOA 레코드의 Serial 정보를 보고Secondary Name Server에 보관된 Serial과 다르다면 DNS 정보를 전체 가져와서 갱신한다.Route 53AWS에서 제공하는 DNS(Domain Name System)이다.Reference [AWS] CloudFront를 이용한 HTTPS 적용 DNS 레코드 종류 ★ 완벽 정리 DNS란? (도메인 네임 시스템 개념부터 작동 방식까지) 11.Route 53이란? DNS 레코드에 대하여 DNS에서 CNAME과 A 레코드의 차이 🌐 DNS 개념 &amp; 동작 ★ 알기 쉽게 정리 DNS란? (도메인 네임 시스템 개념부터 작동 방식까지)" }, { "title": "배포 후 oauth2 수정", "url": "/posts/%EB%B0%B0%ED%8F%AC-%ED%9B%84-OAUTH2-%EC%88%98%EC%A0%95/", "categories": "Project, OAuth2", "tags": "Cloud, OAuth2, Deployment", "date": "2024-01-31 00:00:00 +0900", "snippet": "배포_OAUTH2 + Securityback과 front가 분리되기 전에는&lt;a href=\"/oauth2/authorization/kakao\"&gt;Kakao&lt;/a&gt;위와 같이 설정만 해도 소셜 로그인을 하는데 문제가 없었다.문제는 back과 front를 분리하면서 해당 url을 페이지로 변환하려고 하면서 에러가 발생했다.그래서 href로 하게 되면 자꾸 페이지로 변환하려고 해서 다르게 작성하려고 했다.참고로 github의 repo와 blog를 많이 찾아봤으나 localhost에서 끝나는 경우와배포를 해도 back과 front를 분리 하지 않아서 위와 같은 코드로 작성되어있었다.ajax 시도function oauth_kakao_login(){ $.ajax({ type: \"GET\", url: host + `/oauth2/authorization/kakao`, contentType: false, processData: false, success: function (response) { console.log(\"response : \" + response) } })}→ 검색 결과 : 프론트에서 로그인 요청을 ajax로 요청하면 안된다. 탈락!kakao developerskakao developers에 들어가서 javascript 코드를 보며 내 코드를 수정했다.아래 코드는 demo로 작성된 것을 내 코드에 맞게 일부 제거한 것이다.&lt;head&gt; &lt;script src=\"https://t1.kakaocdn.net/kakao_js_sdk/2.6.0/kakao.min.js\" integrity=\"sha384-6MFdIr0zOira1CHQkedUqJVql0YtcZA1P0nbPrQYJXVJZUkTk/oX4U9GhUIs3/z8\" crossorigin=\"anonymous\"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;a onclick=\"oauth2()\"&gt;Kakao&lt;/a&gt;&lt;/body&gt;Kakao.init('c089c8172def97eb00c07217cae17495'); // 사용하려는 앱의 JavaScript 키 입력function oauth2(){ Kakao.Auth.authorize({ redirectUri: 'https://developers.kakao.com/tool/demo/oauth', });}실행을 하니 로그인 페이지로 넘어갔다.그래서 &lt;a href=\"/oauth2/authorization/kakao\"&gt;Kakao&lt;/a&gt;가 적용되었던 이유는 spring에서 인식을 했기 때문인데지금은 back과 front를 분리하면서 back에서 확인을 할 수 없으니 거기에 맞게 front도 다시 작성해야하는 것 같았다.환경변수위에서 실행한 대로 한다면 여러 정보들을 입력해야한다.front에서 환경변수를 저장해야했는데 node랑 react말고순수 javascript에서는 환경변수를 적용할 방법이 마땅한게 보이지 않았다.그래서 조금 복잡하지만 back에서 적용한 환경변수를 front에서 받아오는걸로 했다.Javascriptfunction oauth(){ let userInfoUrl let kakakokEY $.ajax({ type: \"GET\", url: host + `/kakao/login`, contentType: false, success: function (response) { userInfoUrl = response[0]; kakakokEY = response[1]; Kakao.init(kakakokEY); Kakao.Auth.authorize({ redirectUri: userInfoUrl, }); } })}@RestControllerpublic class SignController { @Value(\"${KAKAO_REDIRECT}\") private String REDIRECTION_URL; @Value(\"${KAKAO_JAVASCRIPT}\") private String JAVASCRIPT; @GetMapping(\"/kakao/login\") public List&lt;String&gt; kakao(){ List&lt;String&gt; list = new ArrayList&lt;&gt;(); list.add(REDIRECTION_URL); list.add(JAVASCRIPT); return list; }이렇게 실행했더니 아래와 같이 동작했다.여기서 로그인을 시도 했더니 이번엔 redirectURL이 not found가 떴다.redirectURL을 로그인 후에 보여지는 페이지로 수정했더니 제대로 동작했다.그러나 내가 참고한 코드는 오직 js 코드라서 back의 로직은 하나도 거치지 않았다.따라서 REST API 코드를 참고했으나 여전히 back 로직을 타고 있지 않았다.그러다가 이 글을 보게 되었는데나랑 비슷한 상황은 아니었지만 답글을 보고 힌트를 얻게 되었다.Backend 주소“정상적인 리디렉션 주소는 백엔드측 주소가 되어야 합니다.”내가 back과 front를 분리하면서 동작이 되지 않았다고 했었다.그 말은 back과 front 주소가 동일했다는 뜻이다.현재는 back과 front 주소가 다르다.그래서 나는 front 주소를 입력해서 oauth2를 구현하려고 했고 그래서 oauth2를 통해 db에 저장되지 않았던 것이다.수정한 코드는 아래와 같이 href 되는 url만 변경하면 끝나는 것이었다.ex) back 주소 : haedal.domain.com&lt;a href= \"https://haedal.domain.com/oauth2/authorization/kakao\"&gt;Kakao&lt;/a&gt;위와 같이 실행한 후에는 security가 잘 적용이 되어서 db에 저장이 되었다." }, { "title": "배포하면서 생긴 채팅 관련 오류", "url": "/posts/%EB%B0%B0%ED%8F%AC%ED%95%98%EB%A9%B4%EC%84%9C-%EC%83%9D%EA%B8%B4-%EC%B1%84%ED%8C%85-%EA%B4%80%EB%A0%A8-%EC%98%A4%EB%A5%98/", "categories": "Project, Chat", "tags": "spring, WebSocket, Chat, Deployment, error", "date": "2024-01-27 00:00:00 +0900", "snippet": "배포하면서 생긴 채팅 관련 오류 모음 집(+SSE)로컬에서 https를 적용했을 때는 문제가 되지 않았으나 배포하면서 발견한 에러들을 정리해봤다.1. 공통 JS와 페이지별 기능 JS채팅 관련 js를 작성한 곳이 chat.js이고여러 페이지에서 공통적으로 사용한 변수들과 메소드를 모아놓은 곳이 global.js다.global.js에서 선언한 token, host를 갖고 오지 못해서 chat.js에서 실행 되지 못하고chat.js에서 nickname을 중복 선언해서 global.js에서 nickname이 중복이라고 에러가 떴다.이 말은 global.js보다 chat.js가 먼저 실행된다는 얘기였다.알고보니 HTML 파일에서 스크립트를 작성할 때 순차적으로 실행이 되는데 global.js가 chat.js 보다 아래에 위치해 있었다.html에 js를 넣을 때도 순서가 중요하다라는걸 느꼈다.혹시 몰라서 $(document).ready(function(){});를 활용할 수도 있긴 하지만현재 코드로는 script 실행 순서만 변경해야 동작한다.2. 채팅 관련 라이브러리 설치Monolith 구조일 때는 BACK과 FRONT가 함께 BUILD되어서 동작했으나BACK과 FRONT가 분리되어 서로 독립적으로 BUILD될 때는 필요한 의존성을 script 등을 통해 관리해야한다.// SockJS&lt;script src=\"https://cdnjs.cloudflare.com/ajax/libs/sockjs-client/1.5.2/sockjs.min.js\"&gt;&lt;/script&gt;// STOMP&lt;script src=\"https://cdnjs.cloudflare.com/ajax/libs/stomp.js/2.3.3/stomp.min.js\"&gt;&lt;/script&gt;3. endpoint/info?t= ~ 404 (Not Found)WebSocket이 처음 connection 시에 endpoint/info?t= ~ 같은 형태의 URL을 호출해서 연결이 된다.근데 여기서 404 에러가 났다. → Spring에서 호출 URL을 처리 못한다는 뜻처음엔 blog에서 수정한 방법을 사용하려고 했으나cors 오류가 없었고 setAllowedOrigins(\"*\")를 사용하라고 했으나 setAllowedOriginPatterns(\"*\")를 사용하고 있었다.나는 sockJs 생성 주소를 잘못 입력해서 생긴 오류 였다.new SockJS('/chat'); → new SockJS(host + '/chat');*host = https://www.domain.com 연결 시 info를 호출하는 이유는 어떤 방법으로 연결해야 할 지 정보를 얻기 위함이다.WebSocket이 모든 브라우저에 적용되지 않고 프록시 서버가 도중에 연결을 끊어버리기도 하기 때문에이런 단점들을 보완한 WebSocketEmulation (SockJS)를 사용한다.SockJS는 우선 WebSocket 연결을 시도하고,실패하였을 경우 Streaming, Long-Polling 등 다른 대체 기술로 연결을 시도한다.잠깐 다른 주제로 넘어가자면 security에서 setAllowedOrigins(\"*\")와 setAllowedOriginPatterns(\"*\") 관한 얘기가 나왔다.이 글은 작성하면서 현재 글과 어울리지 않는다고 판단해서 CORS에서 따로 작성했다.4. Mixed ContentMixed Content: The page at https://www.~ was loaded over HTTPS,but requested an insecure XMLHttpRequest endpoint http://api~.This request has been blocked; the content must be served over HTTPS.https 사이트에서 ajax를 사용해서 비동기로 http 사이트에 request를 요청해서 문제가 발생 했다.암호화된 HTTPS 기반의 사이트에서 암호화되지 않은 HTTP 사이트에 요청을 보내서 Mixed content 에러가 발생한 것이다.html파일 head에 아래 태그를 추가하면 된다.&lt;meta http-equiv=\"Content-Security-Policy\" content=\"upgrade-insecure-requests\"&gt;웹페이지의 보안 정책을 설정하는 HTML 메타 태그 중 하나위 코드가 적용된 페이지에서는 브라우저가 페이지에 있는 모든 HTTP 요청을 HTTPS로 변경하려고 시도하게 된다.이는 중요한 보안 관행 중 하나로, 특히 웹사이트가 HTTPS를 지원하는 경우에 권장되는 설정이라고 한다.5. has been blocked by CORS policyAccess to XMLHttpRequest at https://www.domain.com/templates/login.html(redirected from https://api.domain.com/ws/info?t=)from origin https://www.domain.com has been blocked by CORS policy:No ‘Access-Control-Allow-Origin’ header is present on the requested resource.setAllowedOriginPatterns에 https://api.domain.com을 추가하면 된다.6. websocket connection failed이 글을 보고 security에웹소켓 통신에 대한 권한 허용 코드가 없으니 추가를 해야한다는 얘기인 것 같아서채팅의 endpoint인 ws를 추가했더니 동작했으며 위 2개 오류가 해결되었다. → .antMatchers(\"/ws/**\").permitAll()해당 오류가 뜬 이유는 7번과 동일하다.(JwtAuthenticationFilter로 인해 채팅 불가하므로 접근 허용으로 수정)7. OAuth2, Form Login채팅을 test할 때 주로 소셜로그인을 활용해서 했다가 이번에 폼로그인으로 진행하면서 채팅이 되지 않았다.@RequiredArgsConstructor@Slf4jpublic class JwtAuthenticationFilter extends OncePerRequestFilter { private final JwtTokenProvider jwtTokenProvider; @Override public void doFilterInternal( HttpServletRequest servletRequest, HttpServletResponse servletResponse, FilterChain filterChain) throws ServletException, IOException { }}JwtAuthenticationFilter에서 토큰이 없는 경우나 유효하지 않은 경우에는 인증에 실패한 것으로 처리된다.@Component@RequiredArgsConstructorpublic class CustomAuthenticationEntryPoint implements AuthenticationEntryPoint { @Override public void commence(HttpServletRequest request, HttpServletResponse response, AuthenticationException authException) throws IOException { }}이 때, CustomAuthenticationEntryPoint 클래스의 commence()가 호출되어 인증 실패를 처리하는데채팅할 때 ajax로 통신하는 경우 외에는 header에 token을 넣어주지 않아서 발생한 오류 같았다.그래서 6번에서 해결한 방법과 같이 작성해서 JwtAuthenticationFilter를 실행되지 않게 했다.WebSocketConfig에서 jwt token 검증을 위해 stompHandler를 Interceptor로 설정했기 때문에 채팅은 따로 검증 체크가 들어간다.8. EventSource’s response has a MIME type (“text/plain”) that is not “text/event-stream”. Aborting the connection.SseEmitter 객체를 return해줘야 하는데 해주지 않아서 생긴 오류다.문제는 2가지가 있었다.하나는 url을 수정하는 과정에서 back과 front의 url이 서로 달라서 통신하지 못해 생긴 오류이고또 다른 하나는 7번과 같이 JwtAuthenticationFilter가 실행되면서 인증에 실패해 Controller가 실행되지 못했다.SSE(Server-Sent Events)에서는 HTTP 요청과는 다르게 헤더에 직접적으로 토큰을 담는 것이 불가능하다.따라서 .antMatchers(VIEW_LIST).permitAll()에서 VIEW_LIST에 SSE 통신하는 url을 추가해줬다.REFERENCE 3. 230306 TIL 4. Mixed content 문제 해결(https 사이트에서 http 사이트 요청 시 발생하는 보안 문제) 7 Scheduling 과 SSE 를 활용한 실시간 푸시 알림 구현 " }, { "title": "Connection timed out: connect", "url": "/posts/Connection-timed-out-connect/", "categories": "Error", "tags": "Cloud, Deployment, error", "date": "2024-01-27 00:00:00 +0900", "snippet": "Connection timed out: connect.DB를 연결하려고 보니 Connection timed out: connect. 에러가 떴다.이 글을 보고 EC2의 보안그룹을 체크해봤다.유형 : MYSQL, 포트 범위 : 330으로 설정은 했으나 소스 부분에서 팀원이 “내 IP”만 허용해둬서 나는 접근을 할 수가 없었다.그래서 0.0.0.0/0으로 설정을 해뒀더니 해결되었다. (모든 IP에서 접속 허용)" }, { "title": "배포_redis", "url": "/posts/%EB%B0%B0%ED%8F%AC_Redis/", "categories": "Project, Redis", "tags": "Deployment, Redis, 배포", "date": "2024-01-25 00:00:00 +0900", "snippet": "Redis이 전 글에서 redis를 application.properties에 아래와 같이 설정했다.spring.redis.host = host.docker.internalhost.docker.internal은 Docker for Windows 및 Docker for Mac에서 로컬 호스트를 가리키는 특수한 DNS 이름이다.따라서 Linux에서는 이 이름이 제대로 동작하지 않기 때문에 환경변수를 수정해줘야한다.만약 이를 놓쳤다면UnknownHostException: host.docker.internal: Name or service not known 라는 에러를 볼 수 있을 것이다.docker redisRedis 서버를 백그라운드에서 실행하며, 호스트의 6379 포트를 통해 해당 Redis 서버에 접근docker run -d --name redis-container -p 6379:6379 redis docker run: Docker 이미지를 실행하는 명령어 -d: 백그라운드에서 실행한다. --name redis-container: 실행되는 container에 이름을 지정한다. → “redis-container”로 설정 -p 6379:6379: host의 6379 port와 container의 6379 port를 연결한다. → host에서 Redis에 접근하기 위한 포트 포워딩을 설정한다. redis: 사용할 Docker 이미지의 이름이다. → Redis 이미지를 사용했다. redis container ip 주소 확인하기가장 마지막에 있는 redis-container 부분만 본인 container 이름으로 수정하면 된다.docker inspect -f {\\{range .NetworkSettings.Networks}}{\\{.IPAddress}}{\\{end}} redis-container이렇게 입력하면 redis-container 컨테이너의 IP 주소를 출력해준다.환경변수 적용하기ip 주소를 환경변수에 적용해준다.예시로 1.1.1로 작성spring.redis.host = 1.1.1docker-compose를 이용하면, 컨테이너 명으로 해당 컨테이너에 접근할 수 있다는 글을 본적이 있는데나는 docker-compose를 이용하지 않았고 컨테이너 명을 사용하면 Name or service not known 에러가 뜬다.따라서 ip 주소로 수정을 했고 오류가 나타나지 않게 되었다." }, { "title": "연관관계_proxy", "url": "/posts/%EC%97%B0%EA%B4%80%EA%B4%80%EA%B3%84_Proxy/", "categories": "Project, JPA", "tags": "JPA", "date": "2024-01-22 00:00:00 +0900", "snippet": "Proxy• em.find() vs em.getReference()• em.find(): 데이터베이스를 통해서 실제 엔티티 객체 조회• em.getReference(): 데이터베이스 조회를 미루는 가짜(프록시) 엔티티 객체 조회→ DB 쿼리는 안나가는데 객체는 조회되는 걸 말한다.아래는 기본 코드EntityManagerFactory emf = Persistence.createEntityManagerFactory(\"dal\");EntityManager em = emf.createEntityManager();EntityTransaction tx = em.getTransaction();tx.begin();try { Comment comment = new Comment(); comment.setComment(\"댓글\"); em.persist(comment); em.flush(); em.clear(); // 코드 추가할 곳 tx.commit();}catch (Exception e){ tx.rollback(); e.printStackTrace();}finally { em.close();}emf.close(); Comment findComment = em.getReference(Comment.class, comment.getId());System.out.println(\"findComment.getId() = \" + findComment.getId());System.out.println(\"findComment.getComment() = \" + findComment.getComment());.getReference()를 호출하는 시점에는 select 쿼리가 안나간다.findComment.getId()로 파라미터에 id값을 넣어줬기 때문에 db에서 안가지고 와도 안다.getUsername()은 db에 있기 때문에 JPA가 DB에 쿼리를 날린다.System.out.println(\"findComment = \" + findComment.getClass());Comment를 조회해보면 이름이 Comment가 아니라 hibernate가 강제로 만든 가짜 클래스로 출력된다.→ Proxy class라는 것이다.getReference()라고 하면 진짜 Comment 객체를 주는 것이 아니라hibernate가 자기 내부의 어떤 라이브러리를 써가지고 속칭 proxy 라고 하는 가짜 엔티티 객체를 준다.껍데기는 똑같은데 안이 텅텅 비어있고 내부에는 target이라는게 있다. (target이 진짜 reference를 가리킴)*em.find()를 하면 진짜 객체를 준다.Proxy 특징• 실제 클래스를 상속 받아서 만들어진다.• 실제 클래스와 겉 모양이 같다.• 사용하는 입장에서는 진짜 객체인지 프록시 객체인지 구분하지 않고 사용하면 됨(이론상)• 프록시 객체는 실제 객체의 참조(target)를 보관• 프록시 객체를 호출하면 프록시 객체는 실제 객체의 메소드 호출Proxy의 getComment()을 호출하면 target에 있는 getComment()(Entity의 getComment을 말함)을 대신 호출해준다.하지만 실제 db에서 조회한 적이 없기 때문에 처음에는 target이 없을 것이다.Comment comment = em.getReference(Comment.class, comment.getId());comment.getComment();프록시 객체를 가져와서 comment.getComment()을 호출하면 Comment의 target에 값이 처음에 없다.그러면 JPA가 영속성 컨텍스트에 요청을 한다. (⭐영속성 컨텍스트를 통해서 초기화를 요청한다.⭐)영속성 컨텍스트에서는 DB를 조회해서 실제 Entity를 생성해서 준다.그리고 target에 있는 것에다가 연결을 시켜준다.그래서 getName(MemberProxy)을 했을 때target의 getComment()(Comment)을 통해서 Comment에 있는 getComment()이 반환된다.한번 초기화 되면 이제 Member target(MemberProxy)에 걸리기 때문에 다시 db 조회할 일은 없다.System.out.println(\"findComment.getComment() = \" + findComment.getComment());System.out.println(\"findComment.getComment() = \" + findComment.getComment());• 프록시 객체는 처음 사용할 때 한 번만 초기화• 프록시 객체를 초기화 할 때, 프록시 객체가 실제 엔티티로 바뀌는 것은 아니며,초기화되면 프록시 객체를 통해서 실제 엔티티에 접근 가능하다.Comment를 조회할 때 Registry도 함께 조회해야할까?단순히 Comment 정보만 사용하는 비즈니스 로직일 경우 같이 조회하는 것은 손해다.지연 로딩 LAZY을 사용해서 프록시로 조회@Entitypublic class Comment { @Id @GeneratedValue @Column(name = \"COMMENT_ID\") private Long id; private String comment; @ManyToOne(fetch = FetchType.LAZY) @JoinColumn(name = \"REGISTRY_ID\") private Registry registry;}이렇게 하면 Registry를 프록시 객체로 조회한다. → Comment 클래스만 db에서 조회Comment findComment = em.find(Comment.class, comment.getId());Comment만 가져온 것을 볼 수 있다.registry를 조회해보면 proxy로 나온 것을 볼 수 있다.Registry registry = new Registry();registry.setTitle(\"title\");em.persist(registry);Comment comment = new Comment();comment.setComment(\"댓글\");comment.setRegistry(registry);em.persist(comment);em.flush();em.clear();Comment findComment = em.find(Comment.class, comment.getId());System.out.println(\"findComment.getRegistry().getClass() = \" + findComment.getRegistry().getClass());tx.commit();이제 registry에 무언가를 가지고 오려고 하면 이 시점에 쿼리가 나간다.실제 registry를 사용하는 시점에 proxy 객체가 초기화 되면서 값을 가지고 온다.Comment findComment = em.find(Comment.class, comment.getId());System.out.println(\"findComment.getRegistry().getClass() = \" + findComment.getRegistry().getClass());System.out.println(\"= = = = = = = = = = = = = \");findComment.getRegistry().getTitle();System.out.println(\"= = = = = = = = = = = = = \");그래서 지연로딩으로 세팅하면 연관된 것을 프록시로 가져온다.지연로딩comment를 로딩을 할 때 Registry 인스턴스는 지연로딩으로 세팅되어있기 때문에 프록시로 가지고 온다.이것을 LAZY, 지연로딩이라고 한다.지연 로딩 LAZY을 사용해서 프록시로 조회Comment comment = em.find(Comment.class, 1L);em.find로 comment를 가지고 왔을 때 지연로딩으로 세팅되어있으면가짜 프록시 객체를 받아서 넣는다.Registry registry = comment.getRegistry();registry.getTitle(); // 실제 registry를 사용하는 시점에 초기화(DB 조회)실제 registry를 사용하는 시점에 쿼리가 나간다.⭐ registry를 사용할 때가 아니라 registry에 있는 뭔가를 실제 사용할 때 초기화가 된다.findComment.getRegistry()는 프록시로 가져오기 때문에 쿼리가 나가지 않고프록시를 가져와서 어떤 메소드를 사용할 때 초기화가 일어난다. (ex. findComment.getRegistry().getTitle();)만약 Comment와 Registry가 자주 함께 사용한다면 즉시 로딩 EAGER를 사용해서 함께 조회한다.참고로 LAZY 설정할 때 static import할 수 있다.import static javax.persistence.FetchType.LAZY;@Entitypublic class Comment { @Id @GeneratedValue @Column(name = \"COMMENT_ID\") private Long id; @ManyToOne(fetch = LAZY) @JoinColumn(name = \"REGISTRY_ID\") private Registry registry;}영속성 전이(CASCADE)와 고아 객체영속성 전이• 특정 엔티티를 영속 상태로 만들 때 연관된 엔티티도 함께 영속 상태로 만들도 싶을 때• 예: 부모 엔티티를 저장할 때 자식 엔티티도 함께 저장영속성 전이: 저장@OneToMany(mappedBy=\"parent\", cascade=CascadeType.PERSIST)parent를 저장할 때 연관된 얘도 같이 저장하는게 cascade다.코드로 살펴보기Child child1 = new Child();Child child2 = new Child();Parent parent = new Parent();parent.addChild(child1);parent.addChild(child2);em.persist(parent);em.persist(child1);em.persist(child2);tx.commit();Parent를 중심으로 코드를 작성하고 있는데 persist를 child까지 총 3개를 작성해야 한다.parent를 persist할 때 자동으로 child도 persist 해줬으면 좋을 때 cascade를 사용한다.@OneToMany(mappedBy = \"parent\", cascade = CascadeType.ALL)Child child1 = new Child();Child child2 = new Child();Parent parent = new Parent();parent.addChild(child1);parent.addChild(child2);em.persist(parent);tx.commit();parent만 persist 했는데 Child도 persist 된 것을 볼 수 있다.name 값은 넣지 않아서 null으로 나오는게 맞고PARENT의 ID와 CHILD의 ID 값인 34, 35가 PARENT의 33으로 잘 들어가 있는 것을 볼 수 있다.이 전에 했던 연관관계와는 전혀 관련이 없고 심플하게 Parent를 persist할 때cascade로 선언한 컬렉션 안에 있는 얘들(Child)을 전부 persist 날려주는 것이 cascade다.연관관계를 매핑하는 것과 아무관련 없다라는 뜻은 연관관계를 맺는 과정에 영속성 전이는 필요없다라는 뜻이다.예를 들어, 1:N 연관관계를 맺을 때 CASCADE 속성 없이 @OneToMany만 있어도 사용하여 연관관계를 맺을 수 있다.즉, 1:N 연관관계를 맺는다는 관점에서 CASCADE는 아무런 역할을 하지 않는다.CASCADE를 추가하는 이유는 연관관계 매핑이 아닌 순전히 영속성 전이를 위함이기 때문이다.주의할 점• 영속성 전이는 연관관계를 매핑하는 것과 아무 관련이 없음• 엔티티를 영속화할 때 연관된 엔티티도 함께 영속화하는 편리함을 제공할 뿐종류참고로 bold 처리된 3개만 쓰게 됨• ALL: 모두 적용• PERSIST: 영속• REMOVE: 삭제• MERGE: 병합• REFRESH: REFRESH• DETACH: DETACHCASCADE는 언제 쓸까?1대 다에는 무조건 걸어야 할까? ❌ NO!!하나의 부모가 자식들을 관리할 때 CASCADE가 의미가 있다.CASCADE를 쓰면 안되는 case파일을 여러 군데에서 관리하고 다른 엔티티에서 관리하는 경우 사용하면 안된다.Parent만 Child를 관리하고 연관관계가 있으면 상관없는데다른 객체랑 Child랑 관계가 있으면 사용하면 안된다.소유자가 하나일 때만 CASCADE를 사용한다.Child에서 다른 객체로 나가는 것은 상관이 없는데다른 객체가 Child를 알게 되면 CASCADE를 사용하면 안된다. (운영이 힘들어진다.)다른 객체가 Child를 안다는 것은 Locker → Child 이런식으로 Locker가 Child를 필드에 가지고 있는 것을 말한다.Child에서 다른 부분으로 나간다는 것은 Child → Door 이런식으로 Child가 Door를 필드에 가지고 있는 것을 말한다.결과적으로 영속성 전이와 고아객체는 다른 곳에서 Child를 참고하지 않을 때 사용할 수 있다.Life Cycle이 동일할 때 (Parent와 Child의 LifeCycle이 유사할 때 - 등록, 삭제)단일 소유자 (소유자가 하나일 때)CASCADE를 사용하면 된다.cascade는 부모 엔티티의 특정 동작(예를 들어, 삭제)을 자식 엔티티에도 전파하는 기능이다.고아 객체 고아 객체 제거: 부모 엔티티와 연관관계가 끊어진 자식 엔티티를 자동으로 삭제 orphanRemoval = true Parent parent1 = em.find(Parent.class, id); parent1.getChildren().remove(0); // 자식 엔티티를 컬렉션에서 제거 DELETE FROM CHILD WHERE ID=? 코드로 보기 #46em.flush();em.clear();Parent findParent = em.find(Parent.class, parent.getId());findParent.getChildList().remove(0);아래와 같이 하나가 지워졌다.id가 2번인 child가 지워졌다.@OneToMany(mappedBy = \"parent\", cascade = CascadeType.ALL, orphanRemoval = true)private List&lt;Child&gt; childList = new ArrayList&lt;&gt;();orphanRemoval은 컬렉션에서 빠진 것은 삭제 된다.고아 객체 - 주의• 참조가 제거된 엔티티는 다른 곳에서 참조하지 않는 고아 객체로 보고 삭제하는 기능• 참조하는 곳이 하나일 때 사용해야함! (ex. 게시판의 첨부파일 개념일 때)• 특정 엔티티가 개인 소유할 때 사용• @OneToOne, @OneToMany만 가능• 참고: 개념적으로 부모를 제거하면 자식은 고아가 된다. 따라서 고아 객체 제거 기능을 활성화 하면, 부모를 제거할 때 자식도 함께 제거된다. 이것은 CascadeType.REMOVE처럼 동작한다.이 말은 아래와 같이 설명할 수 있다.코드로 보기 #46코드를 보면 CascadeType.ALL을 지우고 child를 persist 코드로 다시 바꾼 후에// Parent.java@OneToMany(mappedBy = \"parent\", orphanRemoval = true)private List&lt;Child&gt; childList = new ArrayList&lt;&gt;();아래와 같이 parent를 지우게되면 Parent 엔티티가 지워지게 된다.// JpaMain.javaem.persist(parent);em.persist(child1);em.persist(child2);em.flush();em.clear();Parent findParent = em.find(Parent.class, parent.getId());em.remove(findParent);그러면 orphanRemoval 입장에서 해당 컬렉션은 다 날라가게 된다.실행시키면 Child 2개 있는게 지워지는 것을 확인할 수 있다.참고로 @OneToMany(mappedBy = \"parent\", cascade = CascadeType.ALL) 라고만 해도 똑같은 결과가 나온다.orphanRemoval는 조심히 사용해야한다.이것만 기억한다. 특정 엔티티가 개인 소유할 때 사용한다.영속성 전이 + 고아 객체, 생명주기영속성 전이 + 고아 객체, 생명주기• CascadeType.ALL + orphanRemoval=true• 스스로 생명주기를 관리하는 엔티티는 em.persist()로 영속화, em.remove()로 제거→ 라이프 사이클을 JPA 영속성 컨텍스트(엔티티 매니저)를 통해서 한다.• 위 두 옵션을 모두 활성화 하면 부모 엔티티를 통해서 자식의 생명주기를 관리할 수 있다.parent만 persist하고 parent만 remove를 했다.Parent는 JPA를 통해서 생명주기를 관리하고 있고 Child는 Parent가 관리한다.• 도메인 주도 설계(DDD)의 Aggregate Root개념을 구현할 때 유용하다." }, { "title": "Chat 정리", "url": "/posts/Chat-%EC%A0%95%EB%A6%AC/", "categories": "Project, Chat", "tags": "spring, WebSocket, Chat", "date": "2024-01-21 00:00:00 +0900", "snippet": "채팅 정리채팅 기능을 구현하면서 그 과정들을 정리했었는데 기존에 정리했던 것 일부분을 넣어 요약 정리를 해봤다.WebSocket &amp; WebSocket EmulationHTTP 프로토콜의 특징 중 중요한 부분 중 하나는 비연결성이다.HTTP는 비연결성이라는 특징을 가지고 있어서 연결을 끊어버린다.이를 해결하기 위한 방법이 Polling, Long Polling, Streaming이 있다.관련 글 : SSE하지만 위 방식 모두 HTTP를 통해 통신하기 때문에 Request/Response 모두 헤더가 불필요하게 크다.이러한 단점들을 해소하기 위해 나온 것이 WebSocket이다.WebSocket 프로토콜은 서버-클라이언트 간에 단일 TCP 커넥션을 이용해서 양방향 통신을 제공한다.request - response가 있는 것이 아니라 커넥션이 open - close 된 것이다.WebSocket 연결 과정브라우저에서 socket 통신을 이용하기 위해서는socket 통신이 가능한지 확인하는 핸드셰이크(Hand Shake) 과정이 필요하다.핸드쉐이크는 한번의 HTTP 요청과 HTTP 응답으로 이루어진다.핸드쉐이크가 끝나면 HTTP 프로토콜을 웹소켓 프로토콜로 변환하여 통신을 하는 구조다.핸드쉐이크는 먼저 클라이언트가 HTTP로 웹소켓 연결 요청을 하면서 시작된다.Hand Shake 과정1. 브라우저에서 HTTP 통신을 이용하여 서버에 소켓 통신이 가능한지 요청을 보낸다.header에 socket을 사용하기 위한 Upgrade, Connection, WebSocket에 관한 정보를 포함한다.웹소켓 연결 요청에는 Connection: Upgrade와 Upgrade: websocket 헤더를 통해 웹소켓 요청임을 표시한다.Sec-WebSocket-Key 헤더를 통해 핸드쉐이크 응답을 검증할 키 값을 보낸다.2. 서버에서 WebSocket 통신을 지원한다면 101 Switching Protocols 상태 코드를 응답하여 웹소켓 통신을 허용함을 알린다.서버의 응답역시 HTTP로 오며, 정상적인 응답의 상태코드는 101(Switching Protocols)다.Sec-WebSocket-Key 헤더를 통해 받은 값에 특정 값을 붙인 후,SHA-1로 해싱하고 base64로 인코딩한 값을 Sec-WebSocket-Accept 헤더에 보낸다.4. handshake 과정이 성공적으로 끝나면 TCP 연결은 유지한채 HTTP를 webSocket 프로토콜로 바꾸는 protocol switching 과정이 진행된다.→ TCP handshake를 통해 HTTP Upgrade Header를 사용하여 WebSocket 프로토콜로 변경WebSocket을 위한 새로운 소켓이 만들어지고 이 소켓을 이용해 통신한다. → ws / wssWebsocket은 ws는 프로토콜을 사용하고 HTTPS에서는 SSL이 적용된 wss 프로토콜을 사용한다.ex) URL : wss://www.chat.siteimplementation 'org.springframework.boot:spring-boot-starter-websocket'implementation 'org.webjars:sockjs-client:1.1.2'@Configuration@EnableWebSocket // 👈🏻 public class WebSocketConfig implements WebSocketConfigurer { @Override public void registerStompEndpoints(StompEndpointRegistry registry) { registry.addEndpoint(\"/ws\").setAllowedOriginPatterns(\"*\").withSockJS(); }}WebSocket 기반의 애플리케이션을 만들었을 경우, 다음과 같은 문제점들이 존재할 수 있다. 클라이언트의 브라우저가 WebSocket을 지원하지 않음 클라이언트와 서버 사이의 Proxy가 WebSocket Upgrade 헤더를 해석 못해 서버에 전달하지 못함 클라이언트와 서버 사이의 Proxy가 Idle 상태에서 Connection을 도중 종료함위와 같은 상황에서의 해결책은 WebSocket Emulation이다.우선 WebSocket Connection을 시도하고,실패할 경우 : HTTP 기반하에서 동작하는 다른 기술로 전환하여 연결을 시도한다.Node.js를 사용시 Socket.io를 사용하는 것이 일반적이고,Spring Framework를 사용시 SockJS를 사용하는 것이 일반적이다.관련 글 : WebSocketStompWebSocket 프로토콜은 두 가지 유형의 메시지를 정의하고 있지만, 그 메시지의 내용까지는 정의하고 있지 않다.STOMP은 WebSocket 위에서 동작하는 프로토콜로써, 클라이언트와 서버가 전송할 메시지 유형, 형식, 내용들을 정의한다.내가 가장 와닿았던 것은COMMAND를 통해 SEND 또는 SUBSCRIBE, CONNECT 등의 명령을 지정하고, header를 정의할 수 있다는 것이다.MessageType(COMMAND)에 따라서 Controller를 구분지어 활용할 수 있다는 점이 가장 큰 차이로 와닿았다.implementation 'org.webjars:stomp-websocket:2.3.3-1'@Configuration@RequiredArgsConstructor@EnableWebSocketMessageBroker // 👈🏻 public class StompWebSocketConfig implements WebSocketMessageBrokerConfigurer { private final StompHandler stompHandler; @Override public void registerStompEndpoints(StompEndpointRegistry registry) { // websocket 에 연결하기 위한 엔드 포인트를 지정 registry.addEndpoint(\"/ws\").setAllowedOriginPatterns(\"*\").withSockJS(); } @Override public void configureMessageBroker(MessageBrokerRegistry registry) { registry.enableSimpleBroker(\"/queue\", \"/topic\"); registry.setApplicationDestinationPrefixes(\"/app\"); } /* enableSimpleBroker를 통해 메시지 브로커가 /topic으로 시작하는 주소를 구독한 Subscriber들에게 메시지를 전달하도록 한다. setApplicationDestinationPrefixes는 클라이언트가 서버로 메시지를 발송할 수 있는 경로의 prefix를 지정한다. */ // StompHandler가 Websocket 앞단에서 token을 체크할 수 있도록 interceptor로 설정 @Override public void configureClientInboundChannel(ChannelRegistration registration){ // jwt 토큰 검증을 위해 생성한 stompHandler를 인터셉터로 지정해준다. registration.interceptors(stompHandler); }}public class StompHandler implements ChannelInterceptor {}관련 글 : Websocket + stomp + 보안 강화Message Broker &amp; cache메시지 브로커는 송신자가 보낸 메시지를 메시지 큐에 적재하고 이를 수신자가 받아서 사용하는 구조이다.메시지 브로커는 대표적으로 Apache Kafka, Redis, RabbitMQ, Celery 등이 있다.implementation 'org.springframework.boot:spring-boot-starter-data-redis'implementation 'org.springframework.boot:spring-boot-starter-cache'implementation 'redis.clients:jedis:3.6.3'관련 글 : Redis Broker , Redis cacheHttpsHttps 적용 한 코드를 보면 크게 달라진 점은 없다.SSL을 적용한 후에 실행하면 되기 때문이다.SSL 적용과정은 여기에 기록해뒀다.server.ssl.key-store=classpath:localhost.p12server.ssl.key-store-type=PKCS12server.ssl.key-store-password=changeit처음에 https로 적용을 했으니 그에 맞는 프로토콜인 wss를 적용해야한다고 생각이 들어서아래와 같이 작성했었다.let socket = new SockJS('/wss');Network 탭에 들어가서 wss 적용이 되었는지 확인을 해보니 내가 설정한 wss는 엔드포인트 였다라는 것을 알게 되었다.일반적으로 WebSocket의 프로토콜은 HTTP나 HTTPS의 프로토콜에 따라 자동으로 결정되는 것 같다.if (document.location.protocol === 'https:') { socket = new SockJS(\"/coco\");}여기서 endpoint는 아무거나 해도 된다. (ws나 wss를 적는게 아님!)그리고 거기에 맞게 java도 수정해주기만 하면 끝!@Overridepublic void registerStompEndpoints(StompEndpointRegistry registry) { //소켓에 연결하기 위한 엔드 포인트를 지정 registry.addEndpoint(\"/coco\").setAllowedOriginPatterns(\"*\").withSockJS();}REFERENCE ws와 wss WebSocket 통신에 대해 알아보기 웹 소켓의 개념과 간단한 예제 웹소켓에 대해 알아보자" }, { "title": "Local에서 https 적용하기", "url": "/posts/Local%EC%97%90%EC%84%9C-Https-%EC%A0%81%EC%9A%A9%ED%95%98%EA%B8%B0/", "categories": "Project, Chat", "tags": "Chat, Network", "date": "2024-01-20 00:00:00 +0900", "snippet": "채팅 HTTPS 적용하기server와 client 간의 websocket 연결은 HTTP 프로토콜을 통해 이루어진다.wss 란 https 처럼 ws 프로토콜에 데이터 보안을 위해 SSL을 적용한 프로토콜이다.port는 옵션이지만 ws스키마는 기본적으로 80포트를, wss스키마는 443을 사용한다.SSL 적용하기자바는 두 가지의 인증서 형식을 지원한다 PKCS12 (Public Key Cryptographic Standard #12) : 여러 인증서와 키를 포함할 수 있으며, 암호로 보호된 형식 (업계에서 널리 사용됨) JKS (Java KeyStore) : PKCS12와 유사하다. 독점 형식이며, Java 환경으로 제한된다. 빙법은 2가지가 있는데 나는 mkcert 프로그램을 이용했다.1. PKCS12Spring Boot App에 SSL/HTTPS를 적용하기 위해서는 아래와 같은 절차를 거쳐야 한다. SSL 인증서 얻기 application.yml 수정하기실제로 배포하는 app은 정식 인증을 받은 SSL 인증서를 사용하지만 여기서는 Self Signed SSL 인증서를 사용한다.PKCS12를 생성하는 명령어는 java의 keytool을 이용하는 것이므로, OS의 제약을 받지 않는다.윈도우와 Linux모두 아래 명렁어를 사용해 키스토어를 생성할 수 있다.PKCS12 생성하기 alias : 파일 별칭으로 자신이 원하는 이름으로 하면된다. keyalg : 키 알고리즘을 RSA로 설정한다. keystore : 개인키 파일$ keytool -genkey -alias bns-ssl -storetype PKCS12 -keyalg RSA -keysize 2048 -keystore keystore.p12 -validity 3650 alias bns-ssl key alias를 bns-ssl로 지정 keystore keystore.p12 key store 이름을 keystore.p12로 지정 아래와 같이 원하는 값을 입력하면 된다.생성이 끝났다면 다음과 같이 파일이 프로젝트 디렉토리 안에서 생성되어야만 한다.이렇게 생성된 keystore을 프로젝트에 적용한다.프로젝트의 application.yml 혹은 application.properties를 열어 다음을 입력한다.spring: profiles: local # 로컬환경에서만 사용하기# 위의 local 안적고 아래만 작성해도 됨 server: ssl: enabled: true key-store: keystore.p12 key-store-password: 123456 key-store-type: PKCS12 key-alias: bns-ssl port: 8443# - - - - - - .properties - - - - - - - - server.ssl.enabled=trueserver.ssl.key-store = keystore.p12server.ssl.key-store-password=123456server.ssl.key-store-type=PKCS12server.ssl.key-alias=bns-sslserver.port=8443프로젝트 디렉토리 내부에 있기 때문에 keystore의 절대 경로를 지정하지 않고 이름만 등록해도 된다.설정을 완료 했다면 프로젝트를 실행해서 실제로 Https가 잘 적용되었는지 확인해본다.브라우저에서 아래 주소를 입력한다.https://localhost:8443정식 인증을 받은 SSL 인증서를 사용하지 않고 Self Signed SSL 인증서를 사용했기 때문에 연결이 차단된다.나중에 정식 인증을 받은 SSL 인증서를 사용하면 이 문제가 해결된다.localhost(안전하지 않음)으로 이동을 클릭하면 HTTPS가 적용된 사이트를 볼 수 있다.or 설정 → 개인정보 및 보안 → 인증서관리에 들어가서자신이 등록한 self SSL 인증서를 항상 신뢰함으로 체크해주면 된다.오류Failed to start bean ‘webServerStartStop’; nested exception is org.springframework.boot.web.server.WebServerException: Unable to start embedded Tomcat serverIntegrity check failed: java.security.NoSuchAlgorithmException: Algorithm HmacPBESHA256 not available자꾸만 이 오류가 떴다.그러다가 [Spring Boot] embedded tomcat SSL 설정 해당 블로그를 보면서spring boot 버전에 따라 2.x면 몇개를 더 작성해야하는 것을 보고 혹시 버전 차이로 인한 것인지 체크해보기 위해spring boot를 3.x로 업그레이드 하면서 일부를 수정을 하고 실행을 해보니 해당 오류는 나타나지 않고 실행이 되었다.(2.x는 설정하는게 몇 개 부족했던 것 같다.)관련 글 : Spring boot 3.x적용2. mkcertmkcert 라는 프로그램을 이용하여 로컬환경에서 신뢰할 수 있는 인증서 만들 수 있다.(PKCS12형식만 지원)윈도우 사용자 설치 (Ubuntu)공식문서Windows에서는 패키지 매니저인 chocolately를 사용하여 mkcert를 설치할 수 있다.choco 설치powershell을 관리자 권한으로 실행한다.choco 설치 공식문서Set-ExecutionPolicy Bypass -Scope Process -Force; [System.Net.ServicePointManager]::SecurityProtocol = [System.Net.ServicePointManager]::SecurityProtocol -bor 3072; iex ((New-Object System.Net.WebClient).DownloadString('https://community.chocolatey.org/install.ps1'))설치가 완료되면 설치가 제대로 되었는지 체크해본다.인증서 생성로컬을 인증된 발급기관으로 추가한다.$ mkcert -installCA 생성 및 설치 이후 PKCS12 형식 인증서를 생성한다.# 해당 커맨드가 입력된 위치에 localhost.p12라는 파일이 생성됨$ mkcert -pkcs12 localhost1. application.properties 에서 관련 설정을 추가한다. (application.yml)2. 생성된 인증서 (우분투 파일)를 애플리케이션 resource 폴더로 이동시킨다.# application.yml 일 경우server: ssl: key-store: classpath:localhost.p12 # 인증서 경로 작성 key-store-type: PKCS12 # 인증서 형식 작성 key-store-password: changeit # 인증서 비밀번호를 작성 changeit은 설정하지 않았을 때의 기본값# application.properties 일 경우server.ssl.key-store=classpath:localhost.p12server.ssl.key-store-type=PKCS12server.ssl.key-store-password=changeit실행시키면 아래와 같이 log가 찍힌다.실행 페이지REFERENCE PKCS12 로컬 Spring Boot에 SSL 적용하기 [Spring Security] Spring Boot를 이용한 SSL/HTTPS 적용하기 mkcert SEB_BE 60일차 - [인증/보안] 기초 인증서 발급 및 Spring boot에서 HTTPS 서버 구현 " }, { "title": "Spring boot 3.x적용", "url": "/posts/Spring-Boot-3.x%EC%A0%81%EC%9A%A9/", "categories": "Intellij", "tags": "Intellij", "date": "2024-01-18 00:00:00 +0900", "snippet": "11 → 17 변경Java 버전은 17인데 프로젝트의 JDK는 11로 되어있었고 spring boot 버전은 2.x였다.그래서 spring boot는 3.x로 프로젝트 JDK는 17로 통일 시키기로 했다.build.gradleplugins { id 'org.springframework.boot' version '3.0.1'}sourceCompatibility = '17'sourceCompatibility를 17 이상으로 변경한다.Preferences/SettingsPreferences/Settings → Build, Execution, Deployment → Build Tools → GradleGradle의 JVM이 Java 17이상인지 확인한다.Preferences/Settings → Build, Execution, Deployment → Compiler → Java CompilerProject SDKFile → Project Structure로 이동. 프로젝트 SDK의 버전을 확인후 Java 17이상으로 설정한다.ProjectModules참고(적용하면서 생겨난 오류들 해결하기)버전을 업그레이드 하면서 기존 프로젝트에 나타난 문제들을 정리했다.import javax.* 오류javax.* 패키지 부분에서 빨간 줄이 떴다.찾아보니 이클립스 재단은 Jakarta EE 라고 하고 패키지는 jakarta.* 로 명명했다고 한다.다음과 같은 JavaEE 이름들이 JakartaEE 이름으로 새롭게 변경되었고, 패키지 이름로 변경되었다. Java Servlet(javax.servlet) → Jakarta Servlet(jakarta.servlet) Java Message Servie (javax.jms) → Jakarta Messaging (jakart.jms) JPA:Java Persistence API (javax.persistence) → Jakarta Persistence(jakarta.persistence) JTA:Java Transaction API (javax.transaction) → Jakarta Transaction(jakarta.transaction) Java Mail (javax.mail) → Jakarta Mail (jakarta.mail)@PostConstructJava 9 이상부터는 찾을 수 없다고 뜬다.@PostConstruct를 사용할 수 없기 때문에 build.gradle에 종속성을 추가해주면 된다.implementation 'javax.annotation:javax.annotation-api:1.3.2'다른 방법으로는 Spring bean interface 사용이 있다.Spring framework 의 경우 InitializingBean, DisposableBean 을 구현하여 @PostConstruct @PreDestroy 대체가 가능하다고 한다.이 부분은 아래 reference에 첨부된 링크를 참고해서 보면 될듯하다.antMatchers()antMatchers()를 사용할 수 없었고 antMatchers 대신 requestMatchers()를 사용했다.application.properties# do not share idspring.jpa.hibernate.use-new-id-generator-mappings= false위와 같이 사용했었는데 Spring Boot 3.x 부터 제거 되었다고 한다.spring.jpa.hibernate.use-new-id-generator-mappings= false 이 부분은 설정파일에서 제거하면 된다.spring.redis.host는 제거되었다고 해서 아래와 같이 변경했다.spring.redis.host = localspring.redis.port = 6379↓ spring.data.redis.host = localspring.data.redis.port = 6379SLF4JAPPLICATION을 실행하려 보니SLF4J: Failed to load class “org.slf4j.impl.StaticLoggerBinder”. SLF4J: Defaulting to no-operation (NOP) logger implementation라는 에러가 떴다.build.gradle에서implementation 'org.slf4j:slf4j-api:1.7.36'를 작성했었는데 해당 부분을 제거하고 아래로 작성했다.implementation 'org.slf4j:slf4j-simple:1.7.36'이 부분에 대해 검색하다보면 2개를 작성하라는 글이 많은데 이럴 경우 오류가 뜬다.slf4j-log4j12 또는 slf4j-simple 중 하나가 있어야 하며 둘 다 작성하면 안된다.나는 후자로 작성했다.REFERENCE[java 17 적용] Spring Boot 3.x 실행이 안될 경우 (feat. IntelliJ) java: warning: source release 17 requires target release 17[참고] javax.* 스프링 부트 3.0 으로 전환 @PostConstruct I can’t use @PostConstruct and @PostDestroy with Java 11 [Spring] Java @PostConstruct @PreDestroy @Resource 찾을 수 없음 antMatchers Cannot resolve method ‘antMatchers()’ in AuthorizationManagerRequestMatcherRegistry application.properties use-new-id-generator-mappings SLF4J SLF4J: Failed to load class “org.slf4j.impl.StaticLoggerBinder” " }, { "title": "연관관계 기본", "url": "/posts/%EC%97%B0%EA%B4%80%EA%B4%80%EA%B3%84-%EA%B8%B0%EB%B3%B8/", "categories": "Project, JPA", "tags": "JPA", "date": "2024-01-15 00:00:00 +0900", "snippet": "연관관계 기본 Registry(게시글)와 Comment(댓글)가 있다.객체를 테이블에 맞춰 모델링객체를 테이블에 맞춰 모델링할 경우 참조 대신에 외래 키를 그대로 사용하는 것이다.// Comment.java@Entitypublic class Comment { @Id @GeneratedValue @Column(name = \"COMMENT_ID\") private Long id; private String comment; @Column(name = \"REGISTRY_ID\") private Long registryId;}// Main.javaComment findComment = em.find(Comment.class, comment.getId());// Comment가 어느 게시글에서 작성된 것인지 알고 싶어서 조회함Long findRegistryId = findComment.getRegistryId();;Team findRegistry = em.find(Registry.class, findRegistryId);이 경우 식별자로 다시 조회→ 객체지향 X단방향 연관관계registry의 id가 아니라 참조 값을 그대로 가져왔다.위와 같이 적으면 에러가 뜬다.이제 JPA에 이 둘의 관계가 무슨 관계인지(ex. 1:N, N:1) 알려줘야 한다.Registry와 Comment는 1:N에서 누가 1이고 누가 N인지 매우 중요하다.→ DB 관점으로 매우 중요하다.@Column과 같은 어노테이션들은 db와 매핑하는 어노테이션이다.@ManyToOne여기서 Comment가 N이고 Registry가 1이다. (하나의 게시글에 여러 개의 댓글)그래서 Comment 입장에서는 @ManyToOne이라는 어노테이션으로 매핑을 해야한다.@JoinColumnRegistry²의 reference와 Comment 테이블에 있는 REGISTRY_ID(FK)¹와 매핑을 해야한다.@JoinColumn(name = \"REGISTRY_ID\") 이렇게 하면 매핑이 끝난다.// Comment.java@ManyToOne@JoinColumn(name = \"REGISTRY_ID\")private Registry registry;code*getter, setter 생략// Comment.java@Entitypublic class Comment { @Id @GeneratedValue @Column(name = \"COMMENT_ID\") private Long id; private String comment; @ManyToOne @JoinColumn(name = \"REGISTRY_ID\") private Registry registry;}// Registry.java@Entitypublic class Registry { @Id @GeneratedValue @Column(name = \"REGISTRY_ID\") private Long id; private String title;}조회// Main.javatry { Registry registry = new Registry(); registry.setTitle(\"title\"); em.persist(registry); Comment comment = new Comment(); comment.setComment(\"comment\"); comment.setRegistry(registry); em.persist(comment); Comment findComment = em.find(Comment.class, comment.getId()); Registry findRegistry = findComment.getRegistry(); System.out.println(\"findRegistry.getTitle() = \" + findRegistry.getTitle()); tx.commit();}insert 쿼리가 2번 나간 것을 볼 수 있다.참고로 영속성 컨텍스트 말고 db에서 가져오는 쿼리를 보고 싶다면 아래 코드를 추가하면 된다.// Main.javaem.flush(); // 강제 호출 (영속성 컨텍스트에 있는 것들을 db에 쿼리를 날려버려서 싱크를 맞춤)em.clear(); // 영속성 컨텍스트 초기화point관계가 무엇인지 @ManyToOne이 관계를 할 때 join 하는 column은 무엇인지 @JoinColumn양방향 연관관계Comment에서 Registry로 갈 수 있는데 반대로 Registry에서 getComment는 안된다.reference만 넣어두면 Comment ↔ Registry로 왔다갔다 할 수 있다.→ 양방향 연관관계라고 한다. (양쪽으로 참조해서 갈수있게 함)테이블 연관관계는 차이가 하나도 없다.why? REGISTRY_ID(FK) 와 REGISTRY_ID(PK)랑 JOIN하면 되기 때문에테이블의 연관관계는 외래키 하나로 양방향이 다 있는 것이다.사실상 테이블의 연관관계는 방향이라는 개념 자체가 없다.FK만 집어넣으면 양쪽으로 다 알 수 있다.그러나 문제는 객체다.이 전에 Comment에서 Registry로 갈 수 있는데 Registry에서 Comment로 갈 수 있는 방법은 없다.그래서 Registry에 comments라는 List를 넣어줘야 양쪽으로 갈 수 있는 것이다.code*Comment 엔티티는 단방향과 동일하다.Registry 엔티티는 컬렉션을 추가한다.// Registry.java@Entitypublic class Registry { @Id @GeneratedValue @Column(name = \"REGISTRY_ID\") private Long id; private String title; @OneToMany(mappedBy = \"registry\") private List&lt;Comment&gt; comments = new ArrayList&lt;&gt;();}private List&lt;Comment&gt; comments = new ArrayList&lt;&gt;();관례로 ArrayList&lt;&gt;()로 초기화 해준다. (그래야 add할때 nullpoint가 안뜨므로)Registry에서 Comment로 가는 것은 일대 다 이므로 @OneToMany를 작성하고mappedBy를 적어준다. (mappedBy = \"registry\")mappedBy는 일대 다 매핑에서 어떤 거랑 연결되어있는지 적는 곳인데Registry의 변수명 registry랑 매핑이 되어있다라는 얘기다.객체와 테이블이 관계를 맺는 차이 객체 연관관계 = 2개 회원 → 팀 연관관계 1개(단방향) 팀 → 회원 연관관계 1개(단방향) 회원에서 팀으로 가려면 참조 값 하나 넣어줘야 하고팀에서 회원으로 가려면 참조 값을 하나 넣어놔야 한다.→ 단방향 연관관계가 2개가 있는 것이다. 테이블 연관관계 = 1개 회원 ↔ 팀의 연관관계 1개(양방향) 양방향이라고 적었지만 사실은 방향이 없는 것이다.하나만 있으면 양쪽으로 왔다갔다 할 수 있다.연관관계의 주인(Owner)Comment를 바꾸고 싶거나 새로운 Registry에 작성하려고 한다고 가정그럴때 Comment의 registry 값을 변경해야할지 Registry의 comments를 바꿔야 할지 모름(둘다 맞기 때문에)하지만 db 입장에서는 COMMENT에 있는 REGISTRY_ID(FK) 외래키 값만 업데이트 하면 된다.그래서 rule이 생긴다. → 둘 중 하나로 외래 키를 관리해야한다.→ 주인을 정해야한다.“연관관계의 주인”이라는 개념은 양방향 매핑에서 나오는 것이다.• 연관관계의 주인만이 외래 키를 관리(등록, 수정)• 주인이 아닌쪽은 읽기만 가능• 주인은 mappedBy 속성 사용X• 주인이 아니면 mappedBy 속성으로 주인 지정mappedBy 라는 뜻 자체가 저것에 의해 내가 매핑이 되었어 라는 뜻누구를 주인으로?DB 입장에서 보면 외래키(FK)가 있는 곳이 무조건 N(다)이다.외래키가 없는 곳이 무조건 1이다.그 말인 즉슨, DB의 N 쪽이 연관관계의 주인이 된다. → @ManyToOne이미 코드를 보면 답이 다 나와있다.@OneToMany(mappedBy = \"registry\") → mappedBy로 나는 registry에 의해서 관리가 되고 있다.이 registry는 아래 코드를 말한다.// Comment.java@Entitypublic class Comment { @ManyToOne @JoinColumn(name = \"REGISTRY_ID\") private Registry registry;}mappedBy가 적힌 곳은 읽기만 된다.// Registry.java@Entitypublic class Registry { @OneToMany(mappedBy = \"registry\") private List&lt;Comment&gt; comments = new ArrayList&lt;&gt;();}comments에 값을 넣어봤자 아무 일도 일어나지 않는다.(대신 조회는 가능)연관관계의 주인은 Comment에 있는 Registry가 연관관계의 주인이다.그래서 연관관계 주인에 값을 넣어야 한다.주의할 점양방향 매핑시 주의할 점으로는 3가지가 있다.1. 연관관계의 주인에 값을 입력하지 않음// Main.javaRegistry registry = new Registry();registry.setTitle(\"게시글 제목\");em.persist(registry);Comment comment = new Comment();comment.setComment(\"댓글\");// 역방향(주인이 아닌 방향)만 연관관계 설정registry.getComments().add(comment);em.persist(comment);실행하면 COMMENT 테이블에 REGISTRY_ID가 null이다.왜 그럴까? 연관관계의 주인은 Comment에 있는 registry가 연관관계의 주인이다.Registry에 있는 comments는 mappedBy 읽기 전용이다.(가짜 매핑)그래서 연관관계 주인에 값을 넣어야 한다.// Main.javaRegistry registry = new Registry();registry.setTitle(\"게시글 제목\");//registry.getComments().add(comment); ←em.persist(registry);Comment comment = new Comment();comment.setComment(\"댓글\");comment.setRegistry(registry); // ⭐⭐⭐⭐⭐em.persist(comment); 2. 연관관계 편의 메소드 생성하기JPA 입장에서는 아래 코드가 맞는 코드이다.// Main.javaRegistry registry = new Registry();registry.setTitle(\"게시글 제목\");em.persist(registry);Comment comment = new Comment();comment.setComment(\"댓글\");comment.setRegistry(registry); // ⭐⭐⭐⭐⭐em.persist(comment); 그런데 객체지향적으로 생각하면 양쪽에 다 값을 걸어야 한다.// Main.javaRegistry registry = new Registry();registry.setTitle(\"게시글 제목\");em.persist(registry);Comment comment = new Comment();comment.setComment(\"댓글\");comment.setRegistry(registry);em.persist(comment);em.flush(); // 강제 호출 (영속성 컨텍스트에 있는 것들을 db에 쿼리를 날려버려서 싱크를 맞춤)em.clear(); // 영속성 컨텍스트 초기화Registry findRegistry = em.find(Registry.class, registry.getId()); // 1)List&lt;Comment&gt; comments = findRegistry.getComments(); // 2)for (Comment c: comments) { // 2) System.out.println(\"c.getComment() = \" + c.getComment()); // 2)}tx.commit();위 코드를 실행하면 문제 없이 동작한다.실행하면 두개의 select 쿼리가 나오는데1) Registry를 조회했을 때 나오는 쿼리2) 실제 Comment 데이터를 로딩했을 때 (Registry의 comments를 사용하는 시점에 쿼리를 날린다.)flush(), clear()를 해버리기 때문에registry.getComments().add(comment); 라고 코드를 안넣어줘도 동작하지만flush(), clear()를 주석처리하고 실행시키면1) 은 1차 캐시에 있지만 2)에서 컬렉션에는 값이 없다.Registry findRegistry = em.find(Registry.class, registry.getId()); // 1)List&lt;Comment&gt; comments = findRegistry.getComments(); // 2)System.out.println(\"= = = = = = = = =\");for (Comment c: comments) { // 2) System.out.println(\"c.getComment() = \" + c.getComment()); // 2)}System.out.println(\"= = = = = = = = =\");tx.commit();insert 쿼리만 나가는 것을 볼 수 있다.Registry는 순수한 객체 상태이기 때문에 컬렉션에는 값이 없다.저장한 상태 그대로 영속성 컨텍스트에 들어가 있기 때문에 db에서 select 쿼리가 날라가지 않는다.따라서 순수 객체 상태를 고려해서 항상 양쪽에 값을 설정한다.*참고로 테스트 케이스에서도 jpa 없이 작성해 줄 수 있기 때문에 둘 다 값을 세팅해줘야한다.여기서 주의할 점은registry.getComments().add(comment); 와 comment.setRegistry(registry)를 같이 넣어야 한다는 것이다.Registry registry = new Registry();registry.setTitle(\"게시글 제목\");em.persist(registry);Comment comment = new Comment();comment.setComment(\"댓글\");comment.setRegistry(registry); // 👈🏻em.persist(comment);registry.getComments().add(comment); // 👈🏻이 부분을 까먹을 수도 있기 때문에 연관관계 편의 메소드를 생성하는 것을 추천한다.연관관계 편의 메소드// Comment.javapublic void setRegistry(Registry registry) { this.registry = registry; registry.getComments().add(this);}참고로 연관관계 편의 메소드나 jpa 상태를 변경하는 것은 set을 잘 안쓴다.getter, setter 관례 때문에 로직이 추가로 들어가면 이름을 바꿔준다.🔽// Comment.javapublic void changeRegistry(Registry registry) { this.registry = registry; registry.getComments().add(this);}// Main.javaRegistry registry = new Registry();registry.setTitle(\"게시글 제목\");em.persist(registry);Comment comment = new Comment();comment.setComment(\"댓글\");comment.changeRegistry(registry);em.persist(comment);만약 Registry를 기준으로 comment를 넣는다면 아래와 같이 작성하면 된다.// Registry.javapublic void addComment(Comment comment){ comment.setRegistry(this); comments.add(comment);}// Main.javaRegistry registry = new Registry();registry.setTitle(\"게시글 제목\");em.persist(registry);Comment comment = new Comment();comment.setComment(\"댓글\");em.persist(comment); registry.addComment(comment);여기서 조심해야할 것은 연관관계 편의 메소드가 양쪽에 다 있으면 문제를 일으킬 수 있다.그래서 한쪽은 지워준다. (둘 중에 하나만 정해주면 된다.)정리하자면 연관관계의 주인은 Comment에 있는 Registry가 주인이고값을 세팅하는 것은 본인 마음이다. (단, 연관관계 편의 메소드는 둘 중에 하나만 세팅한다.)3. 양방향 매핑시에 무한 루프를 조심한다.Comment에서 toString()을 생성해본다.// Comment.java@Overridepublic String toString() { return \"Comment{\" + \"id=\" + id + \", comment='\" + comment + '\\'' + \", registry=\" + registry + '}';}여기서 registry는 registry.toString()을 또 호출한다는 얘기가 된다.// Comment.java@Overridepublic String toString() { return \"Comment{\" + \"id=\" + id + \", comment='\" + comment + '\\'' + \", registry=\" + registry.toString() + '}';}또 Registry에서 toString()을 생성하면 아래와 같다.// Registry.java@Overridepublic String toString() { return \"Registry{\" + \"id=\" + id + \", title='\" + title + '\\'' + \", comments=\" + comments + '}';}comments는 컬렉션 하나하나 안에 있는 toString()을 다 호출한다.그래서 양쪽으로 toString()을 무한 호출하게 된다.// Main.javaSystem.out.println(findRegistry);→ 실행하면 StackOverflowError가 뜸(양쪽으로 계속 호출하기 때문이다.)정리• 테이블은 외래 키로 조인을 사용해서 연관된 테이블을 찾는다.• 객체는 참조를 사용해서 연관된 객체를 찾는다.• 테이블과 객체 사이에는 이런 큰 차이 있다." }, { "title": "Https 적용하기3(cloudfront, acm, route 53)", "url": "/posts/HTTPS-%EC%A0%81%EC%9A%A9%ED%95%98%EA%B8%B03(CloudFront,-ACM,-Route-53)/", "categories": "Project, Cloud", "tags": "AWS", "date": "2024-01-13 00:00:00 +0900", "snippet": "HTTPS 적용하기(CloudFront, ACM, Route 53)가장 먼저 도메인을 구매한다. (가비아)여기서는 www.domain.com이라고 부르겠다.ACMHTTPS 프로토콜을 위한 ACM을 생성한다.주의할 점은 만들 때 지역을 “버지니아 북부” 로 변경하고 만들어야 한다.서울과 같이 다른 지역으로 설정하면 계속 검증 대기중으로만 뜨게 된다.요청을 완료하면 검증 대기중인 인증서가 띄워진다.CloudFront 적용하기원본 도메인 탭을 누르면 방금 만든 s3 버킷에 대한 도메인을 자동으로 띄워준다.해당 도메인을 클릭하지 말고 S3 &gt; 속성 &gt; 정적 웹 사이트 호스팅 을 보면 나오는 주소를 넣는다.단, http:// 부분은 빼고 넣는다.ex) domain/s3-website.ap-northeast-2.amazonaws.com만약 자동으로 띄워주는 도메인을 등록한다면 cloudfront를 실행했을 때This XML file does not appear to have any style information associated with it. The document tree is shown below.라는 에러를 볼 수 있다.뷰어(Client)가 HTTP로 접근하면 HTTPS로 리다이렉트 하겠다는 설정이다.대체 도메인 이름(CNAME) - 선택사항에 구매한 도메인을 넣으면 된다. ex) www.domain.com사용자 정의 SSL 인증서 - 전에 생성한 SSL 인증서를 선택한다.*사용자 정의 SSL 인증서가 띄워지려면 ACM 상태가 발급됨으로 표시되어야 한다.만약 가비아에 레코드 추가를 했는데 발급됨으로 변경되지 않았다면 보통 바로 적용이 되지 않고 짧으면 15분 길면 몇시간까지 기다려야 발급됨으로 표시된다. ACM에서 지역이 버지니아 북부로 되어있는지 확인한다.접속 확인배포 된 CloudFront의 도메인 이름을 들어가보면 https로 웹 서버에 접속된 것을 확인 할 수 있다.이제 구매한 도메인으로 접속하게끔 Route 53을 활용해본다.Route 53구매한 도메인을 작성하고 나머지는 default 후 호스팅 영역 생성 버튼 클릭레코드는 현재 NS, SOA 2개의 레코드가 존재한다.만약 레코드가 NS, SOA, CNAME 3개의 레코드가 존재한다면ACM에서 Route 53 레코드 생성 버튼을 눌러 자동으로 생성된 것이다.레코드 생성을 눌러 아래와 같이 작성한다. 레코드 이름 : www 레코드 유형 : CNAME 값 : CloudFront 배포 도메인 이름을 작성하면 된다.가비아 설정가비아 도메인의 네임서버를 NS를 클릭하면 나오는 값 4개로 바꿔야 한다.가비아 홈페이지 &gt; 이용 중인 서비스 &gt; 도메인 &gt; (내가 구입한 도메인) 관리 로 들어간다.위 호스트명에 NS 레코드의 라우팅 4개를 넣어주면 된다. (마지막에 .이 안들어가야 한다.)" }, { "title": "Https 적용하기2(cloudfront, acm)", "url": "/posts/HTTPS-%EC%A0%81%EC%9A%A9%ED%95%98%EA%B8%B02(CloudFront,-ACM)/", "categories": "Project, Cloud", "tags": "AWS", "date": "2024-01-12 00:00:00 +0900", "snippet": "HTTPS 적용하기(CloudFront, ACM)가장 먼저 도메인을 구매한다. (가비아)여기서는 www.domain.com이라고 부르겠다.ACMHTTPS 프로토콜을 위한 ACM을 생성한다.주의할 점은 만들 때 지역을 버지니아 북부로 변경하고 만들어야 한다.서울과 같이 다른 지역으로 설정하면 계속 검증 대기중으로만 뜨게 된다.요청을 완료하면 검증 대기중인 인증서가 띄워진다.인증서를 클릭하면 CNAME이름과 CNAME 값이 띄워지는데이 값을 가비아 DNS 설정에 가서 레코드 수정 버튼을 누르고 호스트에 CNAME 이름을, 값/위치에는 CNAME 값을 넣으면 된다.여기서 CNAME 이름은 가장 처음에 나오는 . 부분까지만 작성하고 뒷 부분은 제거 한 후 작성한다.ex) abcdefghijk.www.domain.com. → abcdefghijk 부분만 호스트명에 작성CloudFront 적용하기원본 도메인 탭을 누르면 방금 만든 s3 버킷에 대한 도메인을 자동으로 띄워준다.해당 도메인을 클릭하지 말고 S3 &gt; 속성 &gt; 정적 웹 사이트 호스팅 을 보면 나오는 주소를 넣는다.단, http:// 부분은 빼고 넣는다.ex) domain/s3-website.ap-northeast-2.amazonaws.com만약 자동으로 띄워주는 도메인을 등록한다면 cloudfront를 실행했을 때This XML file does not appear to have any style information associated with it. The document tree is shown below.라는 에러를 볼 수 있다.뷰어(Client)가 HTTP로 접근하면 HTTPS로 리다이렉트 하겠다는 설정이다.대체 도메인 이름(CNAME) - 선택사항에 구매한 도메인을 넣으면 된다. ex) www.domain.com사용자 정의 SSL 인증서 - 전에 생성한 SSL 인증서를 선택한다." }, { "title": "Https 적용하기(s3)", "url": "/posts/HTTPS-%EC%A0%81%EC%9A%A9%ED%95%98%EA%B8%B0(S3)/", "categories": "Project, Cloud", "tags": "AWS", "date": "2024-01-11 00:00:00 +0900", "snippet": "HTTPS 적용하기(S3)S3 적용하기1. IAM 생성사용자 생성 버튼 클릭1page2 page🔽 S3, CloudFront 를 사용할 것이므로 AmazonS3FullAccess, CloudFrontFullAccess 권한 추가🔽 액세스 키 발급액세스 키, 시크릿 키, .csv 파일 저장 ( 기록해 둔다. )🔽 액세스 키 ID, 비밀 액세스 키 github에 적용S3 버킷 생성일반 구성의 버킷 이름 + 모든 퍼블릭 액세스 차단 해제 말고 수정한게 없다. 객체 소유권 : ACL 비활성화됨(권장) 이 버킷의 퍼블릭 액세스 차단 설정 : 모든 퍼블릭 액세스 차단 해제하기!! 버킷 버전 관리 : 비활성화 기본 암호화 기본 암호화 : Amazon S3 관리형 키(SSE-S3)를 사용한 서버 측 암호화 버킷 키 : 활성화 정적 웹 호스팅S3 버킷 생성 후 S3 버킷의 속성 탭 제일 하단에 있는 정적 웹 호스팅을 편집한다.Amazon S3 &gt; 버킷 &gt; ${버킷 이름} &gt; 속성 탭인덱스 문서와 오류 문서는 project에 맞게 설정하면 된다. (ex. index.html, error.html)S3 CORS(Cross-origin 리소스 공유)Amazon S3 &gt; 버킷 &gt; ${버킷 이름} &gt; 권한 탭제일 하단으로 내리면 CORS(Cross-origin 리소스 공유)가 보인다.편집을 누르고 아래를 붙여넣으면 된다.[ { \"AllowedHeaders\": [ \"*\" ], \"AllowedMethods\": [ \"GET\", \"HEAD\" ], \"AllowedOrigins\": [ \"*\" ], \"ExposeHeaders\": [ \"x-amz-server-side-encryption\", \"x-amz-request-id\", \"x-amz-id-2\" ], \"MaxAgeSeconds\": 3000 }]S3 버킷 정책 편집 S3 &gt; 버킷 &gt; 권한 &gt; 버킷 정책 편집 클릭 버킷 ARN 복사 후 정책 생성기 버튼 클릭 Select Type of Policy : S3 Bucket Policy Principal : * Actions : GetObject Amazon Resource Name (ARN) : {복사해온 ARN} + /* Add Statement 클릭Add Statement 클릭 후 나온 코드 정책에 적용한다.(Generate Policy 클릭)S3 업로드 하기css, js, templates로 폴더를 만들어서 각각 업로드 해줬다.중요한 것은 css, js, templates에 ACL을 사용하여 퍼블릭으로 설정을 해야한다.아무 html이나 들어가서 url 입력하면 성공적으로 html이 띄워지는 것을 볼 수 있다." }, { "title": "The given id must not be null!", "url": "/posts/The-given-id-must-not-be-null!/", "categories": "Error", "tags": "Java", "date": "2023-12-08 00:00:00 +0900", "snippet": "The given id must not be null!The given id must not be null! 이라는 오류가 떴다.결론만 말한다면 @ModelAttribute 대신 @RequestBody를 사용하면 된다.추가적으로 request header에data : JSON.stringify(form_data)와 같이 json 형태로 데이터를 넘겨줘야 하며,'contentType': 'application/json' 을 담아준다.json 형태로 데이터를 넘겨주지 않는다면front : 400 (Bad Request)back : Resolved [org.springframework.http.converter.HttpMessageNotReadableException: JSON parse error: Cannot deserialize value of type과 같은 에러를 볼 수 있다.‘contentType’: ‘application/json’ 을 header에 담아주지 않는다면front : 415 (Unsupported Media Type)back : Resolved [org.springframework.web.HttpMediaTypeNotSupportedException: Content type ‘text/plain;charset=UTF-8’ not supported]@RequestBody이제 왜 @RequestBody로 작성을 해야했는지 원인을 파악해본다.그리고 왜 @RequestBody를 작성하면서 header의 data와 contentType을 작성해야했는지@RequestBody에 대해서 공부해보면 그 이유를 파악할 수 있다.참고로 해당 블로그를 통해서 충분히 파악할 수 있으며 아래에 해당 글을 정리한 내용이다.@RequestBody 어노테이션의 역할은 클라이언트가 보내는 HTTP 요청 본문(JSON 및 XML 등)을 Java object로 변환하는 것이다.HTTP 요청 본문 데이터는 Spring에서 제공하는 HttpMessageConverter를 통해 타입에 맞는 객체로 변환된다.클라이언트에서 서버로 JSON 형식의 데이터를 전송할 때 @RequestBody를 사용하면,Spring은 해당 JSON 데이터를 Java 객체로 변환하는 과정에서 MappingJackson2HttpMessageConverter를 활용한다.→ MessageConverter 중 MappingJackson2HttpMessageConverter를 사용한다.public class MappingJackson2HttpMessageConverter extends AbstractJackson2HttpMessageConverter { // 생략}MappingJackson2HttpMessageConverter 클래스는 AbstractJackson2HttpMessageConverter 클래스를 상속받아 구현된 클래스다.public abstract class AbstractJackson2HttpMessageConverter extends AbstractGenericHttpMessageConverter&lt;Object&gt; { protected ObjectMapper defaultObjectMapper; private Object readJavaType(JavaType javaType, HttpInputMessage inputMessage) throws IOException { MediaType contentType = inputMessage.getHeaders().getContentType(); Charset charset = getCharset(contentType); ObjectMapper objectMapper = selectObjectMapper(javaType.getRawClass(), contentType); Assert.state(objectMapper != null, \"No ObjectMapper for \" + javaType); boolean isUnicode = ENCODINGS.containsKey(charset.name()) || \"UTF-16\".equals(charset.name()) || \"UTF-32\".equals(charset.name()); try { InputStream inputStream = StreamUtils.nonClosing(inputMessage.getBody()); if (inputMessage instanceof MappingJacksonInputMessage) { Class&lt;?&gt; deserializationView = ((MappingJacksonInputMessage) inputMessage).getDeserializationView(); // 역직렬화 뷰를 고려하여 ObjectReader 생성 if (deserializationView != null) { ObjectReader objectReader = objectMapper.readerWithView(deserializationView).forType(javaType); if (isUnicode) { return objectReader.readValue(inputStream); } else { Reader reader = new InputStreamReader(inputStream, charset); return objectReader.readValue(reader); } } } // 역직렬화 뷰가 없는 경우 기본적인 역직렬화 수행 if (isUnicode) { return objectMapper.readValue(inputStream, javaType); } else { Reader reader = new InputStreamReader(inputStream, charset); return objectMapper.readValue(reader, javaType); } } catch (InvalidDefinitionException ex) { throw new HttpMessageConversionException(\"Type definition error: \" + ex.getType(), ex); } catch (JsonProcessingException ex) { throw new HttpMessageNotReadableException(\"JSON parse error: \" + ex.getOriginalMessage(), ex, inputMessage); } }}내부적으로 ObjectMapper를 통해 클라이언트가 보낸 JSON 값을 Java 객체로 역직렬화하는 것을 알 수 있다.역직렬화란 생성자를 거치지 않고 리플렉션을 통해 객체를 구성하는 메커니즘이라고 이해하면 된다.역직렬화가 가능한 클래스들은 기본 생성자가 항상 필수다.👉🏻 역직렬화 과정에서 객체를 재구성하고 필드를 채우기 위해 기본 생성자가 필요하기 때문따라서 @RequestBody에 사용하려는 Dto가 기본 생성자를 정의하지 않으면 데이터 바인딩에 실패한다.JSON으로 값을 보내기 위해서는 request header의 Content-Type을 application/json으로 설정하고,request body에는 실제 JSON 형식의 데이터를 포함해야 한다.💡직렬화(serialize)란 자바 언어에서 사용되는 Object 또는 Data를다른 컴퓨터의 자바 시스템에서도 사용 할 수 있도록 바이트 스트림(stream of bytes) 형태로연속적인(serial) 데이터로 변환하는 포맷 변환 기술을 일컫는다.역직렬화는(Deserialize)는 바이트로 변환된 데이터를 원래대로 자바 시스템의 Object 또는 Data로 변환하는 기술이다. 바이트 스트림 이란?스트림은 클라이언트나 서버 간에 출발지 목적지로 입출력하기 위한 데이터가 흐르는 통로를 말한다.자바는 스트림의 기본 단위를 바이트로 두고 있기 때문에,네트워크, 데이터베이스로 전송하기 위해 최소 단위인 바이트 스트림으로 변환하여 처리한다.Serialization Object → Stream of Bytes → [File, Data Base, Memory] → Stream of Bytes → Object Deserialization자바 직렬화(Serializable) - 완벽 마스터하기How Jackson ObjectMapper Matches JSON Fields to Java Fields기본적으로 Jackson은 JSON 필드의 이름을 Java 객체의 getter 및 setter 메소드와 일치시켜JSON 객체의 필드를 Java 객체의 필드에 매핑한다.Jackson은 getter 및 setter 메서드 이름의 “get” 및 “set” 부분을 제거하고 나머지 이름의 첫 번째 문자를 소문자로 변환한다.예를 들어, brand 라는 JSON 필드는 getBrand() 및 setBrand()라는 Java getter 및 setter 메서드와 일치한다.EngineNumber라는 JSON 필드는 getEngineNumber() 및 setEngineNumber()라는 getter 및 setter와 일치한다.JSON 객체 필드를 Java 객체 필드와 다른 방식으로 일치시켜야 하는 경우사용자 정의 직렬화 및 역직렬화를 사용하거나 많은 Jackson Annotations 중 일부를 사용해야 한다.Jackson ObjectMapper@PostMapping(\"/comment\")public CommentResponseDto postComment(@RequestBody CommentRequestDto commentDto) { return commentService.postComment(commentDto);}따라서 @RequestBody를 사용할 CommentRequestDto는 해당 필드를 바인딩할 setter 혹은 getter가 있어야 한다.또한, 역직렬화를 위해 기본 생성자는 필수다.정리Spring에서 HTTP 요청 본문 데이터를 처리하기 위해 HttpMessageConverter 인터페이스가 사용된다.HttpMessageConverter는 HTTP 요청과 응답의 메시지 변환을 담당하는 인터페이스로, 다양한 데이터 타입 간의 변환을 처리한다.MappingJackson2HttpMessageConverter는 HttpMessageConverter 인터페이스를 구현한 구체적인 클래스 중 하나로,JSON 데이터를 Java 객체로 역직렬화하거나 Java 객체를 JSON으로 직렬화하는 역할을 수행한다.내부적으로 MappingJackson2HttpMessageConverter는 Jackson 라이브러리의 ObjectMapper를 활용하여JSON 값을 Java 객체로 역직렬화한다.ObjectMapper를 통해 역직렬화가 이루어지므로 기본 생성자가 필수다.ObjectMapper는 Java 객체의 필드와 JSON 데이터를 매핑할 때 getter와 setter를 활용한다.reference @RequestBody vs @ModelAttribute [HTTP 에러] 415 Unsupported Media Type (@RequestBody 관련) [Spring] Content type ‘text/plain;charset=UTF-8’ not supported" }, { "title": "Detached entity passed to persist", "url": "/posts/detached-entity-passed-to-persist/", "categories": "Error", "tags": "JPA, study, Java", "date": "2023-11-16 00:00:00 +0900", "snippet": "detached entity passed to persist:detached entity passed to persist:~ 라는 에러가 떴다.에러가 뜬 원인은 @Entity에서 @Id를@GeneratedValue(strategy = GenerationType.IDENTITY)로 설정해두고Member member = new Member();member.setId(10L);member.setUsername(\"HELLO WORLD\");해당 객체의 id에 직접 값을 입력했기 때문에 뜨는 에러였다. @Id //@GeneratedValue(strategy = IDENTITY) private Long id;위아 같이 @GeneratedValue(strategy = GenerationType.IDENTITY) 코드를 제거한 후 실행하면 에러가 뜨지 않는다.reference org.hibernate.PersistentObjectException: detached entity passed to persist 에러" }, { "title": "Commit 수정", "url": "/posts/commit-%EC%88%98%EC%A0%95/", "categories": "Git", "tags": "git", "date": "2023-11-10 00:00:00 +0900", "snippet": "가장 마지막 commit 수정커밋 메세지에 오타를 입력했거나 issue 번호를 잘 못 입력해서 수정할 때 사용하면 된다.$ git commit --amend -m \"[ commit 명 ]\"이미 push 된 경우 commit msg 수정 후 아래와 같이 입력한다.$ git push -f [브랜치 명]" }, { "title": "Biginteger", "url": "/posts/BigInteger/", "categories": "Log", "tags": "Java, 코테", "date": "2023-09-26 00:00:00 +0900", "snippet": "BigInteger코테 문제를 풀다가여기에서 a와 b가 long으로도 변환이 안되는 큰 수로 인해 계산을 어떻게 해야할지 몰랐다.a : “18446744073709551615”,\tb : “287346502836570928366”,\tresult : “305793246910280479981”a와 b를 long으로 변환을 시키면 NumberFormatException 오류가 떴다.BigIntegerdocs.oracle 를 참고하여 코드를 작성했다.import java.math.*;class Solution { public String solution(String a, String b){ String answer = \"\"; BigInteger aa = new BigInteger(a); BigInteger bb = new BigInteger(b); answer = String.valueOf(aa.add(bb)); return answer; }}BigInteger는 long 형을 넘는 더 큰 범위의 정수를 다룰 때 사용하는 클래스로 사칙연산 대신 메소드를 사용해야한다.참고로 BigInteger은 정수 , BigDecimal은 실수를 다룬다.reference [java] BigInteger,BigDecimal,long 큰 수의 표현-사용법" }, { "title": "H2 설치 및 실행", "url": "/posts/H2-%EC%84%A4%EC%B9%98-%EB%B0%8F-%EC%8B%A4%ED%96%89/", "categories": "", "tags": "", "date": "2023-08-28 00:00:00 +0900", "snippet": "H2 실행H2 사이트에 들어가서All Platforms를 눌러 압축을 풀어준다.h2 폴더를 프로젝트로 옮겨준다.cd h2cd binwindow는 ./h2.bat을 실행mac은 ./h2.sh를 실행하면 자동으로 h2 콘솔 페이지가 뜬다.http://127.0.0.1:8082/ 주소로 들어가도 된다.위 아이콘을 클릭해도 h2 콘솔 페이지가 뜬다.ERRORUnsupported database file version or invalid file header in file해당 경로에 있는 DB 파일을 삭제 후 시도하면 된다.Database not found, either pre-create it or allow remote database creation (not recommended in secure environments)설정한 jdbc url로 연결하려고 하면 에러가 뜬다.해당 블로그를 통해 문제를 해결했다.Generic H2 (Embedded)를 선택 후 JDBC URL에 jdbc:h2:~/jpashop을 입력하고 연결을 클릭하면“jpashop” 이라는 데이터베이스가 생성된다.만약 생성할 데이터베이스 이름을 변경하고 싶으면 jpashop 부분을 변경하면 된다.그 다음에 다시 연결을 시도하면 error가 뜨지 않고 동작하는 것을 볼 수 있다." }, { "title": "Redis pub&sub", "url": "/posts/Redis-pub&sub/", "categories": "Project, Redis", "tags": "spring, Redis, Chat", "date": "2023-08-19 00:00:00 +0900", "snippet": "Spring의 내장 브로커에서 Redis 브로커로 마이그레이션1. 확장성 및 메시지 처리량 향상Redis는 메모리 기반 데이터베이스로, 데이터를 빠르게 읽고 쓸 수 있는 특징을 가지고 있다.낮은 지연 시간을 제공하며, 높은 메시지 처리량을 가능하게 해 더 많은 사용자나 요청을 처리할 수 있다.2. 간단한 설정과 운영Redis는 간단한 설정을 가지고 있어 초기 구축 및 운영이 간편하다.3. Pub/Sub 패턴 지원Redis는 Pub/Sub 패턴을 지원하여 다중 구독자가 하나의 메시지를 동시에 수신할 수 있도록 해준다.이를 통해 실시간 이벤트 처리를 용이하게 구현할 수 있다.*Redis Pub/Sub은 메시지 브로커 시스템으로, 다른 서비스나 애플리케이션 간에 이벤트 기반 통신을 단순화하기 위해 사용된다.WebSocket은 클라이언트와 서버 간에 실시간 양방향 통신을 제공하는 프로토콜이다.Redis pub/subPub/Sub은 발행/구독 모델(Publish/Subscribe)을 기반으로 한 통신 방법으로,topic(or channel)에 대해 관심 있는 구독자(Subscriber)들에게 메시지를 발행(Publish)하는 방식이다.Subscriber는 여러 개의 채널을 구독할 수 있다. (유튜브와 비슷한 개념)Publisher가 채널에 메시지를 보내면, 그 채널을 구독하고 있는 Subscriber들에게 메시지가 전달된다.메시지를 보낼 때 Publisher는 채널에 어떤 Subscriber가 있는지 알 필요가 없이, 그냥 메시지를 전송만 하면 된다.Publish/Subscribe 구조에서 사용되는 Queue를 일반적으로 Topic이라고 한다.동작 과정1. 발행자가 특정 주제를 선택하여 메시지를 생성하고, 해당 topic의 채널에 메시지를 발행한다.2. 해당 topic을 구독한 모든 구독자들은 채널을 구독하고 있기 때문에 메시지를 받을 준비가 되어있다.3. 발행된 메시지는 해당 topic의 채널로 전달되며, 구독자들은 채널에서 메시지를 수신한다.4. 구독자들은 자신들이 관심을 갖는 특정 topic을 구독하므로, 해당 topic에 관련된 메시지만을 수신하게 된다.5. 새로운 구독자가 특정 topic를 구독하면, 이후 발행되는 해당 topic의 메시지를 받게 된다.code참고로 기존에 설정했던 broker는 제거했다.public class StompWebSocketConfig implements WebSocketMessageBrokerConfigurer { @Override public void configureMessageBroker(MessageBrokerRegistry config) { //config.enableSimpleBroker(\"/topic\"); // sub config.setApplicationDestinationPrefixes(\"/app\"); // pub }}build.gradleRedis 의존성 추가implementation 'org.springframework.boot:spring-boot-starter-data-redis'RedisConfig*추가된 코드만 작성pub/sub은 항상 redis에 발행 된 데이터가 있는지 확인하고 있어야 하기 떄문에 Listener를 등록해야한다.@Configurationpublic class RedisConfig {\t@Value(\"${spring.redis.host}\")\tprivate String redisHost;\t@Value(\"${spring.redis.port}\")\tprivate int redisPort;\t@Bean\tpublic RedisConnectionFactory redisConnectionFactory() {\t\treturn new LettuceConnectionFactory(redisHost, redisPort);\t}\t@Bean //Redis 데이터에 쉽게 접근하기 위한 코드\tpublic RedisTemplate&lt;?, ?&gt; redisTemplate() { //RedisTemplate 에 LettuceConnectionFactory 을 적용\t\tRedisTemplate&lt;?, ?&gt; redisTemplate = new RedisTemplate&lt;&gt;();\t\tredisTemplate.setConnectionFactory(redisConnectionFactory());\t\tredisTemplate.setKeySerializer(new StringRedisSerializer());//redisTemplate.setKeySerializer(new GenericToStringSerializer&lt;&gt;(Object.class));\t\tredisTemplate.setValueSerializer(new StringRedisSerializer());\t\treturn redisTemplate;\t} @Bean public RedisTemplate&lt;String, ChatMessage&gt; chatMessageRedisTemplate(RedisConnectionFactory connectionFactory) { RedisTemplate&lt;String, ChatMessage&gt; redisTemplate = new RedisTemplate&lt;&gt;(); redisTemplate.setConnectionFactory(connectionFactory); redisTemplate.setKeySerializer(new StringRedisSerializer()); redisTemplate.setValueSerializer(new GenericJackson2JsonRedisSerializer()); return redisTemplate; } @Bean // RedisMessageListenerContainer : Redis에서 발행되는 메시지를 수신하고 처리하기 위한 컨테이너 public RedisMessageListenerContainer redisMessageListenerContainer(RedisConnectionFactory connectionFactory) { RedisMessageListenerContainer container = new RedisMessageListenerContainer(); container.setConnectionFactory(connectionFactory); // 컨테이너와 Redis 서버 간의 연결을 설정 return container; }}redisMessageListenerContainer()는 Redis를 브로커로 사용하기 위한 설정나머지 메소드들은 Redis 자체의 기본 설정과 관련된 코드다.Publisher(발행자)@Service@RequiredArgsConstructorpublic class RedisPublisher { // 발행자(Publisher) 추가 private final RedisTemplate&lt;String, ChatMessage&gt; redisTemplate; public void publish(ChannelTopic topic, ChatMessage message) { redisTemplate.convertAndSend(topic.getTopic(), message); }}기존에 @MessageMapping으로 메세지를 받는 메소드에서 바로 redisTemplate.convertAndSend() 해줬는데지금은 RedisPublisher class를 추가해서 @MessageMapping에서 publish()를 호출한 후 실행된다.Subscriber(구독자)@Component@RequiredArgsConstructorpublic class RedisSubscriber implements MessageListener { // 구독자 private final ObjectMapper objectMapper; private final RedisTemplate&lt;String, ChatMessage&gt; redisTemplate; private final SimpMessageSendingOperations messagingTemplate; @Override // Redis 메시지를 수신하면 호출되는 메소드 public void onMessage(Message message, byte[] pattern) { try{ // Redis로부터 수신된 메시지 처리 로직을 구현 String channel = new String(message.getChannel()); String msg = redisTemplate.getStringSerializer().deserialize(message.getBody()); ChatMessage chatMessage = objectMapper.readValue(msg, ChatMessage.class); log.info(\"chatMessage : \" + chatMessage); if(chatMessage.getType().equals(MessageType.TALK)){ messagingTemplate.convertAndSend(channel, chatMessage); } } catch (Exception e){ e.printStackTrace(); } }}*json 형태로 msg를 받는다.onMessage()에서 private final SimpMessageSendingOperations messagingTemplate;를 통해client에 msg를 보낼 수 있고 Controller에서 따로 보낼 수도 있다. (아래 코드 참고)특정 채널의 구독자 수 조회구독이 제대로 되었는지 확인해보고 싶어서 작성했다.implementation 'redis.clients:jedis:3.6.3'import redis.clients.jedis.Jedis;try (Jedis jedis = new Jedis(\"localhost\")) { // 특정 채널의 구독자 수 조회 Map&lt;String, String&gt; stringStringMap = jedis.pubsubNumSub(channel); log.info(\"구독자 수: \" + stringStringMap);}Controller*redis와 관련 없는 코드들은 최대한 제거함@Controller@RequiredArgsConstructor@Slf4jpublic class ChatController { private final SimpMessagingTemplate template; private final RedisMessageListenerContainer redisMessageListener; private final RedisPublisher redisPublisher; private final RedisSubscriber redisSubscriber; private Map&lt;String, ChannelTopic&gt; channels; @PostConstruct public void init(){ channels = new HashMap&lt;&gt;(); } @MessageMapping(\"/chat/sendMessage\") public void sendMessage(@Payload ChatMessage chatMessage) { ChannelTopic channel = channels.get(chatMessage.getRoomId()); redisPublisher.publish(channel, chatMessage.getMessage()); } @MessageMapping(\"/chat/addUser\") public void addUser(@Payload ChatMessage chatMessage, SimpMessageHeaderAccessor headerAccessor) { String roomId = chatMessage.getRoomId(); ChannelTopic channel = new ChannelTopic(roomId); redisMessageListener.addMessageListener(redisSubscriber, channel); channels.put(\"/topic/public/\"+ roomId, channel); chatMessage.setSender(user.getNickname()); chatMessage.setType(ChatMessage.MessageType.JOIN); template.convertAndSend(\"/topic/public/\" + roomId, chatMessage); } @MessageMapping(\"/disconnect\") public void disConnect(@Payload DisconnectPayload disconnectPayload){ String roomId = disconnectPayload.getRoomId(); ChannelTopic channel = channels.get(roomId); redisMessageListener.removeMessageListener(redisSubscriber, channel); channels.remove(roomId); ChatMessage chatMessage = new ChatMessage(); chatMessage.setType(ChatMessage.MessageType.LEAVE); chatMessage.setRoomId(roomId); template.convertAndSend(\"/topic/public/\" + roomId, chatMessage); } }}☑️ RedisTemplate&lt;String, Object&gt;와 SimpMessagingTemplateRedisTemplate&lt;String, Object&gt;은 Spring에서 Redis와 상호작용하기 위한 일반적인 Template class 다.Redis 서버와의 상호작용을 추상화하고, Redis에 데이터를 저장하고 조회하고 수정할 수 있는 메소드를 제공한다.이를 통해 Redis를 데이터 저장소로 사용할 수 있으며, 직렬화 및 역직렬화 메커니즘과 관련된 설정을 지원한다.Redis 서버와 직접적으로 상호작용하기 위해 사용된다.SimpMessagingTemplate은 Spring의 WebSocket 기능을 지원하는 클래스로, 클라이언트 간 실시간 메시징을 위해 사용된다.이는 STOMP (Simple Text Oriented Messaging Protocol)를 통해 WebSocket 연결을 통해 메시지를 보내고 받을 수 있도록 도와준다.주로 웹 소켓을 통해 클라이언트 간의 메시지 전달 및 실시간 통신에 사용한다.RedisTemplate : Redis에 메시지를 저장SimpMessagingTemplate : 웹 소켓 클라이언트에게 메시지를 전송client에서 받기client에서 제대로 값을 받는지 체크하고 싶었다.let socket = new SockJS('/ws');// redis로 응답 받기socket.onmessage = (event) =&gt; { const message = event.data; console.log('받은 메시지:', message) onMessageReceived(message)};data 타입은 String이고 message 형식은 ChatMessage로 값을 보냈을 때 아래와 같이 전달받았다.MESSAGEdestination:/topic/public/123content-type:application/jsonsubscription:sub-0message-id:wrqzxuoi-10content-length:100{\"roomId\":\"123\",\"type\":\"TALK\",\"sender\":\"hi123\",\"message\":\"hihi\"} reference [Redis] 4.Spring boot에서 pub/sub 모델 사용하기 🙈[Spring Redis] Spring Data Redis (2) - Redis pub sub🐵 🗃️ REDIS의 PUB/SUB 기능 (채팅 / 구독 알림)" }, { "title": "Paging", "url": "/posts/Paging/", "categories": "Project", "tags": "spring, 추상화", "date": "2023-08-09 00:00:00 +0900", "snippet": "Paging기존 페이징을 작성할 때는 게시글 페이지만 적용했기 때문에 바로 Service 코드에 작성했다.이후에는 Video, MyPage에도 페이징이 필요해서 이를 Dto에서 추상화 시켜 적용했다.기존 코드DTO@Builder@Getter@AllArgsConstructor@NoArgsConstructorpublic class PagingDto { private List&lt;RegistryResponseDto&gt; boardList; private int curPage; private boolean prev; private boolean next; private int startPage; private int endPage; private int totalPage; public static PagingDto of(List&lt;RegistryResponseDto&gt; registry, int totalPage, int curPage, int startPage, int endPage, boolean prev, boolean next){ return PagingDto.builder() .boardList(registry) .totalPage(totalPage) .curPage(curPage) .startPage(startPage) .endPage(endPage) .prev(prev) .next(next) .build(); }}Servicepublic PagingDto getBoards(int curPage) { Pageable pageable = PageRequest.of(curPage - 1, PAGE_POST_COUNT); Page&lt;Registry&gt; boards = registryRepository.findAllByOrderByCreatedAtDesc(pageable); List&lt;RegistryResponseDto&gt; boardList = boards.stream() .map(board -&gt; new RegistryResponseDto(board.getIdx(), board.getTitle())) .collect(Collectors.toList()); int startPage = ((int)Math.floor((curPage-1) / (double)displayPageNum)) * displayPageNum + 1; // 시작 페이지 번호 int endPage = Math.min(startPage + displayPageNum - 1, boards.getTotalPages()); // 끝 페이지 번호 boolean prev = startPage != 1; // 이전 페이지 여부 boolean next = endPage &lt; boards.getTotalPages(); // 다음 페이지 여부 return PagingDto.builder() .boardList(boardList) .curPage(curPage) .startPage(startPage) .endPage(endPage) .prev(prev) .next(next) .build();}구현DtoPagingDto 클래스는 제네릭 타입 T를 사용하여 일반화된 페이징 정보를 저장하는 클래스다.@Getterpublic class PagingDto&lt;T&gt; {}한 페이지 별로 보여지는 게시물 개수는 페이지 마다 다르므로 Service에서 적용하고dto에서는 각 페이지를 몇 개씩 띄우는 공통적인 부분만 작성했다.나는 모든 페이지가 총 5페이지씩 띄우는 것으로 구현했기 때문에private static final int DISPLAY_PAGE_NUM = 5;로 작성했다.페이징 하는 계산은 그대로 dto에 옮겨준다.단, PagingDto 클래스에서 생성자를 private으로 설정하여 외부에서 직접 인스턴스를 생성하지 못하도록했다.대신 of 메소드를 사용하여 생성자를 간접적으로 호출할 수 있게 작성했다.→ 생성자의 접근을 제한하고, of 메소드를 통해 인스턴스를 생성하는 방식private PagingDto(Pageable page, List&lt;T&gt; content, long total){ this.content = content; this.curPage = page.getPageNumber()+1; this.totalPage = total; this.startPage = (int) ((curPage-1) / (double) DISPLAY_PAGE_NUM) * DISPLAY_PAGE_NUM + 1; this.endPage = (int) Math.min(startPage + DISPLAY_PAGE_NUM - 1, totalPage); this.prev = startPage != 1; this.next = endPage &lt; totalPage;}of 메소드는 Registry, Video를 모두 받아야 하기 때문에모든 클래스의 최상위 클래스인 Object를 사용했다.public static &lt;T&gt; PagingDto&lt;Object&gt; of(Page&lt;T&gt; page, List&lt;Registry&gt; registryContent, List&lt;VideoFile&gt; videoContent, long total) { List&lt;Object&gt; content = new ArrayList&lt;&gt;(); content.addAll(registryContent); content.addAll(videoContent); return new PagingDto&lt;&gt;(page.getPageable(), content, total);}public static 에서 는 제네릭 타입 매개변수를 나타낸다.파라미터에 제네릭이 붙기 때문에 붙여준다.메소드에서 제네릭을 쓸때는 타입 앞에다가 적어줘야 한다.가장 어려웠던 건 어떻게 myPage에 registry와 video를 함께 페이징을 하는 것이었다.같은 개수를 페이징하는 것이아니라 각각 4개, 8개씩 페이징 하는 것이라서각각 다르게 게시물 개수를 보여주되 페이징을 할 때 같이 동작 해야한다.페이지 수도 게시물 개수가 많은 게시물 대로 보여주는 것이 아니라페이징 된 페이징 수를 기준으로 전체 페이지 수 중 더 큰 값을 갖고 가야했다.Service@Override // mypagepublic PagingDto&lt;Object&gt; myPage(int curPage, User user) { Pageable registryPageable = PageRequest.of(curPage - 1, MY_PAGE); Pageable videoPageable = PageRequest.of(curPage - 1, MY_PAGE*2); Page&lt;Registry&gt; registryPage = registryRepository.findByNickname(user.getNickname(), registryPageable); Page&lt;VideoFile&gt; videoPage = videoRepository.findByNickname(user.getNickname(), videoPageable); List&lt;Registry&gt; registryList = registryPage.getContent(); List&lt;VideoFile&gt; videoList = videoPage.getContent(); long total = Math.max(registryPage.getTotalPages(), videoPage.getTotalPages()); if(registryPage.getTotalPages()&gt;=videoPage.getTotalPages()){ return PagingDto.of(registryPage, registryList, videoList, total); }else{ return PagingDto.of(videoPage, registryList, videoList, total); }}최종 코드Dto@Getterpublic class PagingDto&lt;T&gt; { private static final int DISPLAY_PAGE_NUM = 5; private int curPage; private boolean prev; private boolean next; private int startPage; private int endPage; private long totalPage; private List&lt;T&gt; content; public PagingDto(Pageable page, List&lt;T&gt; content, long total){ this.content = content; this.curPage = page.getPageNumber()+1; this.totalPage = total; this.startPage = (int) ((curPage-1) / (double) DISPLAY_PAGE_NUM) * DISPLAY_PAGE_NUM + 1; this.endPage = (int) Math.min(startPage + DISPLAY_PAGE_NUM - 1, totalPage); this.prev = startPage != 1; this.next = endPage &lt; totalPage; } public static &lt;T&gt; PagingDto&lt;T&gt; of(Page&lt;T&gt; page) { return new PagingDto&lt;&gt;(page.getPageable(), page.getContent(), page.getTotalElements()); } public static &lt;T&gt; PagingDto&lt;T&gt; of(Pageable page, List&lt;T&gt; content, long total) { return new PagingDto&lt;&gt;(page, content, total); }} Pageable 대신 Page 사용 Dto는 추상화만 하고 service에서 계산을 다 처리 하게 구현하는 것으로 수정했다. Object를 쓰면 제네릭을 쓰는 이유가 없어진다. → t로 수정(PagingDto&lt;T&gt;) Service@Override // 작성 글 페이징public PagingDto&lt;Registry&gt; getBoards(int curPage) { Pageable pageable = PageRequest.of(curPage - 1, PAGE_POST_COUNT); Page&lt;Registry&gt; boards = registryRepository.findAllByOrderByCreatedAtDesc(pageable); return PagingDto.of(boards);}@Overridepublic PagingDto&lt;Object&gt; myPage(int curPage, User user) { Pageable registryPageable = PageRequest.of(curPage - 1, MY_PAGE); Pageable videoPageable = PageRequest.of(curPage - 1, MY_PAGE*2); Page&lt;Registry&gt; registryPage = registryRepository.findByNickname(user.getNickname(), registryPageable); Page&lt;VideoFile&gt; videoPage = videoRepository.findByNickname(user.getNickname(), videoPageable); List&lt;Registry&gt; registryList = registryPage.getContent(); List&lt;VideoFile&gt; videoList = videoPage.getContent(); List&lt;Object&gt; mergeList = new ArrayList&lt;&gt;(); mergeList.addAll(registryList); mergeList.addAll(videoList); long total = Math.max(registryPage.getTotalPages(), videoPage.getTotalPages()); if(registryPage.getTotalPages()&gt;=videoPage.getTotalPages()){ return PagingDto.of(registryPageable, mergeList, total); } return PagingDto.of(videoPageable, mergeList, total);}" }, { "title": "로그인 문제 해결하기", "url": "/posts/%EB%A1%9C%EA%B7%B8%EC%9D%B8-%EB%AC%B8%EC%A0%9C-%ED%95%B4%EA%B2%B0%ED%95%98%EA%B8%B0/", "categories": "Project", "tags": "spring, Security", "date": "2023-07-29 00:00:00 +0900", "snippet": "로그인 문제 해결하기문제기존에 사용하고 있던 폼 로그인에 내가 작성한 oauth2를 적용하게 되면서로그인이 제대로 이루어지지 않는 상황이 생겼다.코드Securityhttp.authorizeRequests() .antMatchers(\"/css/**\", \"/oauth2/**\", \"/user/**\", \"/taste/**\", \"/js/**\").permitAll() .antMatchers(\"/admin/**\").hasAuthority(\"ADMIN\") .anyRequest().authenticated();http.authorizeRequests() .antMatchers(HttpMethod.GET, GET_WHITE_LIST).permitAll() // GET 요청 허용 .antMatchers(VIEW_LIST).permitAll() .antMatchers(USER_ENABLE).hasAnyRole(\"USER\",\"ADMIN\") // USER 접근 가능2개의 코드를 보여주는 이유는 첫번째 코드는 제대로 oauth2와 폼 로그인이 동작했지만두번째 코드는 기존에 작성되어있던 코드로써 로그인을 하면 엑세스가 거부되면서 403 error가 떴다.여기에서 힌트를 얻어서 문제를 쉽게 해결할 수 있었다.사용자의 역할 정보를 가져오기 위해 UserDetailsService를 구현하고, 해당 서비스를 설정하여 Spring Security에서 사용하도록 해야한다.그 말은 UserDetailService에서 권한을 설정해야한다그런데 실제 UserDetailService에서는 권한 설정이 없었다.UserDetailServiceImpl@Overridepublic UserDetails loadUserByUsername(String username) { log.info(\"[loadUserByUsername] loadUserByUsername 수행. username : {}\", username); return userRepository.findByNickname(username).orElseThrow(() -&gt; { throw new UserNotFoundException(); });}그래서 권한을 가져올 수 없으니 로그인을 해도 Security에서 권한 설정한 페이지를 볼 수 없던 것이었다.@Slf4j@Service@RequiredArgsConstructorpublic class UserDetailServiceImpl implements UserDetailsService { private final UserRepository userRepository; @Override public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException { Optional&lt;User&gt; user = userRepository.findByNickname(username); if (user.isEmpty()) { throw new UsernameNotFoundException(\"User not found with username: \" + username); } // 사용자의 권한 정보를 조회하여 List&lt;GrantedAuthority&gt;로 변환 List&lt;GrantedAuthority&gt; authorities = new ArrayList&lt;&gt;(); authorities.add(new SimpleGrantedAuthority(user.get().getRole().name())); // UserDetails 객체 생성 return new org.springframework.security.core.userdetails.User( user.get().getNickname(), user.get().getPassword(), authorities ); }}UserDetailsService 인터페이스는 스프링 시큐리티에서 인증과 관련된 작업을 처리하기 위한 인터페이스다.스프링 시큐리티는 사용자 인증 정보를 가져와서 인증 작업을 수행하는 데 사용된다.이 인터페이스를 구현한 클래스는 사용자의 인증 정보를 제공하고,필요한 경우 데이터베이스나 다른 소스로부터 사용자 정보를 조회하여 인증에 활용한다.UserDetailsService를 구현하는 클래스에는 실제로 사용자 인증 정보를 조회하는 로직이 포함되어야 한다.이 로직은 보통 데이터베이스 등의 저장소에서 사용자 정보를 조회하고 UserDetails 객체를 생성하여 반환하는 작업을 수행한다.스프링 시큐리티에서 UserDetailsService를 사용하기 위해서는 해당 클래스를 빈으로 등록해야 한다.이 클래스는 비즈니스 로직을 수행하는 서비스 계층의 구현체로 볼 수 있기 때문에@Service 어노테이션을 사용하여 UserDetailsService 구현 클래스를 서비스 계층의 bean으로 등록한다.붙이지 않으면 아래와 같이 에러가 뜬다.***************************APPLICATION FAILED TO START***************************Description:Parameter 0 of constructor in dalcho.adme.config.security.JwtTokenProvider required a bean of type 'dalcho.adme.service.UserDetailService' that could not be found.Action:Consider defining a bean of type 'dalcho.adme.service.UserDetailService' in your configuration.get()을 많이 쓰는 것 같아서 아래와 같이 수정했다.@Overridepublic UserDetails loadUserByUsername(String username) throws UsernameNotFoundException { return userRepository.findByNickname(username) .map(this::buildUserDetails) .orElseThrow(() -&gt; new UsernameNotFoundException(\"User not found with username: \" + username));}private UserDetails buildUserDetails(User user) { List&lt;GrantedAuthority&gt; authorities = Collections.singletonList(new SimpleGrantedAuthority(user.getRole().name())); return new org.springframework.security.core.userdetails.User( user.getNickname(), user.getPassword(), authorities );}loadUserByUsername 메서드는 주어진 사용자명(username)을 기반으로 사용자 정보를 조회하는 역할을 한다.userRepository.findByNickname(username)를 호출하여 해당 사용자를 데이터베이스에서 조회한다.조회한 사용자를 Optional로 받아오고, map 함수를 사용하여 buildUserDetails 메서드를 호출하여 UserDetails 객체를 생성한다.buildUserDetails는 조회한 사용자 정보를 이용하여 UserDetails 인터페이스를 구현한 객체를 생성하는 역할을 한다.buildUserDetails는 사용자의 권한 정보를 GrantedAuthority 객체로 변환하여 권한 목록을 생성한다.SimpleGrantedAuthority 클래스를 사용하여 권한을 나타내고 사용자의 UserRole 값(enum)을 기반으로 권한 객체를 생성한다.생성된 UserDetails 객체에 사용자명, 비밀번호, 권한 목록을 설정하여 반환한다.JWT 토큰의 검증을 위한 목적으로 UserDetailServiceImpl를 사용해서JwtTokenProvider와 OAuth2SuccessHandler에서 사용자의 인증 정보를 가져오게 한다.권한 값 가져오기Spring Security에서는 hasAuthority() 메소드에 전달된 권한 값과 사용자의 권한 정보를 비교하여 접근 제어를 수행한다.따라서 사용자의 권한 정보를 제공하기 위해 UserDetails 인터페이스를 구현한 클래스에서getAuthorities() 메소드를 구현하여 해당 권한 정보를 반환하는 것이 필요하다.UserSecurity에서 권한을 지정하는 설정에서 hasAuthority()에 지정된 권한 값을 가져오기 위해 해당 코드를 작성한다.@Overridepublic Collection&lt;? extends GrantedAuthority&gt; getAuthorities() { List&lt;GrantedAuthority&gt; authorities = new ArrayList&lt;&gt;(); authorities.add(new SimpleGrantedAuthority(this.role.name())); return authorities;}Securityhttp.authorizeRequests() .antMatchers(VIEW_LIST).permitAll() .antMatchers(\"/admin/**\").hasAuthority(\"ADMIN\") .anyRequest().authenticated();어떤 url을 입력해도 VIEW_LIST가 아닌 이상 로그인 페이지로 넘어가게 하고 싶었고ADMIN이 아닌 이상 모두 USER일테니 admin 페이지만 ADMIN 권한을 체크하게 했다." }, { "title": "Java version 변경하기", "url": "/posts/Java-version-%EB%B3%80%EA%B2%BD%ED%95%98%EA%B8%B0/", "categories": "Project", "tags": "Java, error", "date": "2023-07-06 00:00:00 +0900", "snippet": "실습용으로 연습용 project를 하나 만들다가 build 과정에서 오류가 떴다.Spring Boot 3.0부터는 Java 17 이상만 지원하는데 11로 사용하려고 해서 오류가 뜬 것이었다.여기서는 java 17로 적용하는 과정을 작성했다.Java version 변경하기Download여기에서 java 17을 다운받는다.Setting시스템 변수에 있는 JAVA_HOME을 클릭한 후 편집 버튼을 누르고 설치한 jdk 17의 경로를 넣어주면 된다.[기존에 다른 버전의 JDK가 설치되어 있지 않을 경우에만 해당]Path 환경 변수에 JDK의 bin directory를 등록해주려면 Path의 편집을 누른다.JAVA_HOME 이라는 환경변수의 값을 사용하고자 할 때 %JAVA_HOME%과 같이 사용 한다.version 확인하기윈도우 + R 버튼을 눌러 cmd에서 java -version를 확인해 제대로 변경되었는지 확인한다.환경변수환경변수는 운영 체제에서 사용되는 변수로, 시스템의 동작에 영향을 미치는 값을 저장하는 데 사용된다.사용자 변수 : OS내의 사용자 별로 다르게 설정가능한 환경변수시스템 변수 : 시스템 전체에 모두 적용되는 환경변수Path“PATH”는 시스템 변수 중 하나로, 실행 가능한 프로그램의 경로를 저장하는 데 사용된다.운영 체제는 PATH 변수에 지정된 디렉토리를 검색하여 프로그램 실행 시 해당 디렉토리에서 프로그램을 찾을 수 있도록 도와준다.Java를 실행하기 위해서는 Java 실행 파일의 경로가 PATH에 포함되어야 한다.reference 환경변수 설정을 하는 이유 [Java] 자바 버전 변경하는 방법 ( JDK 8 -&gt; JDK 17) %JAVA_HOME% %가 의미하는것이 몬가요?" }, { "title": "랜덤 채팅 문제 해결하기", "url": "/posts/%EB%9E%9C%EB%8D%A4-%EC%B1%84%ED%8C%85-%EB%AC%B8%EC%A0%9C-%ED%95%B4%EA%B2%B0%ED%95%98%EA%B8%B0/", "categories": "Project, Chat", "tags": "spring, WebSocket, Chat", "date": "2023-06-26 00:00:00 +0900", "snippet": "랜덤 채팅 문제 해결문제랜덤 채팅을 시도를 하는 과정에서 접속자 수가 1명인 상태에서 20초가 초과되면 자동으로 접속이 끊겼다.그런데 랜덤 채팅을 test 하던 과정에서 20초 시간이 지나기 전 강제 종료 후 다시 랜덤 채팅을 시도할 경우기존 통신 시도와 새로 시작하는 것이 섞여서 띄워지게 되었다.그래서 client에서는 기존에 통신하던 것이 있으면 강제로 종료시키고 (.abort())랜덤 채팅방을 클릭시 status라는 변수에 random이라는 값을 저장하는데채팅방을 종료시키는 버튼을 누를 때 해당 상태가 random이라면 강제 종료하는 api를 작성했다.이렇게 코드를 작성하고 실행을 해봤는데 20초를 기다리지 않고 강제로 종료하면back에서는 websocket 세션이 닫힐 때 실행되는 메소드의 log가 찍혀있다.Log 분석랜덤채팅은 접속자가 2명 이상일 경우에만 채팅이 열린다.그러므로 접속자가 본인 한명인 경우 채팅이 시작되지 않고 종료된다.채팅이 시작되려면 client에서 socket 통신을 해야지 시작이 된다.그래서 채팅을 시작하기 전에 종료된 경우 client에서는 통신이 이루어지지 않은 것으로 간주해서채팅이 연결된 후 시작하는 로직을 진행하지 않는다.또한 back에서도 채팅이 시작될 때 찍히는 log가 없는 것을 확인했다.그런데 접속자를 기다리는 과정에서 갑자기 종료를 시켜버리면 채팅이 종료된 것도 아닌데@EventListener에서 채팅이 종료되는 메소드를 실행시킨다.코드를 뜯어가 보면서 문제를 해결해봤다.문제 해결하기코드 뜯어보기채팅은 subscribe를 해야 시작된다.randomOnConnected()에서 subscribe가 되고 randomOnConnected()는 2명 이상 접속되었을 때 실행된다.if(users&gt;1) { stompClient.connect({roomId : roomId}, randomOnConnected, onError);}@EventListenerpublic void handleWebSocketDisconnectListener(SessionDisconnectEvent event) { StompHeaderAccessor headerAccessor = StompHeaderAccessor.wrap(event.getMessage()); OAuth2AuthenticationToken token = (OAuth2AuthenticationToken) headerAccessor.getHeader(\"simpUser\");}handleWebSocketDisconnectListener 얘는 걍 메소드 명일 뿐이지파라미터로 주는 SessionDisconnectEvent가 의미있는 것이다.공식문서에서 SessionDisconnectEvent는 STOMP 세션이 종료되면 게시된다. DISCONNECT는 클라이언트에서 전송되었거나 WebSocket 세션이 닫힐 때 자동으로 생성될 수도 있다. 경우에 따라 이 이벤트는 세션당 두 번 이상 게시될 수 있다.여기 에서도 SessionDisconnectEvent란 WebSocket 하위 프로토콜로Simple Messaging Protocol(예: STOMP)을 사용하는 WebSocket 클라이언트의 세션이 닫힐 때 발생하는 이벤트라고 말한다.session이 열린 곳그렇다는 것은 세션이 있다라는 얘긴데 세션이 어디서 열려진 것일까?아래 2개 코드 중 첫번째는 자동으로 인식하고 아래는 Client에서 채팅을 연결할 때 실행되는 코드이다.이 두개의 메소드에 log를 찍어서 어느 곳이 실행되는지 체크해봤다.@EventListenerpublic void handleWebSocketConnectListener(SessionConnectedEvent event) {}@MessageMapping(\"every-chat/addUser\")public void everyChatAddUser(@Payload ChatMessage chatMessage, SimpMessageHeaderAccessor headerAccessor){}SessionConnectEvent : 브로커가 CONNECT에 대한 응답으로 STOMP CONNECTED 프레임을 보낸 직후 게시된다. 이 시점에서 STOMP 세션은 완전히 설정된 것으로 간주할 수 있다그런데 두개의 메소드(handleWebSocketConnectListener, everyChatAddUser) 모두 실행되지 않았다.그리고 log를 자세히 보니 chat이 시작된다는 log가 찍혀있었다.해당 log는 2명 이상이 되어야 찍히는 log인데 어째서인지 적혀있다.그리고 해당 메소드 시작 log는 찍혀있지 않다.코드로 살펴보면 아래와 같다.public void a(){ log.info(\"start\"); // 1번 if(users&lt;2){ }else{ log.info(\"[random chat] chat start !!\"); // 2번 }}1번 코드는 log가 찍혀있지 않는데 2번은 찍혀있는 것이다.그리고 해당 log가 찍히는 시점을 보니랜덤 채팅을 입장했을 때가 아닌 20초를 기다리지 않고 강제로 닫기 버튼을 눌렀을 때 해당 로그가 찍힌다.정상적으로 20초를 기다린 후에 닫기 버튼을 누르면 chat start도 띄워지지 않고 채팅이 시작되지도 않는다는 것을 알았다.원인 파악하기코드를 다시 살펴보니 chat이 시작된다는 log는 사용자가 2명 이상일 경우 실행되는 메소드인데나갔다 들어오면서 2명으로 인식이 되는 것 같았다. (waitingUsers)그래서 강제 종료하는 로직에 채팅이 종료되었을 때처럼 제거를 해주되 waitingUsers 접속중인 user를 제거해줬다. (connectedUsers 아님!!)그런데 제거가 되지 않았다. 안될 수 밖에 없던게 강제 종료하는 메소드에 이미 20초가 지나면 자동취소되는 로직을 재사용하고 있었다.그래서 이 문제는 아닌 것 같았다.waitingUsers를 출력해보니 같은 username이 2개 있었다.따라서 중복체크를 하면 되면 문제를 해결 할 수 있을 것 같았다.ChatRoomMap 에 equals() 메소드를 추가하여 nickname 속성으로 중복 체크했다.public class ChatRoomMap { private String nickname; @Override public boolean equals(Object o) { if (this == o) return true; if (!(o instanceof ChatRoomMap)) return false; ChatRoomMap other = (ChatRoomMap) o; return Objects.equals(nickname, other.nickname); } @Override public int hashCode() { return Objects.hash(nickname); }}equals() 메소드는 nickname 속성을 비교하여 두 ChatRoomMap 객체가 동일한지 확인한다.hashCode() 메소드는 equals() 메소드와 일관성을 유지하기 위해 nickname 속성을 기반으로 해시 값을 반환한다.이렇게 equals() 메소드와 hashCode() 메소드를 오버라이드한 후에는 waitingUsers 맵을 사용할 때 중복된 사용자를 방지할 수 있다.중복된 사용자가 waitingUsers 맵에 이미 존재하는지 확인한 후, 필요한 처리를 수행할 수 있다.이렇게 작성하고 실행하니 더 이상 disconnect가 실행되지 않았다.결론원인은 waitingUsers의 중복이었고 2명이상이 되면서 백에서 roomId를 생성해서client 쪽에서 통신을 시작하지는 않았지만 해당 msg를 보내는 통신을 시도하려고 하였고 disconnect를 감지했다.따라서 강제 종료하는 시점에 waitingUsers를 제거하고 waitingUsers를 담는 ChatRoomMap에서 중복체크를 함으로써 문제를 해결했다!" }, { "title": "Websocket + stomp + 보안 강화", "url": "/posts/WebSocket-+-Stomp-+-%EB%B3%B4%EC%95%88-%EA%B0%95%ED%99%94/", "categories": "Project, Chat", "tags": "spring, WebSocket, Chat, Security", "date": "2023-06-04 00:00:00 +0900", "snippet": "WebSocket + Stomp + 보안 강화하기WebSocket과 STOMP를 사용하여 실시간 통신을 구현하는 경우, 사용자 인증을 강화하여 보안성을 높이는 것이 중요하다.이를 위해 JWT(Json Web Token) 토큰을 사용하여 사용자 인증을 처리하는 방법을 작성했다.JWT(Json Web Token) 토큰JWT(Json Web Token)는 웹에서 사용자 인증 정보를 전송하기 위한 표준 방식이다.JWT는 Base64로 인코딩된 JSON 객체로 이루어져 있으며, 필요한 사용자 정보를 포함한다.JWT는 서버에서 발급하며, 시그니처를 포함하여 유효성 검증이 가능하다.Stomp를 사용하면 헤더에 token을 추가해 보안을 강화할 수 있다.WebSocket 연결 시에만 JWT 인증 검증을 수행하는 것은 일반적인 방법이다. (WebSocket의 특성 때문)WebSocket은 일반 HTTP 요청과 달리, 클라이언트와 서버 사이에 지속적인 연결을 유지하고 있기 때문에,한 번 연결이 되면 해당 연결에서 보내는 모든 메시지는 이전에 검증된 인증 정보를 계속 사용한다.CONNECT 요청에서 JWT 토큰을 검증하고, 유효한 토큰이면 User 객체를 추출하여 Authentication 객체를 생성한다.이후 WebSocket 연결에서는 해당 Authentication 정보를 사용하여 인증을 유지한다.그러나 채팅 중간에 가로채는 공격은 여전히 가능하기 때문에,WebSocket 메시지를 보내거나 받을 때마다 해당 사용자의 인증을 다시 검증하는 것이 좋다.이를 위해서는 WebSocket 요청을 처리하는 Controller에서 인증 검증을 수행하는 Interceptor나 Filter를 사용하면 된다.*일반적인 HTTP 요청의 경우에는 매 요청마다 JWT 인증 검증을 수행하는 것이 안전하다. 이때는 Spring Security의 FilterChain을 사용하여 JWT 인증 검증을 수행할 수 있다. FilterChain을 사용하면 요청이 처리되기 전에 모든 요청에 대해 JWT 인증 검증을 수행하므로, 누군가 요청을 가로채더라도 검증되지 않은 요청은 거절된다.JwtTokenProvider를 사용한 사용자 인증JWT 인증 처리를 위해 JwtTokenProvider 클래스를 작성하여 토큰 검증과 사용자 정보 추출을 담당한다.사용자 인증은 보안적인 측면에서 매우 중요한 요소 중 하나이다.유저의 아이디나 이메일과 같은 정보보다는 유저의 실제 인증을 확인하는 방식을 사용하는 것이 더 안전하다.따라서 JWT (Json Web Token) 토큰을 사용하여 사용자 인증을 확인하는 방식이 좋다.JWT 토큰은 유효성 검증을 위한 시그니처가 포함되어 있어서, 시그니처를 확인하여 토큰의 유효성을 검증할 수 있다.시그니처란?관련 정리글JWT 토큰은 일련의 문자열로 이루어져 있으며, 헤더, 페이로드, 시그니처로 구성되어 있다.시그니처는 토큰의 유효성을 검증하기 위한 값으로,토큰의 헤더와 페이로드를 조합한 후, 이를 서버에서 미리 정해진 비밀키를 이용하여 해시한 값이다.이렇게 생성된 시그니처는 토큰의 끝에 추가되어 전체 토큰이 완성된다.서버에서는 이 시그니처를 이용하여 토큰의 유효성을 검증한다.만약 시그니처를 변경하거나 비밀키가 노출되면, 해당 토큰은 무효화되어야 한다.따라서 시그니처는 JWT 토큰의 중요한 구성 요소 중 하나이며, 토큰의 무결성을 보장하기 위해 반드시 비밀키를 안전하게 관리해야 한다.이 방법은 JWT 토큰을 발급한 인증서버에서 시그니처를 생성하고 검증할 수 있도록 설계되어 있다.따라서, JWT 토큰을 활용하여 사용자 인증을 확인하는 것이 안전한 방법이다.아래는 JWT 토큰 검증과 사용자 정보 가져오기를 위한 메서드이다.public boolean validateToken(String token) { try { Jwts.parser().setSigningKey(secretKey).parseClaimsJws(token); return true; } catch (SignatureException ex) { logger.error(\"Invalid JWT signature\"); } catch (MalformedJwtException ex) { logger.error(\"Invalid JWT token\"); } catch (ExpiredJwtException ex) { logger.error(\"Expired JWT token\"); } catch (UnsupportedJwtException ex) { logger.error(\"Unsupported JWT token\"); } catch (IllegalArgumentException ex) { logger.error(\"JWT claims string is empty.\"); } return false;}public User getUserFromToken(String token) { Claims claims = Jwts.parser().setSigningKey(secretKey).parseClaimsJws(token).getBody(); String nickname = claims.getSubject(); String role = claims.get(\"roles\", String.class); UserRole userRole = UserRole.of(role); return User.builder() .nickname(nickname) .role(userRole) .build();}JwtTokenProvider 클래스에서는 토큰 검증과 사용자 정보 가져오기를 위한 메서드가 제공된다.이 메서드들을 사용하여 WebSocket 요청에서 인증 처리를 할 수 있다.validateToken() 메서드는 입력받은 JWT 토큰의 유효성을 검증하고,getUserFromToken() 메서드는 JWT 토큰에서 추출한 사용자 정보를 반환한다.secretKey는 JWT를 생성하고 검증할 때 사용하는 시크릿 키다.이 값은 서버에서만 알고 있어야 하며, 노출되지 않도록 보안에 유의해야 한다.WebSocket 연결을 요청하는 클라이언트는 JWT 토큰을 Authorization 헤더에 담아 요청한다.이 JWT 토큰을 검증하고, 인증된 사용자의 정보를 WebSocket 세션에 추가하는 과정이 필요하다.이를 위해 ChannelInterceptor를 사용할 수 있다.JWT 토큰을 이용한 인증 처리 @RequestHeader(\"Authorization\")는 채팅 인증이 아닌 HTTP 인증에서 사용할 수 있다.JwtInterceptor 와 ChannelInterceptorJwtInterceptor는 인증이 필요한 모든 요청에 대해 인증을 처리한다.@RequestHeader(\"Authorization\")을 추가하지 않고도 JwtInterceptor를 사용하면 모든 컨트롤러에서 인증 처리를 수행한다.ChannelInterceptor는 특정 채널에 대해 처리를 수행한다.이를 이용하면 특정 컨트롤러에서 처리를 할 수 있다.예를 들어, WebSocket 연결에서 ChannelInterceptor를 사용하면 특정 채널에서 발생하는 메시지를 가로채고 처리할 수 있다.따라서, JwtInterceptor와 ChannelInterceptor는 서로 다른 기능을 가지고 있으며, 사용 목적에 따라 선택하여 사용해야 한다.1. JwtInterceptor를 이용한 JWT 토큰 검사Spring WebSocket에서 JwtInterceptor를 이용하면 WebSocket 요청 시에 JWT 토큰을 검사할 수 있다.JwtInterceptor는 WebSocket 요청이 처리되기 전에 요청의 header에서 JWT 토큰 값을 추출하고,이를 검사하여 인증 처리를 수행한다.JwtInterceptor를 사용하려면 다음과 같이 구현할 수 있다.@Configuration@EnableWebSocketMessageBrokerpublic class WebSocketConfig implements WebSocketMessageBrokerConfigurer { @Autowired private JwtTokenProvider jwtTokenProvider; @Override public void configureClientInboundChannel(ChannelRegistration registration) { registration.interceptors(new JwtInterceptor(jwtTokenProvider)); } //... 생략 ...}위 코드에서 configureClientInboundChannel() 메소드에서 JwtInterceptor를 적용하고 있다.JwtInterceptor는 JwtTokenProvider를 이용하여 JWT 토큰을 검사하고, 인증 정보를 얻어와 처리한다.JwtInterceptor 클래스는 다음과 같이 구현할 수 있다.public class JwtInterceptor implements ChannelInterceptor { private JwtTokenProvider jwtTokenProvider; public JwtInterceptor(JwtTokenProvider jwtTokenProvider) { this.jwtTokenProvider = jwtTokenProvider; } @Override public Message&lt;?&gt; preSend(Message&lt;?&gt; message, MessageChannel channel) throws AuthenticationException { StompHeaderAccessor accessor = MessageHeaderAccessor.getAccessor(message, StompHeaderAccessor.class); if (StompCommand.CONNECT.equals(accessor.getCommand())) { String token = accessor.getFirstNativeHeader(\"Authorization\"); if (token == null || !token.startsWith(\"Bearer \")) { throw new AuthenticationException(\"No JWT token found in request headers\"); } String jwtToken = token.substring(7); if (!jwtTokenProvider.validateToken(jwtToken)) { throw new AuthenticationException(\"JWT token is invalid\"); } Claims claims = jwtTokenProvider.getClaimsFromToken(jwtToken); accessor.setUser(new User(claims.getSubject(), true, new ArrayList&lt;&gt;())); } return message; }}2. ChannelInterceptor를 이용한 JWT 토큰 검증Spring Boot를 사용하여 RESTful API를 개발하다보면, 인증 처리를 해야하는 경우가 있다.이때, JWT(JSON Web Token)은 많이 사용되는 인증 방식 중 하나이다.Spring Security에서는 JWT 인증 처리를 위한 JwtInterceptor를 제공하고 있다.하지만 JwtInterceptor를 사용하는 경우, 모든 컨트롤러에서 인증을 처리해야 하기 때문에 코드의 복잡도가 증가하게 된다.이러한 문제점을 해결하기 위해 Spring에서는 ChannelInterceptor를 제공하고 있다.ChannelInterceptor를 사용하면 특정 컨트롤러나 API에 대해서만 인증 처리를 할 수 있기 때문에 코드의 복잡도를 줄일 수 있다.ChannelInterceptor는 STOMP 프로토콜에서 사용되며, WebSocket 연결 및 메시지 전송/수신 이벤트를 가로채고,메시지를 전송하기 전에 처리할 수 있는 기능을 제공한다.StompHandlerSpring Framework에서 WebSocket을 사용할 때, StompHandler 클래스를 사용하여 Header에 포함된 인증 정보를 검증하는 방법WebSocket 연결 시 JWT 토큰을 확인하기 위해서는, ChannelInterceptorAdapter 내에서 JWT 토큰을 확인하는 코드를 작성해야 한다.이 코드는 ChannelInterceptorAdapter의 preSend() 메서드에서 처리할 수 있으며, 이 메서드는 클라이언트로부터 메시지가 전송되기 전에 호출된다.이 때 JWT 토큰을 확인하여 인증된 사용자인지 확인하고, 필요한 처리를 수행하면 된다.변경 전public class StompHandler implements ChannelInterceptor { private final JwtTokenProvider jwtTokenProvider; @Override public Message&lt;?&gt; preSend(Message&lt;?&gt; message, MessageChannel channel) { StompHeaderAccessor headerAccessor = StompHeaderAccessor.wrap(message); if (StompCommand.CONNECT.equals(headerAccessor.getCommand())) { jwtTokenProvider.validateToken(headerAccessor.getFirstNativeHeader(\"Authorization\")); } return message; }}변경 후기존 코드에서는 StompHandler 클래스에서 JwtTokenProvider 클래스의 validateToken() 메서드를 호출하여 인증 정보를 검증했지만,변경 후에 헤더에서 AccessToken을 추출하고, 해당 토큰을 사용하여 사용자 정보를 가져오는 작업을 수행한다.또, 예외 처리도 변경되었는데 이전 코드에서는 JwtTokenProvider 클래스에서 InvalidTokenException을 던졌지만변경된 코드에서는 MissingAuthorizationException 또는 BadCredentialsException을 던져 예외 처리를 하게 된다.이러한 변경 사항을 적용한 StompHandler 클래스의 코드는 아래와 같다.@RequiredArgsConstructor@Component@Slf4jpublic class StompHandler implements ChannelInterceptor { // client가 connect할 떄 header로 보낸 Authorization에 담긴 jwt Token을 검증 private final JwtTokenProvider jwtTokenProvider; @Override public Message&lt;?&gt; preSend(Message&lt;?&gt; message, MessageChannel channel) { StompHeaderAccessor headerAccessor = StompHeaderAccessor.wrap(message); if (StompCommand.CONNECT.equals(headerAccessor.getCommand())) { log.info(\"websocket 연결 - jwt token 검증\"); String accessToken = headerAccessor.getFirstNativeHeader(\"Authorization\"); UserDetails userDetails = userDetailsService.loadUserByUsername(jwtTokenProvider.getNickname(accessToken)); if (userDetails != null) { log.info(\"[preSend] 인증 확인\"); } else { throw new BadCredentialsException(\"Invalid JWT token\"); } } return message; }}이제 StompHandler 클래스를 사용하여 WebSocket을 보다 안전하게 사용할 수 있다.function connect() { let nickname = localStorage.getItem('wschat.sender'); let token = localStorage.getItem('token'); if (nickname) { let socket = new SockJS('/ws'); stompClient = Stomp.over(socket); stompClient.connect({Authorization: token}, onConnected, onError); }}WebSocket API에서 JWT 인증 구현하기Spring에서 제공하는 ChannelInterceptor는 WebSocket을 통해 들어오는 요청을 인터셉트하고 처리하는 역할을 한다.이를 이용하여 WebSocket API를 개발할 때, 인증 처리와 관련된 기능을 구현할 수 있다.이 경우에는 보통 WebSocket의 메시지 헤더(StompHeaderAccessor)를 활용하여 인증 정보를 전달다.그리고 이러한 인증 정보를 검증하는 작업은 ChannelInterceptor를 활용하여 수행할 수 있다.@MessageMapping(\"/chat/addUser\")public void addUser(@Payload ChatMessage chatMessage, SimpMessageHeaderAccessor headerAccessor) { String token = headerAccessor.getFirstNativeHeader(\"Authorization\"); String nickname = jwtTokenProvider.getNickname(token); chatMessage.setSender(nickname); chatMessage.setType(ChatMessage.MessageType.JOIN); chatService.connectUser(\"Connect\", chatMessage.getRoomId(), chatMessage); template.convertAndSend(\"/topic/public/\" + chatMessage.getRoomId(), chatMessage);}@Header 어노테이션은 STOMP 프로토콜에서 사용되는 어노테이션으로,STOMP 프로토콜 메시지의 header에서 값을 추출하여 메소드의 인자로 전달하는 역할을 한다.@Payload 어노테이션은 WebSocket API의 메시지 payload를 받아들인다는 것을 나타내는 어노테이션이다.이를 이용하여 WebSocket API의 메소드에 @Header(\"Authorization\") 어노테이션을 사용하여HTTP 요청의 Authorization 헤더에서 JWT 토큰 값을 가져올 수 있다.그리고 이 값을 ChannelInterceptor를 사용하여 검증하고, 적절한 인증 정보를 얻어와서 채팅 메시지를 처리하면 된다.@MessageMapping(\"/chat/addUser\")public void addUser(@Payload ChatMessage chatMessage, @Header(\"Authorization\") String token) { String nickname = jwtTokenProvider.getNickname(token); chatMessage.setSender(nickname); chatMessage.setType(ChatMessage.MessageType.JOIN); chatService.connectUser(\"Connect\", chatMessage.getRoomId(), chatMessage); template.convertAndSend(\"/topic/public/\" + chatMessage.getRoomId(), chatMessage);}@Payload 어노테이션은 ChatMessage 클래스의 인스턴스를 메시지 payload로 받아들인다는 것을 나타내는 어노테이션이다.따라서 ChatMessage 클래스에는 token 필드가 없으므로,해당 메소드에서는 @Header(\"Authorization\") 어노테이션을 이용하여 HTTP 요청의 Authorization 헤더에서 JWT 토큰 값을 가져올 수 있다.그리고 이 값을 ChannelInterceptor를 사용하여 검증하고, 적절한 인증 정보를 얻어와서 채팅 메시지를 처리하면 된다.JwtInterceptor와 ChannelInterceptor를 사용하는 방법 모두 HTTP 요청의 헤더에 담긴 토큰 값을 가져올 수 있다는 공통점이 있다.이렇게 가져온 토큰 값을 두 인터셉터에서 검사하여 인증 처리를 수행하고, 필요한 정보를 추출하여 해당하는 기능을 수행할 수 있다.하지만 두 인터셉터는 기능적인 측면에서 차이가 있다.JwtInterceptor는 JWT 토큰 검증을 수행하고, 토큰이 유효한지 검사한 후 토큰 안에 포함된 정보를 추출하는 역할을 한다.ChannelInterceptor는 WebSocket 연결에서 사용하는 헤더 정보를 추출하여 검증하는 역할을 한다.따라서, JwtInterceptor는 RESTful API를 사용하는 서버에서 주로 사용되며,ChannelInterceptor는 WebSocket 연결에서 사용되는 경우가 많다.두 인터셉터 중에서 선택하는 것은 개발자의 취향이나 프로젝트 구조에 따라 다르다.RESTful API와 WebSocket을 함께 사용하는 경우라면 두 인터셉터를 모두 사용할 수 있다.하지만 두 인터셉터를 모두 사용하는 경우에는 토큰 검증과 관련된 코드를 중복해서 작성해야 하기 때문에유지보수 측면에서 불편함이 있을 수 있다.따라서, 두 인터셉터를 모두 사용하는 경우라면, 공통으로 사용되는 코드를 별도의 클래스로 분리하여 작성하고,이를 두 인터셉터에서 참조하도록 구현하는 것이 좋다.이렇게 구현하면 코드의 중복을 피할 수 있으며, 유지보수성이 높은 구조를 만들 수 있다.참고WebSocket 프로토콜은 서버와 클라이언트 사이의 양방향 통신을 제공하므로, 실시간으로 데이터를 주고받을 수 있다.HTTP 프로토콜은 클라이언트에서 서버로 요청을 보내고, 서버에서 클라이언트로 응답을 보내는 단방향 통신 방식이다.WebSocket과 HTTP는 서로 다른 프로토콜이므로, 서로 다른 방식으로 통신한다.WebSocket의 경우 HTTP 프로토콜과는 다른 프로토콜을 사용하기 때문에,HTTP 요청에서 사용하는 doFilter와 WebSocket에서 사용하는 ChannelInterceptorAdapter는 서로 다른 방식으로 작동한다.따라서, 만약 HTTP AJAX 호출에서 사용하는 doFilter로 JWT 토큰을 확인하도록 구현했다면해당 코드는 WebSocket의 ChannelInterceptorAdapter와는 관련이 없다.WebSocket의 ChannelInterceptorAdapter는 HTTP 프로토콜이 아닌 다른 프로토콜을 사용하기 때문에이 ChannelInterceptorAdapter를 사용하여 WebSocket 연결 시 JWT 토큰을 확인하도록 구현해야 한다.따라서, WebSocket 연결 시 JWT 토큰을 확인하기 위해서는ChannelInterceptorAdapter 내에서 JWT 토큰을 확인하는 코드를 작성해야 한다.이 코드는 ChannelInterceptorAdapter의 preSend 메서드에서 처리할 수 있으며,이 메서드는 클라이언트로부터 메시지가 전송되기 전에 호출된다.이 때 JWT 토큰을 확인하여 인증된 사용자인지 확인하고, 필요한 처리를 수행하면 된다." }, { "title": "Nginx", "url": "/posts/NGINX/", "categories": "Study", "tags": "study, summary, Docker, Nginx", "date": "2023-05-23 00:00:00 +0900", "snippet": "NGINX로 Front 배포하기EC2 인스턴스이 전에 언급했던 내용이므로 요약sudo ssh -i {keypair}.pem ubuntu@{ec2 ipv4 주소}docker 설치sudo docker login -u {github username} ghcr.iosudo docker pull ghcr.io/haedal/cicd:latestsudo docker imagessudo docker run --name cicd -p 8080:8080 -e hello.world=\"hello world\" -d ghcr.io/haedal/cicd:latestNGINX 설치 및 연습용 HTML 페이지 띄우기installInstalling NGINX Open Sourcesudo apt-get updatesudo apt-get install nginxsudo nginx -v연습용 page 띄워보기curl -X GET http://localhostcd /root 폴더로 이동cd var/www/htmlcat index.nginx-debian.html변경해보기sudo nano index.nginx-debian.htmlcat index.nginx-debian.htmlhtml 새로 생성sudo nano home.htmlsudo cat home.html서버에서 작성한 rest api 주소를 넣어준다.&lt;html&gt;&lt;head&gt;&lt;title&gt;HELLO-WORLD&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h2&gt; HELLO&lt;/h2&gt;&lt;h5&gt;WORLDd&lt;/h5&gt;&lt;script&gt;fetch('http://{ec2 ipv4 주소}:8080/hello') .then(res =&gt; { if (res.ok) { return res.json(); } else { throw new Error('Response was not OK.'); } }) .then(data =&gt; { document.write(data); }) .catch(error =&gt; { console.error(error); });&lt;/script&gt;&lt;/body&gt;&lt;/html&gt;*nginx.conf 파일은 /etc/nginx 폴더 안에 있음*home.html은 /var/www/html 폴더 안에 있음nginx configcd /cd etc/nginxlsnginx.conf, conf.d : 기본 설정 파일nginx.conf는 NGINX의 주요 설정 파일이며, conf.d 디렉토리는 추가 설정 파일들을 포함하는 디렉토리nginx config 설정location 블록과 proxy_pass 지시어를 사용하여 요청이 특정 경로로 들어오면 해당 경로에 대한 프록시 전달을 설정할 수 있다.location /api { proxy_pass http://backend_server;}위의 설정은 /api 경로로 들어오는 요청을 http://backend_server로 프록시 전달한다.예를 들어, /api/users로 요청이 들어오면, NGINX는 http://backend_server/users라는 프록시 서버로 전달한다.이를 통해 NGINX는 BE 서버의 경로 구조를 Client에 노출시키지 않고, 요청을 전달할 수 있다.따라서, location 블록과 proxy_pass 지시어를 사용하여 경로를 지정하고 프록시 전달을 구성할 수 있다.이를 통해 특정 경로의 요청을 다른 서버로 전달하거나 경로를 변경하여 요청을 처리할 수 있다.실제로 작성을 해본다.CORS 문제 해결을 위한 NGINX 설정CORS (Cross-Origin Resource Sharing)는 웹 애플리케이션에서 도메인 간의 리소스 공유를 제한하는 보안 메커니즘이다.서로 다른 도메인에서 리소스를 요청하거나 전달할 때, 브라우저는 CORS 정책을 적용하여 요청의 유효성을 확인한다.이로 인해 동일 출처 정책(Same-Origin Policy)을 위반하는 요청은 브라우저에서 차단될 수 있다.sudo nano nginx.confsudo cat nginx.confNGINX는 Client의 요청을 받아 Proxy Server로 전달하는 역할을 수행한다.FE의 80 포트로 들어오는 요청을 BE의 8080 포트로 전달하여 CORS 문제를 해결한다.이를 위해 NGINX의 설정 파일에 다음과 같이 proxy 설정을 추가한다.http{ server{ listen 80; server_name {ec2 ipv4 주소}; location /api/ { proxy_pass http://{docker gateway 주소}:8080/; } } ... ☑️ NGINX의 proxy_pass 설정은 Client와 BE 서버 간의 통신을 중계하는 역할☑️ BE 서버에서는 해당 경로에 대한 요청을 처리하여 Client에게 응답을 전달☑️ docker gateway 주소 : 172.17.0.1, docker ip 주소 : 172.17.0.2 sudo docker inspect {container name}Configuring NGINX and NGINX Plus as a Web Server위 사진처럼 location /api/ → /를 양 옆에 작성해준다.예시proxy_pass를 http://domain.com:8080;로 설정Frontend (FE)는 도메인 domain.com에서 호스팅되며, 포트 80을 사용한다.Backend (BE)는 도메인 domain.com에서 호스팅되며, 포트 8080을 사용한다./api로 들어오는 요청은 http://{docker gateway 주소}:8080/로 전달된다.Client가 http://domain.com:8080/api/hello로 요청을 보내면NGINX가 해당 요청을 proxy하여 BE의 도메인인 http://domain.com:8080으로 전달한다.BE 서버에서 /hello에 해당하는 controller를 찾아서 처리한다.→ /api/hello로 들어오는 요청은 BE 서버에서는 /hello에 해당하는 Controller로 라우팅되어 처리된다.Client는 NGINX를 경유하여 응답을 받지만, 실제로 처리되는 서버는 BE다.→ 프록시를 통해 요청이 전달되고 Backend에서는 적절한 Controller로 라우팅되므로,CORS(Cross-Origin Resource Sharing) 문제를 해결할 수 있다.☑️ proxy : client와 server 사이에서 중계 역할을 수행하는 server☑️ 라우팅 : client가 보낸 요청이 BE 서버에서 적절한 handler or Controller로 전달하는 과정Reverse Proxyport는 서비스가 동작하는 특정 번호로, 웹 서버는 일반적으로 80 포트를 사용하여 Client의 요청을 처리한다.그러나 외부 서비스로 요청을 전달해야 할 때 port 중복 문제가 발생할 수 있다. 이때 Reverse Proxy 설정이 유용하다.Reverse Proxy는 Client의 요청을 받아 다른 서버로 전달하고, Server로부터 받은 응답을 Client에게 반환하는 방식이다.Client는 원래의 서버에 직접 요청하는 것처럼 Reverse Proxy Server를 통해 요청을 보내지만,실제로는 Reverse Proxy가 요청을 End Server로 전달한다.☑️ Reverse Proxy : Client로부터의 요청을 받아 해당 요청을 다른 서버로 전달하는 방식☑️ Reverse Proxy Server : Reverse Proxy를 실행하는 서버Client의 요청을 받아서 End Server로 전달하고 End Server로부터 받은 응답을 Client에게 반환☑️ End Server : Client로부터의 요청을 실제로 처리하고 응답을 생성하는 Server예를 들어, Nginx는 80 포트에서 동작하는 웹 서버이고 BE 서버는 8080 포트에서 동작한다.Client는 80 포트로 Nginx에 요청을 보내면, Nginx가 이를 받아 BE 서버로 전달한다.BE 서버는 요청을 처리하고 응답을 Nginx로 반환한 다음, Nginx는 Client에게 응답을 전달한다.이렇게 보내는 포트(80)와 받는 포트(8080)가 다르기 때문에 Reverse Proxy 설정을 사용하여 요청을 올바르게 전달할 수 있다.Nginx에서는 proxy_pass 지시문을 사용하여 Reverse Proxy 설정을 구성할 수 있다.이를 통해 Client로부터의 요청을 받은 Nginx는 해당 요청을 백엔드 서버로 전달하고,Server로부터 받은 응답을 Client에게 반환한다.이렇게 port가 다른 상황에서 Reverse Proxy 설정을 통해 Client는 BE 서버의 존재를 알 필요가 없고Nginx를 통해 원할한 통신을 할 수 있다.Reverse Proxy를 사용하는 이유는 로드 밸런싱을 위해 여러 개의 백엔드 서버에 요청을 분산할 수 있으며,보안을 강화하기 위해 백엔드 서버를 직접 노출하지 않을 수 있다.Reverse Proxy 설정은 포트 연결을 간편하게 처리하며, 유연하고 안전한 웹 서비스 구축을 돕는다.Docker gateway웹 사이트에 접속할 때 대부분은 도메인 주소만 입력하면 되는 경우가 많다.하지만 특정 서비스나 애플리케이션에 접근하기 위해서는 포트 번호를 입력해야 하는 경우도 있다.이때 포트 번호까지 입력하는 것은 사용자 경험에 좋지 않을 수 있다.예를 들어, 네이버에 접속하기 위해 www.naver.com이라고 입력하면 될 것을www.naver.com:8080과 같이 포트 번호를 입력해야 한다면 조금 이상하게 느껴질 것이다.이러한 상황에서 우리를 도와주는 역할을 하는 것이 Docker Gateway(게이트웨이)다.Docker Gateway는 Docker 네트워크에 속한 컨테이너 간 통신을 가능하게 하는 네트워크 요소다.각각의 Docker 컨테이너는 고유한 IP 주소를 가지고 있지만, 외부로부터 접근하려면 해당 컨테이너의 IP 주소와 포트 번호를 알아야 한다.이는 사용자 경험을 해치는 요소가 될 수 있다.따라서 Docker 게이트웨이를 사용하여 외부에서 접근 가능한 포트 번호와 컨테이너 내부의 포트 번호를 매핑시킬 수 있다.이렇게 하면 사용자는 Gateway 주소를 통해 서비스에 접근할 수 있고, 실제로 해당 서비스는 Docker 컨테이너 내의 포트 번호로 전달된다.Gateway를 사용함으로써 포트 번호를 외부로 노출시키지 않고도 서비스에 접근할 수 있으며, Docker 컨테이너의 내부 구조를 숨길 수 있다.Gateway는 사용자가 도메인 주소만 입력하면 서비스의 실제 위치인 포트 번호까지 자동으로 연결해준다.예를 들어, api.naver.com이라는 도메인 주소를 입력하면 게이트웨이는 이를 localhost:8080으로 자동으로 연결해준다.이렇게 Gateway를 사용하면 사용자는 편리하게 서비스에 접근할 수 있고서비스 제공자는 Gateway를 통해 포트 번호를 노출시키지 않고도 서비스를 제공할 수 있다.사용자는 단순히 도메인 주소를 입력하여 서비스에 접근할 수 있으며, 게이트웨이가 포트 번호를 자동으로 연결해준다.Nginx 서버의 설정을 다시 불러와서 변경 사항을 적용sudo service nginx reloadNginx의 설정을 수정한 후에는 변경 사항을 적용하기 위해 위 명령어를 실행해 서버의 중단없이 설정 변경이 반영된다.{ec2 ipv4 주소}/api/hello로 입력하면 기존의 rest api에서 뜨던 coco가 제대로 뜬다.→ 기존에 세팅되던 project server는 문제 없이 띄워진다.{ec2 ipv4 주소}/home.html로 띄우면 404 Not Found 에러가 뜬다.→ 해당 설정에서 /api 주소로 가라는 설정은 있지만 그 외의 설정을 해두지 않아서 에러가 뜬 것 같다.nginx.conf 수정http{ server{ listen 80; server_name {ec2 ipv4 주소}; location / { root /var/www/html; } location /api/ { proxy_pass http://{docker gateway 주소}:8080/; } } ...정적 파일들은 그대로 전달해주면 되므로 location / 처럼 작성하면 된다.☑️ project에 적용할 때는 js의 url만 앞에 /api를 붙여주면 된다.home.html에서 “api”를 추가한다.fetch('http://{ec2 ipv4 주소}/api/hello')정리NGINX와 Spring Boot를 사용하여 FE와 BE를 분리NGINX는 FE 애플리케이션인 정적인 파일 (HTML, CSS, JavaScript)을 제공하는 역할을 담당한다.주로 HTML, CSS, JavaScript를 사용하여 웹 페이지를 구성하고, 사용자와 상호작용을 가능하게 한다.NGINX는 웹 서버 소프트웨어로, 정적인 파일들을 제공하는 데에 특화되어 있다.FE에서 사용되는 HTML, CSS, JavaScript 파일들은 NGINX 서버에 배포되어 사용자에게 전달된다.BE는 FE와 상호작용하여 데이터를 처리하고, 동적인 기능을 제공한다.FE에서 필요한 데이터를 요청하면 BE는 해당 요청을 처리하고 필요한 데이터를 가져와서 JSON 형식으로 FE에게 반환한다.FE는 NGINX 서버에서 정적인 파일을 받고, 사용자의 요청에 따라 동적인 데이터를 BE에 요청한다.이때 FE는 HTTP 통신을 통해 백엔드에 요청을 보내고, JSON 형식으로 데이터를 받는다.BE는 받은 요청을 처리하고, 필요한 데이터를 JSON 형식으로 FE에게 반환다.실제 서비스에서 DTO(Data Transfer Object)를 사용하여 데이터를 정의하고 전달한다.FE는 받은 데이터를 가공하고,필요한 부분을 동적으로 렌더링(데이터와 템플릿을 결합하여 최종적으로 사용자에게 보여지는 결과물을 생성하는 과정)하여사용자에게 보여준다.NGINX를 통한 FE와 BE의 분리NGINX의 설정 파일에서 FE와 BE의 경로를 설정하고,FE에 대한 요청은 NGINX에서 처리하고, BE에 대한 요청은 proxy로 전달하도록 설정한다.http{ server{ listen 80; server_name {ec2 ipv4 주소}; location / { root /var/www/html; } location /api/ { proxy_pass http://{docker gateway 주소}:8080/; } }FE에 대한 요청은 / 경로로 오는 요청을 /var/www/html 디렉토리에서 처리하도록 설정되어 있다.반면 BE에 대한 요청은 /api/ 경로로 오는 요청을백엔드의 Docker Gateway 주소와 port 8080으로 proxy로 전달하도록 설정되어 있다.이렇게 설정하면 FE는 NGINX 서버에서 정적인 파일을 받고, BE에 필요한 데이터를 요청한다.BE는 요청을 처리하고 데이터를 반환하면, FE는 받은 데이터를 가공하여 사용자에게 동적인 내용을 렌더링하여 보여준다.EC2 인스턴스 내부에는 Docker와 Nginx가 설치되어 있으며,Docker 내부에는 기본적으로 제공되는 ‘bridge’라는 네트워크가 있다.‘bridge’ 네트워크의 주소는 172.17.0.1이며, 해당 네트워크에는 Spring Boot와 MySQL이 실행되고 있다.Spring Boot는 172.17.0.2, MySQL은 172.17.0.3의 IP 주소를 할당받아 서로 연결되어 있다.Nginx는 Docker 내부의 Spring Boot에 직접 연결할 수 없기 때문에(주소를 알 수 없음) Docker의 ‘bridge’를 활용하여 연결한다.따라서, Nginx 설정에서는 localhost 대신 ‘bridge’의 주소를 사용하여 연결을 설정한다.location /api/ { proxy_pass http://{docker gateway 주소}:8080/;}bridge는 기본적으로 제공되는 network다.Docker로 연결했기 때문에 위와 같은 주소로 연결을 했을 뿐 naver 주소를 쓰면 naver로 연결된다.MSA를 적용해서 Docker container를 2개로 분리하고 port를 8080, 8081로 만들면 network를 새로 생성해야한다.Docker networkEC2 보안 규칙에서 8080 포트를 지우고 80 포트만 남겨도 되는 이유는 proxy_pass 때문이다.Nginx 서버는 Client의 요청을 받아들이는 포트로 80 포트를 사용한다.80 포트로 들어온 요청을 다른 포트로 전달하기 위해 사용하는 설정이 reverse proxy 설정인 proxy_pass이다.8080 포트는 필요한 경우에만 proxy_pass 설정을 통해 사용하면 된다.Nginx 설정에서는 /api/로 시작하는 요청은 백엔드(Back-End) 서버로 전달되고,그 외의 요청은 정적인 콘텐츠로 처리된다.이를 통해 백엔드와 프론트엔드(Back-End와 Front-End) 간의 역할을 분리할 수 있었다.백엔드는 REST API를 통해 데이터를 처리하고, 프론트엔드는 정적인 콘텐츠를 제공하며 동적인 사용자 인터페이스를 구성할 수 있다.이렇게 역할을 분리함으로써 시스템을 확장하고 유연하게 개발할 수 있으며, 보안과 성능도 개선할 수 있다.front 배포할 때 html, css, js만 넣어주면 된다.폴더를 하나 만들어서 git clone 해주면 끝!Docker에서 사용 가능한 네트워크sudo docker network ls" }, { "title": "배포 자동화", "url": "/posts/%EB%B0%B0%ED%8F%AC-%EC%9E%90%EB%8F%99%ED%99%94/", "categories": "Study, Cloud", "tags": "study, summary, Docker, AWS, EC2, CI/CD, Git Actions", "date": "2023-05-22 00:00:00 +0900", "snippet": "배포 자동화안쓰는 이미지를 지우는 명령어sudo docker image prune -a확인창 띄우지 않게 하기sudo docker image prune -afscript 파일 만들기touch deploy.shtouch : 파일을 생성하는 명령어script 작성@RequiredArgsConstructor@RestControllerpublic class PracController { @Value(\"${hello.world}\") private String helloWorld; @GetMapping(\"/hello\") public String getHelloWorld(){ return helloWorld; }}환경변수로 HELLO WORLD를 작성했기 때문에 script에도 환경변수를 작성해준다.-e로 환경변수를 붙여주면 된다.nano deploy.shCONTAINER_NAME=cicd-containersudo docker pull ghcr.io/haedal/cicd:latestsudo docker rm -f $CONTAINER_NAMEsudo docker run -p 8080:8080 --name $CONTAINER_NAME \\-e HELLO_WORLD=\"HELLO WORLD\" \\-d ghcr.io/haedal-uni/cicd:latestsudo docker image prune -af☑️ 스크립트를 작성할 때 공백이 없게 작성해야한다.sudo docker rm -f $CONTAINER_NAME → 기존에 실행하던 container가 있으면 제거하고 다시 실행시키기 위해 작성-f : container를 삭제하기 전에 확인 프롬프트를 표시하지 않고 바로 삭제(강제 종료)-p: container와 host간의 port를 연결하는 옵션([호스트 포트]:[컨테이너 포트])-d를 넣으면 백그라운드로 돌리기 때문에 내가 console을 닫아도 안꺼진다.-e or --env 옵션을 넣어주면 환경변수로 설정된다.\\를 넣고 엔터를 친후 작성하게 되면 한줄로 쓴 것으로 인식한다. (가독성을 높이기 위해 사용)script 실행sh deploy.sh자동으로 배포시키기push mainname: Run Gradleon: workflow_dispatch: push: branches: - mainmain으로 push할 때 자동으로 돌아가게 작성했다.GitHub Actions에서 원격 SSH 명령 실행SSH Remote Commandsname: remote ssh commandon: [push]jobs: build: name: Build runs-on: ubuntu-latest steps: - name: executing remote ssh commands using password uses: appleboy/ssh-action@v0.1.10 with: host: $ username: $ password: $ port: $ script: whoami아래와 같이 적용했다. deploy: needs: docker runs-on: ubuntu-latest steps: - name: executing remote ssh commands using password uses: appleboy/ssh-action@v0.1.10 with: host: $`` username: $`` key: $`` script: sh deploy.shpassword 대신 key를 사용했다. → ec2 인스턴스 생성할 때 만든 키페어*secrets는 GitHub Secrets(깃허브 시크릿)의 약어script 파일 확인cat deploy.sh*이제 실제 프로젝트에서 properties에 있던 민감한 정보들을 script에 다 옮겨적으면 될 것 같다.Actions secrets 저장하기host : EC2 portusername : SSH usernamekey: 키페어는 .pem 파일을 .txt로 열어서 해당 내용을 copy한 후 붙여넣으면 된다.☑️ EC2 인스턴스에 접속 할때 ssh -i ~ 명령어를 입력하고 나면 ubuntu@~~ 로 뜨는데 이메일 형식처럼 hello@gmail 하듯이 username@ 이라고 생각하면 된다." }, { "title": "Git actions", "url": "/posts/Git-Actions/", "categories": "Study, Cloud", "tags": "study, summary, Docker, AWS, EC2, CI/CD, Git Actions", "date": "2023-05-20 00:00:00 +0900", "snippet": "스터디 - 배포 과정 정리Git ActionsCreate an example workflow많은 repository가 있지만 직접 설정한다.GitHub Docsyml 파일 자체는 들여쓰기가 중요하다.name: learn-github-actionsrun-name: $ is learning GitHub Actionson: [push]jobs: check-bats-version: runs-on: ubuntu-latest steps: - uses: actions/checkout@v3 - uses: actions/setup-node@v3 with: node-version: '14' - run: npm install -g bats - run: bats -vname이 actions의 이름이다.on은 트리거이다.(특정 이벤트가 발생하면 해당 workflow가 실행)jobs의 바로 밑에 설정된 check-bats-version는 job의 이름이다.runs-on : job을 어떤 운영체제에서 실행시킬 건가? → ubuntu 최신버전job에는 여러 steps가 있다. steps에는 “-“(대시)당 하나의 step이라고 보면 된다.steps 섹션 내에 있는 각 항목은 작업(Job)의 단계(Step)를 나타낸다.actions/checkout@v3와 actions/setup-node@v3는 각각 하나의 단계로 간주된다.여러 개의 단계를 정의할 수 있으며, 각 단계는 순차적으로 실행된다.즉, 첫 번째 단계가 완료된 후 두 번째 단계가 실행되는 식이다.따라서 위의 예시에서는 하나의 작업(Job)이 있고, 해당 작업은 두 개의 단계(Step)로 구성되어 있다.먼저 actions/checkout@v3를 실행하고, 그 다음에 actions/setup-node@v3를 실행한다.마켓플레이스에서 쓰는 것들을 uses에 넣는다. uses의 name은 생략될 수 있다.with는 uses가 필요한 인자 같은 것들을 전달한다.run : cmd 창에서 쓰는 명령어처럼 action 안에서 실행을 시킨다고 보면 된다.예제 적용해보기name : Hello Worldon: workflow_dispatchjobs: hello: runs-on: ubuntu-latest steps: - name : Run hello run : echo \"Hello World\"name이 actions의 이름이다. 지금은 Hello World로 설정했으니 실행하면 Hello World로 설정 되어있을 것이다.on은 트리거이다.(특정 이벤트가 발생하면 해당 workflow가 실행)workflow_dispatch로 설정해서 수동으로 직접 돌리는 것으로 설정했다.jobs의 바로 밑에 설정된 hello는 job의 이름이다.runs-on : job을 어떤 운영체제에서 실행시킬 건가? → ubuntu 최신버전echo “hello” : hello를 출력시켜라 라는 의미이다.수동으로 run 하기Actions 탭에서 Hello World를 클릭하고 아래와 같이 Run workflow를 눌러주면 실행되는 것을 볼 수 있다.Hello World가 출력되고 있다.Gradle buildgithub marketplace위 사이트에서 기본적으로 제공되고 있는 설정 파일에 gradle 최신 버전을 적용했다.name: Run Gradleon: workflow_dispatchjobs: gradle: runs-on: ubuntu-latest steps: - uses: actions/checkout@v3 - uses: actions/setup-java@v3 with: distribution: temurin java-version: 11 - name: Grant execute permission for gradlew run: chmod +x gradlew - name: Gradle Build Action uses: gradle/gradle-build-action@v2.4.2 - name: Execute Gradle build run: ./gradlew build -x testRun Gradle 이라는 이름으로 수동으로 run한다.uses의 checkout은 repository를 clone한다는 의미이다.☑️ 이 전에 수동으로 build할 때 java를 설치했었고 test에서 오류가 떠서 test를 제외하고 build를 했었다. - name: Gradle Build Action uses: gradle/gradle-build-action@v2.4.2 - name: Execute Gradle build run: ./gradlew build -x test name: Gradle Build Action은 GitHub Marketplace에 등록된 gradle/gradle-build-action@v2.4.2 action을 사용하고 있다. uses 키워드를 사용하여 해당 액션을 호출하고 실행한다. 이 action은 Gradle 프로젝트 빌드를 수행하는 데 사용된다. name: Execute Gradle build는 command 라인에서 직접 ./gradlew build -x test 명령을 실행하고 있다. run 키워드를 사용하여 해당 명령을 실행할 수 있다. 이는 command를 실행하는 방식이며, 필요한 경우 스크립트 또는 명령을 자유롭게 작성할 수 있다. 따라서, 첫 번째 단계는 Marketplace에서 가져온 Gradle Build Action을 실행하고, 두 번째 단계는 직접적으로 Gradle 빌드를 실행하는 명령을 실행하는 것이다. - name: Grant execute permission for gradlew run: chmod +x gradlew gradlew 파일에 대해 실행 권한을 부여했다.나는 해당 명령어를 입력해야 Actions에서 통과가 된다.(운영체제마다 다른 건가? 라는 추측을 해본다. 나와 운영체제가 다른 팀원들은 모두 권한 명령어를 작성하지 않아도 통과가 되었다.)Dockerfile 작성하기FROM openjdk:11-slimWORKDIR /appCOPY ./*-SNAPSHOT.jar ./app.jarEXPOSE 8080ENTRYPOINT [\"java\", \"-jar\",\"app.jar\"]ec2 public ipv4주소와 같은 정보가 들어가지 않게 주의한다.yml 수정하기jar 파일dockerfile 작성했으니 jar 파일이 있어야한다.Git Actions의 각 Job은 별도의 가상 환경에서 독립적으로 실행된다.따라서 Job 간에는 직접적으로 파일을 공유할 수 없다.각 Job은 독립적인 실행 단위로 간주되며, 작업이 완료되면 해당 Job의 환경은 종료되고 제거된다.그러나 Git Actions에서는 Job 간에 데이터를 전달하고 공유할 수 있는 몇 가지 방법이 있다.Artifacts를 사용하여 하나의 Job에서 생성된 출력물을 저장하고 다른 Job에서 사용할 수 있다.GitHub Actions에서는 Artifact를 생성하고 업로드하기 위해 actions/upload-artifact 액션을 사용할 수 있다.업로드된 Artifact는 다른 작업에서 actions/download-artifact 액션을 사용하여 다운로드할 수 있다.Artifact를 사용하면 작업의 결과를 효율적으로 관리하고, 다른 작업과의 데이터 공유와 협업을 용이하게 할 수 있다.etc) 외부 서비스(예: 클라우드 스토리지, 데이터베이스 등)를 활용하여 데이터를 전달하는 방법ArtifactUpload a Build Artifact- uses: actions/upload-artifact@v3 with: name: my-artifact path: path/to/artifact/world.txt기본적으로 제공되는 코드이다. 여기서 path를 jar 파일 위치로 수정하면 된다.Download a Build Artifactsteps:- uses: actions/checkout@v3- uses: actions/download-artifact@v3 with: name: my-artifact path: path/to/artifact기본적으로 제공되는 코드이다. 여기서 path는 root 위치에서 download 하므로 생략했다.전체 yml 코드name: Run Gradleon: workflow_dispatchjobs: gradle: runs-on: ubuntu-latest steps: - uses: actions/checkout@v3 - uses: actions/setup-java@v3 with: distribution: temurin java-version: 11 - name: Grant execute permission for gradlew run: chmod +x gradlew - name: Gradle Build Action uses: gradle/gradle-build-action@v2.4.2 - name: Execute Gradle build run: ./gradlew build -x test - uses: actions/upload-artifact@v3 with: name: my-artifact path: ./build/libs/*-SNAPSHOT.jar docker: needs: gradle runs-on: ubuntu-latest steps : - uses: actions/checkout@v3 - uses: actions/download-artifact@v3 with: name: my-artifact - run : ls -lljob을 2개로 나눠서 gradle의 문제인지 docker의 문제인지 파악할 수 있게 작성했다.우선 순위 지정 docker: needs: gradle docker를 실행하려면 gradle의 작업이 끝나야 한다. → 작업의 순서를 정해줘야 한다.GitHub Container RegistryGitHub Container RegistryDocker hub 대신 GitHub Container Registry를 사용하여 Docker 이미지를 관리할 수 있다.아래는 공식 사이트에서 기본적으로 제공되는 workflow 일부다. - name: Set up QEMU uses: docker/setup-qemu-action@v2 - name: Set up Docker Buildx uses: docker/setup-buildx-action@v2 - name: Login to Docker Hub uses: docker/login-action@v2 with: username: $ password: $ - name: Login to GitHub Container Registry uses: docker/login-action@v2 with: registry: ghcr.io username: $ password: $ - name: Build and push uses: docker/build-push-action@v4 with: context: . platforms: linux/amd64,linux/arm64 push: true tags: | user/app:latest user/app:1.0.0 ghcr.io/user/app:latest ghcr.io/user/app:1.0.0파일 작성하기name: Run Gradleon: workflow_dispatchjobs: gradle: runs-on: ubuntu-latest steps: - uses: actions/checkout@v3 - uses: actions/setup-java@v3 with: distribution: temurin java-version: 11 - name: Grant execute permission for gradlew run: chmod +x gradlew - name: Gradle Build Action uses: gradle/gradle-build-action@v2.4.2 - name: Execute Gradle build run: ./gradlew build -x test - uses: actions/upload-artifact@v3 with: name: my-artifact path: ./build/libs/*-SNAPSHOT.jar docker: needs: gradle runs-on: ubuntu-latest steps : - uses: actions/checkout@v3 - uses: actions/download-artifact@v3 with: name: my-artifact - name: Set up QEMU uses: docker/setup-qemu-action@v2 - name: Set up Docker Buildx uses: docker/setup-buildx-action@v2 # GitHub Container Registry에 로그인 - name: Login to GitHub Container Registry uses: docker/login-action@v2 with: registry: ghcr.io username: `$` password: `$` # Build 및 GitHub Package 에 이미지 업로드 - name: Build and push uses: docker/build-push-action@v4 with: # 현재 디렉토리 지정 context: . push: true tags: ghcr.io/`$`:latest기본으로 제공되는 변수 알아보기 → GitHub Docs변수를 대문자로 쓸꺼면 “_“를 쓰고 소문자를 쓸꺼면 “.” 을 쓴다 uses : GitHub Marketplace에서 제공되는 액션(Action)을 사용하기 위한 필드 with : uses 필드와 함께 사용되는 옵션을 지정하는 데 사용 액션에 필요한 매개변수, 환경 변수, 인증 정보 등을 설정 registry : Container Registry를 지정하는 field Container Registry는 Docker 이미지를 저장하고 관리하는 저장소 registry: ghcr.io는 GitHub Container Registry를 사용하겠다는 의미 이를 통해 Docker 이미지를 GitHub Container Registry에 푸시하거나, 해당 레지스트리에서 이미지를 가져올 수 있다. docker/login-action을 통해 레지스트리에 로그인하여 인증 정보를 제공해야 한다. path : build context로 사용되는 경로를 지정 path는 context로 대체하여 사용할 수도 있다. tags : 이미지에 대한 식별 가능한 값을 넣을 수 있다.(버전, release명 등) latest는 이미지의 최신 버전을 가리키는 태그 unexpected status: 403 Forbidden실행하게 되면 아래와 같은 에러가 뜬다.buildx failed with: ERROR: failed to solve: failed to push ghcr.io/hihi/cicdtest:latest: unexpected status: 403 Forbidden아래와 같이 작성해서 권한을 허용시켜준다. permissions: contents: read packages: writeEC2로 배포이미지 확인sudo docker images이미지 확인을 해보면 아무것도 안띄워져 있는 것을 볼 수 있다.Amazon EC2 인스턴스에 접속sudo ssh -i adme.pem ubuntu@{ipb4 주소} Docker loginsudo docker login -u {github username} ghcr.iopassword를 입력하라고 뜨는데 github의 password를 입력하면 실패한다.accessToken을 발급받은 후에 해당 token값을 입력해서 password로 사용하면 Login Succeeded가 뜬다.[프로필 settings 클릭] → [왼쪽 하단의 Developer settings 클릭] → [Personal access tokens (classic)에서 Generate new token 클릭 후 token 발급]git actions를 run하면 package가 하나 생긴다.package에 들어가면 pull을 받는 명령어가 띄워지는데 해당 부분을 copy하면 된다.sudo docker pull {yml에서 설정한 docker}name: Build and pushuses: docker/build-push-action@v4with: context: . push: true tags: ghcr.io/$:latest위와 같이 ghcr.io~로 설정했기 때문에 아래와 같은 형식으로 설정하면 된다.ex) sudo docker pull ghcr.io/hello-world/test:latest다른 사람이 만든 이미지를 받아올 수 있을까?docker 로그인 후 pull 받아오려고 하니 denied가 떴다.Docker image를 private으로 설정하면 다른 사람은 해당 이미지를 pull 받을 수 없다.private image는 소유자 또는 이미지에 대한 액세스 권한을 가진 사용자만이 pull 및 사용할 수 있다.따라서 package는 private으로 설정해준다.로그인 후 이미지 확인sudo docker imagessudo docker run --name cicd -p {ec2 port}:{container port} ghcr.io/{github username}/{reposiory name}:latest실행 후 http://{ipv4 주소}:8080/{rest api 주소}로 입력하면 제대로 띄워져 있는 것을 확인할 수 있다." }, { "title": "Cicd 수동", "url": "/posts/CICD-%EC%88%98%EB%8F%99/", "categories": "Study, Cloud", "tags": "study, summary, Docker, AWS, EC2, CI/CD", "date": "2023-05-19 00:00:00 +0900", "snippet": "스터디 - 배포 과정 정리현재 실행 중인 셸 세션을 종료하는 명령어$ exit현재 프로젝트에서는 gradle의 build를 클릭했을 때 test 때문에 에러가 생긴다. 따라서 수동으로 작성했다.*intellij가 build하면 out폴더가 생기고 gradle이 build하면 build폴더가 생긴다.local에서 java jar 빌드1. terminal 에서 내 프로젝트 파일까지 이동한다.2. test 제외하고 build하기./gradlew build -x test→ library에 파일이 하나 생긴다.3. /build/libs 에 빌드된 jar 파일을 확인할 수 있다. ( ls -ll build/libs 로 확인가능하다.)외부 라이브러리 제외하고 내가 작성한 코드만 넣어둔게 plain이다.4. jar 실행 &amp; 환경변수 전달java -jar -Dspring.datasource.url=jdbc:mysql://{ipv4 주소}:{host port}/{schema} -Dspring.datasource.password={password} {jar 파일 위치 경로}/{project name}-0.0.1-SNAPSHOT.jarex) java -jar -Dspring.datasource.url=jdbc:mysql://1111.1.1:1234/chat -Dspring.datasource.password=1234 build/libs/hello-world-0.0.1-SNAPSHOT.jar→ java 로 jar 파일 실행 -D[환경변수] -D[환경변수] 실행할 jar파일EC2에서 직접 build 해서 실행FilZilla에서 ec2를 연결한다.ssh는 22번 포트이므로 22번으로 설정한다.EC2에 jar 파일 넣기jar파일을 ec2 서버로 옮긴다(왼쪽에서 오른쪽) 이때, plain이 아니라 plain없는 jar 파일을 옮기면 된다.java 설치sudo apt install openjdk-11-jre-headlessjava2.x.x 버전을 사용중이어서 11 버전 사용했다.java3.x.x 버전은 최소 17을 사용해야 한다.자바 버전 확인java --versiondocker ip주소 명령어기존에는 외부에서 ec2 접근하는 주소를 넣어줬는데 같은 네트워크 내부면 같은 ip를 넣어주므로써 굳이 나갔다가 들어오는 과정을 생략해준다.→ docker주소를 넣어준다.sudo docker inspect {container name}나는 container name 대신에 sudo docker ps를 입력해서 나오는 container id를 작성했다.network settings에 보면 Gateway, IPAddress를 볼 수 있는데 IPAddress가 docker ip주소이다.jar 파일 실행java -jar -Dspring.datasource.url=jdbc:mysql://{docker ip 주소}:3306/chat -Dspring.datasource.password=1234 {project 명}-0.0.1-SNAPSHOT.jar여기서 jar 파일 주소명을 작성하지 않은 이유는 filezilla에서 jar 파일이 같은 위치에 있기 때문이다.FileZilla의 작업 디렉토리(Working Directory)에 해당 jar 파일이 위치접근방법http://{ipv4 주소}:8080/{rest api 주소}ex) http://{ipv4 주소}:8080/helloEC2에 Dockerfile로 jar 파일을 Image로 빌드 후 container 실행하기Dockerfile 작성Docker docs Docker hubvi Dockerfile nano Dockerfile둘 중에 아무거나 입력한다.FROM openjdk:11-slimWORKDIR /appCOPY ./{project name}-*-SNAPSHOT.jar ./app.jarEXPOSE 8080ENTRYPOINT [\"java\", \"-jar\", \"-Dspring.datasource.url=jdbc:mysql://{ipv4 주소}:3306/chat\", \"-Dspring.datasource.password=1234\", \"app.jar\"]WORKDIR : 도커 이미지를 실행할 때 작업 디렉토리를 설정하는 명령어“/app”으로 작업 디렉토리를 설정했으므로 이후 명령어들은 “/app” 디렉토리 내에서 실행된다.COPY : 현재 Dockerfile과 동일한 위치에 있는 “{project name}–SNAPSHOT.jar” 파일을 “/app/app.jar”로 복사하는 명령어{host 파일 경로} {docker image 경로}와일드카드(*)를 사용하여 버전이 변경될 수 있는 파일명에 대응하고 있다.ENTRYPONT : 도커 이미지가 실행될 때 실행될 명령어를 설정하는 명령어WORKDIR에서 작업 디렉토리를 “/app”으로 설정했기 때문에 “./”를 사용하지 않고 “app.jar”만 작성하여 실행된다.ctrl + x(저장) 을 누르고 Y를 입력한 후 엔터하면 저장이 된다.*만약 Dockerfile을 수정했다면 다시 build하고 run 해야한다.위에서 FileZilla를 통해 jar파일을 옮겨놨기 때문에 COPY 명령어가 실행된 것이다.만약 FileZilla를 사용안했다면 jar 파일을 넣어둬야한다.절대경로와 상대경로./app: ./은 현재 작업 디렉토리를 나타낸다.즉, ./app은 현재 작업 디렉토리 아래의 app이라는 디렉토리를 나타낸다.예를 들어, 현재 작업 디렉토리가 /home/user라면, ./app은 /home/user/app을 의미한다./app: /는 루트 디렉토리를 나타낸다.즉, /app은 루트 디렉토리 아래의 app이라는 디렉토리를 나타낸다.따라서 /app은 파일 시스템의 최상위 디렉토리에서부터 app 디렉토리를 찾는 것을 의미한다../app은 현재 작업 디렉토리를 기준으로 상대적인 경로를 나타내며,/app은 파일 시스템의 루트 디렉토리를 기준으로 절대 경로를 나타낸다.COPY 명령어에서 파일을 복사할 때 상대 경로를 사용하면 ENTRYPOINT에서 파일명만 작성하면되고COPY 명령어에서 절대 경로를 사용하는 경우에는 ENTRYPOINT에서 파일의 전체 경로를 작성해줘야한다.ex) COPY 명령어에서 /app/app.jar로 파일을 복사한 경우 (절대경로)ENTRYPOINT [\"java\", \"-jar\", \"-Dspring.datasource.url=jdbc:mysql://{ipv4 주소}:3306/chat\", \"-Dspring.datasource.password=1234\", \"/app/app.jar\"]Dockerfile 저장이 잘되었는지 확인cat Dockerfileimage buildsudo docker build -t chat .chat이라는 이름의 image buildcontainer 실행sudo docker run --name admeCon -p 8080:8080 -d chat:latestsudo docker run --name [컨테이너이름] -p 8080:8080 -d {실행할 image명 지정}:latest보안그룹 - 인바운드 규칙에서 8080포트(호스트)를 열어줘야 한다.만약 port 번호를 바꾼다면?Dockerfile에서 expose를 80으로 바꾼다면 포트 포워드를 할 때 뒤에 있는 port를 80으로 변경해야한다.HTTP 80 port는 주소창에 port 번호를 입력하지 않아도 된다. (8080:80) but, 80포트 열어주기 필수{ipv4 주소}/rest-apilogsudo docker pssudo docker logs {container 명 or container id}실행되는 것을 볼 수 있다.{ipv4 주소}:8080/rest-api 주소를 입력해서 db에 저장될 만한 rest api url에 접속한 후db를 새로고침하면 db가 띄워져있는 것을 볼 수 있다.터미널창을 나가도 EC2에서 동작중임을 확인할 수 있다. → 배포 완료여기까지 수동으로 작성을 했는데 다음에는 git actions를 활용하여 자동으로 배포하는 방법을 작성할 예정이다." }, { "title": "Ec2+docker+mysql", "url": "/posts/EC2+Docker+MySQL/", "categories": "Study, Cloud", "tags": "study, summary, Docker, AWS, EC2", "date": "2023-05-17 00:00:00 +0900", "snippet": "관련 글 Ec2+docker+mysql 👈🏻 Cicd 수동 Git actions 배포 자동화 Nginx스터디 - 배포 과정 정리EC2 + Docker + MySQLec2 생성하기point ubuntu 클릭 스팟 인스턴스 클릭Spot Instance인스턴스는 AWS의 여유 리소스 또는 EC2 사용자가 사용하지 않는 리소스를 활용하여 제공된다.이러한 인스턴스는 경매 방식으로 가격이 결정되며, 현재의 수요와 공급 상황에 따라 가격이 변동한다.Spot 인스턴스는 비교적 저렴한 가격으로 사용할 수 있어서 비용을 절감할 수 있다.그러나 가격은 변동하기 때문에 인스턴스가 중단될 수 있으며, 중단될 경우에는 사전에 알림을 받고 인스턴스를 종료해야 한다.Spot 인스턴스는 특정 시간 동안 일시적으로 사용 가능한 리소스이기 때문에 중요한 데이터나 지속적인 작업에는 적합하지 않을 수 있다.Spot 인스턴스는 비용 효율적인 방법으로 EC2 인스턴스를 실행하고자 하는 사용자에게 좋은 선택일 수 있다.그러나 임시적인 리소스로 제공되므로 인스턴스 중단에 대비하고 적절한 처리 방법을 고려해야한다.인스턴스 연결하기{키 페어 이름}.pem을 저장한 위치로 경로를 이동시킨 후 아래 명령어를 입력한다.나는 Linux 전용 폴더에 넣어뒀다.keypair 파일의 접근 권한을 변경$ chmod 400 {키 페어 이름}.pemubuntu에서는 chmod 전에 sudo를 적어줘야 실행이 되었다. (sudo chmod 400 {키 페어 이름}.pem)chmod는 파일 또는 디렉토리의 권한을 변경하는 명령어이며, 400은 권한 설정을 나타낸다.400은 해당 파일을 소유한 사용자에게 읽기 권한만 부여하고, 그 외의 사용자에 대해서는 권한을 제한하는 설정이다.일반적으로 AWS에서는 EC2 인스턴스에 연결하기 위해 사용되는 keypair 파일을 400으로 설정하여 보안을 강화하는 것이 권장된다.SSH를 사용하여 Amazon EC2 인스턴스에 접속$ ssh -i {키 페어 주소} ubuntu@ipv4주소나는 키페어 주소를 입력하지 않고 키페어 이름만 작성해야 실행이 되었다. ex) sudo ssh -i chat.pem ubuntu@{ipv4주소}-i {키 페어 주소}는 접속에 사용할 개인 키 파일의 경로를 지정하는 옵션이다.해당 개인 키는 키 페어 생성 시에 다운로드한 .pem 파일이어야 한다.ubuntu@IPv4주소는 SSH로 접속할 EC2 인스턴스의 사용자 이름과 IPv4 주소를 지정하는 부분이다.여기서 ubuntu는 EC2 인스턴스에 접속할 사용자 계정이며, IPv4주소는 EC2 인스턴스의 공개 IPv4 주소이다.위의 명령어를 실행하면 개인 키를 사용하여 SSH 연결이 설정되고, 지정한 사용자 이름으로 EC2 인스턴스에 로그인할 수 있게 된다.이후에는 SSH 세션 내에서 해당 인스턴스를 제어하고 명령을 실행할 수 있다.SSH란?SSH(Secure Shell)는 네트워크 상에서 안전하게 원격으로 컴퓨터에 접속하고 통신하기 위한 프로토콜 및 프로그램이다.SSH를 사용하면 인터넷을 통해 암호화된 연결을 통해 원격 시스템에 로그인하고 명령을 실행하거나 파일을 전송할 수 있다.SSH는 기본적으로 22번 포트를 사용한다. Amazon EC2에서도 기본적으로 SSH 접속을 위해 22번 포트를 사용한다.EC2 인스턴스를 생성할 때 보안 그룹(Security Group)이라는 설정을 지정할 수 있다.보안 그룹은 인스턴스에 대한 네트워크 트래픽을 제어하는 가상 방화벽 역할을 한다.기본적으로 SSH 접속을 허용하기 위해 보안 그룹 구성에 22번 포트를 개방해야 한다.따라서, SSH를 사용하여 EC2 인스턴스에 접속할 때는 일반적으로 SSH 클라이언트에서 22번 포트를 목적지 포트로 지정하게 된다.이렇게 지정된 포트를 통해 SSH 연결이 수립되어 EC2 인스턴스에 접속할 수 있다.만약 22번 포트가 아닌 500같이 다른 번호로 설정했다면?--port 옵션을 사용하여 목적지 포트를 지정해야 한다.ssh -i {키 페어 주소} -p 500 ubuntu@ipv4주소-p 500은 SSH 접속 시 목적지 포트를 500으로 지정하는 옵션이다.실제로 사용하려는 EC2 인스턴스의 포트 번호에 맞게 -p 옵션을 사용하여 목적지 포트를 지정해주면 된다.Docker 설치하기Docker docsapt 저장소 사용HTTPS를 통해 리포지토리를 사용할 수 있도록 패키지 인덱스를 업데이트 apt하고 패키지를 설치sudo apt-get updatesudo apt-get install ca-certificates curl gnupgDocker의 공식 GPG 키를 추가sudo install -m 0755 -d /etc/apt/keyringscurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpgsudo chmod a+r /etc/apt/keyrings/docker.gpgrepository 설정echo \\ \"deb [arch=\"$(dpkg --print-architecture)\" signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \\ \"$(. /etc/os-release &amp;&amp; echo \"$VERSION_CODENAME\")\" stable\" | \\ sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/nulldocker engine 설치package updatesudo apt-get updateDocker Engine, containerd 및 Docker Compose를 설치(최신 버전)sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin확인하기sudo docker -vMySql 설치하기Docker hubMySQL 인스턴스 시작$ docker run --name ${some-mysql} -e MYSQL_ROOT_PASSWORD=${my-secret-pw} -d mysql:tagsome-mysql는 컨테이너에 할당하려는 이름, my-secret-pw는 MySQL 루트 사용자에 대해 설정할 비밀번호,tag는 원하는 MySQL 버전을 지정하는 태그→ ex) docker run -p 3306:3306 --name chat -e MYSQL_ROOT_PASSWORD=1234 -d mysql:latest앞의 3306 port는 ec2 port이고, 뒤의 3306은 container port이다.ex) docker run -p 1111:2222 --name hello -e MYSQL_ROOT_PASSWORD=1234 -d mysql:latest -p 1111:2222: 호스트의 1111 포트를 컨테이너의 2222 포트와 연결한다. 호스트와 컨테이너 간의 포트 매핑을 설정하는 옵션이다. --name hello: 실행되는 컨테이너의 이름을 “hello”로 지정한다. -e MYSQL_ROOT_PASSWORD=1234: 컨테이너 내에서 실행되는 MySQL 서버의 루트 계정의 비밀번호를 “1234”로 설정한다. 환경 변수를 설정하는 옵션이다. -d: 컨테이너를 백그라운드 모드로 실행한다. 컨테이너가 백그라운드에서 실행되면 콘솔에 로그가 출력되지 않는다. mysql:latest : 실행할 컨테이너의 이미지를 지정한다. 여기서는 “mysql” 이미지의 최신 버전을 사용한다. 따라서 이 명령어는 호스트의 1111 포트를 MySQL 컨테이너의 2222 포트와 연결하고, “hello”라는 이름의 컨테이너를 생성하며,MySQL 서버의 루트 계정 비밀번호를 “1234”로 설정하여 MySQL 컨테이너를 백그라운드 모드로 실행하는 역할을 한다.1111은 호스트 컴퓨터의 포트 번호를 나타내며, 2222는 컨테이너 내부의 MySQL 서비스가 실제로 실행되는 포트 번호이다.-p 옵션은 호스트와 컨테이너 간의 포트 매핑을 설정하는데 사용된다.즉, 위의 예시에서 1111 포트로 호스트 컴퓨터에 접속하면, 해당 요청은 컨테이너 내부의 2222 포트로 전달되어 MySQL 서비스에 도달하게 된다.이를 통해 호스트 컴퓨터에서 MySQL 서버에 접근할 수 있다.포트 포워딩을 사용하여 컨테이너 내부의 서비스를 호스트 컴퓨터나 외부로 노출시킬 수 있으며,이를 통해 컨테이너의 서비스에 접근하거나 외부에서 컨테이너의 서비스에 접속할 수 있게 된다.Port Forwarding(포트 포워딩)?포트 포워딩(Port Forwarding)은 네트워크에서 사용되는 용어로,컴퓨터의 네트워크 트래픽을 한 포트에서 다른 포트로 전달하는 기술이다.이를 통해 외부에서 내부 네트워크의 서비스에 접근할 수 있게 된다.일반적으로 컴퓨터는 여러 개의 포트를 가지고 있다.각 포트는 특정 프로토콜(예: HTTP, SSH, FTP)이나 서비스(예: 웹 서버, 데이터베이스)와 연결되어 있다.포트 포워딩을 사용하면 외부에서 컴퓨터의 특정 포트로 요청이 들어오면이를 내부 네트워크에서 다른 포트로 전달하여 서비스에 접근할 수 있게 된다.예를 들어, 웹 서버가 80번 포트를 사용하고 있고, 로컬 컴퓨터의 8080번 포트를 외부로 열어두었다고 가정해 본다.이 때 포트 포워딩을 설정하면 외부에서 8080번 포트로 접속한 요청이 내부 네트워크의 웹 서버로 전달되어 웹 페이지를 볼 수 있게 된다.포트 포워딩은 주로 컴퓨터나 네트워크 장치에 있는 방화벽 또는 라우터에서 설정되며,내부 네트워크의 서비스를 외부로 공개하거나 원격으로 접근할 때 유용하게 사용된다.MySql을 설치했으니 project에 db를 연결해본다.ec2의 Ipv4 주소를 입력한다.user와 password는 MySql 인스턴스를 만들 때 설정한 값을 넣어주면 된다.edit Configurationedit Confguration을 눌러서 새로 Spring Boot를 만들고 기존 project에 맞게 설정 후 환경변수를 위와 같이 작성해주면 된다.☑️ edit Configuration에서 Active profiles에 작성하는게 아니라 Environment variables에 환경변수 넣는 것!jdbc:mysql://{EC2공개주소}:{host port}/스키마 이름위에서 MySQL을 설치할 때 docker run -p 3306:3306 --name chat -e MYSQL_ROOT_PASSWORD=1234 -d mysql:latest로 설치했기 때문에3306으로 설치했고 chat을 입력한 것이다.만약에 EC2 public IP 주소가 1.2.3.4이고 host port가 1111로 매핑되어 있다면, SPRING_DATASOURCE_URL은 다음과 같이 설정될 수 있다jdbc:mysql://1.2.3.4:1111/스키마이름인바운드 규칙 설정MySQL을 적용했으니 인바운드 규칙에 MySQL을 넣어준다.보안보안적으로 모든 IP를 허용해버리면 안되기 때문에 DB는 내 IP만 접근 가능하게 설정해준다.스키마(chat) 생성 후 run 을 하면 정상적으로 동작한다.application.properties에 spring.jpa.hibernate.ddl-auto=create 속성을 넣어주면 실행과 동시에 테이블이 생성되는 것을 볼 수 있다.reference [AWS, Docker] aws ec2 instance에 docker, mysql 설치하기" }, { "title": "Jmh", "url": "/posts/JMH/", "categories": "Project, Chat", "tags": "spring, JMH, 성능 측정, 벤치마크 테스트", "date": "2023-05-08 00:00:00 +0900", "snippet": "JMH를 통한 벤치마킹 테스트관련 글 Websocket Websocket + 부가기능 Websocket (채팅 기록 json 파일 저장하기) Sse Sse 문제점 Websocket + jwt Websocket test Jmh - 채팅 파일 refactoring 👈🏻성능 테스트(JMH)JMH는 Java Microbenchmark Harness의 약자로, Java 코드의 성능을 측정하고 비교하기 위한 도구다.JMH를 사용하면 매우 정확하고 안정적인 벤치마크를 작성할 수 있다.이를 통해 코드 변경에 따른 성능 변화를 측정하거나, 다양한 구현 방법의 성능을 비교 분석할 수 있다.JMH는 측정 대상이 되는 코드가 얼마나 빠르게 동작하는지 측정하기 위해 성능 측정 도구를 사용한다.JMH는 매우 정교하고 통계학적으로 유효한 측정 결과를 얻기 위해 다양한 성능 측정 방법과 통계 기법을 적용한다.JMH는 Oracle의 JIT Compiler 개발자가 만든 것이기 때문에 타 Benchmark Framework 보다 신뢰할 수 있다는 장점이 존재한다.설정위와 같이 src directory 하위에 jmh 폴더를 만들고 main과 같은 형태로 폴더를 구성했다.프로젝트 폴더 └─── src └─── jmh ├─── java └─── resourcesplugins { id \"me.champeau.jmh\" version \"0.6.4\"}jmh{ fork = 1 warmupIterations = 10 iterations = 10 }jmh는 성능 측정을 위한 도구이며, 위 설정은 jmh 프로파일러가 성능 측정을 어떻게 수행할지 제어하는 데 사용된다. fork: 측정할 코드를 포크할 횟수를 지정한다. 몇 번의 자식 프로세스를 만들어서 벤치마크를 실행할 것인지를 결정한다.(default 1) 이 값이 1이면 측정할 코드를 한 번만 포크하며, 이 값이 높을수록 측정 결과의 신뢰성이 높아진다. 하지만 여러 개의 JVM에서 동일한 벤치마크를 실행하고 결과를 평균화하는 것이 더 정확할 수도 있다. warmupIterations: 실제 측정을 시작하기 전에 성능 측정을 위한 샘플 데이터를 생성하는 데 사용되는 반복 횟수를 지정한다. (default 10) 벤치마크를 실행하기 전에 JVM이 최적화를 수행할 수 있도록 JVM을 미리 ‘워밍업’하는 데 필요한 반복 횟수를 결정한다. 이 값은 높으면 더 많은 최적화가 이루어지므로 정확도가 높아진다. 하지만 반복이 길어지므로 실행 시간이 늘어난다. iterations: 실제 측정을 수행하는 반복 횟수를 지정한다. (default 10) 이 값이 높을수록 측정 결과의 신뢰성이 높아진다. 하지만 높은 값은 실행 시간이 길어지므로 효율성을 떨어뜨릴 수 있다. 보통은 fork는 1이나 2로 설정하고, warmupIterations와 iterations는 기본값으로 두는 것이 좋다.그리고 실제로 최적화된 결과를 얻기 위해서는 여러 차례의 실행을 거쳐 평균값을 구해야 한다.*참고 : JMH의 최신 버전 직접 반영해주는 방법dependencies { // JMH implementation 'org.openjdk.jmh:jmh-core:1.32' implementation 'org.openjdk.jmh:jmh-generator-annprocess:1.32'}WarmupJVM warm-up은 코드 실행 전에 JVM을 최적화하고 성능을 향상시키는 과정을 말한다.이 과정은 JIT(Just-In-Time) 컴파일러와 관련이 있는데,컴파일러는 프로그램 실행 중에 실제로 사용되는 코드 블록을 감지하고 네이티브 코드로 컴파일하여 성능을 향상시킨다.네이티브 코드는 컴퓨터의 특정 플랫폼에서 직접 실행할 수 있는 기계어 코드를 말한다.자바 코드는 JVM(Java Virtual Machine)에서 실행되므로 플랫폼에 구애받지 않고 실행될 수 있다.JIT(Just-In-Time) 컴파일러는 프로그램 실행 중에필요한 코드 블록을 선택하여 해당 부분을 네이티브 코드로 변환하여 실행 속도를 높인다.네이티브 코드로 변환된 코드는 해당 플랫폼에서 직접 실행되므로 보통 실행 속도가 빠르다.간단한 예로, 자바 프로그램에서 작성한 코드는 먼저 자바 바이트 코드로 변환된다.JVM은 필요에 따라 JIT(Just-In-Time) 컴파일러를 사용하여 바이트 코드를 해당 플랫폼의 네이티브 코드로 변환한다.네이티브 코드로 변환되면 해당 플랫폼에서 직접 실행될 수 있으며 실행 속도가 빨라진다.기계어 코드는 CPU가 직접 이해하고 실행하는 이진 형식의 코드다.이 코드는 0과 1로 표현되며, CPU가 직접 해석하여 실행한다.따라서 기계어 코드는 특정 CPU 아키텍처에 의해 이해되고 실행된다.그러나 JIT 컴파일러는 프로그램의 초기 실행에서는 모든 코드를 네이티브 코드로 컴파일하지 않고,필요한 부분만 선택적으로 컴파일한다.이로 인해 초기 실행의 성능이 최적화되지 않은 상태로 유지될 수 있다.Warmup을 사용하면 자주 사용되는 클래스를 호출하여 클래스를 메모리에 로딩하고 코드 캐시를 생성한다.이를 통해 코드의 실행 속도를 향상시키고 성능 차이를 최소화할 수 있다.주로 운영환경에서 서버를 재가동하거나,성능 측정 테스트를 수행하기 전에 warm-up을 실행하여 JVM을 최적화하고 안정화된 상태로 성능 측정을 진행한다.이를 통해 초기 실행의 성능 저하를 최소화하고 일관된 성능 측정 결과를 얻을 수 있다.plugins { id \"me.champeau.jmh\" version \"0.6.4\"}jmh{ fork = 1 warmupIterations = 10 iterations = 10 }이 전에 warmupIterations를 10으로 설정했는데 특정 class에서 5로 설정하고 싶다면@Warmup(iterations = 5)와 같이 적으면 된다.@Warmup(iterations = 5)public class Benchmark {}JMH 작성 방법@BenchmarkMode: 벤치마크 결과를 나타내는 모드를 설정한다. Mode.Throughput : 시간당 처리량 측정 Mode.AverageTime : 평균 실행 시간 측정 Mode.SampleTime : 실행 시간 샘플링 측정 Mode.SingleShotTime : 단일 실행 시간 측정 Mode.All : 모든 시간 측정ex. @BenchmarkMode(Mode.AverageTime)으로 설정하면 평균 실행 시간이 결과로 나타난다.@OutputTimeUnit: 결과의 시간 단위를 설정한다. TimeUnit.NANOSECONDS : 나노 TimeUnit.MICROSECONDS : 마이크로 TimeUnit.MILLISECONDS : 밀리 TimeUnit.SECONDS : 초 TimeUnit.MINUTES : 분 TimeUnit.HOURS : 시간 TimeUnit.DAYS : 일ex) @OutputTimeUnit(TimeUnit.MILLISECONDS)와 같이 설정하면 결과를 밀리초 단위로 출력한다.@State : 벤치마크할 상태를 설정한다. Scope.Benchmark : 벤치마크 전체에서 공유 Scope.Thread : 각 스레드마다 별도로 생성. 멀티스레드 환경에서 안전 Scope.Group : 벤치마크 실행 그룹에서 공유@State(Scope.Benchmark): 벤치마크 메서드마다 객체를 새로 생성하지 않고 상태를 유지하며 벤치마크를 수행한다.@Setup: 벤치마크 메서드 실행 전에 초기화 작업을 수행한다.주로 파일 경로 설정 등의 환경 설정 작업을 수행한다. Level.Trial : 벤치마크 전체에서 한 번만 실행 (default) Level.Iteration : 벤치마크 반복마다 실행 Level.Invocation : 각 메서드 호출마다 실행@TearDown : 벤치마크 메서드 실행 후에 정리 작업을 수행한다. Scope.Benchmark : 벤치마크 전체에서 공유 Scope.Thread : 각 스레드마다 별도로 생성. 멀티스레드 환경에서 안전 Scope.Group : 벤치마크 실행 그룹에서 공유1. 클래스에 @State(Scope.Benchmark) 어노테이션을 붙여 벤치마크할 상태를 지정한다.2. 클래스에 @BenchmarkMode(Mode.AverageTime) 어노테이션을 붙여 벤치마크 결과를 나타내는 모드를 설정한다.3. 클래스에 @OutputTimeUnit(TimeUnit.MILLISECONDS) 어노테이션을 붙여 결과의 시간 단위를 설정한다.4. 각 벤치마크 대상 메소드에 @Benchmark 어노테이션을 붙인다.5. 필요한 경우 @Setup 어노테이션을 이용해 벤치마크 실행 전에 필요한 초기화 작업을 수행한다.이렇게 기존 로직을 가지고 똑같이 작성하되 jmh에 필요한 어노테이션을 붙여 벤치마크를 작성하면 된다.JMH 실행 방법terminal에서 gradlew가 있는 최상위 디렉토리로 이동한 후 아래 명령어 입력./gradlew jmh위와 같이 입력하면 terminal에 실행 결과가 뜨지만 아래와 같이 입력해도 된다.cat build/results/jmh/results.txtJMH 기록을 모두 지우려면 아래와 같이 작성한다../gradlew clean파일 마지막 글만 조회하기1차 수정*전체코드는 길어서 생략 → github 참고하거나 파일 조회 코드(제일 하단)에 설명 작성한 것 보기jmh{ fork = 1 warmupIterations = 1 iterations = 1}변경 전 코드는 파일의 끝에서부터 7줄을 읽어올 때 파일 포인터를 이용하여 하나씩 읽어오는 방식을 사용한다.(가독성이 좋게 변수별로 한 줄 씩 파일에 저장해서 총 7줄을 읽어야 했다.)사실 이 부분 때문에 jmh를 사용한 이유기도 하다.해당 방식 때문에 채팅 리스트를 여는 시간이 느리다고 판단되었고 파일을 저장하는 방식을 변경했다.파일을 저장할 때 한 줄 안에 모든 정보를 저장하게 한 다음 파일을 읽어올 때파일 포인터를 끝에서 두 번째 줄로 시작 지점을 이동시킨 다음에 한 줄을 읽고 끝낸다.(한 줄을 저장하고 줄을 한칸 띄어 저장하기 때문에)이 방식은 파일 포인터 이동 횟수가 적기 때문에 더 빠른 성능을 보이는 것 같다.jmh{ fork = 1 warmupIterations = 10 iterations = 1}위와 같이 설정 후 다시 실행했을 때 차이가 더 커진 것을 볼 수 있다.샘플 데이터와 실제 데이터를 10으로 설정하고 실행했다.jmh{ fork = 1 warmupIterations = 10 iterations = 10} Cnt : 총 시행 횟수(포크*반복) 점수 : 벤치마크 결과 오류 : 표준 오류 값. 서로 다른 시행 결과가 얼마나 다른지를 의미stackoverflow“testImproved”의 실행 시간은 평균 1.860 ms/op로 나타났으며, 에러 범위는 ±0.465 ms/op다.“testOriginal”의 실행 시간은 평균 154.466 ms/op로 나타났으며, 에러 범위는 ±51.680 ms/op다.testImproved와 testOriginal 간의 실행 시간 차이가 대략 150배이며, 에러 범위도 50배 정도 줄었다.마지막 글만 가져오는 코드는 확실히 성능이 개선되어 보인다.그외 다른 log들Result \"LastLineBenchmark.testImproved\": 1.860 ±(99.9%) 0.465 ms/op [Average] (min, avg, max) = (1.566, 1.860, 2.398), stdev = 0.308 CI (99.9%): [1.395, 2.325] (assumes normal distribution)(min, avg, max) = (1.566, 1.860, 2.398), stdev = 0.308testImproved의 실행 시간에 대한 최소값, 평균값, 최대값, 표준 편차를 나타낸다.최소값은 1.566 ms/op, 평균값은 1.860 ms/op, 최대값은 2.398 ms/op, 표준 편차는 0.308 ms/op다.CI (99.9%): [1.395, 2.325] (assumes normal distribution)testImproved의 실행 시간에 대한 99.9% 신뢰 구간을 나타낸다.여기서는 1.395 ms/op에서 2.325 ms/op 사이의 값들이 99.9%의 확률로 실제 평균값을 포함한다고 추정된다.신뢰 구간은 실행 시간 추정의 정확성과 신뢰도를 나타낸다.Result \"LastLineBenchmark.testOriginal\": 154.466 ±(99.9%) 51.680 ms/op [Average] (min, avg, max) = (97.067, 154.466, 222.105), stdev = 34.183 CI (99.9%): [102.786, 206.146] (assumes normal distribution)2차 수정Map을 추가하여 file 조회 전 map의 값 유무에 따라 map에서 조회하거나 file에서 조회 하는 방식public LastMessage lastLine(String roomId) { if(lastMessageMap.containsKey(roomId)){ log.info(\" = = = MAP 활용 = = = \"); return lastMessageMap.get(roomId); }else{ log.info(\" = = = MAP 활용 X = = = \"); String filePath = chatUploadLocation + \"/\" + roomId + \".txt\"; // 이하 변경 전 코드와 동일 }}과연 파일 조회만 했을 때보다 map을 활용해서 file 조회를 덜 하는 방식이 얼마나 효과적일지 체크해봤다.또, 처음에 작성한 코드와 얼마나 차이가 나는지 확인하기 위해작성한 순서대로 결과를 띄우려고 메소드 명 앞에 A, B, C, … 를 넣었다.Map 조회만 했을 때 ms로는 시간측정이 되지 않아서 ns로 측정했다.jmh{ fork = 1 warmupIterations = 10 iterations = 10}@State(Scope.Benchmark)@BenchmarkMode(Mode.AverageTime)@OutputTimeUnit(TimeUnit.NANOSECONDS)public class LastLineBenchmark {}map의 값 유무에 따라 map에서 조회하거나 file에서 조회 하는 방식을 jmh에서 사용하기 위해file에서 먼저 조회하고 file 조회 로직에 map에 값을 넣는 로직을 추가했다.내가 최종적으로 작성한 코드를 반영한 메서드는 getFileAftergetMap이다.jmh 결과를 통해 AtestOriginal 메서드는 파일을 열어서 7줄을 읽는 코드로,BtestImproved는 1줄만 읽는 코드로 개선되었다.그리고 DgetFileAftergetMap는 1줄을 읽지만 파일로만 읽지 않고 map의 값을 활용하는 코드다.FonlyGetMap과 ConlyGetFile의 코드를 합친 것이 DgetFileAftergetMap인데,하나만 실행했을 때 시간차이를 체크하기 위해 작성했다.참고로 BtestImproved와 ConlyGetFile의 시간차이가 나는 이유는코드를 수정하면서 일부 변수들을 더 추가하고 저장하면서 코드의 수정이 일어났기 때문에약간의 차이가 나는 것이다.평균적으로 파일로만 조회하는 경우 약 2.42초가 걸리는 반면,파일을 조회한 후에 map을 조회할 때의 실행 시간이 더 빠르다는 것을 알 수 있다.이를 통해 파일 조회를 최소화하고, map과 같은 메모리 캐싱을 활용하는 것이 효율적인 것으로 판단된다.파일 조회 코드 성능 비교@BenchmarkMode(Mode.AverageTime)@OutputTimeUnit(TimeUnit.MILLISECONDS)@State(Scope.Benchmark)public class ReadFileBenchmark { private String chatUploadLocation; @Setup public void setup() { chatUploadLocation = \"./src/main/resources/static/files/\"; } @Benchmark // 벤치마크 대상 메소드 public Object readFileBefore() throws IOException, ParseException { String roomId = \"111\"; String str = Files.readString(Paths.get(chatUploadLocation + \"/\" + roomId + \".txt\")); JSONParser parser = new JSONParser(); return parser.parse(\"[\" + str + \"]\"); } @Benchmark // 벤치마크 대상 메소드 public Object readFileAfter() throws IOException, ParseException { String roomId = \"111\"; List&lt;String&gt; lines = Files.lines(Paths.get(chatUploadLocation, roomId + \".txt\")).collect(Collectors.toList()); String jsonString = \"[\" + String.join(\",\", lines) + \"]\"; JSONParser parser = new JSONParser(); return parser.parse(jsonString); }}JMH(Java Microbenchmark Harness)을 사용하여 두 개의 파일 읽기 메소드를 벤치마크하는 코드다.JMH는 자바 마이크로 벤치마크 프레임워크로, 자바 성능 측정을 위해 만들어졌다.이 코드는 두 개의 메소드를 실행하여 파일을 읽은 후, 결과를 비교한다.readFileBefore() 메소드는 Files.readString() 메소드를 사용하여 파일을 읽는다.readFileAfter() 메소드는 Files.lines() 메소드를 사용하여 파일을 한 줄씩 읽은 후, 리스트에 담아서 문자열로 변환한다.두 개의 메소드를 실행하여 각각의 실행 시간을 측정한 후, 결과를 비교하여 성능을 개선하였는지 확인할 수 있다.실행마지막 글만 가져오기 성능비교와는 다르게 큰 차이는 없어보인다.jmh{ fork = 1 warmupIterations = 10 iterations = 1}jmh{ fork = 1 warmupIterations = 10 iterations = 10}logResult \"ReadFileBenchmark.readFileAfter\": 1.155 ±(99.9%) 0.232 ms/op [Average] (min, avg, max) = (0.929, 1.155, 1.411), stdev = 0.154 CI (99.9%): [0.923, 1.388] (assumes normal distribution)Result \"ReadFileBenchmark.readFileBefore\": 1.212 ±(99.9%) 0.652 ms/op [Average] (min, avg, max) = (0.854, 1.212, 2.339), stdev = 0.431 CI (99.9%): [0.560, 1.864] (assumes normal distribution)*파일 저장하기는 변경된 부분이 거의 없으므로 성능의 큰 차이가 없을 것이다.따라서 JMH 코드를 작성할 필요가 없다.코드의 가독성을 높이거나 코드 스타일을 변경하는 경우에는 JMH 코드를 작성할 필요가 없다.코드를 변경했을 때 성능이 향상되지 않았더라도 가독성이 높아진다면, 코드를 이해하기 쉬워지므로 변경한 것이 좋다.메소드를 벤치마크한다는 것은 해당 메소드를 실행하여 소요되는 시간, CPU 사용량 등의 성능 지표를 측정하고 분석하는 것을 말한다.즉, 해당 메소드의 성능을 정량적으로 측정하여,application의 병목 구간이나 성능 개선이 필요한 부분을 파악하고 개선할 수 있는 기반을 마련하는 것이다.벤치마크를 통해 개선된 성능은 사용자 경험을 향상시키고, 서버의 처리량을 증가시키며, 더 나은 확장성과 안정성을 제공할 수 있다.변경 전 후 코드파일 저장하기변경 전public void saveFile(ChatMessage chatMessage) { // 파일 저장 if (connectUsers.get(chatMessage.getRoomId()) != 0) { if ((chatMessage.getType().toString()).equals(\"JOIN\")) { reset(chatMessage.getSender(), chatMessage.getRoomId()); } else { countChat(chatMessage.getSender(), chatMessage.getRoomId()); } } JsonObject jsonObject = new JsonObject(); jsonObject.addProperty(\"roomId\", chatMessage.getRoomId()); if (chatMessage.getType().toString().equals(\"JOIN\")) { jsonObject.addProperty(\"type\", \"JOINED\"); } else { jsonObject.addProperty(\"type\", chatMessage.getType().toString()); } jsonObject.addProperty(\"sender\", chatMessage.getSender()); jsonObject.addProperty(\"message\", chatMessage.getMessage()); jsonObject.addProperty(\"adminChat\", adminChat.get(chatMessage.getRoomId())); jsonObject.addProperty(\"userChat\", userChat.get(chatMessage.getRoomId())); Gson gson = new GsonBuilder().setPrettyPrinting().create(); String json1 = gson.toJson(jsonObject); try { FileWriter file = new FileWriter(chatUploadLocation + \"/\" + chatMessage.getRoomId() + \".txt\", true); File file1 = new File(chatUploadLocation + \"/\" + chatMessage.getRoomId() + \".txt\"); if (file1.exists() &amp;&amp; file1.length() == 0) { file.write(json1); chatAlarm(chatMessage.getSender(), chatMessage.getRoomId()); } else { file.write(\",\" + json1); } file.flush(); file.close(); // 연결 끊기 } catch (IOException e) { log.error(\"[error] \" + e); }}변경 후public void saveFile(ChatMessage chatMessage) { if (connectUsers.get(chatMessage.getRoomId()) != 0) { if (chatMessage.getType() == ChatMessage.MessageType.JOIN) { reset(chatMessage.getSender(), chatMessage.getRoomId()); } else { countChat(chatMessage.getSender(), chatMessage.getRoomId()); } } JsonObject jsonObject = new JsonObject(); jsonObject.addProperty(\"roomId\", chatMessage.getRoomId()); if (chatMessage.getType() == ChatMessage.MessageType.JOIN){ jsonObject.addProperty(\"type\", \"JOINED\"); }else { jsonObject.addProperty(\"type\", chatMessage.getType().toString()); } jsonObject.addProperty(\"sender\", chatMessage.getSender()); jsonObject.addProperty(\"message\", chatMessage.getMessage()); jsonObject.addProperty(\"adminChat\", adminChat.get(chatMessage.getRoomId())); jsonObject.addProperty(\"userChat\", userChat.get(chatMessage.getRoomId())); Gson gson = new Gson(); String json = gson.toJson(jsonObject); try (PrintWriter out = new PrintWriter(new BufferedWriter(new FileWriter(chatUploadLocation + \"/\" + chatMessage.getRoomId() + \".txt\", true)))){ if (new File(chatUploadLocation + \"/\" + chatMessage.getRoomId() + \".txt\").length() == 0) { out.println(json); chatAlarm(chatMessage.getSender(), chatMessage.getRoomId()); } else { out.println(\",\" + json); } } catch (IOException e) { log.error(\"[error] \" + e); }}파일을 저장할 때 사용하는 FileWriter 클래스를 PrintWriter 클래스로 대체했다.코드 중간에 조건문을 수정하여 ChatMessage 클래스의 type 속성을 확인할 때 toString() 메서드를 사용하지 않고,ChatMessage.MessageType.JOIN과 같이 enum 상수를 사용하여 비교하는 것으로 변경했다.Gson 클래스를 생성할 때 setPrettyPrinting() 메서드를 사용하지 않아서 코드가 더 간결해졌다.setPrettyPrinting() 메서드는 JSON 데이터를 출력할 때 들여쓰기를 적용하는 기능인데, 이 기능이 필요하지 않아서 생략했다.PrintWriter와 FileWriter 차이 → “data를 출력시키는 방법”개행을 하게 될 때 PrintWriter에서는 println()을 사용하여 자동으로 해주지만FileWriter는 직접 덧붙여야 한다.참고 글 : PrintWriter과 FileWriter 차이파일 조회하기변경 전public Object readFile(String roomId) { long startTime = System.currentTimeMillis(); try { String str = Files.readString(Paths.get(chatUploadLocation + \"/\" + roomId + \".txt\")); JSONParser parser = new JSONParser(); Object obj = parser.parse(\"[\" + str + \"]\"); long stopTime = System.currentTimeMillis(); log.info(\"readFile : \" + (stopTime - startTime) + \" 초\"); return obj; } catch (NoSuchFileException e) { throw new FileNotFoundException(); } catch (IOException | ParseException e) { log.error(\"[error] \" + e); return null; }}변경 후public Object readFile(String roomId) { long startTime = System.currentTimeMillis(); try { List&lt;String&gt; lines = Files.lines(Paths.get(chatUploadLocation, roomId + \".txt\")).collect(Collectors.toList()); String jsonString = \"[\" + String.join(\",\", lines) + \"]\"; JSONParser parser = new JSONParser(); Object obj = parser.parse(jsonString); long stopTime = System.currentTimeMillis(); log.info(\"readFile : \" + (stopTime - startTime) + \" 초\"); return obj; } catch (NoSuchFileException e) { throw new FileNotFoundException(); } catch (IOException | ParseException e) { log.error(\"[error] \" + e); return null; }}Files.readString()을 사용하여 파일의 내용을 가져왔지만,변경 코드에서는 Files.lines()를 사용하여 각 라인을 읽어들인 후 String.join()을 사용하여 하나의 JSON 문자열로 결합했다.또한 Collectors.toList()를 사용하여 리스트로 변환한 후 String.join()을 사용하여 결합했다.파일 마지막 json만 조회변경 전public List lastLine(String roomId) { try{ // 2. 뒤에서 7줄 읽기 RandomAccessFile file = new RandomAccessFile(chatUploadLocation + \"/\" + roomId + \".txt\", \"r\"); StringBuilder lastLine = new StringBuilder(); int lineCount = 7; // 2. 전체 파일 길이 long fileLength = file.length(); // 3. 포인터를 이용하여 뒤에서부터 앞으로 데이터를 읽는다. for (long pointer = fileLength - 1; pointer &gt;= 0; pointer--) { // 3.1. pointer를 읽을 글자 앞으로 옮긴다. file.seek(pointer); // 3.2. pointer 위치의 글자를 읽는다. char c = (char) file.read(); // 3.3. 줄바꿈이 7번(lineCount) 나타나면 더 이상 글자를 읽지 않는다. if (c == '\\n') { lineCount--; if (lineCount == 0) { break; } } // 3.4. 결과 문자열의 앞에 읽어온 글자(c)를 붙여준다. lastLine.insert(0, c); } StringTokenizer st = new StringTokenizer(lastLine.toString(), \",\"); String roomNum = st.nextToken().trim(); String type = st.nextToken().trim(); String sender = st.nextToken().trim(); String msg = st.nextToken().trim(); String admin = st.nextToken().trim(); String user = StringUtils.removeEnd(st.nextToken().trim(), \"}\"); String adminChat = admin.substring(admin.indexOf(\"adminChat\")+12); String userChat = user.substring(user.indexOf(\"userChat\")+11); String message = msg.substring(msg.indexOf(\"message\")+10); String messages = new String(message.getBytes(\"iso-8859-1\"), \"utf-8\"); List&lt;String&gt; chat = new ArrayList&lt;&gt;(); chat.add(adminChat.trim()); chat.add(userChat.trim()); chat.add(messages.trim()); return chat; // 4. 결과 출력 }catch (FileNotFoundException e) { e.printStackTrace(); } catch (IOException e) { e.printStackTrace(); } return new ArrayList&lt;&gt;();}변경 후public List&lt;String&gt; lastLine(String roomId) { try (RandomAccessFile file = new RandomAccessFile(chatUploadLocation + \"/\" + roomId + \".txt\", \"r\")) { long fileLength = file.length(); // 파일 포인터를 파일 끝으로 이동시킴 file.seek(fileLength); // 파일 포인터를 끝에서 두 번째 줄의 시작 지점으로 이동시킴 long pointer = fileLength - 2; while (pointer &gt; 0) { file.seek(pointer); char c = (char) file.read(); if (c == '\\n') { break; } pointer--; } file.seek(pointer + 1); // 두 번째 줄의 내용을 읽어서 반환함 String line = file.readLine(); if (line == null || line.trim().isEmpty()) { return Collections.emptyList(); } if (line.startsWith(\",\")) { line = line.substring(1); } JSONObject json = new JSONObject(line); int adminChat = json.getInt(\"adminChat\"); int userChat = json.getInt(\"userChat\"); String message = json.getString(\"message\").trim(); String messages = new String(message.getBytes(\"iso-8859-1\"), \"utf-8\"); List&lt;String&gt; chat = new ArrayList&lt;&gt;(); chat.add(Integer.toString(adminChat)); chat.add(Integer.toString(userChat)); chat.add(messages); return chat; } catch (IOException | JSONException e) { e.printStackTrace(); return Collections.emptyList(); }}파일이 저장될 때 마지막 줄은 공백으로 비워져 있다.그래서 끝에서 2번째 줄을 가지고 오는 코드로 작성했다. try-with-resources 구문을 사용하여 파일 close()를 명시적으로 호출하지 않아도 자동으로 파일을 닫아준다. 파일 포인터를 끝에서 두 번째 줄의 시작 지점으로 이동시켜서 파일을 한 번만 읽어도 되도록 개선되었다. 이전 코드에서는 파일의 끝부터 7줄을 읽어야 했다. 불필요한 문자열 처리가 제거되어 코드가 간결해졌다. 이전 코드에서는 문자열을 분리하고 다시 합치는 등의 작업이 있었지만, 변경된 코드에서는 JSON 객체를 바로 파싱하여 필요한 값을 추출했다. 변경된 코드는 이전 코드보다 효율적이고 간결해졌다.2차 수정채팅방을 키고 닫고를 자주 하면서 계속 파일을 열고 마지막 글을 가져오는 시간이 너무 많이 소요되는 것 같아 수정했다.채팅을 할 때 HashMap으로 값을 변경하면서 가장 최근에 작성한 글만 담아두고 있다가채팅방 리스트를 띄울 때 가장 최근의 글을 HashMap으로 값을 가져오게 했다.위에서 작성했던 코드는 채팅을 입력하지 않은 처음 시작할 때만 실행되고 그 이후에는 HashMap을 활용하게 했다.lastMessageMap은 채팅을 하면 해당 기록을 파일에 저장 하는 과정에서 update하게 된다.그 과정에서 return값을 DTO로 변경하고 dto에서 활용할 때 list.get(0) 과 같이순서에 의해 값을 설정했는데 dto에서 값을 꺼내오는 것으로 변경했다.파일 저장 method 코드 추가// 파일 저장 메소드 내 코드 추가LastMessage lastMessage = LastMessage.of(chatMessage, adminCnt, userCnt, days, time);lastMessageMap.put(chatMessage.getRoomId(), lastMessage);Dto// 변경 전public static ChatRoomDto of(String roomId, String nickname, User user, List&lt;String&gt; list) { return ChatRoomDto.builder() .roomId(roomId) .nickname(user.getNickname()) .adminChat(Integer.valueOf(list.get(0))) .userChat(Integer.valueOf(list.get(1))) .message(list.get(2)) .day(list.get(3)) .time(list.get(4)) .build();}// 변경 후public static ChatRoomDto of(String roomId, User user, LastMessage lastMessage) { return ChatRoomDto.builder() .roomId(roomId) .nickname(user.getNickname()) .adminChat(lastMessage.getAdminChat()) .userChat(lastMessage.getUserChat()) .message(lastMessage.getMessage()) .day(lastMessage.getDay()) .time(lastMessage.getTime()) .build();}최근 채팅 기록 가져오기private Map&lt;String, LastMessage&gt; lastMessageMap;@PostConstruct // @PostConstruct는 의존성 주입이 이루어진 후 초기화를 수행하는 메서드private void setUp() { this.lastMessageMap = new ConcurrentHashMap&lt;&gt;();}public LastMessage lastLine(String roomId) { if(lastMessageMap.containsKey(roomId)){ log.info(\" = = = MAP 활용 = = = \"); return lastMessageMap.get(roomId); }else{ log.info(\" = = = MAP 활용 X = = = \"); String filePath = chatUploadLocation + \"/\" + roomId + \".txt\"; // 이하 변경 전 코드와 동일 }}Reference [Java] gradle 환경에서 JMH를 사용하여 벤치마킹하기 JMH를 사용한 gradle 환경에서의 Java 코드 벤치마킹 JMH(Java Microbenchmark Harness) 사용법 JMH" }, { "title": "Redis cache", "url": "/posts/Redis-Cache/", "categories": "Project, Redis", "tags": "spring, Redis, Cache, Chat", "date": "2023-04-28 00:00:00 +0900", "snippet": "Redis란Redis(Remote Dictionary System)는 인메모리 데이터 저장소로주로 세션 관리, 캐싱, db 및 메시지 브로커 역할을 수행하는 오픈 소스다.다양한 데이터 타입(String, List, Hash, Set 등)을 지원하며단일 스레드로 동작하여 동시성 이슈가 적고 빠른 속도를 제공한다.유연한 데이터 모델 지원하여 대용량 데이터를 처리하는 데 유용한 NoSQL 데이터베이스로 활용된다.Redis Cache캐싱(Cache)은 자주 참조되는 데이터를 메모리에 저장하여 반복 작업을 줄이고 성능을 향상시키는 것을 의미한다.Redis Cache는 인메모리 데이터 저장소로, 빠른 응답이 필요한 애플리케이션에서 효과적이다.Redis Cache를 적용하는 방법은 크게 두 가지로 나눌 수 있다.1. Spring 어노테이션 사용 (@Cacheable, @CachePut 등)2. RedisTemplate 사용이 글에서는 두 가지 방법을 통해 Redis Cache를 적용하는 과정을 설명한다.나는 두 가지 방법 모두 사용하여 Redis Cache를 적용했다.RedisTemplate을 사용하여 특정 데이터를 선택적으로 저장하고 검색했으며Annotation을 사용하여 전체 method의 결과를 캐시했다.spring.io - cacheCache 설정1. 의존성 추가build.gradle에 의존성 추가implementation 'org.springframework.boot:spring-boot-starter-data-redis'implementation 'org.springframework.boot:spring-boot-starter-cache'2. 설정 파일 구성application.properties에서 Redis 정보 추가#redis cachespring.cache.type = redis# redis dockerspring.redis.host = host.docker.internalspring.redis.port = 6379spring.cache.redis.cache-null-values=false # null 값도 캐시할지 여부3. Redis 설정 파일 작성Redis Cache 기능을 활성화하고 Redis 연결 정보를 설정하기 위해 RedisConfig 클래스를 작성했다.@Configuration@EnableCaching // 캐시 기능 활성화 public class RedisConfig { @Value(\"${spring.redis.host}\") private String redisHost; @Value(\"${spring.redis.port}\") private int redisPort; @Bean public RedisConnectionFactory redisConnectionFactory() { return new LettuceConnectionFactory(redisHost, redisPort); } @Bean public CacheManager cacheManager() { // Spring 어노테이션 사용할 때 작성하는 설정 RedisCacheConfiguration cacheConfig = RedisCacheConfiguration.defaultCacheConfig() .serializeKeysWith(RedisSerializationContext.SerializationPair.fromSerializer(new StringRedisSerializer())) .serializeValuesWith(RedisSerializationContext.SerializationPair.fromSerializer(new GenericJackson2JsonRedisSerializer())) .entryTtl(Duration.ofMinutes(30)); return RedisCacheManager.builder(redisConnectionFactory()) .cacheDefaults(cacheConfig) .build(); }} serializeKeysWith(): Redis에 저장되는 key의 직렬화 방식을 설정. StringRedisSerializer를 사용해 문자열로 직렬화 serializeValuesWith() : Redis에 저장되는 value의 직렬화 방식을 설정. GenericJackson2JsonRedisSerializer를 사용해 JSON 형식으로 직렬화하여 객체 데이터를 JSON으로 저장 entryTtl : 캐시 데이터의 유효 시간 설정 → 30분 참고)CacheManager 설정은 Spring 어노테이션 기반 캐시와 연동되므로RedisTemplate으로 Redis를 제어할 때는 이 설정을 따르지 않는다.RedisTemplate에서는 TTL 등 설정을 개별적으로 코드 내에서 정의할 수 있다.4. 캐시 적용하기 : annotation 활용사용할 서비스 method에 annotation 적용하면 된다. @Cacheable : 메서드의 결과를 캐시에 저장하고, 이후에 동일한 인자로 메서드가 호출될 때 캐시에서 결과를 반환 캐시에 데이터가 존재하면 메서드의 로직을 실행하지 않고 캐시에서 데이터를 조회하여 반환 캐시에 데이터가 없으면 메서드의 로직을 실행하고 그 결과를 캐시에 저장한 후 반환 @CacheEvict : 지정된 캐시에서 데이터를 제거. 주로 데이터를 삭제할 때 사용 @CachePut : 메서드의 결과를 강제로 캐시에 저장. 주로 데이터를 갱신할 때 사용 메서드의 로직을 실행하고 그 결과를 캐시에 저장 항상 메서드의 로직을 실행하므로 캐시에서 데이터를 조회하지 않는다. condition, unless 어노테이션 옵션으로 특정 조건에 따른 캐시적용여부 설정도 가능하다.@Cacheable(key = \"#nickname\", value = \"createRoom\", unless = \"#result == null\", cacheManager = \"cacheManager\")public ChatRoomDto createRoom(String nickname) { // 메서드 로직}@Cacheable은 캐시에 이미 데이터가 있으면 메서드 로직을 실행하지 않고 캐시에서 데이터를 반환한다.@CachePut을 사용하면 매번 메서드 로직이 실행되어 최신 상태가 유지된다. unless = \"#result == null\" : 반환값이 null일 경우 캐시 저장을 하지 않도록 설정 cacheManager = \"cacheManager\" : 위의 config에서 작성한 cacheManager 사용 @Cacheable의 key 속성은 캐시할 데이터의 key를 지정하고, value 속성은 캐시할 데이터의 value를 지정한다.여기서 key는 사용자의 nickname이 되고 value는 createRoom()의 반환값이 저장 될 것이다.@Cacheable 어노테이션에서 value를 설정할 때 mehtod의 반환 타입이 void인 경우value를 지정할 수 없으므로 value = ““와 같이 빈 문자열로 설정해야 한다.4.1 문제점기존에 @Caceable을 사용했으나 값을 제대로 가져올 때가 있고 없을 때가 있었다.처음엔 cacheManager 설정도 바꿔보다가@CachePut으로 바꾸고 test를 해보니 값을 제대로 가져오기 시작했다.왜 @Caceable에서 @CachePut로 수정을 하니 제대로 동작했을까?@Cacheable 어노테이션은 메서드가 호출되기 전에 캐시를 확인하고, 캐시에 저장된 결과가 있으면 해당 결과를 반환한다.만약 캐시에 값이 없을 때 null을 반환한다면, 이후에도 항상 null을 반환할 것이다.@CachePut 어노테이션은 메서드의 로직을 실행하고 그 결과를 강제로 캐시에 저장한다.매번 메서드가 호출될 때마다 로직이 실행되고 그 결과가 캐시에 갱신된다.그래서 null 값을 방지 하기 위해 unless = \"#result == null\"로 작성하고 RedisConfig에서도 추가했다.@Beanpublic CacheManager cacheManager() { RedisCacheConfiguration cacheConfig = RedisCacheConfiguration.defaultCacheConfig() .disableCachingNullValues() // null value cache X .entryTtl(Duration.ofHours(3)) .serializeKeysWith(RedisSerializationContext.SerializationPair.fromSerializer(new StringRedisSerializer())) .serializeValuesWith(RedisSerializationContext.SerializationPair.fromSerializer(new GenericJackson2JsonRedisSerializer())); return RedisCacheManager.builder(redisConnectionFactory()) .cacheDefaults(cacheConfig) // 기본 캐시에 TTL 적용 .build();}5. TTL 설정TTL은 “Time To Live”의 약자로, 캐시된 데이터가 유효한 시간을 의미한다.Redis에서 기본 TTL을 설정하거나, 특정 캐시별로 TTL을 다르게 적용할 수도 있다.데이터가 없는 경우 캐시에 null 값을 저장할 경우에는 TTL이 적용되지 않는다.캐시된 데이터가 null 일 때도 TTL을 적용하도록 설정하고 싶다면RedisCacheConfiguration.defaultCacheConfig().disableCachingNullValues()를 사용하면 된다.@Beanpublic CacheManager cacheManager() { RedisCacheConfiguration defaultCacheConfig = RedisCacheConfiguration.defaultCacheConfig() .entryTtl(Duration.ofHours(3)) // 기본 TTL은 3시간 .serializeKeysWith(RedisSerializationContext.SerializationPair.fromSerializer(new StringRedisSerializer())) .serializeValuesWith(RedisSerializationContext.SerializationPair.fromSerializer(new GenericJackson2JsonRedisSerializer())); RedisCacheConfiguration roomIdCacheConfig = RedisCacheConfiguration.defaultCacheConfig() .entryTtl(Duration.ofHours(5)) // roomId 캐시의 TTL을 5시간으로 설정 .serializeKeysWith(RedisSerializationContext.SerializationPair.fromSerializer(new StringRedisSerializer())) .serializeValuesWith(RedisSerializationContext.SerializationPair.fromSerializer(new GenericJackson2JsonRedisSerializer())); return RedisCacheManager.builder(redisConnectionFactory()) .cacheDefaults(defaultCacheConfig) .withCacheConfiguration(\"roomId\", roomIdCacheConfig) // ROOMID 캐시에 대한 설정 적용 .build();}.withCacheConfiguration(\"roomId\", roomIdCacheConfig) : roomId 캐시에 대한 설정을 cacheConfig로 지정CacheManagerBuilder에서 roomId 캐시에 대한 설정을 지정하기 위한 것이다.어노테이션을 활용해서 Cache를 적용할 때 value 값으로 “roomId”를 설정하면해당 method의 return값은 TTL이 5시간 적용되어 활용된다.여기서 roomId는 아래 코드 처럼 value에 적힌 값이 된다.@Cacheable(key = \"#chatMessage.sender\", value = \"roomId\", unless = \"#chatMessage.roomId == null\")만약 모든 어노테이션에 캐시를 적용할 것이라면 아래와 같이 작성하면 된다.@Beanpublic CacheManager cacheManager() { RedisCacheConfiguration cacheConfig = RedisCacheConfiguration.defaultCacheConfig() .entryTtl(Duration.ofHours(3)) .serializeKeysWith(RedisSerializationContext.SerializationPair.fromSerializer(new StringRedisSerializer())) .serializeValuesWith(RedisSerializationContext.SerializationPair.fromSerializer(new GenericJackson2JsonRedisSerializer())); return RedisCacheManager.builder(redisConnectionFactory()) .cacheDefaults(cacheConfig) // 기본 캐시에 TTL 적용 .build();} 6. RedisTemplate을 활용한 Cache 적용RedisTemplate을 사용하면 데이터 접근과 제어를 세부적으로 설정할 수 있다.6.1 RedisTemplate 설정@Configuration@EnableCachingpublic class RedisConfig { @Bean //Redis 데이터에 쉽게 접근하기 위한 코드 public RedisTemplate&lt;String, String&gt; redisTemplate() { //RedisTemplate 에 LettuceConnectionFactory 을 적용 RedisTemplate&lt;String, String&gt; redisTemplate = new RedisTemplate&lt;&gt;(); redisTemplate.setConnectionFactory(redisConnectionFactory()); redisTemplate.setKeySerializer(new StringRedisSerializer()); redisTemplate.setValueSerializer(new StringRedisSerializer()); return redisTemplate; } @Bean public RedisTemplate&lt;String, ChatRoomDto&gt; chatRoomDtoRedisTemplate() { RedisTemplate&lt;String, ChatRoomDto&gt; redisTemplate = new RedisTemplate&lt;&gt;(); redisTemplate.setConnectionFactory(redisConnectionFactory()); redisTemplate.setKeySerializer(new StringRedisSerializer()); redisTemplate.setValueSerializer(new GenericJackson2JsonRedisSerializer()); // JSON 직렬화 설정 return redisTemplate; }}6.2 데이터 저장과 조회ChatMessage.sender와 nickname은 같은 값private final RedisTemplate&lt;String, String&gt; redisTemplate;public void addRedis(ChatMessage chatMessage){ long expireTimeInSeconds = 24 * 60 * 60; long creationTimeInMillis = System.currentTimeMillis(); long remainingTimeInSeconds = expireTimeInSeconds - ((System.currentTimeMillis() - creationTimeInMillis) / 1000); redisTemplate.opsForValue().set(chatMessage.getSender(), chatMessage.getRoomId(), remainingTimeInSeconds, TimeUnit.SECONDS);}public String getRedis(String nickname){ return redisTemplate.opsForValue().get(\"roomId:\" + nickname);}redisTemplate의 opsForValue() 를 이용해 chatMessage.getSender()를 key로 하고chatMessage.getRoomId()를 value로 하는 key-value 쌍을 Redis에 저장하고 있다.Redis에 저장되는 데이터의 구조는 sender가 key이고 roomId가 value인 형태가 된다.redisTemplate.opsForValue().set()의 마지막 인자로 TTL을 지정하는 방식으로 Redis 캐시에 TTL을 설정했다.24시간을 기준으로 현재시간으로 부터 남은 시간을 초 단위로 계산해서 만료시간 설정한다.어노테이션을 사용하면 bean에서 설정한 TTL이 적용되고RedisTemplate을 사용해 데이터를 저장하면 코드에서 설정한 TTL(24시간)이 적용된다.💡 결론RedisTemplate을 사용하면 캐시를 저장할 때 TTL과 같이 직접 설정이 가능하다.redisTemplate.opsForValue().set(key, value);@Cacheable과과 같이 어노테이션을 사용할 때는 메서드의 반환 값이 자동으로 캐시에 저장된다.어노테이션을 사용하면 무조건 반환되는 타입으로만 Redis에 저장이 되므로,반환되는 값이 아닌 데이터를 Redis에 저장할 때에는 직접 RedisTemplate를 통해 구현하면 된다.REFERENCE Spring Cache, 제대로 사용하기 [JAVA Spring Boot] Rest API + 레디스 캐시 (Redis Cache) 적용 및 샘플 예제 SpringBoot기반 Redis Cache 활용법 Cache 기능 Redis로 구현하기 [Spring] Spring에서 Redis로 Cache 사용하기 (CrudRepository, RedisTemplate) Springboot: redis를 통해 캐시 기능 간단 적용" }, { "title": "Websocket test", "url": "/posts/WebSocket-Test/", "categories": "Project", "tags": "spring, WebSocket, Chat, test", "date": "2023-04-26 00:00:00 +0900", "snippet": "WebSocket Test관련 글 Websocket Websocket + 부가기능 Websocket (채팅 기록 json 파일 저장하기) Sse Sse 문제점 Websocket + jwt Websocket test 👈🏻 Jmh - 채팅 파일 refactoring채팅 애플리케이션에서 WebSocket을 이용해 메세지 송수신을 구현한 경우, 해당 기능을 테스트해볼 필요가 있다.이를 위해 테스트 코드를 작성할 수 있는데, 이 과정에서 Mockito 프레임워크를 활용할 수 있다.Mockito는 객체의 행위를 검증하기 위한 프레임워크로, 테스트 코드 작성 시 객체를 가짜 객체로 만들어 원하는 대로 동작하도록 설정할 수 있다.즉, 테스트 코드에서 객체가 실제로 실행되지 않고, 미리 정해진 동작만 수행하도록 구현되는 것이다.class ChatControllerTest { // server → client @Mock private SimpMessagingTemplate template; /* ChatController의 sendMessage() 메소드에서 실제로 template.convertAndSend()가 호출되는지 확인하기 위해서 SimpMessagingTemplate 인스턴스를 Mock 객체로 생성 */ @InjectMocks private ChatController chatController; @BeforeEach void setUp() { // @ExtendWith(MockitoExtension.class)를 class에 붙이거나 해당 메소드를 쓰거나 /* @Mock 어노테이션으로 선언된 필드들을 초기화 하기 위해서는 MockitoAnnotations 클래스의 openMocks() 메소드를 이용해야한다. 이 코드는 모든 @Mock 어노테이션으로 선언된 필드를 초기화 하기 위해 작성*/ MockitoAnnotations.openMocks(this); // this : ChatControllerTest 클래스의 인스턴스 //@Mock 어노테이션을 통해 선언한 SimpMessagingTemplate 객체를 Mockito에서 제공하는 mock 객체로 만들기 위해서는 this 인스턴스를 전달 } @Test void sendMessageTest() { // given ChatMessage chatMessage = new ChatMessage(); chatMessage.setType(ChatMessage.MessageType.TALK); chatMessage.setMessage(\"message\"); chatMessage.setSender(\"sender\"); chatMessage.setRoomId(\"roomId\"); /* client -&gt; server (없어도 되는 코드) StompHeaderAccessor headerAccessor = StompHeaderAccessor.create(StompCommand.SEND); headerAccessor.setDestination(\"/app/chat/sendMessage\"); headerAccessor.setSessionId(\"session1\"); //StompSession을 생성하면 내부에서는 자동으로 sessionId를 생성 headerAccessor.setSessionAttributes(new HashMap&lt;&gt;()); */ // when chatController.sendMessage(chatMessage); // then verify(template).convertAndSend(eq(\"/topic/public/\" + chatMessage.getRoomId() ), eq(chatMessage)); // verify : 특정 객체가 특정 메소드를 특정 매개 변수로 호출되는지 확인 // verify(template) : SimpMessagingTemplate 객체가 제공하는 메소드 중 하나가 호출되었는지 검증하는 용도 // eq : Mockito에서 제공하는 메소드로, 객체를 비교할 때 사용 }}WebSocket 통신에서 사용하는 SimpMessagingTemplate 객체를 테스트하기 위해,해당 객체를 가짜 객체로 만들어 Mockito를 이용해 동작을 검증할 수 있다.테스트 코드에서는 @Mock 어노테이션을 사용해 SimpMessagingTemplate을 가짜 객체로 만들어주고,@InjectMocks 어노테이션을 사용해 ChatController 객체에 가짜 객체를 주입한다.또한, WebSocket으로 메세지를 송수신하는 경우, 송수신할 때의 메세지 형식도 매우 중요하다.이를 테스트하기 위해, 예상되는 메세지와 실제 전송되는 메세지를 검증할 필요가 있다.이를 위해 verify 메소드를 사용해 SimpMessagingTemplate 객체에서 전송된 메세지가 예상한 대로인지 검증할 수 있다.테스트 코드에서는 MockitoAnnotations.openMocks(this) 코드를 사용해 테스트 클래스 내의 객체를 가짜 객체로 만들어 줄 수 있다.이 코드를 사용하면, @BeforeEach 어노테이션에서 가짜 객체를 생성하는 코드를 작성할 필요가 없어져 더욱 편리하다.마지막으로, @ExtendWith(MockitoExtension.class) 어노테이션을 통해 JUnit5에서 Mockito를 사용할 수 있다.하지만 이미 MockitoAnnotations.openMocks(this) 코드를 사용했기 때문에 이 어노테이션을 사용할 필요가 없다.@ExtendWith(MockitoExtension.class)를 작성하면 JUnit Jupiter의 기능을 확장할 수 있지만,MockitoExtension은 이미 기본으로 활성화되어 있기 때문에, 굳이 @ExtendWith(MockitoExtension.class)를 작성하지 않아도 된다.@ExtendWith(MockitoExtension.class)를 작성하고 싶다면 @BeforeEach void setUp() {} 코드를 제거하면 된다." }, { "title": "Redis 적용", "url": "/posts/Redis-%EC%A0%81%EC%9A%A9/", "categories": "Project, Redis", "tags": "spring, Redis", "date": "2023-04-17 00:00:00 +0900", "snippet": "RedisJava의 Redis ClientJava 의 Redis Client 는 크게 두 가지가 있다. → Jedis 와 Lettuce원래 Jedis 를 많이 사용했으나 여러 가지 단점 (멀티 쓰레드 불안정, Pool 한계 등등..) 과Lettuce 의 장점 (Netty 기반이라 비동기 지원 가능) 때문에 Lettuce 로 추세가 넘어가고 있었다.그러다 결국 Spring Boot 2.0 부터 Jedis 가 기본 클라이언트에서 deprecated 되고 Lettuce 가 탑재되었다.관련 글 Jedis 보다 Lettuce 를 쓰자2가지 접근 방식Spring Data Redis는 Redis에 2가지 접근 방식을 제공한다.RedisTemplate, Redis Repository를 이용한 방식이다.공통 setting공식문서build.gradle의존성 추가implementation 'org.springframework.boot:spring-boot-starter-data-redis'implementation 'org.springframework.session:spring-session-data-redis'application.propertieshost 와 port 를 설정한다.spring.redis.host = host.docker.internalspring.redis.port = 6379나는 docker에서 redis를 실행시켰기 때문에 host를 위와 같이 작성했다.6379는 기본값이기 때문에 만약 Redis를 6379 로 띄웠다면 따로 설정하지 않아도 연결이 된다.코드에서 properties에 작성한 값을 로딩할 때는@Value(\"${spring.redis.port}\")와 같이 SpEL(Spring Expression Language)을 작성하면 된다.application@SpringBootApplication@EnableRedisHttpSession //Redis에 세션 데이터를 저장public class AdmeApplication { // chat/room public static void main(String[] args) { SpringApplication.run(AdmeApplication.class, args);ConfigSpring Boot의 RedisAutoConfiguration은 RedisTemplate과 StringRedisTemplate 두 가지 bean을 자동으로 생성하여 제공하고 있다.따라서 만약 개별 설정을 하고자 하는 경우 아래와 같이 작성하면 된다.@Configurationpublic class RedisConfig { @Value(\"${spring.redis.host}\") private String redisHost; @Value(\"${spring.redis.port}\") private int redisPort;/*RedisTemplate 에 LettuceConnectionFactory 을 적용해주기 위해 설정*/ @Bean public RedisConnectionFactory redisConnectionFactory() { return new LettuceConnectionFactory(redisHost, redisPort); } @Bean //Redis 데이터에 쉽게 접근하기 위한 코드 public RedisTemplate&lt;?, ?&gt; redisTemplate() { //RedisTemplate 에 LettuceConnectionFactory 을 적용 RedisTemplate&lt;?, ?&gt; redisTemplate = new RedisTemplate&lt;&gt;(); redisTemplate.setConnectionFactory(redisConnectionFactory()); //모든 Key, Value Serialization을 변경할 수 있음 redisTemplate.setKeySerializer(new StringRedisSerializer()); redisTemplate.setValueSerializer(new StringRedisSerializer()); return redisTemplate; } @Bean public StringRedisTemplate stringRedisTemplate() { //StringRedisTemplate은 문자열을 다룰 때 사용 StringRedisTemplate stringRedisTemplate = new StringRedisTemplate(); stringRedisTemplate.setKeySerializer(new StringRedisSerializer()); stringRedisTemplate.setValueSerializer(new StringRedisSerializer()); stringRedisTemplate.setConnectionFactory(redisConnectionFactory()); return stringRedisTemplate; }}StringRedisTemplate - docs.spring.ioRedisTemplate과 RedisTemplate의 문자열 중심 확장인 StringRedisTemplate 타입이 있다.RedisTemplate의 defaultSerializer는 JdkSerializationRedisSerializer이고StringRedisTemplate의 defaultSerializer는 StringRedisSerializer이다.stringRedisTemplate bean은 일반적인 String 값을 key, value로 사용하는 경우 사용하면 된다.redisTemplate bean은 java Object를 redis에 저장하는 경우 사용하면 된다.public class StringRedisTemplate extends RedisTemplate&lt;String,String&gt;StringRedisTemplate은 따로 Bean으로 안만들어도 쓸 수 있다.RedisTemplateController @MessageMapping(\"/chat/addUser\") private final RedisService redisService; private final Long hours = 10L; public void addUser(@Payload ChatMessage chatMessage, @Header(\"Authorization\") String token) { String nickname = jwtTokenProvider.getNickname(token); chatMessage.setSender(nickname); redisService.setRedisTemplate(chatMessage, hours); redisService.getRedisTemplate(chatMessage.getSender()); chatService.connectUser(\"Connect\", chatMessage.getRoomId()); template.convertAndSend(\"/topic/public/\" + chatMessage.getRoomId(), chatMessage); }Service@Service@RequiredArgsConstructor //public class RedisService { private final RedisTemplate&lt;String, String&gt; redisTemp; private final StringRedisTemplate redisTemplate; private final RedisRepository redisRepository; // string (opsForValue) public void setRedisTemplate(ChatMessage chatMessage, Long expirationTime){ redisTemplate.opsForValue().set(chatMessage.getSender(), chatMessage.getRoomId(), expirationTime, TimeUnit.HOURS); // 키가 이미 있다면 마지막에 Set한 값으로 덮어씀 } public String getRedisTemplate(String key){ return redisTemplate.opsForValue().get(key); } public void setRedisValue(ChatMessage chatMessage){ ValueOperations&lt;String, String&gt; values = redisTemp.opsForValue(); values.set(chatMessage.getSender(), chatMessage.getRoomId()); } public String getRedisValue(String key){ ValueOperations&lt;String, String&gt; values = redisTemp.opsForValue(); return values.get(key); }}String에 특화된 StringRedisTemplate이므로String 만 다루려면 아래 서비스 사용하고, 그게 아니라면 RedisTemplate 빈 정의하여 사용하면 된다.redisTemplate을 주입받은 후에 원하는 Key, Value 타입에 맞게 Operations 을 선언해서 사용할 수 있다.ValueOperations, SetOperations, HashOperations은 각각 Strings, Set, Hash 자료구조에 대한 Operations이다.ex) SetOperations&lt;String, String&gt; setOperations = redisTemp.opsForSet(); method 설명 opsForValue Strings를 쉽게 Serialize / Deserialize 해주는 Interface opsForList List를 쉽게 Serialize / Deserialize 해주는 Interface opsForSet Set를 쉽게 Serialize / Deserialize 해주는 Interface opsForZSet ZSet를 쉽게 Serialize / Deserialize 해주는 Interface opsForHash Hash를 쉽게 Serialize / Deserialize 해주는 Interface Redis RepositoryDto@Getter@AllArgsConstructor@NoArgsConstructor@Builderpublic class RedisResponseDto { private String nickname; private String roomId; private Long hour; public static RedisResponseDto of(Redis redis){ return RedisResponseDto.builder() .nickname(redis.getNickname()) .roomId(redis.getRoomId()) .hour(redis.getExpiration()) .build(); }}Redis@Getter@RedisHash(\"chatRoom\")@ToString@NoArgsConstructor(access = AccessLevel.PROTECTED)public class Redis { @Id private String id; @Indexed // 필드 값으로 데이터 찾을 수 있게 하는 어노테이션(findByAccessToken) private String nickname; private String roomId; @TimeToLive(unit = TimeUnit.HOURS) private Long expiration; @Builder public Redis(String nickname, String roomId, Long hour){ this.nickname = nickname; this.roomId = roomId; this.expiration = hour; }}Repositorypublic interface RedisRepository extends CrudRepository&lt;Redis, String&gt; { Redis findByNickname(String nickname);}Servicepublic void addRedis(ChatMessage chatMessage, Long hours){ Redis redis = new Redis(chatMessage.getSender(), chatMessage.getRoomId(), hours); Redis save = redisRepository.save(redis);}public String getRedis(String key){ Redis byNickname = redisRepository.findByNickname(key); return RedisResponseDto.of(byNickname).getRoomId();}public void deleteRedis(String key){ redisTemplate.delete(key);}Docker Redis 설치*나는 docker desktop을 이용했지만 직접 설치하고 싶은 경우에 “Redis 오류”에 첨부한 링크 참고하면 된다.redis를 run한 다음에Optional settings에서 container name과 port를 작성했다.그 다음에 application을 실행시키면 정상적으로 동작한다.$ docker psdocker에 띄워진 컨테이너 확인CONTAINER ID 값 복사docker exec -it {Redis컨테이너이름} redis-clidocker로 redis 컨테이너를 실행*-it란 무엇일까?-it를 붙여줘야, 명령어를 실행한 후 계속 명령어를 적을 수 있다고 한다.만약 -it 가 없다면, redis-cli를 열어주기만 했다가 바로 다시 밖으로 나와버린다. 따라서 -it를 반드시 적어준다.02. Docker 통한 Redis CLI 접속 방법 + 기본 사용법$ keys *redis에 저장된 key들을 확인[Redis] docker로 설치한 redis 접근$ flushall : 전체 키 삭제Redis 오류1. org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis; nested exception is io.lettuce.core.RedisConnectionException: Unable to connect to localhost/&lt;unresolved&gt;:6379처음엔 application.properties에 spring.redis.host = localhost 로 설정했다.docker에 redis 설치후에 spring.redis.host = host.docker.internal로 변경했더니 실행이 잘 되었다.도커에서 컨테이너를 띄우면 각 컨네이너와 localhost는 독립적이게 된다.따라서 docker에서 실행중인 서버는 localhost로 접속을 하는 것이 아닌 docker host ip를 통해서 접속을 해야 한다.redis 설치할 때 참고한 blog window로 redis 설치 👉🏻 [REDIS] 📚 Window10 환경에 Redis 설치 &amp; 설정 docker로 redis 설치 👉🏻 Springboot에서 Docker Redis와 연동하기오류 해결 참고글 👉🏻 Docker Redis + Spring 연결2. RedisConfig - bean이 2개 @Bean //Redis 데이터에 쉽게 접근하기 위한 코드 public RedisTemplate&lt;String, String&gt; redisTemplate() { //RedisTemplate 에 LettuceConnectionFactory 을 적용 RedisTemplate&lt;String, String&gt; redisTemplate = new RedisTemplate&lt;&gt;(); redisTemplate.setConnectionFactory(redisConnectionFactory()); redisTemplate.setKeySerializer(new StringRedisSerializer()); redisTemplate.setValueSerializer(new StringRedisSerializer()); return redisTemplate; } @Bean public StringRedisTemplate stringRedisTemplate() { //StringRedisTemplate은 문자열을 다룰 때 사용 StringRedisTemplate stringRedisTemplate = new StringRedisTemplate(); stringRedisTemplate.setKeySerializer(new StringRedisSerializer()); stringRedisTemplate.setValueSerializer(new StringRedisSerializer()); stringRedisTemplate.setConnectionFactory(redisConnectionFactory()); return stringRedisTemplate; }StringRedisTemplate만 사용하려고 해서 굳이 bean등록을 안해도 되지만 한번 써보기 위해서 작성했다가 아래와 같이 에러가 떴다.***************************APPLICATION FAILED TO START***************************Description:Parameter 0 of constructor in com.dalcho.adme.service.RedisService required a single bean, but 2 were found: - redisTemplate: defined by method 'redisTemplate' in class path resource [com/dalcho/adme/config/RedisConfig.class] - stringRedisTemplate: defined by method 'stringRedisTemplate' in class path resource [com/dalcho/adme/config/RedisConfig.class]Action:Consider marking one of the beans as @Primary, updating the consumer to accept multiple beans, or using @Qualifier to identify the bean that should be consumed내 생각에 해당 오류가 뜨는 이유는 redisTemplate도 String, String 타입인데StringRedisTemplate은 RedisTemplate의 &lt;String, String&gt; 타입이기 때문에 같은 bean이 2개잖아? 이래서 뜨는 것 같다.위 redsiTemplate의 타입을 &lt;?,?&gt;로 수정하면 해결 완료3. redis 값controller에서 save 후에 get을 하면 값이 떴는데 controller와 service를 이용해서 get을 받아오면 null이 떴다.아래 코드를 추가시켜서 null이 뜨지 않았다.implementation 'org.springframework.session:spring-session-data-redis'@EnableRedisHttpSession //Redis에 세션 데이터를 저장public class AdmeApplication {}findBy~할 때 model의 ~ 부분에 @Indexed를 붙여줘야 한다.그래야 값을 가져올 수 있다. @Indexed // 필드 값으로 데이터 찾을 수 있게 하는 어노테이션(findByAccessToken) private String nickname;reference Spring Boot 에서 Redis 사용하기 스프링부트 Redis 연습 1 - get/set 구현 Spring Boot에서 Redis 활용 Spring Boot Data Redis 사용해보기 [Java + Redis] Spring Data Redis로 Redis와 연동하기 - RedisTemplate 편 5분 안에 구축하는 Redis(레디스) " }, { "title": "Sorting algorithms", "url": "/posts/Sorting-Algorithms/", "categories": "Study", "tags": "study, summary, Algorithm, Sorting Algorithms", "date": "2023-03-30 00:00:00 +0900", "snippet": "선택 정렬 : Selection Sort해당 순서에 원소를 넣을 위치는 이미 정해져 있고, 어떤 원소를 넣을지 선택한다목록의 정렬되지 않은 부분에서 가장 작은 요소를 반복적으로 선택하여 목록의 정렬된 부분으로 이동하여 작동process1. 주어진 배열 중에 최소값을 찾는다.2. 그 값을 맨 앞에 위치한 값과 교체한다.3. 맨 처음 위치를 뺀 나머지 배열을 같은 방법으로 교체한다.목록의 정렬되지 않은 부분에서 가장 작은 요소를 반복적으로 선택하고 정렬되지 않은 부분의 첫 번째 요소와 교체한다.전체 목록이 정렬될 때까지 목록의 정렬되지 않은 나머지 부분에 대해 이 프로세스가 반복된다.반복할 때마다 정렬된 하위 배열 크기는 1씩 증가하고 정렬되지 않은 하위 배열 크기는 1씩 감소한다.void selectionSort(int[] arr) { int indexMin, temp; for (int i = 0; i &lt; arr.length-1; i++) { // 1. 위치(index)를 선택 indexMin = i; for (int j = i + 1; j &lt; arr.length; j++) { // 2. i+1번째 원소부터 선택한 위치(index)의 값과 비교 if (arr[j] &lt; arr[indexMin]) { // 3. indexMin = j; } } // 4. swap(arr[indexMin], arr[i]) temp = arr[indexMin]; arr[indexMin] = arr[i]; arr[i] = temp; } System.out.println(Arrays.toString(arr));}3. 오름차순이므로 현재 선택한 자리에 있는 값보다 순회하고 있는 값이 작다면, 위치(index)를 갱신4. ‘2’번 반복문이 끝난 뒤에는 indexMin에 ‘1’번에서 선택한 위치(index)에 들어가야하는 값의 위치(index)를 갖고 있으므로 서로 교환(swap)ex) 1회전 결과 예시void selectionSort(int[] arr) { int indexMin, temp; for (int i = 0; i &lt; arr.length-1; i++) { indexMin = i; // indexMin = 0 for (int j = i + 1; j &lt; arr.length; j++) { if (arr[j] &lt; arr[indexMin]) { // arr[3] = 3 &lt; arr[0] = 9 indexMin = j; // indexMin = 3 } } temp = arr[indexMin]; // temp = arr[3] → temp = 3 arr[indexMin] = arr[i]; // arr[3] = arr[0] → arr[3] = 9 arr[i] = temp; // arr[i] = 3; → arr[0] = 3; }}reference 선택 정렬(Selection Sort) Selection Sort Algorithm 기본적인 정렬 알고리즘 (선택, 삽입, 버블) [알고리즘] 선택 정렬(selection sort)이란버블 정렬 : Bubble Sort선택 정렬과 같이 이미 해당 순서에 원소를 넣을 위치는 정해져 있고, 어떤 원소를 넣을지 선택한다선택 정렬과는 다르게 최대값을 찾고, 그 최대값을 맨 마지막 원소와 교환하는 과정에서 차이가 있다.process1. 1회전에 첫 번째 원소와 두 번째 원소를, 두 번째 원소와 세 번째 원소를, 세 번째 원소와 네 번째 원소를, …이런 식으로 (마지막-1)번째 원소와 마지막 원소를 비교하여 조건에 맞지 않는다면 서로 교환한다.2. 1회전을 수행하고 나면 가장 큰 원소가 맨 뒤로 이동하므로 2회전에서는 맨 끝에 있는 원소는 정렬에서 제외되고,2회전을 수행하고 나면 끝에서 두 번째 원소까지는 정렬에서 제외된다.이렇게 정렬을 1회전 수행할 때마다 정렬에서 제외되는 데이터가 하나씩 늘어난다.codevoid bubbleSort(int[] arr) { int temp = 0; for(int i = 0; i &lt; arr.length; i++) { // 1. for(int j= 1 ; j &lt; arr.length-i; j++) { // 2. if(arr[j-1] &gt; arr[j]) { // 3. // swap(arr[j-1], arr[j]) temp = arr[j-1]; arr[j-1] = arr[j]; arr[j] = temp; } } } System.out.println(Arrays.toString(arr));}1. 제외될 원소의 갯수를 의미한다. 1회전이 끝난 후, 배열의 마지막 위치에는 가장 큰 원소가 위치하기 때문에 하나씩 증가시켜준다.2. 원소를 비교할 index를 뽑을 반복문이다.j는 현재 원소를 가리키고, j-1은 이전 원소를 가리키게 되므로, j는 1부터 시작하게 된다.3. 현재 가르키고 있는 두 원소의 대소를 비교한다.해당 코드는 오름차순 정렬이므로 현재 원소보다 이전 원소가 더 크다면 이전 원소가 뒤로 가야하므로 서로 자리를 교환해준다.예시void bubbleSort(int[] arr) { int temp = 0; for(int i = 0; i &lt; arr.length; i++) { for(int j= 1 ; j &lt; arr.length-i; j++) { if(arr[j-1] &gt; arr[j]) { // arr[0] &gt; arr[1] → 7 &gt; 4 temp = arr[j-1]; // temp = arr[0] → temp = 7 arr[j-1] = arr[j]; // arr[0] = arr[1] → arr[0] = 4 arr[j] = temp; // arr[1] = 7 } } }}reference 기본적인 정렬 알고리즘 (선택, 삽입, 버블) 거품 정렬(Bubble Sort) [알고리즘] 버블 정렬(bubble sort)이란삽입 정렬 : Insertion Sort매 순서마다 해당 원소를 삽입할 수 있는 위치를 찾아 해당 위치에 넣는다process1. 정렬은 2번째 위치(index)의 값을 temp에 저장한다.2. temp와 이전에 있는 원소들과 비교하며 삽입해나간다.3. ‘1’번으로 돌아가 다음 위치(index)의 값을 temp에 저장하고, 반복한다codevoid insertionSort(int[] arr) { for(int index = 1 ; index &lt; arr.length ; index++){ // 1. int target = arr[index]; int prev = index - 1; while( (prev &gt;= 0) &amp;&amp; (arr[prev] &gt; target) ) { // 2. arr[prev+1] = arr[prev]; // 이 전 원소를 한칸 씩 뒤로 미룬다. prev--; } arr[prev + 1] = target; // 3. } System.out.println(Arrays.toString(arr));}1. 첫 번째 원소 앞(왼쪽)에는 어떤 원소도 갖고 있지 않기 때문에, 두 번째 위치(index)부터 탐색을 시작한다.temp에 임시로 해당 위치(index) 값을 저장하고, prev에는 해당 위치(index)의 이전 위치(index)를 저장한다.2. 이전 위치(index)를 가리키는 prev가 음수가 되지 않고, 이전 위치(index)의 값이 ‘1’번에서 선택한 값보다 크다면,서로 값을 교환해주고 prev를 더 이전 위치(index)를 가리키도록 한다.3. ‘2’번에서 반복문이 끝나고 난 뒤, prev에는 현재 temp 값보다 작은 값들 중 제일 큰 값의 위치(index) 를 가리키게 된다.따라서, (prev+1)에 temp 값을 삽입해준다.예시void insertionSort(int[] arr) { for(int index = 1 ; index &lt; arr.length ; index++){ int target = arr[index]; // target = arr[1] → temp = 5 int prev = index - 1; // prev = 0 // target이 이전 원소보다 크기 전까지 반복 while( (prev &gt;= 0) &amp;&amp; (arr[prev] &gt; target) ) { arr[prev+1] = arr[prev]; // arr[1] = arr[0] → arr[1] = 8 prev--; } /* 위 반복문에서 탈출하는 경우 앞의 원소가 target보다 작다는 의미이므로 target 원소는 prev번째 원소 뒤에 와야한다. 그러므로 temp는 prev+1에 위치하게 된다. */ arr[prev + 1] = temp; // arr[1] = 5 }}결과적으로 타겟 이전 원소가 타겟 숫자보다 크기 직전까지 모든 수를 뒤로 한 칸씩 밀어내는 것이다.reference 기본적인 정렬 알고리즘 (선택, 삽입, 버블) 삽입 정렬(Insertion Sort) [알고리즘] 삽입 정렬(insertion sort)이란 자바 [JAVA] - 삽입 정렬 (Insertion Sort)퀵 정렬 : Quick Sort분할 정복(divide and conquer) 방법 을 통해 주어진 배열을 정렬한다. *분할 정복 : 문제를 작은 2개의 문제로 분리하고 각각을 해결한 다음, 결과를 모아서 원래의 문제를 해결하는 전략이다.하나의 리스트를 피벗(pivot)을 기준으로 두 개의 비균등한 크기로 분할하고 분할된 부분 리스트를 정렬한 다음,두 개의 정렬된 부분 리스트를 합하여 전체가 정렬된 리스트가 되게 하는 방법분할(Divide): 입력 배열을 피벗을 기준으로 비균등하게 2개의 부분 배열 (피벗을 중심으로 왼쪽: 피벗보다 작은 요소들, 오른쪽: 피벗보다 큰 요소들)로 분할한다.정복(Conquer): 부분 배열을 정렬한다. 부분 배열의 크기가 충분히 작지 않으면 순환 호출을 이용하여 다시 분할 정복 방법을 적용한다.결합(Combine): 정렬된 부분 배열들을 하나의 배열에 합병한다.순환 호출이 한번 진행될 때마다 최소한 하나의 원소(피벗)는 최종적으로 위치가 정해지므로, 이 알고리즘은 반드시 끝난다는 것을 보장할 수 있다.퀵 정렬에서 피벗을 기준으로 두 개의 리스트로 나누는 과정process1. 배열 가운데서 하나의 원소를 고른다. 이렇게 고른 원소를 피벗(pivot) 이라고 한다.2. 피벗 앞에는 피벗보다 값이 작은 모든 원소들이 오고,피벗 뒤에는 피벗보다 값이 큰 모든 원소들이 오도록 피벗을 기준으로 배열을 둘로 나눈다.이렇게 배열을 둘로 나누는 것을 분할(Divide) 이라고 한다. 분할을 마친 뒤에 피벗은 더 이상 움직이지 않는다.3. 분할된 두 개의 작은 배열에 대해 재귀(Recursion)적으로 이 과정을 반복한다.code왼쪽 pivot 방식으로 작성했다. 그 외의 방법은 아래 첨부된 블로그 링크를 참고한다. 자바 [JAVA] - 퀵 정렬 (Quick Sort)정복(Conquer)부분 배열을 정렬한다.부분 배열의 크기가 충분히 작지 않으면 순환 호출을 이용하여 다시 분할 정복 방법을 적용한다. array : 정렬할 배열 low : 현재 부분 배열의 왼쪽 high : 현재 부분 배열의 오른쪽public void quickSort(int[] array, int low, int high) { // low가 high보다 크거나 같다면 정렬할 원소가 1개 이하이므로 정렬하지 않고 return한다. if(low &gt;= high) return; // 정렬할 범위가 2개 이상의 데이터이면(list의 크기가 0 or 1이 아니면) // +) // 분할 int pivot = partition(array, low, high); // 피벗은 제외한 2개의 부분 배열을 대상으로 순환 호출 quickSort(array, low, pivot-1); // 정복(Conquer) 1. quickSort(array, pivot+1, high); // 정복(Conquer) 2. }+)피벗을 기준으로 요소들이 왼쪽과 오른쪽으로 약하게 정렬 된 상태로 만들어준 뒤최종적으로 pivot의 위치를 얻는다.그리고 나서 해당 피벗을 기준으로 왼쪽부분 리스트와 오른쪽 부분 리스트로 나누어 분할 정복을 해준다.1. (low ~ 피벗 바로 앞) 앞쪽 부분 리스트 정렬2. (피벗 바로 뒤 ~ high) 뒤쪽 부분 리스트 정렬분할입력 배열을 피벗을 기준으로 비균등하게 2개의 부분 배열(피벗을 중심으로 왼쪽 : 피벗보다 작은 요소들, 오른쪽 : 피벗보다 큰 요소들) 로 분할한다.‘피벗’을 하나 설정하고 피벗보다 작은 값들은 왼쪽에, 큰 값들은 오른쪽에 치중하도록 하는 것이다.이 과정을 흔히 파티셔닝(Partitioning)이라고 한다. array : 정렬할 배열 left : 현재 부분 배열의 왼쪽 right : 현재 부분 배열의 오른쪽 public int partition(int[] array, int left, int right) { /** // 최악의 경우, 개선 방법 int mid = (left + right) / 2; swap(array, left, mid); */ int pivot = array[left]; // 가장 왼쪽값을 피벗으로 설정 int low = left, high = right; while(low &lt; high) { // low가 high보다 작을 때 까지만 반복 /* high가 low보다 크면서 high의 요소가 pivot보다 작거나 같은 원소를 찾을 때 까지 high를 감소시킨다. */ while(low &lt; high &amp;&amp; pivot &lt; array[high]) { high--; } /* low가 high보다 크면서 low의 요소가 pivot보다 큰 원소를 찾을 때 까지 low를 증가시킨다. */ while(low &lt; high &amp;&amp; pivot &gt;= array[low]){ low++; } // 교환 될 두 요소를 찾았으면 두 요소를 바꾼다. swap(array, low, high); } /* 마지막으로 맨 처음 pivot으로 설정했던 위치(a[left])의 원소와 low가 가리키는 원소를 바꾼다. */ array[left] = array[low]; array[low] = pivot; // 두 요소가 교환되었다면 피벗이었던 요소는 low에 위치하므로 low를 반환한다. return low;} public class QuickSort { public void quickSort(int[] array, int low, int high) { // low가 high보다 크거나 같다면 정렬할 원소가 1개 이하이므로 정렬하지 않고 return한다. if(low &gt;= high){ return; } // 분할 int pivot = partition(array, low, high); // 피벗은 제외한 2개의 부분 배열을 대상으로 순환 호출 quickSort(array, low, pivot-1); // 정복(Conquer) quickSort(array, pivot+1, high); // 정복(Conquer) System.out.println(Arrays.toString(array)); } public int partition(int[] array, int left, int right) { int pivot = array[left]; // 가장 왼쪽값을 피벗으로 설정 int low = left, high = right; while(low &lt; high) { // low가 high보다 작을 때 까지만 반복 while(low &lt; high &amp;&amp; pivot &lt; array[high]) { high--; } while(low &lt; high &amp;&amp; pivot &gt;= array[low]){ low++; } swap(array, low, high); } swap(array, left, low); return low; } private void swap(int[] a, int i, int j) { int temp = a[i]; a[i] = a[j]; a[j] = temp; } public static void main(String[] args) { int[] arr = {5, 3, 8, 4, 9, 1, 6, 2, 7}; QuickSort quickSort = new QuickSort(); quickSort.quickSort(arr, 0, arr.length-1); }}reference 퀵 정렬(Quick Sort) [알고리즘] 퀵 정렬(quick sort)이란 자바 [JAVA] - 퀵 정렬 (Quick Sort) [알고리즘] 퀵정렬 (Quick Sort) Java Example" }, { "title": "비동기", "url": "/posts/%EB%B9%84%EB%8F%99%EA%B8%B0/", "categories": "Project", "tags": "spring", "date": "2023-03-26 00:00:00 +0900", "snippet": "비동기 처리비동기에 대해서 스터디에서 잠깐 주제로 나와서 얘기를 해봤었다.포인트는 응답과 동시성이었다.내가 알고있는 비동기는 응답을 기다리지 않고 다음 로직을 실행하는 것이다.그런데 동시에 일어난다가 동기이고 그렇지 않은 경우가 비동기로 알고있는 팀원도 있었다. (→ 요청과 그 결과가 동시에 일어난다)결론은 실행시켰을 때 반환값이 기대되는 경우는 반환값을 받기 전까지 실행하지 않는다는 얘기이기 때문에같은 말이라고 보면 될 것 같다.동기 ex) 콜센터 비동기 ex) 이메일JAVAJAVA에서 비동기 처리를 위해 Thread를 사용할 수 있다.Thread를 구현하는 방법에는 두 가지가 존재한다.하나는 Thread 클래스를 상속하여 구현하는 방법과 다른 하나는 Runnable 인터페이스를 구현하는 방법이 있다.자바에서는 다중 상속을 하지 못하기 때문에 대부분 확장성을 고려하여 Runnable 인터페이스를 구현하는 편이다.추가로, Executor는 기능적으로 보면 Thread와 유사하여 Thread의 대체제로 생각할 수 있지만,정확하게는 Runnable의 작업을 실행시키는 함수를 담은 인터페이스라고 한다.public void method() { Thread thread = new Thread(new Runnable() { @Override public void run() { // do something } }); thread.start(); // start()로 Thread를 실행한다.}동시에 1000개의 호출이 이뤄진다면 동시에 1000개의 thread가 생성되는 방식이다.thread를 관리할 수 없기 때문에 위험한 방법이다.병렬작업 처리량이 많아지면 성능이 저하되는데, 이를 막기 위해서 Thread Pool을 사용해야 한다.Thread Pool은 Thread 개수를 미리 정해 놓고, 작업 큐에 들어오는 요청을 미리 생성해 놓은 Thread들에게 할당하는 방식이다.JDK 1.5부터는 java.util.concurrent Package에 ExecutorService 인터페이스와 Executors 클래스를 제공하고 있다.주요 인터페이스로는, 1) Executor, 2) ExecutorService, 3) ScheduledExecutorService 가 있다.Executor동시에 여러 요청을 처리해야 하는 경우에 매번 새로운 쓰레드를 만드는 것은 비효율적이다.그래서 쓰레드를 미리 만들어두고 재사용하기 위한 쓰레드 풀(Thread Pool)이 등장하게 되었는데,Executor 인터페이스는 쓰레드 풀의 구현을 위한 인터페이스이다.Executor executor = Executors.newSingleThreadExecutor(); // single threadexecutor.execute(() -&gt; System.out.println(\"Thread: \" + Thread.currentThread().getName()));Executor는 쓰레드를 생성하고 처리하는 인터페이스이다.execute()라는 메서드만을 가지고 있는데, 쓰레드를 처리할 수는 있지만 종료할 수는 없다.ide에서 실행시켜보면 강제종료하기 전까지 계속 실행되는 것을 확인할 수 있다.ExecutorServiceThread를 관리하기 위해서는 JDK 1.5부터 제공하는 java.util.concurrent.ExecutorService를 사용하면 된다.ExecutorService에 Task(작업)를 지정해주면 가진 ThreadPool을 이용하여 Task를 실행한다.Task는 큐(Queue)로 관리되기 때문에 ThreadPool의 Thread 갯수보다 실행할 Task가 많은경우미실행된 Task는 큐에 저장되어 실행을 마친 Thread가 생길 때까지 기다린다.ExecutorService는 Executor를 상속 받은 인터페이스이다. Thread를 생성하고 처리하고 종료하는 등의 작업을 할 수 있다.ExecutorService는 Executor를 상속 받았기 때문에 execute()와 submit() 모두 호출이 가능하다.execute()는 Runnable 인터페이스만 인자로 받을 수 있지만, submit()은 Runnable과 Callable 인터페이스 모두 인자로 받을 수 있다.execute()는 return값이 없는 Runnable 객체를 작업 큐에 저장한다.작업 처리 도중에 예외가 발생하면 Thread가 종료되고 해당 Thread를 Thread Pool에서 제거한뒤다른 작업 처리를 위해서 새로운 Thread를 생성한다.submit()는 작업 처리 결과를 받을 수 있도록 Future를 리턴한다. (비동기적 연산의 처리 결과를 표현하기 위해 사용)submit()는 작업 처리 도중에 예외가 발생하더라도 Thread는 종료되지 않고 다음 작업을 위해 재사용된다.그러므로 Thread 생성 오버헤드를 줄이기 위해 submit()을 사용하는 것이 좋다.*오버헤드 어떤 처리를 하기 위해 들어가는 간접적인 처리 시간 · 메모리 등을 말한다. 예를 들어 A라는 처리를 단순하게 실행한다면 10초 걸리는데, 안전성을 고려하고 부가적인 B라는 처리를 추가한 결과 처리시간이 15초 걸렸다면, 오버헤드는 5초가 된다.submit()을 사용하면 작업을 ExecutorService가 만든 쓰레드풀에서 처리하고, shutdown()으로 쓰레드 풀을 종료할 수 있다.shutdown()을 사용하면 작업이 다 종료될 때까지 기다리고 종료하지만,작업이 끝나든 말든 지금 당장 종료하고 싶다면 shutdownNow()를 사용하면 된다. public static void main(String args[]) throws InterruptedException { // 4개의 고정된 쓰레드풀을 갖고 있는 ExecutorService를 생성하는 코드 ExecutorService executor = Executors.newFixedThreadPool(4); executor.submit(() -&gt; { String threadName = Thread.currentThread().getName(); System.out.println(\"Job1 \" + threadName); }); executor.submit(() -&gt; { String threadName = Thread.currentThread().getName(); System.out.println(\"Job2 \" + threadName); }); executor.submit(() -&gt; { String threadName = Thread.currentThread().getName(); System.out.println(\"Job3 \" + threadName); }); executor.submit(() -&gt; { String threadName = Thread.currentThread().getName(); System.out.println(\"Job4 \" + threadName); }); // 더이상 ExecutorService에 Task를 추가할 수 없다. // 작업이 모두 완료되면 쓰레드풀을 종료시킨다. executor.shutdown(); // shutdown() 호출 전에 등록된 Task 중에 아직 완료되지 않은 Task가 있을 수 있다. // Timeout을 20초 설정하고 완료되기를 기다린다. // 20초 전에 완료되면 true를 리턴하며, 20초가 지나도 완료되지 않으면 false를 리턴한다. if (executor.awaitTermination(20, TimeUnit.SECONDS)) { System.out.println(LocalTime.now() + \" All jobs are terminated\"); } else { System.out.println(LocalTime.now() + \" some jobs are not terminated\"); // 모든 Task를 강제 종료 executor.shutdownNow(); } }ExecutorService를 만들어 작업을 실행하면, shutdown이 호출되기 전까지 계속해서 다음 작업을 대기하게 된다.그러므로 작업이 완료되었다면 반드시 shutdown을 명시적으로 호출해주어야 한다.위에서 얘기한 문제를 해결하기 위해 Thread Pool을 적용했지만 Thread Pool도 단점이 있다.4개의 Thread를 만들어 놓았지만 실제로 1개의 요청만 들어온다면나머지 3개의 Thread는 메모리만 차지하게 되고 메모리 낭비가 발생한다.또한 작업 완료 소요 시간이 다를 경우 유휴 시간이 발생하게 된다.예를 들어 A, B, C, D Thread가 있을 경우 A, B는 이미 처리가 끝났는데C, D는 완료되지 않았을 경우 A, B Thread는 C, D의 작업이 끝날 때까지 가다리게게 된다.이를 방지 하기 위해 JDK 1.7부터는 forJoinPool를 제공하며,해당 블로그에서 자세한 설명을 볼 수 있다. 쓰레드풀 과 ForkJoinPool💬자바에서는 ExecutorService를 통해서 비동기를 처리할 수 있다.요청마다 Thread를 찍어내는 방법도 있지만 매 요청 마다 Thread가 생성되면 Thread 관리가 되지 않아서 위험하다.ExecutorService를 사용하면 원하는 크기만큼의 Thread Pool을 생성하고 풀에서 Thread를 꺼내서 사용하고 다시 반납하는 방식으로 처리한다.application에서 비동기 메서드가 많이 필요한 경우 method를 비동기에 맞게 수정해야하는 번거로움이 있다.스프링에서는 개발자들의 번거러움을 해결해주기 위해서 @EnablyAsync, @Async 어노테이션을 제공해준다.@EnableAsync, @Async 두개로 비동기 메서드를 구현할 수 있다.@EnableAsync를 사용하면 SimpleAsyncTaskExecutor를 사용하도록 설정되어 있다.SimpleAsyncTaskExecutor는 매번 Thread로 생성하는 방식이기 때문에 설정을 오버라이딩해서 사용하는게 좋다.Spring기본적으로 Spring Event 는 동기적이다. 하지만 @Async를 통해 비동기로 동작할 수 있다.@Async (SimpleAsyncTaskExecutor)Spring의 @Async를 사용하면 간단하게 처리가 가능하다.@EnableAsync를 Application 클래스에 붙이고, 비동기를 사용하려는 메소드위에 @Async를 붙이면 적용된다.1. @EnableAsync로 @Async를 쓰겠다고 스프링에게 알린다.2. 비동기로 수행되었으면 하는 메서드위에 @Async를 적용한다.@SpringBootApplication@EnableAsyncpublic class AdmeApplication { public static void main(String[] args) { SpringApplication.run(AdmeApplication.class, args); }}public class HelloService{ @Async public void helloWorld() throws Exception{ }}하지만 해당방법은 default값으로 적용되는데,SimpleAsyncTaskExecutor를 사용하게되고 Thread Pool에 의한게 아닌 Thread를 만들어내는 역할만 한다.Thread를 제대로 관리해주지 못한다.@Async의 기본설정은 SimpleAsyncTaskExecutor를 사용하도록 되어있기 때문이다.주의 사항private 메서드에는 적용이 안된다. public만 된다.self-invocation(자가 호출)해서는 안된다. → 같은 클래스 내부의 메서드를 호출하는 것은 안된다.@Async (ThreadPoolTaskExecutor)스터디에서 다른 팀원들은 설정 없이 @Async만 적용했다.(위 방법)따로 설정없이 @Async만 하면 필요할때만 꺼내주기 때문에 설정안하는게 효과적이기 때문에 적용했다고 했다.하지만 나는 채팅으로 실시간성이 중요하기 때문에 미리 해두는게 더 효율적이라고 느껴서 직접 설정했다.직접 설정하는 방법은 Thread Pool을 이용해서 thread를 관리가능한 방식이다.위에서 적용했던 Applcation에 @EnableAsync를 제거 해준 뒤, AsyncConfig 생성한다. (SpringAsyncConfig 클래스에 설정해뒀기 때문에 중복 된다.)Application 클래스에 @EnableAutoConfiguration(혹은 @SpringBootApplication) 설정이 되어있다면런타임시 @Configuration가 설정된 SpringAsyncConfig 클래스의 threadPoolTaskExecutor bean 정보를 읽어들인다.ThreadPoolTaskExecutorThread Pool을 적용해 일정 수의 사용자 동시에 처리가 가능하도록 한다.Thread Pool이란 Thread를 미리 만들어놓은 집단? 이라고 보면된다.Thread Pool을 사용하는 Executor@Configuration // Bean 등록@EnableAsync // Async 설정public class AsyncConfiguration { @Bean(name=\"executor\") public Executor asyncThreadPool() { ThreadPoolTaskExecutor taskExecutor = new ThreadPoolTaskExecutor(); taskExecutor.setCorePoolSize(3); // 생성할 개수(thread pool에 항상 존재하는 최소 개수) taskExecutor.setMaxPoolSize(10); // 동시 동작하는 최대 Thread의 수 taskExecutor.setQueueCapacity(15); // 큐의 사이즈 taskExecutor.setThreadNamePrefix(\"Async-Executor-\"); taskExecutor.setDaemon(true); taskExecutor.initialize(); return taskExecutor; }} CorePoolSize : 최초 동작 시에 corePoolSize만큼 Thread가 생성하여 사용된다.(Default 1) MaxPoolSize : Queue 사이즈 이상의 요청이 들어오게 될 경우, Thread의 개수를 MaxPoolSize만큼 늘린다. (Default : Integer.MAX_VAULE) QueueCapacity : CorePoolSize 이상의 요청이 들어올 경우, LinkedBlockingQueue에서 대기하게 되는데 그 Queue의 사이즈를 지정해주는 것이다.(Default : Integer.MAX_VAULE) SetThreadNamePrefix : Thread명 설정 최초 3개의 Thread에서 처리하다가 처리속도가 밀릴경우 15개 사이즈 queue에서 대기하고그보다 많은 요청이 발생할 경우 최대 10개 Thread까지 생성해서 처리하게 된다.현재 점유하고 있는 Thread의 개수가 corePoolSize만큼 있을 때 요청이 오면queueCapacity의 개수만큼 있을 때 요청이 오면 maxPoolSize만큼 Thread Pool을 생성한다.core 사이즈만큼의 Thread에서 task를 처리할 수 없을 경우 queue에서 대기하게 된다.queue가 꽉 차게 되면 그때 max 사이즈만큼 Thread를 생성해서 처리하게 된다.만약 현재 점유하고 있는 Thread의 개수가 maxPoolSize만큼 있고큐에 담긴 요청이 queueCapactiry의 개수만큼 있을 때 요청이 오면 RejectedExecutionExceptionex) Request 500, ThreadPool 300, Queue 100일 때, Request 500개 요청 ThreadPool 300개 먼저 사용 Queue 100개 사용나머지 100개의 요청에 대해서 어떻게 처리할 지 RejectedExcutionHandler에서 지정된 정책으로 처리처리되지 못한 100개의 요청에 대해서 org.springframework.core.task.TaskRejectedException 발생되며 요청을 무시클래스에 설정한 @Async annotation에 bean의 이름을 제공하면SimpleAsyncTaskExecutor가 아닌 설정한 TaskExecutor로 thread를 관리하게 된다.@Async(\"executor\") // 비동기public void publish(String sender, String roomId) {}RejectedExecutionHandlerMaxPoolSize thread까지 생성하고 queue까지 꽉 찬 상태에서 추가 요청이 오면RejectedExecutionException 예외가 발생한다.taskExecutor.setRejectedExecutionHandler(new ThreadPoolExecutor.CallerRunsPolicy());예외와 누락 없이 최대한 처리하려면 CallerRunsPolicy로 설정하는 것이 좋다고 한다.Shutdown별도로 정의한 Thread Pool에서 열심히 작업이 이루어지고 있을 때 application 종료를 요청하면아직 처리되지 못한 task는 유실되게 된다.유실 없이 마지막까지 다 처리하고 종료되길 원한다면 설정을 추가해야한다.taskExecutor.setWaitForTasksToCompleteOnShutdown(true);Timeout만약 모든 작업이 처리되길 기다리기 힘든 경우라면 최대 종료 대기 시간을 설정할 수 있다.taskExecutor.setAwaitTerminationSeconds(60); // shutdown 최대 60초 대기비동기 처리를 위해서 ThreadPoolTaskExecutor 를 사용했는데 주 설정인setCorePoolSize, setMaxPoolSize, setQueueCapacity 이 3가지만 알았고나머지는 알지를 못했는데 비동기에 대해 공부를 하면서 이 부분을 체크하지 못하고 넘어갔다가내 예상과 다른 결과가 나올 때 해당 원인을 모르고 넘어갈 수 있다는 생각이 들었다.reference ThreadPoolTaskExecutor 이용하여 성능 개선하기 ThreadPoolTaskExecutor Queue가 full의 처리 정책 Spring ThreadPoolTaskExecutor 설정 Spring @Async 비동기처리 [Spring] @Async 비동기 멀티스레드 사용법 스프링 비동기 (Asynchronous) [JAVA] 비동기 처리 방법 - Thread Asynchronous Request? 동기, 비동기 / 직렬, 동시 [Java] Callable, Future 및 Executors, Executor, ExecutorService, ScheduledExecutorService에 대한 이해 및 사용법 Java - ExecutorService를 사용하는 방법 ExecutorService 사용법 스레드풀(ThreadPool)에서 execute()와 submit()의 차이 [운영체제] 면접대비 Overview Difference between ExecutorService execute() and submit() method in Java How does @Async work? @Async를 지금까지 잘 못 쓰고 있었습니다(@Async 사용할 때 주의해야 할 것, 사용법)" }, { "title": "Mysql pw 바꾸기", "url": "/posts/MySql-pw-%EB%B0%94%EA%BE%B8%EA%B8%B0/", "categories": "Project", "tags": "MySQL", "date": "2023-03-23 00:00:00 +0900", "snippet": "MySql 비밀번호 바꾸기MySql 실행$ mysql -u root -p만약에 port 번호가 3306으로 설정하지 않았다면 mysql -u root -p --port {포트번호}로 작성한다.나는 mysql -u root -p --port 3307로 작성했다.그 다음 기존 password를 작성하면 된다.비밀번호 변경mysql&gt; alter user 'root'@'localhost' identified with mysql_native_password by '{바꿀비밀번호}';ex) alter user 'root'@'localhost' identified with mysql_native_password by 'apple';나는 SQL 버전이 8 이상이라서 위와 같이 작성했는데 버전이 8 미만인 경우에는 작성하는 방법이 다르다.참고 blog → [MySql] MySql 비밀번호 변경 방법종료mysql&gt; exitBye" }, { "title": "Websocket + jwt", "url": "/posts/WebSocket-+-JWT/", "categories": "Project, Chat", "tags": "spring, WebSocket, Chat, Security", "date": "2023-03-11 00:00:00 +0900", "snippet": "WebSocket + JWT관련 글 Websocket Websocket + 부가기능 Websocket (채팅 기록 json 파일 저장하기) Sse Sse 문제점 Websocket + jwt 👈🏻 Websocket test Jmh - 채팅 파일 refactoring내가 채팅방을 작성하면서 security를 구현한 이유는 stomp를 사용하면 헤더에 token을 추가해 보안을 강화할 수 있다는 것이제 코드로 작성해본다.WebSocketConfigStompHandler가 Websocket 앞단에서 token을 체크할 수 있도록 interceptor로 설정한다.private final StompHandler stompHandler;@Overridepublic void configureClientInboundChannel(ChannelRegistration registration){ // jwt 토큰 검증을 위해 생성한 stompHandler를 인터셉터로 지정해준다. registration.interceptors(stompHandler);}JwtTokenProvider// 기존에 작성한 코드 활용// jwt token을 복호화 하여 이름을 얻는다.public String getUsername(String token) { log.info(\"[getUsername] 토큰 기반 회원 구별 정보 추출\"); // 토큰을 생성할때 넣었던 sub 값 추출 String info = getClaims(token).getBody().getSubject(); log.info(\"[getUsername] 토큰 기반 회원 구별 정보 추출 완료\"); return info;}private Jws&lt;Claims&gt; getClaims(String jwt){ try{ return Jwts.parser().setSigningKey(secretKey).parseClaimsJws(jwt); }catch (SignatureException e){ // 잘못된 jwt signature log.error(\"Invalid JWT signature\"); throw e; } catch (MalformedJwtException e){ log.error(\"Invalid JWT token\"); throw e; } catch (ExpiredJwtException e){ // jwt 만료 log.error(\"Expired JWT token\"); throw e; } catch (UnsupportedJwtException e){ // 지원하지 않는 jwt log.error(\"Unsupported JWT token\"); throw e; } catch (IllegalArgumentException e){ // 잘못된 jwt 토큰 log.error(\"JWT claims string is empty\"); throw e; }}Jwts.parser().setSigningKey(secretKey).parseClaimsJws(jwt) 을 사용하는 코드가 많아서 묶어서 사용예시 출력getClaims(token) : header={alg=HS256},body={sub=haedal, roles=USER, iat=1516239022, exp=1234567890},signature=ajslkdfjaldkfjaDSLFieo정리글 👉🏻 Session과 jwtStompHandlerwebsocket 연결 시 요청 header의 jwt token 유효성을 검증하는 코드를 추가한다.유효하지 않은 jwt 토큰이 세팅될 경우 websocket 연결을 하지 않고 예외처리 된다.@RequiredArgsConstructor@Componentpublic class StompHandler implements ChannelInterceptor { private final JwtTokenProvider jwtTokenProvider; @Override public Message&lt;?&gt; preSend(Message&lt;?&gt; message, MessageChannel channel) { StompHeaderAccessor headerAccessor = StompHeaderAccessor.wrap(message); // websocket 연결 시 header의 jwt token 검증 if (StompCommand.CONNECT.equals(headerAccessor.getCommand())) { jwtTokenProvider.validateToken(headerAccessor.getFirstNativeHeader(\"Authorization\")); } return message; }}headerAccessor.getNativeHeader() : 지정된 네이티브 헤더가 있는 경우 모든 값을 반환headerAccessor.getFirstNativeHeader() : 지정된 네이티브 헤더가 있는 경우 첫 번째 값을 반환preSend() 메소드에서 클라이언트가 CONNECT할 때 헤더로 보낸 Authorization에 담긴 jwt Token을 검증하도록 한다.function connect(event) { let socket = new SockJS('/ws'); stompClient = Stomp.over(socket); stompClient.connect({Authorization:token}, onConnected, onError);}ChatControllerfunction sendMessage(event) { let messageContent = messageInput.value.trim(); if (messageContent &amp;&amp; stompClient) { let chatMessage = { roomId: roomId, sender: username, message: messageInput.value, type: 'TALK' }; saveFile(chatMessage) stompClient.send(\"/app/chat/sendMessage\", {Authorization:token}, JSON.stringify(chatMessage)); messageInput.value = ''; } event.preventDefault(); // 계속 바뀌는 것을 방지함}Authorization으로 header에 token값을 넣었으니 Controller에서 @Header(\"Authorization\")라고 작성했다.@Controller@RequiredArgsConstructorpublic class ChatController { private final JwtTokenProvider jwtTokenProvider; @MessageMapping(\"/chat/sendMessage\") public void sendMessage(@Payload ChatMessage chatMessage, @Header(\"Authorization\") String token) { String nickname = jwtTokenProvider.getUsername(token); template.convertAndSend(\"/topic/public/\" + chatMessage.getRoomId(), chatMessage); }} websocket을 통해 서버에 메세지가 send 되었을 때도 jwt token 유효성 검증이 필요하다.위와 같이 회원 대화명(id)를 조회하는 코드를 삽입하여 유효성이 체크될 수 있도록 한다.reference [Spring boot + React] STOMP로 실시간 채팅 구현하기 (3) - 사용자 인증 구현하기 Spring Boot + STOMP + JWT Socket 인증하기 Spring websocket chatting server(4) - SpringSecurity+Jwt를 적용하여 보완강화하" }, { "title": "Oauth2 적용", "url": "/posts/OAuth2-%EC%A0%81%EC%9A%A9/", "categories": "Project, OAuth2", "tags": "spring, Security, OAuth2", "date": "2023-03-06 00:00:00 +0900", "snippet": "OAuth2stomp를 활용하면 header에 token값을 넣어 인증을 할 수 있다는 글을 많이 보았다.실제로 적용하는 곳은 많지 않았는데 해당 기능을 적용할 수 있으니 한번 해봐야하지 않을까? 싶었다.그러려면 security를 적용해야했고 기존 project에는 이미 security가 적용되어있어다른 방법으로 로그인을 구현해봐야겠다 싶어서 OAuth를 활용했다.*Authentication : 인증, Authorization : 인가공식 문서OAuth2란OAuth 정리 글Security flow스프링 시큐리티에서 동작하는 기본적인 formLogin을 할 경우(별도 설정x) client로 부터 요청을 받으면 servlet filter에서 SecurityFilterChain으로 작업이 위임되고 그 중 UsernamePasswordAuthenticationFilter(AuthenticationFilter에 해당)에서 인증을 처리 AuthenticationFilter가 요청을 가로채서 해당 정보를 통해 UsernamePasswordAuthenticationToken 객체 (사용자가 입력한 데이터를 기반으로 생성, 즉 현 상태는 미검증 Authentication) 생성 AuthenticationFilter는 요청 객체(HttpServletRequest)에서 username과 password를 추출해서 token을 생성 AuthenticationManger에게 token을 전달. AuthenticationManager는 인터페이스이며, 일반적으로 사용되는 구현체는 ProviderManager다. ProviderManager는 인증을 위해 AuthenticationProvider로 token을 전달한다. (UsernamePasswordAuthenticationToken 객체를 전달) AuthenticationProvider는 token의 정보를 UserDetailsService에 전달한다. UserDetailsService는 전달받은 정보를 통해 db에서 일치하는 사용자를 찾아 UserDetails 객체를 생성한다. 생성된 UserDetails 객체는 AuthenticationProvider로 전달되며, 해당 Provider에서 인증을 수행하고 성공하게 되면 ProviderManager로 권한을 담은 토큰을 전달한다. → 인증이 완료되면, 사용자 정보를 담은 Authentication 객체를 반환 ProviderManager는 검증된 token을 AuthenticationFilter로 전달한다. AuthenticationFilter는 검증된 token(Authentication 객체)을 SecurityContextHolder에 있는 SecurityContext에 저장 ☑️ UsernamePasswordAuthenticationFilter란Form based Authentication 방식으로 인증을 진행할 때 아이디, 패스워드 데이터를 파싱하여 인증 요청을 위임하는 필터이다.유저가 로그인 창에서 Login을 시도할 때 보내지는 요청에서 아이디(username)와 패스워드(password) 데이터를 가져온 후인증을 위한 토큰을 생성 후 인증을 다른 쪽에 위임하는 역할을 하는 필터이다.Spring Boot 기반의 HttpSecurity를 설정하는 코드에서 http.formLogin(); 을 사용하면시큐리티에서는 기본적으로 UsernamePasswordAuthenticationFilter 을 사용하게 된다.@Beanpublic SecurityFilterChain filterChain(HttpSecurity http)throws Exception { http.formLogin();}OAuth 로그인을 하게 된다면 UsernamePasswordAuthenticationFilter 대신 OAuth2LoginAuthenticationFilter 가 호출된다.두 필터의 상위 클래스는 AbstractAuthenticationProcessingFilter이다.스프링 시큐리티는 AbstractAuthenticationProcessingFilter를 호출하고,로그인 방식에 따라 구현체인 UsernamePasswordAuthenticationFilter 와 OAuth2LoginAuthenticationFilter 가 동작하는 방식이다.OAuth2 flow1. OAuth2 login flow는 맨처음 Request URL을 보내면서 시작된다.http://localhost:8080/oauth2/authorize/kakaoSpring Security OAuth 2.0 기본 요청 경로는 /oauth2/authorization/{registrationId} 이다.&lt;a href=\"/oauth2/authorization/kakao\"&gt;kakao&lt;/a&gt;위와 같은 주소를 사용하려면 back과 front의 주소가 같아야한다.만약에 back과 front가 주소가 다를 경우 back의 주소를 작성해야한다.ex) &lt;a href=\"https://backend.haedal.com/oauth2/authorization/kakao\"&gt;kakao&lt;/a&gt;참고 글 : 배포 후 oauth2 수정2. resource server는 client의 id와 redirect_uri를 확인한다.3. 해당 값이 같으면 Resource Server가 Resource Owner에게 Client에게 권한을 허용할 것인지 메세지를 띄워 권한을 확인한다.4. 임시 비밀번호 같은 authroization code를 Resource Server가 Resource Owner에게 주면 Resource Owner는 Clinet에게 준다.*여기서 Resource Owner는 authroization code를 받았는지도 모른다.Location: ${REDIRECT_URI}?code=${AUTHORIZE_CODE}http://localhost:8080/login/oauth2/code/kakao?code = skfjskdjfaei 이런 식으로 넘겨준다.→ 카카오의 유저 정보를 모아 놓은 서버에서 해당 유저가 있기 때문에 있는 유저다 라고 알려주는 것5. JwtAuthenticationFilter가 토큰을 처리한다.6. Resource Owner의 정보에 접근하기 위해 Access Token이 필요하며Resource Server에서 요구하는 정보 grant_type, client_id, redirect_uri, code를 보낸다.curl -v -X POST \"https://kauth.kakao.com/oauth/token\" \\ -H \"Content-Type: application/x-www-form-urlencoded\" \\ -d \"grant_type=authorization_code\" \\ -d \"client_id=${REST_API_KEY}\" \\ --data-urlencode \"redirect_uri=${REDIRECT_URI}\" \\ -d \"code=${AUTHORIZE_CODE}\"7. AccessToken을 받는다.= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =여기까지가 oauth2과정으로 인증이 통과되었다는 것은 로그인 성공을 의미한다.이 다음은 custom하여 인가과정을 작성한 것인데 나는 OAuth2+JWT를 적용했다.8. SecurityConfig에서 정의한 CustomOAuthService는 인증된 사용자의 세부사항을 확인해서 db에 없을 경우 값을 저장한다.9. 만일 CustomOAuthService가 성공이라면 OAuth2SuccessHandler가 실행되어서JWT authentication token(인증 토큰)을 만들고 redirect_uri로 간다.(queryString에 jwtToken을 넣는다.)10. 만일 CustomOAuthService에서 에러가 발생한다면throw new OAuth2AuthenticationException(new OAuth2Error(\"error\"), new RuntimeException(\"에러 발생!!\"));와 같이 작성하여 Oauth2FailureHandler가 실행되게 한다.JWTJWT는 Claim 기반 방식을 사용한다.여기서 Claim이란 사용자에 대한 속성 값들을 가리킨다.즉, JWT은 의미있는 토큰 (사용자의 상태를 포함) 으로 구성되어 있기 때문에,Auth Server에 검증 요청을 보내야만 했던 과정을 생략하고각 서버에서 수행할 수 있게 되어 비용 절감 및 Stateless 아키텍처를 구성할 수 있다. 클라이언트 (사용자) 는 Auth Server에 로그인을 한다. Auth Server에서 인증을 완료한 사용자는 JWT 토큰을 전달 받는다. 클라이언트는 특정 애플리케이션 서버에 리소스 (서비스에 필요한 데이터) 를 요청할 때, 앞서 전달 받은 JWT 토큰을 Authorization Header에 넣어 전달한다. 애플리케이션 서버는 전달 받은 JWT 토큰의 유효성을 직접 검사하여 사용자 인증을 할 수 있다. 고려해야 할 점은, 사용자 인증 정보가 필요한 요청을 보낼 때 헤더에 JWT 토큰 값을 넣어 보내야 하기 때문에데이터가 증가하여 네트워크 부하가 늘어날 수 있다.또한 토큰 자체에 사용자 정보를 담고 있기 때문에 JWT가 만료되기 전에 탈취당하면 서버에서 처리할 수 있는 일이 없다.JWT 방식은 한 번 만들어 클라이언트에게 전달하면 제어가 불가능하기 때문에 만료 시간을 필수적으로 넣어 주어야 한다.code 작성나는 kakao, naver, google 3개를 적용했는데 아래는 kakao만 작성했다.[흐름 정리]JwtTokenProvider에서 OAuth2 로그인 과정이 수행된다.SecurityConfig에서 OAuth2로그인 성공시에 CustomOAuthService에서 처리를 한다.OAuth2 Filter 단에서 직접 커스텀한 OAuth2 Service의 “loadUser()” 메소드가 실행된다.로그인을 성공하게 되면 OAuth2SuccessHandler의 “onAuthenticationSuccess” 메소드가 실행된다.OAuth2SuccessHandler에서 최초 로그인 확인 및 JWT 생성 및 응답 과정이 실행된다.*모든 과정은 Spring Security Filter 과정에서 수행된다. → Login Controller는 존재하지 않는다.OAuth 2.0 설정// securtiyimplementation 'org.springframework.boot:spring-boot-starter-security' implementation 'io.jsonwebtoken:jjwt:0.9.1' // jwt implementation 'org.springframework.boot:spring-boot-starter-oauth2-client' implementation 'org.springframework.boot:spring-boot-configuration-processor'// 소셜 로그인을 통한 인증과 권한 처리를 쉽게 할 수 있게 해준다.application.properties*application.properties에서 spring.profiles.includes = name이라고 작성하면 application-name.properties 부분을 작성할 수 있다.spring.profiles.include=oauthapplication.properties에서 spring.profiles.includes = oauth를 작성한 후 application-oauth-properties를 작성했다.application-oauth.properties# kakao about urispring.security.oauth2.client.provider.kakao.user-name-attribute=idspring.security.oauth2.client.provider.kakao.authorization-uri=https://kauth.kakao.com/oauth/authorizespring.security.oauth2.client.provider.kakao.token-uri=https://kauth.kakao.com/oauth/tokenspring.security.oauth2.client.provider.kakao.user-info-uri = https://kapi.kakao.com/v2/user/me# kakao certification need application informationspring.security.oauth2.client.registration.kakao.client-name=kakaospring.security.oauth2.client.registration.kakao.authorization-grant-type=authorization_codespring.security.oauth2.client.registration.kakao.client-id = # kakao certification uses method &amp; userinfo scopespring.security.oauth2.client.registration.kakao.client-authentication-method=POSTspring.security.oauth2.client.registration.kakao.client-secret = spring.security.oauth2.client.registration.kakao.redirect-uri=http://localhost:8080/login/oauth2/code/kakaospring.security.oauth2.client.registration.kakao.scope=profile_nickname, account_email{baseUrl}/login/oauth2/code/{registrationId} 로 redirect-uri를 받고 있다고 해서login/oauth2/code/kakao로 Redirection Endpoint를 작성했다.domainUser@Getter@Entity@NoArgsConstructor(access = AccessLevel.PROTECTED)@ToStringpublic class User implements UserDetails { public static final String DEFAULT_PROFILE_IMG_PATH = \"images/default-profile.png\"; @GeneratedValue(strategy = GenerationType.IDENTITY) @Id @Column(name = \"user_id\") private Long id; @Column(nullable = false) private String nickname; @Column(nullable = false) private String password; @Column(nullable = false) private String email; @Column(nullable = false) @Enumerated(value = EnumType.STRING) private UserRole role; @Column(nullable = false) private boolean enabled = true; // 1 @Column(nullable = false) private String socialId; private String social; private String profile = DEFAULT_PROFILE_IMG_PATH; @Builder // UserMapper와 연결 public User(String socialId, String email, String password, UserRole role, String username, String nickname, String social) { this.socialId = socialId; this.email = email; this.password = password; this.username = username; this.nickname = nickname; this.role = role == null ? UserRole.USER : role; this.profile = DEFAULT_PROFILE_IMG_PATH; this.social = social; } @Override public Collection&lt;? extends GrantedAuthority&gt; getAuthorities() { return null; } @Override public String getUsername() { return null; } @Override public boolean isAccountNonExpired() { return false; } @Override public boolean isAccountNonLocked() { return false; } @Override public boolean isCredentialsNonExpired() { return false; } @Override public boolean isEnabled() { return this.enabled; }}UserRole@Getter@AllArgsConstructorpublic enum UserRole { USER, // 사용자 권한 ADMIN; // 관리자 권한 public static UserRole of(String name) { for (UserRole role : values()) { if (role.name().contains(name)) return role; } throw new BadConstantException(); }}UserMapper@Component@RequiredArgsConstructor@Slf4jpublic class UserMapper { // 인증 public static User ofKakao(OAuth2User oAuth2User, String nickname) { var attributes = oAuth2User.getAttributes(); Map&lt;String, Object&gt; kakao_account = (Map&lt;String, Object&gt;) attributes.get(\"kakao_account\"); Map&lt;String, Object&gt; properties = (Map&lt;String, Object&gt;) oAuth2User.getAttributes().get(\"properties\"); return User.builder() .socialId(String.valueOf(attributes.get(\"id\"))) .email((String) kakao_account.get(\"email\")) .password(\"\") .username( (String) properties.get(\"nickname\")) .nickname(nickname) .social(\"kakao\")// .picture((String)attributes.get(\"picture\")) .build(); } // 인가 public static User of(OAuth2User oAuth2User, String nickname) {// nickname과 role만 있으면 됨 var authority = oAuth2User.getAuthorities(); String auth = authority.toString().replace(\"[\",\"\").replace(\"]\",\"\"); return User.builder() .password(\"\") .nickname(nickname) .role(UserRole.of(auth)) .build(); }}사용자가 OAuth 2.0 Provider를 통해 성공적으로 인증되면 OAuth2User.getAuthorities()를 사용하여 권한을 얻을 수 있다.UserDetailServicepublic interface UserDetailService extends UserDetailsService { UserDetails loadUserByUsername(String nickname) throws UserNotFoundException;}UserDetailServiceImplJwtTokenProvider가 제공한 사용자 정보로 DB에서 알맞은 사용자 정보를 가져와 UserDetails 생성@Service@RequiredArgsConstructor@Slf4jpublic class UserDetailServiceImpl implements UserDetailService {// @AuthenticationPrincipal에서 값을 받아오기 위해서는 아래 코드를 작성해야 한다. private final UserRepository userRepository; // User entity의 id 값 가져오기 (인증) @Override public UserDetails loadUserByUsername(String email) { log.info(\"[loadUserByUsername] loadUserByUsername 수행. email : {}\", email); return userRepository.findByEmail(email).orElseThrow(() -&gt; { throw new UserNotFoundException(); }); }}JwtTokenProvider에서 토큰의 payload에서 가져온 email 정보를 통해 Repository에서 유저 정보를 가져와야한다.그러기 위해서 UserDetailSerivce를 구현하는 클래스를 생성하여 loadUserByUsername 오버라이드 해서 이를통해 가져오면 된다.UserRepositorypublic interface UserRepository extends JpaRepository&lt;User, Long&gt; { Optional&lt;User&gt; findByEmail(String email);}configSecurityConfig@Configuration@RequiredArgsConstructor@EnableWebSecurity //spring security 활성화를 위한 annotationpublic class SecurityConfig { private final JwtTokenProvider jwtTokenProvider; private final CustomOAuthService oAuthService; private final OAuth2SuccessHandler successHandler; private final Oauth2FailureHandler failureHandler; @Bean public SecurityFilterChain filterChain(HttpSecurity http)throws Exception { http.csrf().disable() // rest api 에서는 csrf 공격으로부터 안전하고 매번 api 요청으로부터 csrf 토큰을 받지 않아도 되어 disable로 설정 .sessionManagement(); // Rest Api 기반 애플리케이션 동작 방식 설정 http.authorizeRequests() .antMatchers(\"/css/**\", \"/login/**\", \"/oauth2/**\").permitAll() .antMatchers(\"/admin/**\").hasAuthority(\"ADMIN\") .anyRequest().authenticated(); http .oauth2Login() // OAuth2 로그인 설정 시작점 .userInfoEndpoint() // OAuth2 로그인 성공 이후 사용자 정보를 가져올 때 설정 담당 .userService(oAuthService) // OAuth2 로그인 성공 시, 후작업을 진행할 UserService 인터페이스 구현체 등록 .and() .successHandler(successHandler) .failureHandler(failureHandler) .userInfoEndpoint().userService(oAuthService); http.addFilterBefore(new JwtAuthenticationFilter(jwtTokenProvider), UsernamePasswordAuthenticationFilter.class); // JwtAuthenticationFilter UsernamePasswordAuthenticationFilter보다 앞으로 설정 return http.build(); }}Spring Security는 여러가지의 필터를 순차적으로 돌며 해당되는 필터를 실행한다.그리고 인증에 관련된 책임은 AuthenticationManager에 의해 수행된다.기본적으로 Filter로 수행되는 것은 Form기반의 아이디와 비밀번호로 진행되는 UsernamePasswordAuthenticationFilter가 수행된다.하지만 JWT 인증을 위해서는 새로운 필터를 만들어 UsernamePasswordAuthenticationFilter보다 먼저 수행되게 설정해야 한다..antMatchers(\"/admin/**\").hasAuthority(\"ADMIN\")Spring Security에서 제공하는 역할(Role)과 권한(Authority)이 있다.A와 B는 둘 다 관리자의 역할을 가지고 있지만 원칙상 A 계정은 게시판의 글을 등록할 수만 있으며, B 계정은 등록된 글을 삭제만 할 수 있다고 했을 때 역할은 같지만 권한은 다르게 설정해야 할 것이다.hasRole 메소드에는 ‘ROLE_’ 접두어를 내부적으로 붙여준다.따라서 hasRole을 사용할 떄는 “ROLE_ADMIN”과 같이 작성해야하며 DB에도 동일하게 저장되어있어야한다.alter table user change column role role enum('ROLE_USER','ROLE_ADMIN');(Spring Security) OAuth2 서비스 구현 정리 3 Spring Security - Authorization(권한) 설정(ROLE), TagLib authorize 추가 ☑️ 참고어느 곳에서는 addFilterBefore 대신 addFilterAfter를 사용했다.http.addFilterAfter(jwtAuthenticationFilter, LogoutFilter.class);인증을 처리하는 기본필터 UsernamePasswordAuthenticationFilter 대신별도의 인증 로직을 가진 필터를 생성하고 사용하고 싶을 때 아래와 같이 필터를 등록한다. addFilterBefore 지정된 필터 앞에 커스텀 필터를 추가 (UsernamePasswordAuthenticationFilter 보다 먼저 실행된다) addFilterAfter 지정된 필터 뒤에 커스텀 필터를 추가 (UsernamePasswordAuthenticationFilter 다음에 실행된다.) addFilterAt 지정된 필터의 순서에 커스텀 필터가 추가된다 PasswordEncoderConfigurationconfig에 PasswordEncoder를 넣었다가 순환참조 error가 난 적이 있었는데 따로 빼서 등록을 해야 된다.@Configurationpublic class PasswordEncoderConfiguration { @Bean public PasswordEncoder passwordEncoder(){ return PasswordEncoderFactories.createDelegatingPasswordEncoder(); }}OAuth 사용자가 소셜 로그인을 정상적으로 완료 AbstractAuthenticationProcessingFilter에서 OAuth2 로그인 과정을 호출 Resource Server에서 넘겨주는 정보를 토대로 OAuth2LoginAuthenticationFilter의 attemptAuthentication()에서 인증 과정을 수행 attemptAuthentication attemptAuthentication() 처리 과정에서 OAuth2AuthenticationToken을 생성하기 위해 OAuth2LoginAuthenticationProvider의 authenticate()를 호출 authenticate authenticate() 처리 과정에서 OAuth2User를 생성하기 위해 OAuth2UserService의 loadUser()를 호출 OAuth2UserService의 기본 구현체는 DefaultOAuth2UserService이지만, 커스텀한 OAuth2User를 반환하도록 구현하고 싶었으므로 직접 구현한 CustomOAuth2UserService의 loadUser()가 호출된다. CustomOAuthServiceDefaultOAuth2UserService를 구현한 OAuth2UserService 작성SecurityConfig에서 OAuth2로그인 성공시에 CustomOAuthService에서 처리를 한다.@Service@RequiredArgsConstructor@Slf4jpublic class CustomOAuthService implements OAuth2UserService&lt;OAuth2UserRequest, OAuth2User&gt; { private final UserRepository userRepository; private final HttpSession httpSession; private final PasswordEncoder passwordEncoder; @Override public OAuth2User loadUser(OAuth2UserRequest userRequest) throws OAuth2AuthenticationException { // DefaultOAuth2UserService 객체를 성공정보를 바탕으로 만든다. OAuth2UserService&lt;OAuth2UserRequest, OAuth2User&gt; delegate = new DefaultOAuth2UserService(); // 생성된 Service 객체로 부터 User를 받는다. OAuth2User oAuth2User = delegate.loadUser(userRequest); // OAuth2 서비스 id (구글, 카카오, 네이버) String registrationId = userRequest.getClientRegistration().getRegistrationId(); // kakao // OAuth2 로그인 진행 시 키가 되는 필드 값(PK) String userNameAttributeName = userRequest.getClientRegistration().getProviderDetails().getUserInfoEndpoint() .getUserNameAttributeName(); // kakao는 id // OAuth2 로그인을 통해 가져온 OAuth2User의 attribute를 담아주는 of 메소드 // SuccessHandler가 사용할 수 있도록 등록해준다. OAuth2Attribute oAuth2Attribute = OAuth2Attribute.of(registrationId, userNameAttributeName, oAuth2User.getAttributes()); User user = userRepository.findByEmail(oAuth2Attribute.getEmail()).orElseGet(() -&gt; { log.info(\"[db save] : user social login\"); User saved = UserMapper.ofKakao(oAuth2User, nickname); userRepository.save(saved); return saved; }); if (!user.isEnabled()) throw new OAuth2AuthenticationException(new OAuth2Error(\"Not Found\"), new UserNotFoundException()); Map&lt;String, Object&gt; memberAttribute = oAuth2Attribute.convertToMap(); // {name=kakao에서 설정한 이름, id=email, key=email, email=test@kakao.com, picture=null} memberAttribute.put(\"id\", user.getId()); // 로그인한 user를 return한다. return new DefaultOAuth2User(Collections.singleton(new SimpleGrantedAuthority(user.getRole() .name())), memberAttribute, \"email\"); }}☑️ 참고OAuth2UserService oAuth2UserService = new DefaultOAuth2UserService(); 로 적은 글이 있어서 찾아봤다.→ OAuth2UserService&lt;OAuth2UserRequest, OAuth2User&gt; oAuth2UserService = new DefaultOAuth2UserService();OAuth2AttributeOAuth2 로그인을 통해서 가져온 OAuth2User의 정보를 담아주기 위한 OAuth2Attribute를 생성한다.스프링 부트에서는 google 및 facebook에 대한 OAuth2정보를 기본적으로 제공한다.하지만 Kakao와 NAVER 는 스프링 부트에서 기본적인 정보를 제공하지 않으므로아래와 같이 따로 해당 정보를 제공하는 클래스를 작성해야한다.@Builder(access = AccessLevel.PRIVATE)@Getterpublic class OAuth2Attribute { private Map&lt;String, Object&gt; attributes; // OAuth2 반환하는 유저 정보 Map private String attributeKey; private String email; private String name; private String picture; static OAuth2Attribute of(String provider, String attributeKey, Map&lt;String, Object&gt; attributes) { switch (provider) { case \"google\": return ofGoogle(attributeKey, attributes); case \"kakao\": return ofKakao(\"email\", attributes); case \"naver\": return ofNaver(\"id\", attributes); default: throw new RuntimeException(); } } private static OAuth2Attribute ofGoogle(String attributeKey, Map&lt;String, Object&gt; attributes) { return OAuth2Attribute.builder() .name((String) attributes.get(\"name\")) .email((String) attributes.get(\"email\")) .picture((String)attributes.get(\"picture\")) .attributes(attributes) .attributeKey(attributeKey) .build(); } private static OAuth2Attribute ofKakao(String attributeKey, Map&lt;String, Object&gt; attributes) { Map&lt;String, Object&gt; kakaoAccount = (Map&lt;String, Object&gt;) attributes.get(\"kakao_account\"); Map&lt;String, Object&gt; kakaoProfile = (Map&lt;String, Object&gt;) kakaoAccount.get(\"profile\"); return OAuth2Attribute.builder() .name((String) kakaoProfile.get(\"nickname\")) .email((String) kakaoAccount.get(\"email\")) .picture((String)kakaoProfile.get(\"profile_image_url\")) .attributes(kakaoAccount) .attributeKey(attributeKey) .build(); } private static OAuth2Attribute ofNaver(String attributeKey, Map&lt;String, Object&gt; attributes) { Map&lt;String, Object&gt; response = (Map&lt;String, Object&gt;) attributes.get(\"response\"); return OAuth2Attribute.builder() .name((String) response.get(\"name\")) .email((String) response.get(\"email\")) .picture((String) response.get(\"profile_image\")) .attributes(response) .attributeKey(attributeKey) .build(); } Map&lt;String, Object&gt; convertToMap() { Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put(\"id\", attributeKey); map.put(\"key\", attributeKey); map.put(\"name\", name); map.put(\"email\", email); map.put(\"picture\", picture); return map; }}OAuth2SuccessHandler@Slf4j@RequiredArgsConstructor@Componentpublic class OAuth2SuccessHandler implements AuthenticationSuccessHandler { private final JwtTokenProvider jwtProvider; @Value(\"${oauth.redirection.url}\") private String REDIRECTION_URL; @Override public void onAuthenticationSuccess(HttpServletRequest request, HttpServletResponse response, Authentication authentication) throws\t\t\tIOException { OAuth2User oAuth2User = (OAuth2User) authentication.getPrincipal(); String email = (String) oAuth2User.getAttributes().get(\"email\"); User userInfo = userRepository.findByEmail(email).orElseThrow(UserNotFoundException::new); String nickname = userInfo.getNickname(); User user = UserMapper.of(oAuth2User, nickname); // kakao type으로 넣기 String token = jwtProvider.generateToken(user); // string 으로 받는다 response.sendRedirect(getRedirectionURI(token, user));\t} private String getRedirectionURI(String token, User user) { if(user.getRole().name().equals(UserRole.USER.name())){ return UriComponentsBuilder.fromUriString(REDIRECTION_URL).queryParam(\"token\", token).build().toUriString(); }else if (user.getRole().name().equals(UserRole.ADMIN.name())){ return UriComponentsBuilder.fromUriString(ADMIN_REDIRECTION_URL).queryParam(\"token\", token).build().toUriString(); }else{ throw new RuntimeException(\"[error] 잘못된 권한입니다.\"); } };}Oauth2FailureHandler@Componentpublic class Oauth2FailureHandler implements AuthenticationFailureHandler { @Value(\"${oauth.failure.url}\") private String FAILURE_URL; @Override public void onAuthenticationFailure(HttpServletRequest request, HttpServletResponse response, AuthenticationException exception) throws IOException, ServletException { response.setCharacterEncoding(\"utf-8\"); response.setContentType(\"text/html; charset=UTF-8\"); PrintWriter printWriter = response.getWriter(); printWriter.println(\"&lt;script&gt;\"); printWriter.println(String.format(\"alert('%s')\", exception.getMessage())); printWriter.println(String.format(\"window.location.href='%s'\", FAILURE_URL)); printWriter.println(\"&lt;/script&gt;\"); }}jwtJwtTokenProviderJwt Token을 생성, 인증, 권한 부여, 유효성 검사, PK 추출 등의 다양한 기능을 제공하는 클래스JwtTokenProvider에 Token을 통해 사용자 정보를 조회할 수 있는 메서드를 작성한다.@Component@RequiredArgsConstructor@Slf4jpublic class JwtTokenProvider { private final UserDetailService userDetailsService; @Value(\"${springboot.jwt.secret}\") private String secretKey; // 토큰 생성에 필요한 key private final long TOKEN_VALID_MILISECOND = 1000L * 60 * 60 * 10; // token 유효시간 : 10시간 long refreshPeriod = 1000L * 60L * 60L * 24L * 30L * 3L; // SecretKey 초기화 @PostConstruct // Bean 객체로 주입된 후 수행 protected void init() { log.info(\"[init] JwtTokenProvider 내 secretKey 초기화 시작\"); // secretKey 를 base64 형식으로 인코딩 secretKey = Base64.getEncoder().encodeToString(secretKey.getBytes(StandardCharsets.UTF_8)); log.info(\"[init] JwtTokenProvider 내 secretKey 초기화 완료\"); } public String createToken(User user) { log.info(\"[createToken] 토큰 생성 시작\"); // Claims 객체에 담아 Jwt Token 의 내용에 값 넣기, sub 속정에 값 추가(Uid 사용) Claims claims = Jwts.claims().setSubject(user.getNickname()); claims.put(\"roles\", user.getRole().name()); // 사용자 권한확인용 추가 Date now = new Date(); // Token 생성 String token = Jwts.builder() .setClaims(claims) .setIssuedAt(now) .setExpiration(new Date(now.getTime() + TOKEN_VALID_MILISECOND)) .signWith(SignatureAlgorithm.HS256, secretKey) .compact(); log.info(\"[createToken] 토큰 생성 완료\"); return token; } // 필터에서 인증에 성공시 SecurityContextHolder 에 저장할 Authentication 생성 public Authentication getAuthentication(String token) { log.info(\"[getAuthentication] 토큰 인증 정보 조회 시작\"); Claims claims = getClaims(token).getBody(); String role = claims.get(\"roles\").toString(); User user = User.builder() .nickname(claims.getSubject()) .role(UserRole.of(role)) .build(); log.info(\"[getAuthentication] 토큰 인증 정보 조회 완료\"); return new UsernamePasswordAuthenticationToken(user, token, user.getAuthorities()); } public String getNickname(String token) { log.info(\"[getUsername] 토큰 기반 회원 구별 정보 추출\"); // 토큰을 생성할때 넣었던 sub 값 추출 String info = getClaims(token).getBody().getSubject(); log.info(\"[getUsername] 토큰 기반 회원 구별 정보 추출 완료\"); return info; } // Token 유효기간 체크 public boolean validateToken(String token) { log.info(\"[validateToken] 토큰 유효 체크 시작\"); try { Jws&lt;Claims&gt; claims = Jwts.parser(). setSigningKey(secretKey) .parseClaimsJws(token); return !claims.getBody().getExpiration().before(new Date()); } catch (Exception e) { log.info(\"[validateToken] 토큰 유효 체크 예외 발생\"); return false; } }} private Jws&lt;Claims&gt; getClaims(String jwt){ try{ return Jwts.parser().setSigningKey(secretKey).parseClaimsJws(jwt); }catch (SignatureException e){ log.error(\"Invalid JWT signature\"); throw e; } catch (MalformedJwtException e){ log.error(\"Invalid JWT token\"); throw e; } catch (ExpiredJwtException e){ log.error(\"Expired JWT token\"); throw e; } catch (UnsupportedJwtException e){ log.error(\"Unsupported JWT token\"); throw e; } catch (IllegalArgumentException e){ log.error(\"JWT claims string is empty\"); throw e; } }}JwtAuthenticationFilterJwt가 유효한 토큰인지 인증하기 위한 FilterCustomFilter를 만들어 UsernamePasswordAuthenticationFilter보다 먼저 걸리도록 설정해야한다.스프링 시큐리티에서는 기본적으로 토큰 처리를 위한 필터가 없으므로 구현해서 Filter Chain에 추가해야 한다.@RequiredArgsConstructor@Slf4jpublic class JwtAuthenticationFilter extends OncePerRequestFilter { private final JwtTokenProvider jwtTokenProvider; private final String BEARER = \"Bearer \"; @Override protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain filterChain) throws ServletException, IOException { String token = request.getHeader(HttpHeaders.AUTHORIZATION); request.setAttribute(\"existsToken\", true); // 토큰 존재 여부 초기화 if (isEmptyToken(token)) request.setAttribute(\"existsToken\", false); // 토큰이 없는 경우 false로 변경 if (token == null || !token.startsWith(BEARER)) { filterChain.doFilter(request, response); return; } token = parseBearer(token); if (jwtTokenProvider.validateToken(token)) { Authentication authentication = jwtTokenProvider.getAuthentication(token); // JwtTokenProvider를 통해 Jwt 토큰을 검증 받는다. SecurityContextHolder.getContext().setAuthentication(authentication); } filterChain.doFilter(request, response); } private boolean isEmptyToken(String token) { return token == null || \"\".equals(token); } private String parseBearer(String token) { return token.substring(BEARER.length()); }}JWT 토큰 검증이 필요한 경우에만 동작하도록 조건 처리를 한다.클라이언트에서는 Authorization Header에 토큰을 담아서 보내므로,HttpServletRequest에서 토큰을 추출한 후, 검증하여 Authentication을 SecurityContext에 저장한다.ErrorClientRegistrationRepositoryoauth를 적용하면서 가장많이 본 오류다.***************************APPLICATION FAILED TO START***************************Description:Method springSecurityFilterChain in org.springframework.security.config.annotation.web.configuration.WebSecurityConfiguration required a bean of type 'org.springframework.security.oauth2.client.registration.ClientRegistrationRepository' that could not be found.Action:Consider defining a bean of type 'org.springframework.security.oauth2.client.registration.ClientRegistrationRepository' in your configuration.위 문제는 아래와 같이 수정하다보니 해결되었다.1. properties에 정보입력하기 [본문 내용 참고하기]2. security extends없애기spring 공식 blog 5.7.x 버전부터는 아래와 같이 변경@Configurationpublic class SecurityConfiguration extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { http .authorizeHttpRequests((authz) -&gt; authz .anyRequest().authenticated() ) .httpBasic(withDefaults()); }}변경 후 추상화 객체가 빠지고 @Bean을 추가하고 함수 명이 바뀌고 리턴값이 생긴걸 볼 수 있다.@Configurationpublic class SecurityConfiguration { @Bean public SecurityFilterChain filterChain(HttpSecurity http) throws Exception { http .authorizeHttpRequests((authz) -&gt; authz .anyRequest().authenticated() ) .httpBasic(withDefaults()); return http.build(); }}OAuthServiceSecurityConfig에서 OAuth2로그인 성공시에 OAuthService에서 처리를 한다.그런데 code는 잘 받아오는데 OAuthService로 가지 않는 상황이 생겼다.로그를 찍어봐도 애초에 OAuthService로 가지 않는 문제가 발생했다.http.oauth2Login() // OAuth2 로그인 설정 시작점 .userInfoEndpoint() // OAuth2 로그인 성공 이후 사용자 정보를 가져올 때 설정 담당 .userService(oAuth2UserService) // OAuth2 로그인 성공 시, 후작업을 진행할 UserService 인터페이스 구현체 등록 .and() .successHandler(successHandler) .failureHandler(failureHandler); .authorizationEndpoint().baseUri(\"/oauth2/authorize\") // 소셜 로그인 Url .and() .redirectionEndpoint().baseUri(\"/oauth2/callback/**\");// 소셜 인증 후 Redirect UrlbaseUri 같은 경우에는 successHandler에서 처리해주기 때문에 생략했다.http.oauth2Login() .userInfoEndpoint().userService(customOAuth2UserService) .and() .successHandler(successHandler) .failureHandler(failureHandler) .userInfoEndpoint().userService(customOAuth2UserService);redirection카카오 로그인을 하면 “리디렉션한 횟수가 너무 많습니다.” 라는 오류가 뜨면서 계속 reload 되었다.리디렉션 에러는 session 문제였다.security에 .sessionCreationPolicy(SessionCreationPolicy.STATELESS); 를 작성했었는데위 코드는 세션을 사용하지 않는다를 의미한다. 이부분을 제거하니 제대로 동작하였다.1. 클라이언트가 OAuth2 서비스 제공자에게 인증 요청을 보낸다.2. 사용자는 서비스 제공자에게 로그인 정보를 제공하고, 인증을 수행한다.3. 서비스 제공자는 클라이언트에게 인증 코드 또는 Access Token을 발급한다.4. 클라이언트는 발급 받은 인증 코드 또는 Access Token을 사용하여 서비스 제공자의 API에 요청을 보낸다.5. 서비스 제공자는 인증 코드 또는 Access Token의 유효성을 검증하고, 인증 및 자원 접근을 허용한다.OAuth2 로그인 과정에서 session을 사용하여 인증 정보를 저장하고 관리한다.session은 server에서 상태를 유지하고 client는 sessionID를 통해 인증을 유지한다.따라서 OAuth2를 사용하는 경우 session 기반의 인증방식을 활용해서 로그인을 처리한다.RESTful API와 같은 stateless한 시스템을 구축하려면 다른 토큰 기반의 인증 방식을 고려해야한다.reference Kakao developers REST API docs [JAVA] Spring Boot(스프링 부트) - Security(시큐리티) 설정 Spring Security + JWT를 통해 프로젝트에 인증 구현하기 발급받은 JWT로 요청하기 [Spring Boot] OAuth2 + JWT + React 적용해보리기 Spring Security 와 OAuth 2.0 와 JWT 의 콜라보 Spring Security 커스텀 필터를 이용한 인증 구현 - 스프링시큐리티 설정(2) Spring Security OAuth 설정 및 이해하기 Spring Security OAuth2 Login Flow Spring Security - UsernamePasswordAuthenticationFilter 란 [Spring Boot] Spring Security (5) - 역할(hasRole)과 권한(hasAuthority)의 차이는 무엇일까? (Spring Security) OAuth2 서비스 구현 정리" }, { "title": "Oauth2", "url": "/posts/OAuth2/", "categories": "Project, OAuth2", "tags": "spring, Security, OAuth2", "date": "2023-03-05 00:00:00 +0900", "snippet": "OAuth애플리케이션 인증을 위한 접근 관한 개방형 표준 프로토콜 인증 : 사용자가 누구인지 확인하는 단계 ex) login 권한 : 사용자가 해당 리소스에 접근할 권리가 있는지를 확인Open Authorization의 약자로 인터넷 사용자들이 비밀번호를 제공하지 않고,다른 웹사이트 상의 자신들의 정보에 대해 웹사이트나 애플리케이션의 접근권한을 부여할 수 있는 공통적인 수단으로사용되는 접근 위임을 위한 개방형 표준이다.OAuth가 사용되기 전에는 인증방식의 표준이 없었기 때문에 기존의 기본인증인 아이디와 비밀번호를 사용하였는데,보안상 취약한 구조일 가능성이 매우 높았다.OAuth는 이런 제각각 인증방식을 표준화한 인증방식이다.OAuth를 이용하면 이 인증을 공유하는 애플리케이션끼리 별도의 인증이 필요없다.따라서 여러 애플리케이션을 하나의 인증으로 통합 사용이 가능하다.OAuth 2.0OAuth 1.0과의 차이점 https를 통해 암호화를 해서 보완 강화 api서버에서 인증서버와 리소스 서버가 분리 scope 기능 추가 : token에 대한 접근 제한 범위 설정 token 탈취 문제 개선(Access Token + Refresh Token) client 구현 복잡성 간소화 : Bearer Token + TLSrole term description Authentication 신원 확인 Authorization 권한 부여 Client google, facebook 등의 아이디로 로그인이 가능한 제 3의 서비스 Resource Owner google, facebook 등의 아이디로 로그인하는 사용자 Resource Server 회원의 정보를 저장하고 있는 서버(google, facebook 등) Authorization Server 로그인을 통해 인증 후 권한을 부여하는 서버(google, facebook 등) Authentication Server 실제로 로그인 서비스를 제공하는 서버(google, facebook 등) Access Token 실제 요청을 보낼 때 사용하는 토큰 (google, facebook 등에서 로그인 시 발급) Refresh Token Access Token이 만료된 경우 재발급을 위해 사용하는 토큰 (google, facebook 등에서 로그인 시 발급) OAuth2 Flow사용자를 Resource Owner라고 하고 로그인하려고 하는 우리가 만든 서비스(로그인 하려는 서비스)를 Client,사용자가 회원가입이 되어있는 서비스를 Resource Server라고 한다.Resource Server와 Authorization Server로 나눌 수 있는데데이터를 가지고 있는 서버와 인증과 관련된 처리를 전담하는 서버로 나눌 수 있다.여기서는 설명을 위해 합쳐서 Resource Server라고 통일한다.Resource Server에서 나의 id, password를 Client에 정보를 제공해줄 것이다.이것은 id와 password를 공유하기 문에 보안상 좋지 않다.oAuth를 사용하면 Resource Server에서 accessToken을 발급해주고Client에서 accessToken으로 로그인을 할 수 있게 해준다.RegisterResource Server를 이용하려면 Client가 사전에 승인을 받아야 한다.이때, Redirect URI를 등록해야한다.Redirect URI는 사용자가 OAuth 2.0 서비스에서 인증을 마치고 (ex. google login 페이지에서 로그인을 마쳤을 때)사용자를 리디렉션시킬 위치이다.OAuth 2.0 서비스는 인증이 성공한 사용자를 사전에 등록된 Redirect URI로만 리디렉션 시킨다.승인되지 않은 URI로 리디렉션 될 경우, 추후 설명할 Authorization Code를 중간에 탈취당할 위험성이 있기 때문이다.Redirect URI는 기본적으로 보안을 위해 https만 허용된다.단, 루프백(localhost)은 예외적으로 http가 허용된다.등록과정을 마치면, Client ID와 Client Secret를 얻을 수 있다.Client ID는 공개되어도 상관없지만 Client Secret는 공개되면 안된다.Authorized redirect URIs : 이 주소로 전달해주세요 (이 외의 주소로 오면 정보 안줌)Resource Owner의 승인사용하고자 하는 기능 B, C일때,Resource Owner에 로그인이 되어있지 않으면 로그인을 하라고 요청한 후로그인이 되면 Resource Server는 client의 id값과 같고 redirect_uri와 값이 같은지 확인한다.값이 같다면 scope에 해당하는 권한을 client에게 부여할 것인지를 확인하는 메세지를 Resource Server가 Resource Owner에게 전송한다.Resource Owner가 허용하게 되면 Resource Server는 정보를 수집해서 아래와 같이 서버에 저장한다.Resource Server의 승인Resource Server가 Client에게 accessToken을 발급하기 전에 임시 비밀번호를 발급한다.authorization code = 3이라는 임시 비밀번호를 발급해서 Resource Owner에게 주면Resource Owner는 모르게 해당 location 주소로 이동을 한다.code=3번에 의해서 Client는 code=3이라는 값을 알게 된다.Client는 해당 주소로 Resource Owner를 통하지 않고 Resource Server에 직접 접근한다.Resource Server는 위 정보가 완전히 일치하면 Access Token을 발급한다.Access Token 발급인증을 했기 때문에 authorization code를 지운다.그리고 accessToken을 발급한다. 그리고 Client에게 AccessToken 값을 응답해준다.Referesh tokenaccessToken은 수명이 있다. 그 수명이 끝나면 api에 접속했을 때 db를 주지 않는다.그러면 다시 발급을 하려면 위와 같이 해야되는데 그런 것을 하지 않고 referesh token을 발급할 수 있다.Invalid Token Error이 뜨면 Access Token 수명이 다 된 것OAuth 인증 방식 종류인증 종류에는 4가지 방식이 있는데 이 중에서 나는 Authorization Code Grant Type 방식을 사용했다. Authorization Code Grant Type Implicit Grant Type Resource Owner Password Credentials Grant Type Client Credentials Grant TypeAuthorization Code Grant Type 권한 부여 코드 승인 타입Resource Owner에게 사용 허락을 받았다는 증서인 권한 코드 (Authorization Code)를 가지고 AccessToken을 요청하는 방식클라이언트가 파리미터로 클라이언트 ID, 리다이렉트 URI, 응답 타입을 code로 지정하여 권한 서버에 전달한다.정상적으로 인증이 되면 권한 코드 부여 코드를 클라이언트에게 보낸다.(응답 타입은 code, token 이 사용 가능하다. 응답 타입이 token 일 경우 암시적 승인 타입에 해당한다.)성공적으로 권한 부여 코드를 받은 클라이언트는 권한 부여 코드를 사용하여 엑세스 토큰을 권한 서버에 추가로 요청한다.이때 필요한 파라미터는 클라이언트 ID, 클라이언트 비밀번호, 리다이렉트 URI, 인증 타입이다.마지막으로 받은 엑세스 토큰을 사용하여 리소스 서버에 사용자의 데이터를 보낸다.보통 서버 사이드에서 인증을 처리하는 경우 이 방식을 많이 사용하고, (code에서도 이방식을 사용한다.)Resource Owner에게 사용 허락을 받은 후 증서를 따로 받고,이 증서와 함께 요청하는 방식이므로 다른 방식보다 조금 더 복잡하다.대신 다른 방식보다 좀 더 신뢰성이 있는 방식이라 발급되는 액세스 토큰의 유효시간이 좀 더 길고,다시 액세스 토큰을 발급받을 수 있는 Refresh Token을 함께 발급해 준다.Implicit Grant Type 암시적 승인 타입Authorization Code Grant Type과 다르게 권한 코드 교환 단계 없이 엑세스 토큰을 즉시 반환받아 이를 인증에 이용하는 방식이다.클라이언트가 파리미터러 클라이언트 ID, 리다이렉트 URI, 응답 타입을 code로 지정하여 권한 서버에 전달한다.정상적으로 인증이 되면 권한 코드 부여 코드를 클라이언트에게 보낸다.(응답 타입은 code, token 이 사용 가능하다. 응답 타입이 token 일 경우 암시적 승인 타입에 해당한다.)응답 해준 Access Token 이 유효한지 검증 요청을 한다.요청 받은 Access Token 정보에 대한 검증에 대한 응답값을 돌려준다.유효한 Access Token 기반으로 Resource Server와 통신한다.Resource Owner Password Credentials Grant Type 리소스 소유자 암호 자격 증명 승인 타입클라이언트가 암호를 사용해 엑세스 토큰에 대한 사용자의 자격 증명을 교환하는 방식인증을 진행한다. 대부분 ID, Password를 통해서 자격 증명이 진행된다.넘겨 받은 정보기반으로 권한 서버에 Access Token 정보를 요청한다.Access Token 정보를 응답 받습니다. 이때 Refresh Token 정보도 넘겨 줄 수도 있다.Access Token 기반으로 Resource Server와 통신한다.리소스 소유자가 장치 운영 체제 또는 높은 권한을 가진 응용 프로그램과 같이 클라이언트와 신뢰 관계가 있는 경우에 적합하다.Client Credentials Grant Type 클라이언트 자격 증명 승인 타입Access Token 정보를 요청한다.Access Token 정보를 응답한다. 이때 Refresh Token 정보는 응답하지 않는 것을 권장한다. 별다른 인증 절차가 없기 때문에 Refresh Token 까지 넘기지 않는 것이라고 생각한다.Access Token 기반으로 Resource Server와 통신한다.클라이언트가 컨텍스트 외부에서 액세스 토큰을 얻어 특정 리로스에 접근을 요청할때 사용한다.reference OAuth 2.0. 생활코딩 OAuth란? &amp; OAuth1 vs OAuth2 OAuth2 인증방식 종류들 OAuth 2.0 기반 인증 방식 OAuth 프로토콜의 이해와 활용 3 - OAuth 인증방식의 종류 [Spring] Spring Security 기본 개념 (JWT / OAuth2.0 / 동작 방식 / 구성 요소) OAuth2 인증 방식 정리 OAuth 2.0 개념과 동작원리" }, { "title": "Sse 문제점", "url": "/posts/SSE-%EB%AC%B8%EC%A0%9C%EC%A0%90/", "categories": "Project", "tags": "spring, WebSocket, Chat, SSE", "date": "2023-03-01 00:00:00 +0900", "snippet": "처음에 실시간 알림을 구현하기 위해 여기저기 글들을 보았다.이전에 웹소켓 하면서 실시간 알림을 구현하기에는 SSE가 적당하다는 글을 보아서SSE에 대해서 공부하려고 했다. SSE를 사용하면 문제가 있는데 그 문제를 해결하기 위해서검색해보고 해당 문제를 보다가 그 문제에 관한 또 다른 문제가 엮이고 엮여서 정리하기로 했다.이 글은 SSE에 대한 내용보다는 SSE를 사용하면서 나타나는 문제에 대한 해결을 어떻게 해야할지에 관한 글이다.관련 글 Websocket Websocket + 부가기능 Websocket (채팅 기록 json 파일 저장하기) Sse Sse 문제점 👈🏻 Websocket + jwt Websocket test Jmh - 채팅 파일 refactoring들어가기 전SSE에 대해서 알아보기 전에 먼저 알아야 할 부분에 대해서 작성해봤다.SSE 정리 글트랜잭션여러 쿼리를 논리적으로 하나의 작업으로 묶어 주는 것예시) 거래가 일어날 때 실행되는 쿼리는 다음과 같다.UPDATE : 구매자 계좌에서 10000원 ➖UPDATE : 판매자 계좌에서 10000원 ➕그런데 이 과정에서 오류가 발생해서 구매자 계좌에서는 10000원이 빠졌는데판매자의 계좌에서는 10000원이 들어오지 않는 경우가 생길 수도 있다.UPDATE : 구매자 계좌에서 10000원 ➖ ⬇️ 오류 발생 UPDATE : 판매자 계좌에서 10000원 입금 ❌ (???) 이러한 상황을 방지 하고자 나온 것이 트랜잭션이다.하나의 작업으로 이루어지는 쿼리들을 트랜잭션이라는 논리적인 하나의 작업 단위로 묶어서쿼리들이 한꺼번에 모두 실행되거나 아예 아무 쿼리도 실행되지 않게 해주는 것이다.— — — — — — — 트랜잭션 — — — — — — — — — — ¦ ¦¦ UPDATE : 구매자 계좌에서 10000원 ➖ ¦ ¦ UPDATE : 판매자 계좌에서 10000원 ➕ ¦ ¦ ¦ — — — — — — — — — — — — — — — — — — — — — — — @Transactional@Transactional은 클래스나 메서드에 붙여줄 경우, 해당 범위 내 메서드가 트랜잭션이 되도록 보장해준다.@Transactional이 클래스 혹은 메서드에 붙일 때, Spring은 해당 메서드에 대한 프록시를 만든다.프록시 패턴은 디자인 패턴 중 하나로, 어떤 코드를 감싸면서 추가적인 연산을 수행하도록 강제하는 방법이다.트랜잭션의 경우, 트랜잭션의 시작과 연산 종료시의 커밋 과정이 필요하므로,프록시를 생성해 해당 메서드의 앞뒤에 트랜잭션의 시작과 끝을 추가하는 것이다.스프링 컨테이너는 트랜잭션 범위의 영속성 컨텍스트 전략을 기본으로 사용한다.Service에서 @Transactional을 사용할 경우, 해당 코드 내의 method를 호출할 때 영속성 컨텍스트가 생긴다는 뜻이다.영속성 컨텍스트는 프록시가 트랜잭션을 시작할 때 생겨나고,메서드가 종료되어 프록시가 트랜잭션을 커밋할 경우 영속성 컨텍스트가 flush되면서 해당 내용이 반영된다.이후 영속성 컨텍스트 역시 종료되는 것이다.*AOP에 바탕을 두고 설계되었기 때문에, 프록시는 트랜잭션 AOP로 명칭☑️ 만약 같은 트랜잭션 내에서 여러 EntityManager를 쓰더라도, 이는 같은 영속성 컨텍스트를 사용한다.☑️ 같은 EntityManager를 쓰더라도, 트랜잭션이 다르면 다른 영속성 컨텍스트를 사용한다.영속성 컨텍스트영속성 컨텍스트란 눈에 보이지 않으며 Entity를 영구히 저장하는 환경이라는 뜻이다.영속성 컨텍스트는 사용자의 요청 시점에서 생성이 되지만,데이터를 쓰거나 수정할 수 있는 트랜잭션은 비즈니스 계층에서만 사용할 수 있도록 트랜잭션이 일어난다.SSE의 문제점SSE를 사용하면 JPA 사용시 Connection 고갈문제가 있다.SSE 통신을 하는 동안은 HTTP Connection이 계속 열려있습니다. 만약 SSE 연결 응답 API에서 JPA를 사용하고 open-in-view 속성을 true로 설정했다면, HTTP Connection이 열려있는 동안 DB Connection도 같이 열려있게 됩니다.즉 DB Connection Pool에서 최대 10개의 Connection을 사용할 수 있다면, 10명의 클라이언트가 SSE 연결 요청을 하는 순간 DB 커넥션도 고갈되게 됩니다. 따라서 이 경우 open-in-view 설정을 반드시 false로 설정해야 합니다.Spring에서 Server-Sent-Events 구현하기그래서 open-in-view에 대해 찾아보게 되었다.open-in-view는 관례상 OSIV라고 한다.OSIV(Open-Session-In-View)OSIV(Open Session In View)는 영속성 컨텍스트를 뷰까지 열어두는 기능이다.영속성 컨텍스트가 유지되면 엔티티도 영속 상태로 유지된다.뷰까지 영속성 컨텍스트가 살아있다면 뷰에서도 지연 로딩을 사용할 수가 있다.JPA에서는 OEIV(Open EntityManager In View), 하이버네이트에선 OSIV(Open Session In View)라고 한다.하지만 관례상 둘 다 OSIV로 부른다.SpringBoot는 기본적으로 OSIV를 허용한다.false로 설정할 경우에만 application.properties(yml)에서 spring.jpa.open-in-view: false 로 설정하면 된다.여기서 예시로 연관관계를 많이 들고 있다. 이유는 LAZY 로딩때문이다.TRUEtrue일 경우 영속성 컨텍스트가 트랜잭션 범위를 넘어선 레이어까지 살아있다.Api라면 클라이언트에게 응답될 때까지, View라면 View가 렌더링될 때까지 영속성컨텍스트가 살아있다.그래서 지금까지 View Template이나 API 컨트롤러에서 지연 로딩이 가능했던 것이다.지연 로딩은 영속성 컨텍스트가 살아있어야 가능하고, 영속성 컨텍스트는 기본적으로 데이터베이스 커넥션을 유지한다.동작원리☑️ 클라이언트의 요청이 들어오면 서블릿 필터나, 스프링 인터셉터에서 영속성 컨텍스트를 생성한다.단 이 시점에서 트랜잭션은 시작하지 않는다.☑️ 서비스 계층에서 @Transeactional로 트랜잭션을 시작할 때1번에서 미리 생성해둔 영속성 컨텍스트를 찾아와서 트랜잭션을 시작한다.☑️ 서비스 계층이 끝나면 트랜잭션을 커밋하고 영속성 컨텍스트를 플러시한다.이 시점에 트랜잭션은 끝내지만 영속성 컨텍스트는 종료되지 않는다.☑️ 컨트롤러와 뷰까지 영속성 컨텍스트가 유지되므로 조회한 엔티티는 영속 상태를 유지한다.☑️ 서블릿 필터나, 스프링 인터셉터로 요청이 돌아오면 영속성 컨텍스트를 종료한다.이때 플러시를 호출하지 않고 바로 종료한다.서비스 계층에서 트랜잭션이 끝나면 컨트롤러와 뷰에는 트랜잭션이 유지되지 않는 상태이다.엔티티를 변경하지 않고 단순히 조회만 할 때는 트랜잭션이 없어도 동작하는데,이것을 트랜잭션 없이 읽기(Nontransactional reads)라 한다.하여 만약 프록시를 뷰 렌더링하는 과정에 초기화(Lazy loading)가 일어나게 되어도조회 기능이므로 트랜잭션이 없이 읽기가 가능하다.☑️ 영속성 컨텍스트는 기본적으로 트랜잭션 범위 안에서 엔티티를 조회하고 수정할 수 있다.☑️ 영속성 컨텍스트는 트랜잭션 범위 밖에서 엔티티를 조회만 할 수 있다.이것을 트랜잭션 없이 읽기(Nontransactional reads)라 한다.FALSE트랜잭션을 종료할 때 영속성 컨텍스트 또한 닫힌다.그러므로 Service에서 끝나기 때문에 영속성컨텍스트가 Transaction 범위 바깥인 Controller에서 Lazy loading 을 시도하면 에러가 뜬다.영속성 컨텍스트가 닫혔다면 Lazy loading 또한 할 수 없다.ex) Registry와 Comment의 1:N 관계에서게시글 페이지에서 Registry를 가져올 때는 Comment는 지연로딩이기 때문에영속성 컨텍스트에 proxy 객체만 있고 실제 객체는 없다.여기서 Service가 Controller로 가게 되면영속성 컨텍스트는 닫히게 되고 view에서 comment를 호출할 경우Controller는 comment에 접근하고 싶어도 영속성 컨텍스트가 이미 닫혀있어서 error를 내게 된다.*LazyInitializationException이 발생OSIV 장단점sping.jpa.open-in-view : true 장점 뷰 렌더링 종료시까지 영속성 컨텍스트가 유지 지연 로딩을 하나의 트랜잭션 안에서 처리하지 않아도 되기 때문에 코드 구현에 있어서 상대적으로 편하고, 관리해야 할 코드도 줄어듬 단점 DB 커넥션을 뷰 렌더링 종료시까지 유지 상황에 따라 커넥션 부족 문제가 발생할 수 있음 sping.jpa.open-in-view : false 장점 DB 커넥션 리소스의 효율적인 사용 트랜잭션을 종료할 때 영속성 컨텍스트를 닫으면서 DB 커넥션을 반환 단점 모든 지연 로딩을 트랜잭션 안에서 처리 이 문제를 해결하기 위해 추가적인 Service Layer를 관리/생성해야함. 코드의 구현량 증가 보통 고객 서비스의 실시간 API는 OSIV를 끄고, ADMIN처럼 커넥션을 많이 사용하지 않는 곳에서는 OSIV를 키는 것을 권장한다.문제 해결하기나는 채팅과 실시간 알림을 사용한다.그러면 sping.jpa.open-in-view : false로 설정후에 오류가 안나게 하려면 어떻게 해야할까?OSIV를 끄면 트랜잭션을 종료할 때 영속성 컨텍스트를 닫고, 데이터베이스 커넥션도 반환한다.따라서 커넥션 리소스를 낭비하지 않는다.OSIV를 끄면 모든 지연로딩을 트랜잭션 안에서 처리해야 한다.따라서 지금까지 작성한 많은 지연 로딩 코드를 트랜잭션 안으로 넣어야 하는 단점이 있다.그리고 view template에서 지연로딩이 동작하지 않는다.결론적으로 트랜잭션이 끝나기 전에 지연 로딩을 강제로 호출해 두어야 한다.Command와 Query 분리실무에서 OSIV를 끈 상태로 복잡성을 관리하는 좋은 방법이 있다.바로 Command와 Query를 분리하는것이다.Command : 결과를 반환하지 않고 시스템의 상태를 변화시킨다.Query : 결과 값을 반환하고, 시스템의 관찰 가능한 상태를 변화시키지 않는다. (free of side effect) Service MainService: 핵심 비즈니스 로직 QueryService: 화면이나 API에 맞춘 서비스 (주로 읽기 전용 트랜잭션 사용) INSERT : ID만 반환 UPDATE : void 조회는 내부 변경 로직이 없는 메서드로 설계reference [JPA]open-session-in-view 를 알아보자 [JPA] OSIV (Open Session In View) Spring에서 Server-Sent-Events 구현하기 [JPA] Open In View [JPA] 영속성 컨텍스트와 OSIV(Open Session In View) JPA - OSIV(Open Session In View) 정리 [JPA] 성능 최적화하기 (읽기 전용으로 변경, OSIV) [10분 테코톡] 🌼 예지니어스의 트랜잭션 @Transactional 어노테이션의 이해 " }, { "title": "Sse", "url": "/posts/SSE/", "categories": "Project", "tags": "spring, WebSocket, Chat, SSE", "date": "2023-02-28 00:00:00 +0900", "snippet": "SSE(Server-Sent-Event)관련 글 Websocket Websocket + 부가기능 Websocket (채팅 기록 json 파일 저장하기) Sse 👈🏻 Sse 문제점 Websocket + jwt Websocket test Jmh - 채팅 파일 refactoring이 전에 websocket 재 연결에 대해 잠시 헤매고 있을 때(stomp 적용 전)SSE를 사용하는 것에 대해 들어봤었다. 물론 그때는 채팅이기때문에 적용을 하지 않았고채팅이 끝나고 알림기능을 구현할 때 적용해봐야지 생각이 들었다.그리고 이번에 알림기능을 적용하면서 SSE에 대해서 공부하게 되었다.SSE에 대해서 이론을 어느정도 파악하고 코드를 작성하는 방법에 대해서 찾아보니간단한 코드도 있고 조금 설정을 해야하는 코드들도 있었다. 나는 간단한 방법으로 작성했다.front 참고 [Spring] Websocket / Sock js를 사용한 실시간 알림전송 기능 구현전체적인 코드 참고 Spring에서 Server-Sent-Events 구현하기그 외 알림 기능을 구현해보자 - SSE(Server-Sent-Events)! [Spring + SSE] Server-Sent Events를 이용한 실시간 알림*이론 관련 reference는 하단에 적어뒀다.CLIENT - SERVERHTTP 프로토콜의 특징 중 중요한 부분 중 하나는 비연결성이다.HTTP는 비연결성이라는 특징을 가지고 있어서 연결을 끊어버린다.이를 해결하는 방식이 Polling(폴링) 이다.Polling클라이언트가 주기적으로 서버에 요청을 보내는 방법이다.일정 시간마다 서버에 요청을 보내 데이터가 갱신되었는지 확인하고 만약 갱신되었다면 데이터를 응답받는다.클라이언트와 서버 모두 구현이 단순해서 서버가 요청에 대한 부담이 크지 않고 요청 주기를 넉넉하게 잠아도 될 정도로실시간성이 중요하지 않다면 고려해 볼만한 방법이다.그러나 클라이언트가 계속 Request를 보내면서 서버의 부담은 점점 늘어난다.그리고 Connection을 맺고 끊는 것에 대한 비용 부담이 커지기 때문에 좋지 않을 뿐더러이러한 방식이 진짜 실시간으로 동작한다고 보기에도 어려운 점이 존재한다.(주기적으로 보내는 것이기에 바로 응답한다는 것에 대한 보장이 없다.)다른 방법으로 Long Polling(긴 폴링)이 있다.Long Polling요청을 보내고 서버에서 변경이 일어날 때까지 대기하는 방법이다.즉, Connection을 계속 열어두고 요청이 온다면 해당 요청을 처리하는 것이다.처음에 긴 Connection을 가질 수 있게 Request를 보낸다.그리고 지속되고 있는 Connection 시간동안 어떤 이벤트가 발생했을 때 그 이벤트에 대한 결과 값을 지속되고 있는 Connection을 통해 보내면 된다.그리고 다시 긴 Connection을 가질 수 있게 Request를 보낸다. 위의 방식을 반복하게 된다.폴링 방식과 달리 계속적으로 Connection을 열어두고 있다가 바로 그에 대한 결과값을 받기에 실시간성이 보장될 것이다.실시간 메시지 전달이 중요하지만 서버의 상태가 빈번하게 변하지 않는 경우에 적합하다.하지만 시간 간격이 좁다면 사실상 기존 폴링과 큰 차이가 없게되고 지속적으로 연결되어 있기 때문에다수의 클라이언트에게 동시에 이벤트가 발생될 경우Response를 보내고 Request를 다시 보내야하기 때문에 순간적인 부담이 급증하게 된다.streamingLong polling과 마찬가지로 클라이언트에서 서버로 일단 http request를 날린다.서버에서 클라이언트로 이벤트를 전달할때 해당 요청을 끊지 않고 필요한 메시지만 보내기를(flush) 반복하는 방식이다.long polling에 비해 서버에서 메시지를 보내고도 다시 http request 연결을 하지 않아도 되어 부담이 경감될것으로 보인다.long polling, streaming 방식의 경우 서버에서 클라이언트로 메시지를 보낼 수 는 있으나클라이언트에서 서버로 메시지를 보내는것은 문제가 있을 수 있다.위 방식 모두 HTTP를 통해 통신하기 때문에 Request/Response 모두 헤더가 불필요하게 크다.이러한 단점들을 해소하기 위해 나온 것이 바로 웹 소켓(WebSocket)이다.WebSocket웹 소켓은 HTTP와 같은 프로토콜의 일종으로 클라이언트와 서버 간의 효율적인 양방향 통신을 실현하기 위한 구조이다.웹 소켓은 양방향 통신으로 진행되고 최초 접속이 일반 Http 요청을 이용한 Handshaking으로 이루어진다.(80, 443 포트로 접속하므로 추가로 방화벽을 열지 않고도 가능하다. 그렇기 때문에 HTTP 규격인 CORS 적용, 인증 등을 기존과 동일하게 보장받을 수 있다.)Http와 같이 연결 후 끊어버리는 것이 아니라 연결 후 계속적으로 Connection을 지속하므로연결하는데 필요한 불필요한 비용을 제거할 수 있다.또한 위에서 HTTP 통신의 Request/Response 헤더가 불필요하게 크기에 문제가 생겼는데웹소켓을 이용하면 최초 접속시에만 헤더 정보를 보내고 더 이상 보내지 않으므로 이를 처리해줄 수 있다.그리고 기존 Http 요청과 달리 웹소켓 포트에 접속해 있는 모든 클라이언트에게 이벤트 방식으로 응답한다.변경 사항의 빈도가 자주 일어나지 않고, 데이터의 크기가 작은 경우 Ajax, Streaming, Long polling 이 더 효과적일 수 있다.실시간성을 보장해야 하고, 변경 사항의 빈도가 잦다면, 또는 짧은 대기 시간, 고주파수, 대용량의 조합인 경우 WebSocket이 좋은 해결책이 될 수 있다.SSESSE는 웹소켓과 달리, 클라이언트는 서버로부터 데이터만 받을 수 있게 된다.SSE는 웹소켓과 달리 별도의 프로토콜을 사용하지 않고 HTTP 프로토콜만으로 사용이 가능하기에 훨씬 가볍다.접속에 문제가 있으면 자동으로 재연결을 시도하지만 클라이언트가 페이지를 닫아도 서버에서 감지하기가 어렵다.또 다른 특징으로 HTTP/1.1의 경우 브라우저당 6개의 접속만을 허가하며 HTTP/2에서는 100개까지의 접속을 허용한다.Spring Framework는 4.2(2015년)부터 SseEmitter 클래스를 제공하여 서버 사이드에서의 SSE 통신 구현이 가능해졌다.JS에서는 EventSource를 이용하여 연결 생성 및 전송된 이벤트에 대한 제어가 가능하다.EventSource를 이용하여 연결 생성 요청을 서버에 보낸다면 서버는 이를 처리해 연결을 진행해주어야한다.그렇기 위해서는 서버에서 이 요청을 처리해줄 수 있는 부분을 구현해야한다.   Socket Server-Sent-Event 브라우저 지원 대부분 브라우저에서 지원 대부분 모던 브라우저 지원(polyfills 가능) 통신 방향 양방향 일방향(서버 -&gt; 클라이언트) 리얼타임 Yes Yes 데이터 형태 Binary, UTF-8 UTF-8 자동 재접속 No Yes(3초마다 재시도) 최대 동시 접속 수 브라우저 연결 한도는 없지만 서버 셋업에 따라 다름 HTTP를 통해서 할 때는 브라우저당 6개 까지 가능 / HTTP2로는 100개가 기본 프로토콜 websocket HTTP 베터리 소모량 큼 작음 Firewall 친화적 Nope Yes WebSocket은 양방향 통신에 적합하다.채팅에서와 같이 클라이언트와 서버가 양방향 통신이 필요한 부분에서는 좋은 선택이겠지만알림 서비스는 단지 알림을 받는 사람 입장에서는 전혀 요청을 하지 않고 서버에서만 응답을 받는 단방향 시스템이므로알림 기능만을 고려했을 때, 웹소켓보다 가벼운 SSE를 선택하는 것이 더 나은 선택으로 느껴졌다.그래서 초반에는 초기에 작성했던 websocket 코드를 사용해서 할까 싶었지만SseEmitter를 활용해서 구현하고 싶어졌다.Code 클라이언트에서 SSE 연결 요청을 보낸다. 서버에서는 클라이언트와 매핑되는 SSE 통신 객체를 만든다. 서버에서 이벤트가 발생하면 해당 객체를 통해 클라이언트로 데이터를 전달한다.Clientconst eventSource = new EventSource(`/room/subscribe/?id=${username}`);클라이언트에서는 EventSource라는 인터페이스로 SSE 연결 요청을 할 수 있다.const eventSource = new EventSource(`/room/subscribe/?id=${username}`);eventSource.onopen = (e) =&gt; {};eventSource.onerror = (e) =&gt; {};eventSource.onmessage = (e) =&gt; { let message = JSON.parse(e.data + \"\\n\") alarmForm(message) }};서버에서 데이터를 푸쉬하면, message가 실행되고, e.data에서 데이터를 가져올 수 있다.data:행 다음에 메시지가 오고, 스트림 맨 마지막에는 \\n 문자가 두개 있다면 스트림이 끝난 것으로 간주한다.메시지가 길어서 여러줄을 보내야 한다면, data:행을 사용하여 메시지를 분할하면 된다.\\n으로 하나만 줄바꿈이 되어 있다면, message이벤트는 하나만 발생한다.Serverspring framework 4.2부터 SSE 통신을 지원하는 SseEmitter API를 제공한다.이를 이용해 SSE 구독 요청에 대한 응답을 할 수 있다.private static final Long DEFAULT_TIMEOUT = 60L * 1000 * 60;private static final Map&lt;String, SseEmitter&gt; CLIENTS = new ConcurrentHashMap&lt;&gt;();@GetMapping(\"/room/subscribe\")public SseEmitter subscribe(String id) throws IOException { // id는 nickname으로 지정 SseEmitter emitter = new SseEmitter(DEFAULT_TIMEOUT);}생성자를 통해 만료시간을 설정할 수 있다.springboot의 내장 톰캣을 사용하면 30초로 설정된다.만료 시간이 되면 브라우저에서 자동으로 서버에 재연결 요청을 보낸다.이때 생성된 SseEmitter 객체는 향후 이벤트가 발생했을 때,해당 클라이언트로 이벤트를 전송하기 위해 사용되므로 서버에서 저장하고 있어야한다.CLIENTS.put(id, emitter);Emitter를 생성하고 나서 만료 시간까지 아무런 데이터도 보내지 않으면 재연결 요청시 503 Service Unavailable 에러가 발생할 수 있다.따라서 처음 SSE 연결 시 더미 데이터를 전달해주는 것이 안전하다.emitter.send(SseEmitter.event() .name(\"connect\") // 해당 이벤트의 이름 지정 .data(\"connected!\")); // 503 에러 방지를 위한 더미 데이터SseEmitter를 생성할 때는 비동기 요청이 완료되거나 타임아웃 발생 시 실행할 콜백을 등록할 수 있다.타임아웃이 발생하면 브라우저에서 재연결 요청을 보내는데,이때 새로운 Emitter 객체를 다시 생성하기 때문에(Controller의 subscribe() 참조) 기존의 Emitter를 제거해주어야 한다.따라서 onCompletion 콜백에서 자기 자신을 지우도록 등록한다.emitter.onTimeout(() -&gt; CLIENTS.remove(id));emitter.onCompletion(() -&gt; CLIENTS.remove(id));주의할 점은 이 콜백이 SseEmitter를 관리하는 다른 스레드에서 실행된다.따라서 thread-safe한 자료구조를 사용하지 않으면 ConcurrnetModificationException이 발생할 수 있다.여기서는 thread-safe한 자료구조인 ConcurrentHashMap을 사용했다. (etc. CopyOnWriteArrayList)ConcurrentHashMap은 thread-safe하기 때문에, Multi-Thread 환경에서 사용할 수 있다.이제 서버에서 무언가 변경 사항이 생겼을 때 클라이언트의 요청이 없어도 데이터를 전송할 수 있다.누군가 /room/publish를 호출하면 서버에서 admin과 user를 구분하는 message를SSE Connection이 열려있는 모든 client에게 전달한다.document.querySelector('#messageForm').addEventListener(\"submit\", () =&gt; { fetch(`/room/publish?sender=${username}&amp;roomId=${roomId}`);});채팅방에서 누군가가 채팅을 하고 있다면 알림이 뜬다.@GetMapping(\"/room/publish\")public void publish(String sender, String roomId) { Set&lt;String&gt; deadIds = new HashSet&lt;&gt;(); CLIENTS.forEach((id, emitter) -&gt; { try { ChatMessage chatMessage = chatService.ringAlarm(sender, roomId); // 알림 메세지 형식 설정 emitter.send(chatMessage, MediaType.APPLICATION_JSON); } catch (Exception e) { CLIENTS.remove(id); log.warn(\"disconnected id : {}\", id); } });}채팅을 완료한 후에 알림을 보내는 식이면 엄청 오래걸리는 작업이 존재할 때 그만큼 알림도 늦게 간다.따라서 위 코드에서 @Async를 활용해서 비동기적으로 처리하게 했다.랜덤채팅에서 구현한 비동기 설정을 활용했다.reference mdn - Server-Sent Events 사용하기 이론 Spring에서 Server-Sent-Events 구현하기 알림 기능을 구현해보자 - SSE(Server-Sent-Events)! 48일차-7/24 토 -항해99 코드 [Spring] Server Sent Event(SSE) [Spring] Websocket / Sock js를 사용한 실시간 알림전송 기능 구현 서버 사이드 이벤트 (Server Side Events, SSE) [NODE] 📚 Server Sent Events 💯 정리 (+사용법) webSocket 으로 개발하기 전에 알고 있어야 할 것들" }, { "title": "Websocket(채팅 기록 json 파일 저장하기)", "url": "/posts/WebSocket(%EC%B1%84%ED%8C%85-%EA%B8%B0%EB%A1%9D-Json-%ED%8C%8C%EC%9D%BC-%EC%A0%80%EC%9E%A5%ED%95%98%EA%B8%B0)/", "categories": "Project, Chat", "tags": "spring, WebSocket, Chat", "date": "2023-02-17 00:00:00 +0900", "snippet": "Json 파일 저장하기관련 글 Websocket Websocket + 부가기능 Websocket (채팅 기록 json 파일 저장하기) 👈🏻 Sse Sse 문제점 Websocket + jwt Websocket test Jmh - 채팅 파일 refactoring문제채팅 대화내용을 보여주기 위해서 처음에는 클라이언트에서 sessionStorage로 저장하려고 했는데 생각보다 쉽지 않았다. type이 “TALK”인 경우에만 저장하기 → 대화가 1번 이루어지면 저장이 되지 않고 2번 작성한 경우 제일 먼저 작성한 것만 저장이 된다. (이런 식으로 하나씩 저장이 안된다.) 그래서 저장이 무조건 되게 if문을 추가해서 sessionStorage의 길이와 실제 작성한 채팅 횟수가 같지 않으면 다시 저장하게끔 설정했더니 무한루프가 되어버렸다. for문으로 대화 저장된 값들을 가져오는데 순서가 뒤죽박죽이다. → admin도 같이 sessionStorage를 저장하면서 뒤죽박죽으로 나오는 것 같다. 그래서 서버에서 저장해서 채팅 기록을 띄워주는 방향으로 바꿨다.db에 저장하는 것보다 파일에 저장하는게 더 효율적일 것 같아서 파일에 저장하는 방식으로 진행했다.채팅을 띄워주는 형식이 json으로 받기 때문에 저장도 json형식으로 해야겠다고 생각해서 JSONObject를 사용했다.그런데 문제가 생겼다. 아래와 같이 글을 작성하면파일에 제대로 저장이 되는것까지 확인됐다.오! 잘 되는건가?😃 싶었는데 글을 한번 더 써보고 문제를 발견했다.구분자가 없다.😭 결과 이미지를 올린 블로그만 보니 다 하나씩만 하고 올려뒀다. 하나만 하고 올려둔건가🤔Unexpected token LEFT BRACE({) at position 95.라는 에러가 뜨는데 “{}” 끝나고 바로 “{“ 로 시작되서 에러가 뜬 것 같다.그래서 내가 생각한 방법은 배열 안에 json 방식을 넣는 것이었다.[ {}, {} ] 이런 방식을 생각하고 JSONArray를 사용해서 JSONObject를 넣었다.그랬더니…[{}] [{}] 이런 형식으로 저장됐다. 하핳😅예상보다 엄청난 삽질이 시작되었다. 그래도 결과가 나왔으니 이렇게 글을 정리하게 됐다. 😙이게 맞는지는 모르겠으나 아래와 같이 작성안하면 내가 원하는 결과가 안나온다.아무튼 원하는 결과가 나왔으니 정리해본다.추가된 코드를 설명하다보니 기존에 작성된 코드는 생략되어있는 경우도 있다.중간에 메소드 전체 코드가 궁금해지거나 다른 설명이 필요하다면 웹소켓 1편 or 2편을 보면 된다. 웹소켓 1편 : 기본 웹소켓 2편 : 부가기능setFile (client)서버에서 @MessageMapping으로 메세지를 보낼 때 마다 실행되는 함수에 setFile을 실행시켰다.메세지를 보내면 바로 file로 저장이 된다.function sendMessage(event) { let chatMessage = { roomId: roomId, sender: username, message: messageInput.value, type: 'TALK' }; setFile(chatMessage) // ⬅️ stompClient.send(\"/app/chat/sendMessage\", {}, JSON.stringify(chatMessage));}function setFile(chatMessage) { $.ajax({ type: \"POST\", url: `/room/enter/` + roomId + '/' + roomName, data: JSON.stringify(chatMessage), contentType: 'application/json', processData: false, success: function(response) { } });}setFile (server)JSON은 JavaScript Object Notation 의 줄임말로 말 그대로 자바스크립트에서 객체를 표현하는 방법이다.JAVA에서 JSON을 다룰 때 보통 google의 json-simple을 사용하는 것 같다.maven을 사용하는 경우 pom.xml에 의존성을 설정하면 되고그 외는 설치(직접 라이브러리 받아서 classpath 경로에 넣어두세요)를 하라고 하는데나는 그냥 maven에 적힌 의존성 설정을 그대로 gradle에 적용하면 되지 않나 싶어서 그대로 적용했다. (설치하기 귀찮,,)&lt;!-- https://mvnrepository.com/artifact/com.googlecode.json-simple/json-simple --&gt;&lt;dependency&gt; &lt;groupId&gt;com.googlecode.json-simple&lt;/groupId&gt; &lt;artifactId&gt;json-simple&lt;/artifactId&gt; &lt;version&gt;1.1.1&lt;/version&gt;&lt;/dependency&gt;위가 maven 설정인데 groupId를 보고 gradle에 적용했더니 잘 된다.implementation 'com.googlecode.json-simple:json-simple:1.1.1'대부분 maven만 적용 코드가 있고 나머지는 다운받으라고 해서 gradle도 다운받아야 하는건 아닌가 확신이 들지 않을 때gradle에 implementation 'com.googlecode.json-simple:json-simple:1.1.1' 코드를 없애고 import하면 아래와 같이 뜬다.import org.json.simple.JSONObject;import org.json.simple.parser.JSONParser;import org.json.simple.parser.ParseException;그래서 gradle도 의존성만 추가하면 되는 듯하다.json-simple에서는 java와 json의 값들을 아래와 같이 mapping 해서 사용한다. Json value JAVA class 설명 배열 java.util.List JSON에서의 배열인 [] 표기법은 List로 표현. (실제로는 List를 구현한 JSONArray로 맵핑됨) 객체 java.util.Map JSON에서의 객체인 ‘{}’ 표기법은 key-value 형식인 Map으로 표현. (실제로는 Map을 구현한 JSONObject로 맵핑됨) private void saveFile(ChatMessage chatMessage) { // 파일을 저장하는 method JSONObject json = new JSONObject(); json.put(\"roomId\", chatMessage.getRoomId()); json.put(\"type\", chatMessage.getType().toString()); json.put(\"sender\", chatMessage.getSender()); json.put(\"message\", chatMessage.getMessage()); Gson gson = new GsonBuilder().setPrettyPrinting().create(); String json1 = gson.toJson(json); try { FileWriter file = new FileWriter(chatUploadLocation + \"/\" + chatMessage.getRoomId() + \".txt\", true); //뒤에 true 붙이면 덮어쓰기 가능 File file1 = new File(chatUploadLocation + \"/\" + chatMessage.getSender() + \"-\" + chatMessage.getRoomId() + \".txt\"); if (file1.exists() &amp;&amp; file1.length() == 0) { file.write(json1); } else { file.write(\",\" + json1); } file.flush(); file.close(); // 연결 끊기 } catch (IOException e) { e.printStackTrace(); }}☑️ FileOutputStream &amp; FileWriter파일을 저장할 때 보통 FileOutputStream 이랑 FileWriter를 쓰던데FileWriter는 문자 데이터를 파일에 쓰는 클래스이고 FileOutputStream은 바이트 데이터를 파일로 출력하는 클래스이다.☑️ JSONObjectJSONObject json = new JSONObject();에 client에서 받아온 값을 넣으면 아래와 같이 저장된다.{“sender”: “ss”, “type”: “TALK”, “message”: “안녕하세요”, “roomId”: “3d41c3ed-8ddb-458d-a248-64fb9fb74e6f”}☑️ 내용 덮어쓰기FileWriter file = new FileWriter(\"url\", true) 에서 true를 넘겨주면 원래 있던 파일의 내용에 덮어쓰게 된다.☑️ 파일 저장 방식File file1 = new File(chatUploadLocation + \"/\" + chatMessage.getSender() + \"-\" + chatMessage.getRoomId() + \".txt\");위 코드를 작성한 이유는 쉼표(,)를 넣기 위함이다.파일이 없다면 처음 작성한 것이므로 처음에는 쉼표(,)를 작성하지 않고 그 뒤부터 json을 넣기 전에 쉼표(,)를 넣는다.저장하는 형식코드에 따라서 이쁘게 파일을 작성할 수 있다. 아래 사진을 첨부했으니 차이를 알 수 있을 것이다.나는 2번 방식을 사용했다.1.try { FileWriter file = new FileWriter(chatUploadLocation + \"/\" + chatMessage.getRoomId() + \".txt\", true); File file1 = new File(chatUploadLocation + \"/\" + chatMessage.getRoomId() + \".txt\"); if (file1.exists() &amp;&amp; file1.length() == 0) { file.write(json.toJSONString()); } else { file.write(\",\" + json.toJSONString()); } file.flush(); file.close(); // 연결 끊기} catch (IOException e) { e.printStackTrace();}2.Gson gson = new GsonBuilder().setPrettyPrinting().create();String json1 = gson.toJson(json);try { FileWriter file = new FileWriter(chatUploadLocation + \"/\" + chatMessage.getRoomId() + \".txt\", true); File file1 = new File(chatUploadLocation + \"/\" + chatMessage.getRoomId() + \".txt\"); if (file1.exists() &amp;&amp; file1.length() == 0) { file.write(json1); } else { file.write(\",\" + json1); } file.flush(); file.close(); // 연결 끊기} catch (IOException e) { e.printStackTrace();}getFile (server)이 부분이 가장 오래 걸렸다.어떻게 하면 값을 [{}, {}] 형식으로 가져올까 고민했다.처음에는 FileReader를 사용해서 파일을 읽어온 다음 list를 생성해서 파일 전체 값을 넣으면 되지 않을까 싶었는데JSONParser parser = new JSONParser();Object object = parser.parse(reader);JSON 데이터를 넣어서 Object로 만들어주는 과정에서 오류가 났다.{}, {} 형식으로 저장을 해서 콤마가 문제고 콤마를 없애면 “{“가 문제였다.{ \"chatMessage\" : [ { \"name\" : \"hi\" } ]}이런 식으로 저장해서 가져오는 방법도 있는데 꼭 저렇게 저장해야하나 싶어서 다른 방법을 찾았다.찾아보니 Files 클래스를 이용하면, 텍스트 파일 내용 전체를 List나 배열, String에 쉽게 담을 수 있다고 한다.*java.nio.file.Files 클래스는 Java 7 이후부터 사용할 수 있다. Files 클래스는 모두 static 메소드로 구성이 되어있다.그래서 이를 활용해서 한번에 파일을 읽고 list에 담았다.그런데.. 무슨 이유인지는 모르겠으나 서버에서는 분명 [{}, {}] 형태로 보내는데 client에서는 {}, {}로 받아버린다.😭그래서 결국 아래와 같은 코드로 구현했다.public Object readFile(String roomId) { try { String str = Files.readString(Paths.get(chatUploadLocation + \"/\" + roomId + \".txt\")); JSONParser parser = new JSONParser(); Object obj = parser.parse(\"[\" + str + \"]\"); return obj; } catch (NoSuchFileException e){ throw new FileNotFoundException(); }catch (IOException | ParseException e) { e.printStackTrace(); return null; }}☑️ FileNotFoundException은 CustomException이다.CustomException은 해당 글 Custom Exception을 참고한다.getFile (client)왜인지는 아직도 모르겠으나 for문이 무한루프로 계속 돌아간다.length는 무한루프가 아닌데도 해당 for문을 여러 번 돈다.그래서 isRun 변수로 무한루프를 막았다.let isRun = false;function getFile() { if (isRun == true){ return; } isRun = true; $.ajax({ type: \"GET\", url: `/room/enter/` + roomId + '/' + roomName, contentType: false, processData: false, success: function(response) { for (let i = 0; i &lt; response.length; i++) { onMessageReceived(response[i]) } } })}function onMessageReceived(payload) { // 메세지 받기 let message = JSON.parse(payload.body);}onMessageReceived에서 값을 처리하기 위해선 [object Object] 로 보내야 하므로JSON.stringify(response)으로 작성을 하지 않았다.onMessageReceived(response)에서 parse를 사용하는데 parse는 string 객체를 json 객체로 변환시켜준다.하지만 나는 data를 body로 보내지도 않고 미리 json으로 저장을 했기 때문에 JSON.parse(payload.body); 코드를 사용할 필요가 없었다.그래서 그냥 response를 보내면 SyntaxError 에러가 떴다. 이를 해결하기 위해 try ~ catch문을 사용했다.function onMessageReceived(payload) { // 메세지 받기 let message; try { message = JSON.parse(payload.body); } catch (SyntaxError) { message = payload; }} JSON.parse() : string 객체를 json 객체로 변환 JSON.stringify() : json 객체를 String 객체로 변환실행 화면reference 파일 입출력 클래스: FileReader, FileWriter, FileInputStream, FileOutputStream Javascript JSON.parse(), JSON.stringify() 사용하는법 [JAVA] JAVA에서 JSON 데이터 다루기. GOOGLE의 JSON-SIMPLE 사용 방법 [Java] 텍스트 파일 읽기 ( FileReader, BufferedReader, Scanner, Files ) AJAX 중복요청, 중복클릭, 중복호출 막는 여러가지 방법들 " }, { "title": "Websocket +부가기능", "url": "/posts/WebSocket-+%EB%B6%80%EA%B0%80%EA%B8%B0%EB%8A%A5/", "categories": "Project, Chat", "tags": "spring, WebSocket, Chat", "date": "2023-02-06 00:00:00 +0900", "snippet": "WebSocket관련 글 Websocket Websocket + 부가기능 👈🏻 Websocket (채팅 기록 json 파일 저장하기) Sse Sse 문제점 Websocket + jwt Websocket test Jmh - 채팅 파일 refactoring1편에 이어서 채팅기능을 구현했으므로 고객센터를 구현하기 위해 admin과 user를 구분하여 작성했다.부가적인 기능 추가 해당 채팅방을 만든 사람 즉, 본인과 관리자만 해당 채팅방 이용 하게하기 관리자만 채팅 리스트 띄우기(그 외는 본인이 만든 채팅방만 띄워주게하기) 채팅이 완료되면 5분뒤에 채팅방 삭제 시키기삭제 버튼을 누르면 5분뒤에 삭제를 하기 위해서 ChatMessage의 MessageType에 DELETE를 추가했다.public enum MessageType { JOIN, TALK, LEAVE, DELETE}stompClient.send(\"/app/chat/end-chat\", {}, JSON.stringify({roomId: roomId, sender: username, type: 'DELETE'}))전체코드는 해당 링크에 올려뒀다. github_SocketChatRoomController@Controller@RequiredArgsConstructorpublic class ChatRoomController { private final ChatServiceImpl chatService; // 채팅 리스트 화면 @GetMapping(\"/room\") public String rooms(Model model) { return \"chat-list\"; } // 채팅방 입장 화면 @GetMapping(\"/room/enter/{roomId}\") public String roomDetail(Model model, @PathVariable String roomId){ model.addAttribute(\"roomId\", roomId); return \"chat-room\"; } // 모든 채팅방 목록 반환 @GetMapping(\"/rooms\") @ResponseBody public List&lt;ChatRoomDto&gt; room() { return chatService.findAllRoom(); } // 본인 채팅방 @GetMapping(\"/room/one/{nickname}\") @ResponseBody public ChatRoomDto roomOne(@PathVariable String nickname) { return chatService.roomOne(nickname); } // 채팅방 생성 @PostMapping(\"/room\") @ResponseBody public ChatRoomDto createRoom(@RequestBody String nickname){ return chatService.createRoom(nickname); } // 완료된 채팅방 삭제하기 @DeleteMapping(\"/room/one/{roomId}\") @ResponseBody public void deleteRoom(@PathVariable String roomId){ chatService.deleteRoom(roomId); } // 삭제 후 채팅방 재 접속 막기 @GetMapping(\"/room/{roomId}\") @ResponseBody public boolean getRoomInfo(@PathVariable String roomId) { return chatService.getRoomInfo(roomId); }}DtoChatRoomDto@Getter@Setter@ToString@Builder@AllArgsConstructorpublic class ChatRoomDto { private String roomId; // 채팅방 아이디 private String roomName; // 채팅방 이름 private String nickname; public ChatRoomDto() { } public static ChatRoomDto create(String name) { ChatRoomDto room = new ChatRoomDto(); room.roomId = UUID.randomUUID().toString(); room.roomName = name; return room; } public static ChatRoomDto of (Socket socket){ return ChatRoomDto.builder() .roomId(socket.getRoomId()) .nickname(socket.getNickname()) .build(); }}ChatRoomMap@Getter@Setterpublic class ChatRoomMap { private static ChatRoomMap chatRoomMap = new ChatRoomMap(); private Map&lt;String, ChatRoomDto&gt; chatRooms = new LinkedHashMap&lt;&gt;(); private ChatRoomMap(){} public static ChatRoomMap getInstance(){ return chatRoomMap; }}domain@Getter@NoArgsConstructor(access = AccessLevel.PROTECTED)@Entity@ToStringpublic class Socket { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) @Column(name = \"socket_id\") private Long idx; @Column(nullable = false) private String nickname; @Column(nullable = false) private String roomId; public Socket(String roomId, String nickname){ this.roomId = roomId; this.nickname = nickname; }}socket 코드를 작성하면서 db에 최대한 저장안하려고 했는데채팅방에 들어갈 유저를 특정 유저로 정해놓고 해당 채팅방을 들어가게 하려면 db가 필요할 것 같았다.db 내용은 최소한의 column으로 username과 roomId 만 설정했다.roomName은 username으로 자동 설정되므로 추가하지 않았다.table 만들기CREATE TABLE IF NOT EXISTS socket ( id bigint(5) NOT NULL AUTO_INCREMENT, # AUTO_INCREMENT : 자동으로 1씩 증가 room_id varchar(255) NOT NULL, nickname varchar(255) NOT NULL, PRIMARY KEY (socket_id));Service@Slf4j@RequiredArgsConstructor@Servicepublic class ChatServiceImpl { private final ChatRepository chatRepository; //채팅방 불러오기 public List&lt;ChatRoomDto&gt; findAllRoom() { List&lt;ChatRoomDto&gt; chatRoomDtos = new ArrayList&lt;&gt;(); List&lt;Socket&gt; all = chatRepository.findAll(); try { for(int i=0; i&lt;all.size(); i++){ chatRoomDtos.add(ChatRoomDto.of(all.get(i))); } } catch (NullPointerException e) { throw new RuntimeException(\"data 없음! \") ; } return chatRoomDtos; } //채팅방 하나 불러오기 public boolean getRoomInfo(String roomId) { return chatRepository.existsByRoomId(roomId); } //채팅방 생성 public ChatRoomDto createRoom(String nickname) { ChatRoomDto chatRoom = new ChatRoomDto(); if (!chatRepository.existsByNickname(nickname)) { chatRoom = ChatRoomDto.create(nickname); ChatRoomMap.getInstance().getChatRooms().put(chatRoom.getRoomId(), chatRoom); Socket socket = new Socket(chatRoom.getRoomId(), nickname); log.info(\"Service socket : \" + socket); chatRepository.save(socket); return chatRoom; } else{ Optional&lt;Socket&gt; byNickname = chatRepository.findByNickname(nickname); return ChatRoomDto.of(byNickname.get()); } } public ChatRoomDto roomOne(String nickname){ Optional&lt;Socket&gt; byNickname = chatRepository.findByNickname(nickname); return ChatRoomDto.of(byNickname.get()); } public void deleteRoom(String roomId) throws IllegalStateException{ Timer t = new Timer(true); TimerTask task = new MyTimeTask(chatRepository, roomId); t.schedule(task,300000); log.info(\"5분뒤에 삭제 됩니다.\"); }}5분뒤에 삭제되는 채팅방 구현해당 코드는 단발성으로써 5분뒤에 삭제되는 로직이다.Timer : 실제 타이머의 기능을 수행하는 클래스TimerTask : “Timer” 클래스가 수행되어야 할 내용을 작성하는 클래스 → run method 재정의 필수schedule()은 타이머를 작동시키는 method이다.Time@Slf4j@RequiredArgsConstructorpublic class MyTimeTask extends TimerTask { private final ChatRepository chatRepository; private String roomId; public MyTimeTask(ChatRepository chatRepository, String roomId){ this.chatRepository = chatRepository; this.roomId = roomId; } @Override public void run() { Socket socket = chatRepository.findByRoomId(roomId).orElseThrow(NullPointerException :: new); chatRepository.delete(socket); log.info(\"5분이 지나 삭제 되었습니다.\" + socket); }}Repositorypublic interface ChatRepository extends JpaRepository&lt;Socket, Long&gt; { boolean existsByNickname(String nickname); Optional&lt;Socket&gt; findByNickname(String nickname); boolean existsByRoomId(String roomId); Optional&lt;Socket&gt; findByRoomId(String roomId);}채팅방 gif왼쪽 : 일반 user || 오른쪽 : adminreference Java 를 활용한 Timer구현하기 [Spring]Springboot + websocket 채팅[1] [Spring]Springboot + websocket 채팅[2]" }, { "title": "Websocket", "url": "/posts/WebSocket/", "categories": "Project, Chat", "tags": "spring, WebSocket, Chat", "date": "2023-01-29 00:00:00 +0900", "snippet": "WebSocket관련 글 Websocket 👈🏻 Websocket + 부가기능 Websocket (채팅 기록 json 파일 저장하기) Sse Sse 문제점 Websocket + jwt Websocket test Jmh - 채팅 파일 refactoring기존에 작성했던 webSocket그동안 채팅 구현을 하기 위해 이것 저것 보면서 적용하느라 뭐가 뭔지도 모르고 쓴 경향이 있었다.그러다보니 이번에 제대로 공부를 하면서 구현하려고 했고 초반에는 어디서는 이 코드만 쓰고 또 어디서는 이 코드만 쓰고또 다른데는 내가 현재 작성했던 코드를 써서 뭐가 뭔지도 모르겠고 정리가 잘 안되는 느낌이었는데여러 글들을 보면서 글을 정리하기 시작했고 그러다보니 어느정도 감을 잡게 되었다. (💡코드에 정답은 없다!)하지만 내가 생각한 부분에 대한 검증을 받을 수 없기 때문에 맞는지는 모르겠고 추측만 하는 것도 있다.*이 전에 작성한 코드들이 있어서 비교하면서 작성해봤다.내용이 길어져서 1편과 2편으로 나눠서 작성했다.관련 글 : SSE아래는 기존에 작성했던 코드 일부이다. 현재는 handler를 사용하지 않는다.Handler웹소켓(WebSocket)은 서버와 클라이언트 간 양방향 통신을 가능하게 하는 프로토콜이다.이를 구현하기 위해 핸들러(Handler) 클래스를 사용한다.서버-클라이언트 소켓 통신에서 사용하는 메세지 스펙을 정의 한다.WebSocket Handler 클래스는 아래와 같이 4개의 메소드를 Override 해야한다. afterConnectionEstablished : 웹소켓 연결이 성공적으로 이루어졌을 때 handleTextMessage :웹소켓을 통해 데이터를 주고받을 때 afterConnectionClosed : 웹소켓 연결이 종료됐을 때 호출 handleTransportError : 웹소켓 통신 중 에러가 발생했을 때 호출문자열 메시지 기반으로 테스트를 진행하기 때문에 TextWebSocketHandler를 상속받아 메시지를 전달받는다.public class WebSocketHandler extends TextWebSocketHandler { private final Map&lt;String, WebSocketSession&gt; sessions = new ConcurrentHashMap&lt;&gt;(); @Override // 웹 소켓 연결 public void afterConnectionEstablished(WebSocketSession session){} @Override // 양방향 데이터 통신 protected void handleTextMessage(WebSocketSession session, TextMessage message){} @Override // 소켓 연결 종료 public void afterConnectionClosed(WebSocketSession session, CloseStatus closeStatus){} @Override // 소켓 통신 에러 public void handleTransportError(WebSocketSession session, Throwable throwable){}}@OnOpen, @OnMessage, @OnClose, @OnError 어노테이션을 사용하여 핸들러를 정의할 수 있다.이 경우에는 Session을 사용한다.public class WebSocketHandler extends TextWebSocketHandler{ private static List&lt;Session&gt; sessionUsers = Collections.synchronizedList(new ArrayList&lt;&gt;()); @OnOpen public void open(Session newUser) throws IOException {} @OnMessage public void onMessage(Session receiveSession, String msg) throws IOException {} @OnClose public void onClose(Session nowUser, CloseReason closeReason) {} @OnError public void onError(Session session, Throwable e) {}}나도 @OnOpen, @OnMessage, @OnClose, @OnError를 사용했고 WebSocketSession대신 Session을 사용했다.WebSocketSession과 Session 둘 다 Closeable을 상속받고 있었고 크게 차이점을 느끼진 못했다.*WebSocketSession은 Spring에서 Websocket Connection이 맺어진 세션WebSocketSession ( = session) afterConnectionEstablished (= @OnOpen) handleTextMessage (= @OnMessage) afterConnectionClosed (= @OnClose) handleTransportError (= @OnError)각자 스타일에 맞게 작성하면 될 듯 하다.이론 정리WebSocket이란?Websocket을 이해하려면 먼저 http를 알아야한다.*HTTP와 WebSocket이 같은 이미지에 있는 이유는 둘 다 protocol이기 때문이다.browser와 server는 http를 이용해서 소통할 수 있다. (인터넷 데이터 교환에서 필수 요소)브라우저는 서버에서 http request(요청)을 보낸다.서버는 해당 request를 보고 브라우저가 홈페이지 정보를 요구하는걸 확인 후 서버는 http response를 브라우저에 보낸다.👧🏻(user) → http 요청 [데이터 보내줘] →  🖥️(서버)👧🏻(user) ← 데이터 ← 🖥️(서버)⭐ 서버가 브라우저의 요청(request)에 응답(response)하고 나면 브라우저 - 서버 간 통신은 끝나게 된다.서버가 브라우저에게 데이터를 보낼 수 있는 것은 브라우저가 요청을 했을 때 뿐이다. 이 때문에 웹 소켓이 생겨났다.WebSocketWebSocket은 서버와 클라이언트 간에 단일 TCP 커넥션을 통해 양방향 통신을 지원하는 프로토콜이다.HTTP와 달리 request-response 패턴이 아닌 open - close로 커넥션이 열려있는 상태에서 데이터를 주고받는다.이러한 특성은 전화 통화와 유사하며, 양쪽 모두 메시지를 주고받을 수 있다.ex) 전화 통화는 양방향이므로 나도 메세지를 보내고 받을 수 있고 상대방도 똑같이 할 수 있다.또한 둘이 전화를 끊기 전까지는 전화 통화는 열려있다.Spring Framework는 WebSocket API를 제공한다.WebSocket 서버는 WebSocketHandler 인터페이스를 구현하여 각 경로에 대한 핸들러를 설정할 수 있다.Message 형식에 따라 TextWebSocketHandler or BinaryWebSocketHandler 핸들러를 확장해 구현할 수도 있다.public abstract class AbstractoWebSocketHandler implements WebSocketHandler{ public AbstractWebSocketHandler(){}}문자열 메시지 기반으로 진행하기 때문에 TextWebSocketHandler를 상속받아 메시지를 전달받는다.public class WebSocketHandler extends TextWebSocketHandler{}위에서 처음에 작성했던 코드가 이에 해당한다.STOMP(Simple Text Oriented Messaging Protocol)STOMP은 WebSocket 위에서 동작하는 프로토콜로, 클라이언트와 서버가 전송할 메시지 유형, 형식, 내용 등을 정의한다.STOMP (Simple Text Oriented Messaging Protocol)은 메세징 전송을 효율적으로 하기 위해 탄생한 프로토콜이고,기본적으로 pub / sub 구조를 기반으로 하여 클라이언트와 서버가 메시지를 주고받을 때 사용된다.우체통(Topic)이 있다면 집배원(Publisher)이 신문을 우체통에 배달하는 행위가 있고,우체통에 신문이 배달되는 것을 기다렸다가 빼서 보는 구독자(Subscriber)의 행위가 있다.이때 구독자는 다수가 될 수 있다. pub / sub 컨셉을 채팅방에 빗대면 다음과 같다. 채팅방 생성 : pub / sub 구현을 위한 Topic이 생성됨 채팅방 입장 : Topic 구독 채팅방에서 메세지를 송수신 : 해당 Topic으로 메세지를 송신(pub), 메세지를 수신(sub) pub/sub 구조Pub/sub 구조는 발신자가 메시지를 특정 수신자에게 직접 보내는 것이 아니라중간 컴포넌트(브로커 또는 버스)를 통해 메시지를 보내고,해당 메시지를 구독한 수신자에게 전달된다.이는 비동기 메시징 패턴으로, 발신자와 수신자가 서로를 알 필요가 없이 중간 컴포넌트를 통해 통신한다.*비동기 : 요청을 보낸 후 결과를 기다리지 않고 바로 다른 동작 수행 어떤 일의 수행 즉시 결과가 나온다는 보장이 없다.Publisher(발신자)는 Subscriber(수신자)에 대한 정보를 몰라도 그냥 일단 메세지를 채널에 보내놓는다이 때 메세지에 맞는 Topic으로 보내놓으면, 해당 Topic을 구독중인 Subscriber에게만 메세지가 가게 된다☑️ pub/sub 구조에서 수신자는 발행자에 대한 지식 없이 원하는 메세지만을 수신할 수 있다.발행자와 수신자 사이에는 브로커 또는 버스라고 불리는 중간 컴포넌트가(채널) 있다. 발행자와 수신자 모두 중간 컴포넌트의 존재를 안다. 하지만 발신자와 수신자는 서로를 모른다. 중간 컴포넌트만 알면 되기 때문이다.☑️ 발신자의 메세지는 특별한 수신자가 정해져 있지 않다.발신자는 메세지를 구독을 신청한 수신자(들)에게 전달할 뿐, 구독을 했으면 메세지를 보내고 안 했으면 안 보낸다.☑️ pub/sub 구조는 비동기 messaging 패러다임이다.발행자는 이벤트가 발생했을 때마다 중간 컴포넌트(브로커 또는 버스)에게 알려준다. 중간 컴포넌트는 각 이벤트들을 필터링해서 받아야 할 수신자들에게 보내준다. 이벤트가 발생했다고 해서 곧바로 수신자가 그 정보를 얻을 수 있는 것은 아니다. 발행자가 이벤트를 중간 컴포넌트에게 알려주고 나면, 그 행위의 결과를 기다리지 않고 바로 다른 자기 할일을 한다.Spring Framework 및 Spring Security는 STOMP를 사용하여 WebSocket을 구현할 때 더 다양한 기능을 제공한다.스프링에서 지원하는 STOMP을 사용하게 된다면, 스프링 WebSocket 애플리케이션은 STOMP Broker로 동작한다.메시지를 @Controller의 메시지 핸들링하는 메서드로 라우팅하거나,Simple In-Memory Broker를 이용해서 Subscribe중인 다른 클라이언트들에게 메시지를 브로드캐스팅한다.Simple In-Memory Broker는 클라이언트의 Subscribe 정보를 자체적으로 메모리에 유지한다.또한 RabbitMQ, ActiveMQ 같은 Message Broker를 이용해, Subscription(구독)을 관리하고 메세지를 브로드캐스팅할 수 있다.Messaging with Redis Messaging with RabbitMQ👉🏻 WebSocket 기반으로 각 Connection(연결)마다 WebSocketHandler를 구현하는 것 보다@Controller 된 객체를 이용해 조직적으로 관리할 수 있다.SUBSCRIBE /topic/public/3d41c3ed-8ddb-458d&gt;&gt;&gt; SUBSCRIBEid:sub-0destination:/topic/public/3d41c3ed-8ddb-458droomId가 3d41c3ed-8ddb-458d로 되어있는 형태인데만약 아래와 같이 roomId로 차이점을 주지않았다면채팅방이 여러 개를 만들 수 있어도 서로 공유하고 있는 채팅방이 될 것이다.&gt;&gt;&gt; SUBSCRIBEid:sub-0destination:/topic/publicSTOMP 형식COMMANDheader:valueBodySTOMP 형식은 COMMAND, header, body로 구성되며, 메시지를 보내거나 받을 때 사용된다.메시지는 Body에 담아서 보내는 형식이다.또한, SEND, SUBSCRIBE COMMAND 요청 Frame에는 메세지가 무엇이고, 누가 받아서 처리할지에 대한 Header 정보가 포함되어 있다.HTTP의 형식과 닮은 것을 알 수 있는데, COMMAND는 Method와 비슷한 역할이라고 보면 된다.SEND: 서버로 보내기, SUBSCRIBE: 구독할곳 등록하기, MESSAGE: 다른 subscribers들에게 braodcast하기 정도로 이해하면 된다.이런 명령어들은 “destination” 헤더를 요구하는데 이것이 어디에 전송할지, 혹은 어디에서 메세지를 구독할 것 인지를 나타낸다.STOMP는 Publisher(발행자)-Subscriber(구독자) 관계를 기반으로 동작한다.발행자와 구독자를 지정하여 메시지 브로커가 특정 구독 채널에 메시지를 전송하는 방식이다.즉 Broker를 통해 타 사용자들에게 메세지를 보내거나 서버가 특정 작업을 수행하도록 메세지를 보낼 수 있게 된다.채팅방 입장&gt;&gt;&gt; SENDdestination:/app/chat/addUsercontent-length:77{\"roomId\":\"3d41c3ed-8ddb-458d\",\"sender\":\"ss\",\"type\":\"JOIN\"}messageSEND app/chat/addUser&gt;&gt;&gt; SENDdestination:/app/chat/sendMessagecontent-length:92{\"roomId\":\"3d41c3ed-8ddb-458d\",\"sender\":\"ss\",\"message\":\"hi\",\"type\":\"TALK\"}MESSAGE /topic/public/3d41c3ed-8ddb-458d&lt;&lt;&lt; MESSAGEdestination:/topic/public/3d41c3ed-8ddb-458dcontent-type:application/jsonsubscription:sub-0message-id:1taozffc-1content-length:92{\"roomId\":\"3d41c3ed-8ddb-458d\",\"type\":\"TALK\",\"sender\":\"ss\",\"message\":\"hi\"}퇴장&lt;&lt;&lt; MESSAGEdestination:/topic/public/3d41c3ed-8ddb-458dcontent-type:application/jsonsubscription:sub-0message-id:b0lxbjax-3content-length:93{\"roomId\":\"3d41c3ed-8ddb-458d\",\"type\":\"LEAVE\",\"sender\":\"ss\",\"message\":null}메세지는 STOMP의 “destination” 헤더를 기반으로 @Controller 객체의 @MethodMapping 메서드로 라우팅 된다.STOMP의 “destination” 및 Message Type을 기반으로 메세지를 보호하기 위해 Spring Security를 사용할 수 있다.내장 메세지 브로커를 사용한 경우 컴포넌트 구성공식문서clientInboundChannel은 WebSocket 클라이언트로 부터 받은 메시지를 전달한다.clientOutboundChannel은 WebSocket 클라이언트에게 메시지를 전달한다.brokerChannel은 서버의 애플리케이션 코드 내에서 브로커에게 메시지를 전달한다.STOMP 사용하는 이유WebSocket은 통신 프로토콜 일뿐이다.특정 주제를 구독한 사용자에게만 메시지를 보내는 방법 또는 특정 사용자에게 메시지를 보내는 방법과 같은 내용은 정의하지 않는다.내가 생각한 websocket만 사용했을 때와 stomp 프로토콜을 적용했을 때 차이는stomp 프로토콜을 정의하면 back에서 각각 MessageType을 내가 설정할 수 있어서 Controller로 적용할 수 있고각 채팅방을 roomId로 구분하게 되면서 헤더에 roomId를 넣어야 했는데 이 부분을 쉽게 처리할 수 있었다.Message Broker란Message Broker(메시지 브로커)는 Publisher(송신자)로부터 전달받은 메시지를 Subscriber(수신자)로 전달해주는 중간 역할이다.응용 소프트웨어 간에 메시지를 교환할 수 있게 하며메시지가 적재되는 공간을 Message Queue(메세지 큐)라고 하며 메시지의 그룹을 Topic(토픽)이라고 한다.메시지 브로커는 송신자가 보낸 메시지를 메시지 큐에 적재하고 이를 수신자가 받아서 사용하는 구조이다.이러한 구조를 Pulibsh/Subscribe(pub/sub) Pattern이라고 하며, Producer/Consumer Pattern 이라고도 한다.메시지 브로커는 대표적으로 Apache Kafka, Redis, RabbitMQ, Celery 등이 있다.이후에 Message Broker로 Redis를 적용한다. Redis pub&amp;sub실시간 데이터를 처리할 때 DB에서 조회하는 것보다메시지 브로커를 이용하여 처리하는 것이 성능이 뛰어나다는 것을 알 수 있는데 단점도 존재한다.DB를 사용하는 경우 Query를 이용하여 원하는 데이터만 필터링하여 조회할 수 있지만,메시지 브로커를 이용하면 Queue에 적재된 그대로 사용하기 때문에 불가능하다.따라서, 적재할 때 필터링된 데이터를 적재하던가 적재된 데이터를 Logstash를 이용하여 필터링해서 사용해야 한다.또한, 메시지 큐에 적재된 메시지는 주로 7일을 보관하기 때문에 장기간 보관해야하는 경우 별도의 저장소에 저장해야한다.메세지 큐란?메시지 지향 미들웨어(Message Oriented Middleware: MOM)를 구현한 시스템을 메시지 큐(Message Queue: MQ)라고 한다.MOM은 비동기 메시지를 사용하여 다른 응용프로그램 사이의 데이터 송수신을 의미하며,메시지 큐를 통해 이러한 데이터를 교환한다.Producer(sender)가 메시지를 큐에 전송하면 Consumer(receiver) 가 처리하는 방식으로,producer 와 consumer 에 message 프로세스가 추가되는 것이 특징이다.MQ를 사용하면 메시지를 비동기로 요청을 처리하고 queue에 저장하여 consumer에게 병목을 줄여줄 수 있다.대표적인 메시지 큐로는 Kafka, Apache ActiveMQ, RabbitMQ 등이 있다.kafka분산형 스트리밍 플랫폼(A distributed streaming platform)이다.(발행/구독: pub-sub은 메시지를 특정 수신자에게 직접적으로 보내주는 시스템이 아니고,메시지를 받기를 원하는 사람이 해당 토픽(topic)을 구독함으로써 메시지를 읽어 올 수 있다.)대용량 실시간 로그처리에 특화되어 설계된 메시징 시스템으로메시지를 메모리에 저장하는 기존 메시징 시스템과는 달리 파일에 저장을 하는데그로 인해 카프카를 재시작해도 메시지 유실 우려가 감소된다.기본 메시징 시스템(rabbitMQ, ActiveMQ)에서는 브로커(Broker)가 컨슈머(consumer)에게 메시지를 push해 주는 방식인데,카프카는 컨슈머(Consumer)가 브로커(Broker)로부터 메시지를 직접 가져가는 PULL 방식으로 동작하기 때문에컨슈머는 자신의 처리 능력만큼의 메시지만 가져와 최적의 성능을 낼 수 있다.Apache ActiveMQActiveMQ는 JMS를 지원하는 클라이언트를 포함하는 브로커, 자바 뿐만 아니라 다양한 언어를이용하는시스템간의 통신을 할 수 있게 해준다.클라이언트 간 메시지를 송수신 할 수 있는 오픈 소스 Broker(JMS 서버)다.JMS란JMS 는 자바 기반의 MOM(메시지 지향 미들웨어) API 이며 둘 이상의 클라이언트 간의 메시지를 보낸다.핵심 개념은 Message Broker 와 Destination 이다. Message Broker : 목적지에 안전하게 메시지를 건네주는 중개자 역할. Destination: 목적지에 배달될 2가지 메시지 모델 QUEUE, TOPIC. Queue: Point to Point ( Consumer 는 메시지를 받기 위해 경쟁한다.) Topic: Publish to Subscribe. ActiveMQ 메세지 처리 구조기본적으로 Message를 생산하는 Producer, activeMQ Broker(Server), Message를 소비하는 Consumer로 구성되어 있다.Producer → Broker → ConsumerProducer(생산자)가 message를 Queue/Topic에 넣어두면 Consumer가 message를 가져와 처리하는 방식 QUEUE 모델의 경우 메시지를 받는 Consumer가 다수일 때 연결된 순서로 메시지는 제공된다. TOPIC 모델의 경우 메시지를 받는 Consumer가 다수일 때 메시지는 모두에게 제공된다. rabbitMQ오픈소스 AMQP 브로커다.JMS는 API, AMQP는 프로토콜이다. JMS는 메시지의 형식이 아닌 브로커와 통신하는 방법을 정의한다.또한 자바 애플리케이션에만 국한돼 있다.AMQP는 브로커와 통신하는 방법에 대해서 논하지 않지만 메시지가 유선을 통해 큐에 어떻게 넣고 꺼내지는지에 대해 정의한다.서로 다른 두 가지 애플리케이션이 있을 때, 둘 다 자바면 JVMS를 통해 통신할 수 있지만 이중에 하나가 루비라면 JMS는 사용하지 못할것이다.정리WebsocketWebSocket은 통신 프로토콜로서 연결이 끊기지 않아야 하는 실시간 통신에 사용된다.SockJS브라우저에서 Websocket을 지원하지 않거나, 네트워크 Proxy 제약 등으로 인한 Websocket을 사용할 수 없을 경우fallback option을 제공하는데, 이는 SockJS Protocol에 기반으로 Websocket API를 사용할 수 있도록 한다.STOMP웹소켓만 사용했을 땐 직접 세션을 관리해서, 해당 세션으로 채팅 데이터를 전송해야했다면,STOMP을 사용함으로써 publish/subscribe (발행/구독) 구조로 간단하게 메세지를 선택적으로 수신할 수 있다.Code공식문서1. WebSocket Connection 설정client는 /ws 경로에 연결하여 WebSocket Connection을 수립한다.이후 client는 해당 Connection을 통해 STOMP 프레임을 서버로 전송할 수 있다.2. 구독 요청클라이언트는 /topic/public 경로의 Destination 헤더를 가지고 SUBSCRIBE 프레임을 전송한다.이 프레임은 서버에 도착하면 디코딩되어 Message로 변환되고, 메시지는 clientInboundChannel로 전송된다.서버는 이를 메시지 브로커로 라우팅하고, 해당 클라이언트의 구독(Subscription) 정보를 저장한다.3. 메시지 송신이후, 클라이언트는 /app/chat/sendMessage 경로의 Destination 헤더를 가지고 메시지를 전송한다./app prefix는 해당 메시지가 @MessageMapping 메서드를 가진 컨트롤러로 라우팅될 수 있도록 도와준다.클라이언트가 메시지를 보낼 때는 해당 경로로 메시지가 라우팅되어 sendMessage() 메서드가 호출된다.➡️ /app 접두사가 벗겨진 후에는 /chat/sendMessage 목적지 경로만 남게 된다.4. 메시지 처리// Redis pub/sub 예시 코드 @MessageMapping(\"/chat/sendMessage\")public void sendMessage(@Payload ChatMessage chatMessage) { ChannelTopic channel = channels.get(\"/topic/public/\" + chatMessage.getRoomId()); redisPublisher.publish(channel, chatMessage);}@MessageMapping 가진 sendMessage() 가 반환한 값은 스프링의 Message로 변환된다.Message의 Payload는 sendMessage() 가 반환한 값을 기반으로 하고,기본적으로 Destination 헤더는 /topic/public으로 설정된다.Destination 헤더는 클라이언트가 보낸 기존 /app/chat/sendMessage 경로의 목적지 헤더에서/topic/public 으로 변경된 값으로 설정된다.이후, 변환된 Message는 brokerChannel로 전송되고 메시지 브로커에 의해서 처리된다.5. 메시지 전송메시지 브로커는 매칭되는 구독자들(subscribers)을 찾아서 각각에게 MESSAGE 프레임을 보낸다.이 작업은 clientOutboundChannel을 통해 이루어지며,스프링의 Message가 STOMP의 Frame으로 인코딩되어 WebSocket 커넥션으로 전송된다.Buildimplementation 'org.springframework.boot:spring-boot-starter-websocket'implementation 'org.webjars:sockjs-client:1.1.2' // 프론트단에서 사용하는 sockjs 라이브러리implementation 'org.webjars:stomp-websocket:2.3.3-1'implementation 'org.webjars.bower:bootstrap:4.3.1'implementation 'org.webjars:jquery:3.5.1'webjars란 클라이언트에서 사용하는 웹 라이브러리를 JAR 파일 안에 패키징 한 것이다.*jar 파일은 개발자가 작성한 코드와 해당 코드가 실행되기 위해 필요한 리소스들을 압축하여 단일 실행 가능한 파일로 패키징하는 것을 의미 *war 파일은 Web Application Archive의 약자로, 전체 웹 애플리케이션을 압축하여 단일 파일로 패키징하는 것을 의미implementation 'org.webjars:webjars-locator-core'를 입력해서webjar-locator를 통해 아래 코드에서 버전을 생략 할 수 있다.아래는 위 라이브러리를 설치해서 client에 적용한 코드이다.&lt;link rel=\"stylesheet\" href=\"/webjars/bootstrap/4.3.1/dist/css/bootstrap.min.css\"&gt;&lt;script src=\"/webjars/jquery/jquery.min.js\"&gt;&lt;/script&gt;&lt;script src=\"/webjars/sockjs-client/sockjs.min.js\"&gt;&lt;/script&gt;&lt;script src=\"/webjars/stomp-websocket/stomp.min.js\"&gt;&lt;/script&gt;&lt;script src=\"/webjars/bootstrap/4.3.1/dist/js/bootstrap.min.js\"&gt;&lt;/script&gt; *min.js 는 minify 의 줄임말로, 공백과 줄바꿈을 제거하여 용량을 줄인 파일애플리케이션은 클라이언트로 부터 받은 메시지를 처리하기 위해 @Controller 클래스를 사용할 수 있다.이러한, 컨트롤러는 @MessageMapping, @SubscribeMapping, @ExceptionHandler 메서드를 선언할 수 있다.ChatControllerWebSocketConfig에서 “/app”로 시작하는 대상이 있는 클라이언트에서 보낸 모든 메시지는@MessageMapping 어노테이션이 달린 메서드로 라우팅 된다.아래는 초반에 작성했던 코드이다.@Controllerpublic class ChatController { @MessageMapping(\"/chat/sendMessage\") @SendTo(\"/topic/public\") public ChatMessage sendMessage(@Payload ChatMessage chatMessage) { return chatMessage; } @MessageMapping(\"/chat/addUser\") @SendTo(\"/topic/public\") public ChatMessage addUser(@Payload ChatMessage chatMessage, SimpMessageHeaderAccessor headerAccessor){ headerAccessor.getSessionAttributes().put(\"username\", chatMessage.getSender()); return chatMessage; }}@MessageMapping(\"/chat/sendMessage\") : 클라이언트에서 /app/chat/message로 메세지를 발행한다.@SendTo(\"/topic/public\") : /topic/public 에 구독중인 클라이언트에게 메세지를 보낸다.특정 사용자가 “app/chat/sendMessage”라는 경로로 메세지를 보내면“/topic/public” 라는 토픽을 구독하는 사용자들에게 메세지를 전달한다.client :stompClient.subscribe('/topic/public', onMessageReceived);stompClient.send(\"/app/chat/addUser\", {}, JSON.stringify({sender: username, type: 'JOIN'}))이후에 url에 roomId를 추가하면서 코드를 변경했다.@Controller@RequiredArgsConstructorpublic class ChatController { private final SimpMessagingTemplate template; @MessageMapping(\"/chat/sendMessage\") public void sendMessage(@Payload ChatMessage chatMessage) { template.convertAndSend(\"/topic/public/\"+ chatMessage.getRoomId(), chatMessage); } @MessageMapping(\"/chat/addUser\") public void addUser(@Payload ChatMessage chatMessage, SimpMessageHeaderAccessor headerAccessor){ headerAccessor.getSessionAttributes().put(\"username\", chatMessage.getSender()); headerAccessor.getSessionAttributes().put(\"roomId\", chatMessage.getRoomId()); template.convertAndSend(\"/topic/public/\" + chatMessage.getRoomId(), chatMessage); }}client :stompClient.subscribe('/topic/public/'+ roomId, onMessageReceived);stompClient.send(\"/app/chat/addUser\", {}, JSON.stringify({roomId: roomId, sender: username, type: 'JOIN'}))@MessageMapping 는 지정한 경로를 기반으로 메시지를 라우팅할 수 있다.기본적으로, 매핑은 Ant-Style Path 패턴으로 구성하고, Template 변수도 지원한다. (ex, /something*, /something/{id})Template 변수는 @DestinationVariable로 선언한 메서드 인자를 통해서 전달받을 수 있다.@MessageMapping(\"/chat/message/{roomId}\")\tpublic void sendsMessage(@DestinationVariable(\"roomId\") String roomId, @Payload ChatMessage chatMessage) { } @MessageMapping : prefix, endpoint 설정을 포함한 입력한 url로 발행된 메세지 구독 @DestinationVariable : 구독 및 발행 url 의 pathparameter @Payload : 수신된 메세지의 데이터 ☑️ MessageHeaderAccessor, SimpMessageHeaderAccessor, StompHeaderAccessor 타입이 지정된 접근자 메서드를 통해서 Header 정보에 접근한다. ☑️ @Payload MessageConverter 의해서 변환된 메시지의 Payload에 접근한다. ☑️ convertAndSend Object 타입 객체를 인자로 받아 내부적으로 Message 타입으로 변환 MessageSendingOperations Convert the given Object to serialized form, possibly using a MessageConverter, wrap it as a message and send it to the given destination.Config@Configuration // 컨테이너 등록@EnableWebSocket // 웹소켓 서버를 사용하도록 정의public class WebSocketConfig implements WebSocketConfigurer { @Override public void registerStompEndpoints(StompEndpointRegistry registry) { registry.addEndpoint(\"/ws/chat\").setAllowedOriginPatterns(\"*\"); }}@Configuration : 해당 클래스가 Bean의 설정을 할 것이다 라는 것을 말한다.registerStompEndpoints() : Client에서 websocket연결할 때 사용할 API 경로를 설정해주는 메서드🔽WebSocket SockJs 설정@Configuration // 컨테이너 등록@EnableWebSocketpublic class WebSocketConfig implements WebSocketConfigurer { @Override public void registerStompEndpoints(StompEndpointRegistry registry) { registry.addEndpoint(\"/ws/chat\").setAllowedOriginPatterns(\"*\").withSockJS(); }}클라이언트가 웹 소켓 서버에 연결하는 데 사용할 웹 소켓 엔드 포인트를 등록한다.endpoint 구성에 withSockJS()를 사용한다.WebSocket은 HTML5 이후에 나왔기 때문에, HTML5 이전의 기술에는 적용이 어렵다.이때 SockJS를 이용해서 웹 소켓을 지원하지 않는 브라우저에 폴백 옵션을 활성화하는 데 사용된다.*Fallback 이란? : 어떤 기능이 약해지거나 제대로 동작하지 않을 때, 이에 대처하는 기능 또는 동작🔽STOMP 사용@Configuration @EnableWebSocketMessageBrokerpublic class WebSocketConfig implements WebSocketMessageBrokerConfigurer { @Override public void registerStompEndpoints(StompEndpointRegistry registry) { registry.addEndpoint(\"/ws/chat\").setAllowedOriginPatterns(\"*\").withSockJS(); }}구현할 interface의 대상이 WebSocketMessageBrokerConfigurer로 바뀌었다.→ 웹 소켓 연결을 구성하기 위한 메서드를 구현하고 제공한다.@Configuration@EnableWebSocketMessageBrokerpublic class ChatConfig implements WebSocketMessageBrokerConfigurer { @Override public void registerStompEndpoints(StompEndpointRegistry registry) { registry.addEndpoint(\"/ws\").setAllowedOriginPatterns(\"*\").withSockJS(); } @Override public void configureMessageBroker(MessageBrokerRegistry registry) { registry.enableSimpleBroker(\"/queue\", \"/topic\"); registry.setApplicationDestinationPrefixes(\"/app\"); }}☑️ @EnableWebSocketMessageBroker : Stomp을 사용하기위해 선언하는 어노테이션WebSocket 서버를 활성화하는 데 사용된다.☑️ WebSocketMessageBrokerConfigurer 를 상속받아 STOMP로 메시지 처리 방법을 구성한다.☑️ registerStompEndpoints() : 클라이언트에서 WebSocket에 접속할 수 있는 endpoint를 지정/ws 는 WebSocket 또는 SockJS 클라이언트가 WebSocket Handshake로 커넥션을 생성할 경로이다.var socket = new SockJS('/ws');☑️ configureMessageBroker() : 한 클라이언트에서 다른 클라이언트로 메시지를 라우팅 하는 데 사용될 메시지 브로커를 구성☑️ enableSimpleBroker(“/queue”, “/topic”); : 해당 경로로 SimpleBroker를 등록한다. (메시지 받을 때 관련 경로 설정)Simple In-Memory Broker를 사용하도록 설정.SimpleBroker는 해당하는 경로를 SUBSCRIBE하는 client에게 메시지를 전달하는 간단한 작업을 수행한다./topic, /queue로 시작하는 “destination” 헤더를 가진 메세지를 브로커로 라우팅한다.&gt;&gt;&gt; SUBSCRIBEid:sub-0destination:/topic/public/3d41c3ed-8ddb-458d메시지 브로커는 특정 주제를 구독 한 연결된 모든 클라이언트에게 메시지를 broadcast 한다.*브로드캐스팅은 송신 호스트가 전송한 데이터가 네트워크에 연결된 모든 호스트에 전송되는 방식을 의미지금은 STOMP가 갖고있는(내장하고 있는) SimpleBroker 를 사용해 간단한 인 메모리 메시지 브로커를 활성화했다.만일 이용자 수가 증가하여 처리해야하는 데이터가 많아진다면,내장되어있는 SimpleBroker는 철저하게 Spring Boot가 실행되는 (정확하게는 채팅 서버) 곳의 메모리를 잡아먹는다.따라서 다른 많은 비즈니스 로직과 채팅에 대한 부담까지 ‘하나의 서버’가 떠안게 된다.→ RabbitMQ 또는 ActiveMQ와 같은 다른 모든 기능을 갖춘 메시지 브로커를 사용하게 되면채팅 관리 따로 빼서 서버의 부담을 줄일 수 있다.☑️ setApplicationDestinationPrefixes(“/app”); : client에서 SEND 요청을 처리한다. (메시지 보낼 때 관련 경로 설정)클라이언트가 메시지를 보낼 때 경로 맨앞에 /app이 붙어있으면 Broker로 보내진다./app 경로로 시작하는 STOMP 메세지의 “destination” 헤더는 @Controller의 @MessageMapping로 라우팅된다./app 시작되는 메시지가 message-handling methods으로 라우팅 되어야 한다는 것을 명시client :var socket = new SockJS('/ws');stompClient = Stomp.over(socket);stompClient.connect({}, onConnected, onError);function onConnected() { stompClient.subscribe('/topic/public/'+ roomId, onMessageReceived); //(Object) subscribe(destination, callback, headers = {}) // 목적지 \"/topic/public\"을 구독 // send(path, header, message)로 메세지를 보낼 수 있음 stompClient.send(\"/app/chat/addUser\", {}, JSON.stringify({roomId: roomId, sender: username, type: 'JOIN'})) //(void) send(destination, headers = {}, body = '') // 목적지 \"/app/chat/adduser\"로 메세지를 보낸다.}예를 들어 ‘app/chat/addUser’로 클라이언트가 SEND 프레임을 보내면&gt;&gt;&gt; SENDdestination:/app/chat/addUsercontent-length:77{\"roomId\":\"3d41c3ed-8ddb-458d\",\"sender\":\"ss\",\"type\":\"JOIN\"}@Controller에서는 /app desination prefix를 제외한 경로 /chat/addUser를 @MessageMapping하면 된다.예시 2)var chatMessage = { roomId: roomId, sender: username, message: messageInput.value, type: 'TALK'};stompClient.send(\"/app/chat/sendMessage\", {}, JSON.stringify(chatMessage));&lt;&lt;&lt; MESSAGEdestination:/topic/public/3d41c3ed-8ddb-458dcontent-type:application/jsonsubscription:sub-0message-id:1taozffc-1content-length:92{\"roomId\":\"3d41c3ed-8ddb-458d\",\"type\":\"TALK\",\"sender\":\"ss\",\"message\":\"hi\"}EventListener@RequiredArgsConstructor@Componentpublic class WebSocketEventListener { private final SimpMessageSendingOperations sendingOperations; private static final Logger logger = LoggerFactory.getLogger(WebSocketEventListener.class); @EventListener public void handleWebSocketConnectListener(SessionConnectedEvent event) { logger.info(\"Received a new web socket connection \"); } @EventListener public void handleWebSocketDisconnectListener(SessionDisconnectEvent event) { StompHeaderAccessor headerAccessor = StompHeaderAccessor.wrap(event.getMessage()); String username = (String) headerAccessor.getSessionAttributes().get(\"username\"); String roomId = (String) headerAccessor.getSessionAttributes().get(\"roomId\"); if (username != null) { logger.info(\"User Disconnected : \" + username); ChatMessage chatMessage = new ChatMessage(); chatMessage.setType(ChatMessage.MessageType.LEAVE); chatMessage.setSender(username); chatMessage.setRoomId(roomId); sendingOperations.convertAndSend(\"/topic/public/\" + roomId, chatMessage); } }}event listner를 이용하여 소켓 연결(socket connect) 그리고 소켓 연결 끊기(disconnect) 이벤트를 수신하여사용자가 채팅방을 참여(JOIN)하거나 떠날때(LEAVE)의 이벤트를 logging 하거나 broadcast 할 수 있다.SimpMessagingTemplate와 SimpMessageSendingOperations은 모두 Spring의 WebSocket 메시징을 처리하는 인터페이스다.*SimpMessagingTemplate은 SimpMessageSendingOperations 인터페이스의 구현체 (SimpMessagingTemplate은 SimpMessageSendingOperations의 모든 메소드 사용가능)→ 특정 Broker로 메세지를 전달(특정 사용자에게 메세지 전송)Server에서 Client로 특정 메시지를 BroadCast 해줘야 하는 상황에메시지를 보내고자 하는 위치에서 SimpMessagingTemplate 객체를 주입받아 위와 같이 사용을 해주면 된다.Client에서는 Topic을 subscribe 하고 있을 경우 Message를 받을 수 있게 된다.ChatMessage@Getter@Setter@NoArgsConstructor@AllArgsConstructorpublic class ChatMessage { public enum MessageType { JOIN, TALK, LEAVE } private String roomId; // 채팅방 아이디 private MessageType type; // message type private String sender; // message 보내는 사람 private String message; // 내용(message)}MessageType에 따라서 채팅형식이 달라지게 설정했다.reference Spring Websocket &amp; STOMP WebSocket Spring WebSocket 소개 [Spring Boot] WebSocket과 채팅 (3) - STOMP [Spring]Springboot + websocket 채팅[1] [Spring]Springboot + websocket 채팅[2] Spring websocket으로 간단 채팅 프로그램 만들기 [Spring] WebSocket 구현하기 [Spring Boot] WebSocket STOMP 사용시 BroadCast 메시지 전달 방법 [Tech.] Message Broker란? [Spring Boot] WebSocket과 채팅 (4) - RabbitMQ HTTP vs WebSocket 차이점 [메시지 지향 미들웨어:MOM] ActiveMQ, rabbitMQ, Kafka pub/sub 구조란 무엇인가 [Pub/Sub] Publish/Subscribe 구조(모델) Spring Boot + STOMP + JWT Socket 인증하기 [Spring Boot] 소켓 통신을 위한 Websocket 서버 구성 [02.15]webjar [WebSocket] Spring Boot + STOMP + Redis Pub/Sub 이용한 채팅 서버 구현 [스프링 인 액션] 8장 JMS : 비동기 메시지 전송하기Youtube 오늘의 테크용어 : 웹소켓이 뭐냐면 WebRTC? WebSockets? 5분 개념정리!" }, { "title": "Negative test", "url": "/posts/Negative-Test/", "categories": "Study", "tags": "spring, test", "date": "2023-01-20 00:00:00 +0900", "snippet": "Negative TestMock Test 코드 작성을 다 끝낸 후에 예외에 관한 test도 해봐야한다고 들었다.CommentService.java@Overridepublic CommentResponseDto postComment(CommentRequestDto commentDto) { Registry registry = registryRepository.getReferenceById(commentDto.getRegistryIdx()); User user = userRepository.findByNickname(commentDto.getNickname()).orElseThrow(UserNotFoundException::new); Comment comment = commentDto.toEntity(registry, user); commentRepository.save(comment); return CommentResponseDto.of(comment);}CommentServiceTest.java@Test@DisplayName(\"저장 실패 _ user not found\")void save_user_not_found() { when(userRepository.findByNickname(anyString())).thenReturn(Optional.empty()); CustomException e = assertThrows(UserNotFoundException.class, () -&gt; commentService.postComment(commentDto)); assertEquals(USER_NOT_FOUND, e.getErrorCode());}처음에는 .thenThrow(new UserNotFoundException()); 로 예외에 관해서 처리를 하려고 했으나 수정했다.userRepository.findByNickname(commentDto.getNickname()) 자체가 Optonal.empty이다.그래서 실제 로직의 orElseThrow 전에는 비어있는 값이어야 하므로 thenReturn으로 Optional.empty()를 작성했다.assertThrows(expectedType, executable) : executable에서 expectedType의 예외가 발생했는지 확인하는 메서드commentService.postComment(commentDto)를 실행해서 첫번째 인자인 예외 타입과 같은지(혹은 캐스팅이 가능한 상속 관계의 예외인지) 검사assertEquals(expect, actual) : 객체 actual이 expect와 같은 값을 가지는지 확인하는 메서드pr - Negative TestTest를 작성하면서아래 글은 Negative Test와 직접적인 관련은 없지만 test를 작성하면서 코드에 다시 생각해볼 수 있었던 계기가 되어 정리해봤다.이래서 test 코드는 정상 동작도 중요하지만 예외 test도 중요하다는 생각이 들게 되었다.CommentService.java@Overridepublic CommentResponseDto postComment(CommentRequestDto commentDto) { Registry registry = registryRepository.getReferenceById(commentDto.getRegistryIdx()); User user = userRepository.findByNickname(commentDto.getNickname()).orElseThrow(UserNotFoundException::new); Comment comment = commentDto.toEntity(registry, user); commentRepository.save(comment); return CommentResponseDto.of(comment);}본 코드로 돌아와서 findByNickname만 사용하는게 아니라 그 위 코드 getReferenceById로도 값을 찾는다.userRepository.findByNickname()에 exception 처리가 되어있지만registryRepository.getReferenceById()에는 exception 처리가 되어있지 않다.그래서 문득 예외상황에 대한 test 코드를 작성하면서 registry의 idx값도 존재하지 않을 수도 있을텐데? 싶었다.ExceptionHandler로 처리하였고 이 부분은 findById() vs getReferenceById() 글에 작성해뒀다.reference 완벽정리! Junit5로 예외 테스트하는 방법 JUnit 대표적 단정(Assert) 메서드, 라이프사이클(Lifecycle) 메서드" }, { "title": "Custom exception", "url": "/posts/Custom-Exception/", "categories": "Study", "tags": "spring, Exception, Java", "date": "2023-01-13 00:00:00 +0900", "snippet": "Custom ExceptionCustomException을 만들기 전에는 기존에 작성한 것처럼 표준 예외를 사용해서 message를 주면 되지 않을까 라는 생각이 들었었다.원 글은 해당 블로그에서 보면 되고 나는 각각의 장단점에 대해서 요약해봤다.표준 예외로 처리할 때 장점1. 예외 메시지로도 충분히 의미를 전달할 수 있다.UserNameEmptyException 처럼 이름만 봐도 사용자 이름의 입력값이 비어있는 경우 발생하는 예외임을 알 수 있다.하지만 그 이유를 위해서 커스텀 예외를 만드는 것은 지나친 구현이다.2. 표준 예외를 사용하면 가독성이 높아진다. IllegalArgumentException : 인수로 부적절한 값이 들어올 때 던지는 예외 IllegalStateException: 일을 수행하기에 적합하지 않은 상태의 객체인 경우 던지는 예외 UnsupportedOperationException : 요청받은 작업을 지원하지 않는 경우에 던지는 예외 이미 익숙하고, 쓰임에 대해 잘 알고있는 예외들이 많은 반면에 처음 보는 예외들은 당연히 구체적인 쓰임을 잘 모른다.이런 이유로 낯선 예외보다는 익숙한 예외를 마주치는 것이 당연히 가독성이 높을 수 밖에 없다.3. 일일히 예외 클래스를 만들다보면 지나치게 커스텀 예외가 많아질 수 있다.예외가 지나치게 많아진다면 메모리 문제도 발생할 수 있고, 클래스 로딩에도 시간이 더 소요될 가능성이 있다.이미 자바에서는 충분히 많은 표준 예외를 제공하고 있으므로 표준 예외를 재사용한다면 이를 막을 수 있다.사용자 정의로 예외를 처리할 때 장점1. 이름으로도 정보 전달이 가능하다.NoSuchElementException만으로는 어떤 요소가 없는지 알 수 없다.하지만 PostNotFoundException이 발생했다면, Post를 찾는 요청을 보냈지만 해당 요소가 없다는 상황을 유추할 수 있을 것이다.2. 상세한 예외 정보를 제공할 수 있다.컬렉션의 범위를 벗어난 index 접근 요청이 생겼을 때 custom exception을 통해서요청 받은 컬렉션의 최대 범위가 어디까지인지, 요청한 index는 몇인지 바로 알 수 있다.3. 예외에 대한 응집도가 향상된다.클래스를 만드는 행위는 관련 정보를 해당 클래스에서 최대한 관리하겠다는 이야기다.같은 예외가 여러 곳에서 사용될수록 이 장점은 더 극대화될 것이다.4. 예외 발생 후처리가 용이하다.예외는 상속 관계에 있기 때문에,  Exception이나 RuntimeException을 잡아두면 프로그램 내에서 발생하는 거의 모든 예외에 대해 처리가 가능하다.하지만 이는 프로그래머가 의도하지 않은 예외까지 모두 잡아내 혼란을 야기할 수 있다.재사용성이 높은 것은 표준 예외들의 장점이다. 하지만 그 장점 때문에 발생 위치를 정확하게 파악하기 힘들다는 단점도 생긴다.마구잡이로 쓰기 보다는 적절한 상황에 맞춰서 Custom Exception을 작성해야할 것 같다.아래는 Custom Exception을 작성한 코드이다.ErrorCode다양한 상황에서 쓰일 Error Code를 만든다.@Getterpublic enum ErrorCode { // Registry REGISTRY_NOT_FOUND(HttpStatus.NOT_FOUND, \"게시글이 존재하지 않습니다.\"), // Comment COMMENT_NOT_FOUND(HttpStatus.NOT_FOUND, \"해당 댓글이 존재하지 않습니다.\"), // User USER_NOT_FOUND(HttpStatus.NOT_FOUND, \"해당 유저를 찾을 수 없습니다.\"), PERMISSION_DENIED(HttpStatus.UNAUTHORIZED, \"사용자 권한이 없습니다.\"); private final HttpStatus httpStatus; private final String message; ErrorCode(HttpStatus httpStatus, String message) { this.httpStatus = httpStatus; this.message = message; }}☑️ 상태를 담을 HttpStatus와 message를 담을 String 속성을 추가했다.🐣 HTTP Status Code(HTTP 상태 코드) :HTTP Status Code(HTTP 상태 코드)는 클라이언트가 보낸 HTTP 요청에 대한 서버의 응답을 코드로 표현한 것으로 해당 코드로 요청의 성공 / 실패 / 실패요인 등을 알 수 있다.🐣 HttpStatus를 따르지 않고 USER_NOT_FOUND(40410, \"유저 없음\") 과 같이 custom해서 만들어도 된다.다만 이럴 경우에는 HttpStatus타입이 아닌 Integer타입으로 바꿔야 한다고 한다.CustomExceptionErrorCode를 담을 class를 만든다. public class CustomException extends RuntimeException { private static final long serialVersionUID = 4663380430591151694L; private final ErrorCode errorCode; public CustomException(ErrorCode errorCode) { super(errorCode.getMessage()); this.errorCode = errorCode; } public ErrorCode getErrorCode() { return errorCode; }}☑️ RuntimeException을 상속☑️ ErrorCode만 속성으로 추가했다. ➡️ 상태(HttpStatus)와 메세지(message) 정보 모두 담겨있다. Exception 클래스를 상속 받아 정의한 checked Exception 반드시 오류를 처리 해야만 하는 Exception 예외 처리하지 않으면 컴파일 오류를 발생 시킨다. RuntimeException 클래스를 상속 받아 정의한 unChecked Exception 예외 처리하지 않아도 컴파일 시에는 오류를 발생시키지 않는다. 🐣 serialVersionUID 작성 이유serialVersionUID 값을 파일 등으로 저장을 할 때 해당하는 클래스의 버전이 맞는지를 확인하는 중요한 장치이다.serialVersionUID 는 직렬화에 사용되는 고유 아이디인데, 선언하지 않으면 JVM에서 디폴트로 자동 생성된다.Java VM에서 내부 알고리즘에 따라서 자동으로 작성을 하게 되는데, 이것은 어떤 Java VM을 사용하는지에 따라서 달라지게 된다.클라이언트가 Windows가 서버가 Linux일 경우 Java VM이 다르므로 이 값이 다르게 설정이 되고,역직렬화를 할때 exception이 발생할 수 있다. 따라서 무조건 serialVersionUID 값을 설정하기를 권장한다.serialVersionUID는 private static final 로 선언하면 된다.CustomExceptionHandler컨트롤러 전역에서 발생하는 Custom에러를 잡아줄 Handler를 만든다.ExceptionHandler가 붙은 함수는 꼭 protected / private 처리를 해준다. (외부에서 함수를 부르게 되면 그대로 에러 객체를 리턴하기 떄문이다.)@RestControllerAdvicepublic class CustomExceptionHandler { private final Logger LOGGER = LoggerFactory.getLogger(CustomExceptionHandler.class); // Logger를 등록 @ExceptionHandler(CustomException.class) protected ResponseEntity&lt;ErrorResponseEntity&gt; handleCustomException(CustomException e) { return ErrorResponseEntity.toResponseEntity(e.getErrorCode()); }}@ExceptionHandler(CustomException.class)🐣 발생한 CustomException 예외를 잡아서 하나의 메소드에서 공통 처리할 수 있게 해준다. 해당 메소드가 () 들어가는 예외타입을 처리한다. Controller에만 등록이 가능하다. (Service영역은 ❌!) 등록한 Controller 영역 안에서만 작동한다. @ExceptionHandler({ Exception1.class, Exception2.class}) 와 같이 두 개 이상 등록도 가능하다.@ControllerAdvice + @ExceptionHandler🐣 모든 컨트롤러에서 발생하는 CustomException을 캐치한다.해당 객체가 스프링의 controller에서 발생하는 예외를 처리하는 존재임을 명시한다.@ControllerAdvice 와 @RestControllerAdvice 차이Spring은 전역적으로 예외를 처리할 수 있는 @ControllerAdvice와 @RestControllerAdvice 어노테이션을각각 Spring3.2, Spring4.3부터 제공하고 있다.두 개의 차이는 @Controller와 @RestController와 같은데, @RestControllerAdvice는 @ControllerAdvice와 달리@ResponseBody가 붙어 있어 응답을 Json으로 내려준다는 점에서 다르다.ErrorResponseEntityError 내용을 담을 Response Entity를 작성한다.@Data@Builderpublic class ErrorResponseEntity { private int status; private String code; private String message; public static ResponseEntity&lt;ErrorResponseEntity&gt; toResponseEntity(ErrorCode e){ return ResponseEntity .status(e.getHttpStatus()) .body(ErrorResponseEntity.builder() .status(e.getHttpStatus().value()) .code(e.name()) .message(e.getMessage()) .build() ); }}CustomException을 toResponseEntity로 보내면, ErrorCode e안의 내용을 가지고 Response를 만든다.🐣 ResponseEntity란?Spring Framework에서 제공하는 클래스 중 HttpEntity 라는 클래스가 존재한다.이것은 HTTP 요청(Request) 또는 응답(Response)에 해당하는 HttpHeader와 HttpBody를 포함하는 클래스이다.HttpEntity 클래스를 상속받아 구현한 클래스가 RequestEntity, ResponseEntity 클래스이다.출력 예시RegistryNotFoundException// 게시글이 없을 때public class RegistryNotFoundException extends CustomException { public RegistryNotFoundException(){ super(ErrorCode.REGISTRY_NOT_FOUND); }}RegistryServiceImpl// 게시글 상세 보기public ResRegistryDto getIdxRegistry(Long idx) throws CustomException { Registry getIdxRegistry = registryRepository.findById(idx).orElseThrow(RegistryNotFoundException::new); return ResRegistryDto.of(getIdxRegistry);}reference [이론 참고 사이트] [SpringBoot] HTTP Status Code 제어 중요성 및 방법 [Spring] @RestControllerAdvice를 이용한 Spring 예외 처리 방법 - (2/2) [Spring] Controller에서의 Exception 처리 [완벽해설] serialVersionUID에 대한 정확한 설명 [Java] “serialVersionUID”이란? 어떤 역할을 가지고 있기에 선언이 되어 있는가? [Spring Boot] ResponseEntity란 무엇인가? [스프링부트] @ExceptionHandler를 통한 예외처리[코드 참고 사이트 및 영상] [SpringBoot] Custom Exception Response 만들기 woowacourse-teams/2022-f12 서비스 특성에 맞춘 예외 처리 방법 Custom Exception [ 스프링 부트 (Spring Boot) ]" }, { "title": "Mock test", "url": "/posts/Mock-Test/", "categories": "Study", "tags": "spring, test", "date": "2023-01-10 00:00:00 +0900", "snippet": "Mock TestUserServiceTest가짜 객체는 동작을 하지 않는다. (passwordEncoder의 encode가 null)처음에 test 코드를 작성했을 때 회원가입 로직에서 인코딩 된 pw와 인코딩 되지 않은 pw를 비교하여 검증을 하려고 했다.하지만 encode된 pw가 제대로 값을 띄우지 못하고 계속 null이 떴고 그 이유를 알지 못했다.아래 코드는 인코딩이 제대로 되지 않아서 user에 그냥 password 그 자체의 값을 넣어줬고String pw = passwordEncoder.encode(signUpRequestDto.getPassword()); 값을 출력해보면 null로 출력되었다.문제가 된 코드class UserServiceTest { @InjectMocks SignServiceImpl userService; @Mock UserRepository userRepository; @Mock PasswordEncoder passwordEncoder; User user; @Test @DisplayName(\"회원가입 test\") void signUp() { //given SignUpRequestDto signUpRequestDto = new SignUpRequestDto(); signUpRequestDto.setNickname(\"끼까꿍\"); signUpRequestDto.setPassword(\"뮤뮤\"); signUpRequestDto.setName(\"김철수\"); List&lt;String&gt; role = Collections.singletonList(\"ROLE_USER\"); String pw = passwordEncoder.encode(signUpRequestDto.getPassword()); user = User.builder() .nickname(signUpRequestDto.getNickname()) .name(signUpRequestDto.getName()) .password(signUpRequestDto.getPassword()) .roles(role) .build(); when(userRepository.save(any(User.class))).thenReturn(user); //when userService.signUp(signUpRequestDto); verify(userRepository).save(any(User.class)); //then assertAll( // 2가지 test () -&gt; assertEquals(signUpRequestDto.getNickname(), user.getNickname()), () -&gt; assertEquals(signUpRequestDto.getName(), user.getName()) ); }원인@Mock은 가짜 객체이다.가짜 객체는 실제 서비스에 맞게 쓰려고 하면 NULL로 뜬다. → 가짜 객체는 동작을 안한다.실제 객체를 가지고 쓴 다음 stubbing을 통해서 가짜 객체를 사용한 다음 retnrun 값을 실제 객체로 넣어줘야한다.요약PasswordEncoder passEncoder = PasswordEncoderFactories.createDelegatingPasswordEncoder(); : 실제 객체 만들기String pw = passEncoder.encode(signUpRequestDto.getPassword()); : 실제 객체로 encoding하기when(passwordEncoder.encode(user.getPassword())).thenReturn(pw); : 가짜 객체에 실제 객체를 return한다. (가짜 객체로 실행했을 때 이렇게 동작해라 라고 알려줘야 한다.)전체 코드 @Test @DisplayName(\"회원가입 test\") void signUp() { //given PasswordEncoder passEncoder = PasswordEncoderFactories.createDelegatingPasswordEncoder(); // 1번 SignUpRequestDto signUpRequestDto = new SignUpRequestDto(); signUpRequestDto.setNickname(\"끼까꿍\"); signUpRequestDto.setPassword(\"뮤뮤\"); signUpRequestDto.setName(\"김철수\"); List&lt;String&gt; role = Collections.singletonList(\"ROLE_USER\"); String pw = passEncoder.encode(signUpRequestDto.getPassword()); // 2번 user = User.builder() .nickname(signUpRequestDto.getNickname()) .name(signUpRequestDto.getName()) .password(pw) .roles(role) .build(); when(userRepository.save(any(User.class))).thenReturn(user); //when userService.signUp(signUpRequestDto); verify(userRepository).save(any(User.class)); // then assertFalse(user.getName().isEmpty()); // 3번 }1번. 실제 객체PasswordEncoder 설정 파일로 가면 아래와 같이 정의했다.@Configurationpublic class PasswordEncoderConfig { @Bean public PasswordEncoder passwordEncoder() { return PasswordEncoderFactories.createDelegatingPasswordEncoder(); }}여기서 return값을 복사한 다음 실제 객체로 test코드에 작성해준다.2번. password 인코딩passEncoder.encode(signUpRequestDto.getPassword());실제 객체에 encoding 후 User 객체에 값을 넣어준다.3번. 검증UserService 로직에서 name이 비어있는지 체크하는 코드가 작성되어있다.해당 부분을 체크하고 마무리하였다.참고로 test하려고 하는 로직에 없는 로직을 작성할 경우 *Please remove unnecessary stubbings or use ‘lenient’ strictness. 와 같은 에러가 뜰 수 있다.이 부분은 아래 예시로 참고한다.RegistryServiceTest코드에 없는 로직을 test 코드에 작성하지 않는다.RegistryService.javapublic PagingResult getBoards(int curPage) { Pageable pageable = PageRequest.of(curPage - 1, PAGE_POST_COUNT); Page&lt;Registry&gt; boards = registryRepository.findAllByOrderByCreatedAtDesc(pageable);// 생성 날짜 순으로 보여주기 List&lt;Registry&gt; boardList = boards.getContent(); // 조회된 데이터 // 코드 생략}위 코드는 db에서 생성 날짜 순으로 페이징 된 결과를 출력시킨다.위 로직에는 repository에 저장하는 코드가 없다.그런데 test 코드에 객체를 저장하는 코드를 작성하면 안된다는 얘기다.RegistryServiceTest.java @Test public void paging() { User user = User.builder() .nickname(\"nickname\") .password(\"123456\") .build(); Registry registry = Registry.builder() .title(\"test\") .main(\"main\") .user(user) .build(); // when(registryRepository.save(any())).thenReturn(registry); // 실제 코드에 없어서 기각 // 이후 코드 생략" }, { "title": "Mock", "url": "/posts/Mock/", "categories": "Study", "tags": "spring, test", "date": "2023-01-05 00:00:00 +0900", "snippet": "Mock 이란?Mock은 진짜 객체와 비슷하게 동작하지만 프로그래머가 직접 그 객체의 행동을 관리하는 객체이다.개발이 덜된 API를 이용할 경우나, 테스트 진행에 외부 API가 필요한 경우 등외부API를 신경 안 쓰고 객체를 테스트할 때 사용한다.MockingMocking은 unit 테스트에서 주로 등장하는데, 테스트 대상의 객체에 의존되어 있는 다른 객체들을 페이크 객체로 만드는 것이다ex)테스트 대상은 다른 객체, 함수 간의 의존성을 가지고 있을 수 있다.회원 가입을 하기 위해서는 ID, PW를 저장하면 되지만,실제로 ID 중복체크도 있고, 비밀번호 유효성 검사, 암호화 등등 하나의 행동에는 실제로 다양한 의존 관계가 존재한다.하지만, 나는 ID / PW 가 제대로 저장되는지만 알고 싶고 이를 테스트 하고 싶다.이를 위해서는 ID 중복체크는 무조건 True, 비밀번호 유효성 검사도 무조건 True, 암호화는 ‘a123’으로 만들어 준다고 가정해본다.DB insert 되기 전 객체의 데이터는 { ID: 'idid', PW: 'a123' } 라면, 정상적으로 회원 가입 로직을 수행한 것으로 볼 수 있을 것이다.위에서 회원 가입이라는 행동에 의존된 것들을 가짜 행위한다고 가정한 것이 Mocking이다.테스트 대상이 아닌 것들을 Fake Object, Fake Action 처리하는 것을 의존성을 Mocking 처리했다고 말할 수 있다.이처럼 Mocking은 테스트 대상 객체의 행동을 고립시키기 위해서,의존성을 배제하기 위해서는 의존되어있는 객체들의 행동을 가짜로 만들어주는 것이다.MockitoMockito 란 단위 테스트를 위한 Java mocking framework이다.스프링부트 2.2 이상이라면 spring-boot-starter-test에 Mockito가 포함되어있다.*Mockito 없이 직접 Mock을 만들 수 있는데 blog에 있는 글을 보면 된다. 단점은 의존 개수와 크기에 따라 구현하는데 많은 부담감이 생긴다고 한다.1. Mockito를 이용하여 Mock 생성하기class CommentServiceTest { @Test void mockito_test() { UserRepository userRepository = mock(UserRepository.class); RegistryRepository registryRepository = mock(RegistryRepository.class); CommentRepository commentRepository = mock(CommentRepository.class); CommentServiceImpl commentService = new CommentServiceImpl(commentRepository, registryRepository, userRepository); assertThat(commentService).isNotNull(); }} 2. @Mock 어노테이션으로 생성하기먼저 class에 어노테이션을 붙여준다. JUnit5 extension을 이용하여 사용할 수 있다.@ExtendWith(MockitoExtension.class)class RegistryServiceTest {}@ExtendWith(MockitoExtension.class): test 클래스가 Mockito를 사용함을 의미한다.@Mock 사용방법은 2가지로 나눠진다. 생성자 주입 2. @Mock 객체 주입방법 1. 주입된 @Mock 객체로 직접 생성자에 주입@ExtendWith(MockitoExtension.class)class RegistryServiceTest { @Test void mockito_test(@Mock UserRepository userRepository, @Mock RegistryRepository registryRepository){ RegistryServiceImpl registryService = new RegistryServiceImpl(registryRepository, userRepository); assertThat(registryService).isNotNull(); }}@Mock: 실제 구현된 객체 대신에 Mock 객체를 사용하게 될 클래스를 의미한다.테스트 런타임 시 해당 객체 대신 Mock 객체가 주입되어 Unit Test가 처리된다.방법 2. @InjectMocks를 통해 자동으로 @Mock 객체를 주입@ExtendWith(MockitoExtension.class)class RegistryServiceTest { @Mock UserRepository userRepository; @InjectMocks RegistryServiceImpl registryService; @Test void mockito_test(){ assertThat(registryService).isNotNull(); }}@InjectMocks: Mock 객체가 주입된 클래스를 사용하게 될 클래스를 의미한다.테스트 런타임 시 클래스 내부에 선언된 멤버 변수들 중에서@Mock으로 등록된 클래스의 변수에 실제 객체 대신 Mock 객체가 주입되어 Unit Test가 처리된다.이를 토대로 정리해보면RegistryServiceTest는 Mockito를 사용(@ExtendWith)하고, UserRepository를 실제 객체가 아닌 Mock 객체로 바꾸어 주입(@Mock)한다.따라서 테스트 런타임 시 RegistryServiceImpl의 멤버 변수로 선언된 UserRepository에 Mock 객체가 주입(InjectMocks)된다.@MockBean@MockBean은 Mock과 달리 org.springframework.boot.test.mock.mockito 패키지 하위에 존재한다.즉 spring-boot-test에서 제공하는 어노테이션이다. Mockito의 Mock 객체들을 Spring의 ApplicationContext에 넣어준다.그리고 동일한 타입의 Bean이 존재할 경우 MockBean으로 교체해준다.@MockBean은 스프링 컨텍스트에 mock객체를 등록하게 되고스프링 컨텍스트에 의해 @Autowired가 동작할 때 등록된 mock 객체를 사용할 수 있도록 동작한다.언제 @Mock을 쓰고 언제 @MockBean을 쓸까?Spring Boot Container가 필요하고 Bean이 container에 존재 해야한다면 @MockBean을 쓰고 아니라면 @Mock을 쓰면 된다.@Mock은 @InjectMocks에 대해서만 해당 클래스안에서 정의된 객체를 찾아서 의존성을 해결한다.@MockBean은 mock 객체를 스프링 컨텍스트에 등록하는 것이기 때문에 @SpringBootTest를 통해서 Autowired에 의존성이 주입되게 된다.@Autowired라는 강력한 어노테이션으로 컨텍스트에서 알아서 생성된 객체를 주입받아 테스트를 진행할 수 있도록 한다. Mock 종류 의존성 주입 @Mock @InjectMocks @MockBean @Autowired 🐣 @Mock을 사용하면 의존성 주입으로 @InjectMocks을 쓰고 @MockBean을 사용하면 주입할 때 @Autowired를 쓰면 된다.spring에서는 @Mock을 쓰나 @MockBean 을 쓰나 상관없다.다만 스프링 부트를 쓰지 않고 자바만을 가지고 사용한다면 @mock으로 작성해야한다.Mockito로 test 코드 작성하기Mockito는 Stub 작성과 Verify가 중심을 이루며 다음과 같은 순서로 진행된다.CreateMock : 인터페이스에 해당하는 Mock 객체를 만든다. Stub : 테스트에 필요한 Mock 객체의 동작을 지정한다.(필요시만) Exercise : 테스트 메소드 내에서 Mock객체를 사용한다. Verify : 메소드가 예상대로 호출됐는지 검증한다.스터빙(Stubbing)이란?Stub은 테스트가 실행되고 통과할 정도로만 구현된다.만들어진 mock 객체의 메소드를 실행했을 때 어떤 리턴 값을 리턴할지를 정의하는 것이다.Mock과 Stub의 차이점Stub의 대표적인 예제는 Controller - Service 관계를 들 수 있다.Controller는 일반적으로 Service에서 가공된 데이터를 가져온다.하지만, Controller의 응답을 테스트함에 있어서 Service가 어떻게 실행되는지 궁금하지 않다.Service로부터 반환받은 데이터를 클라이언트에게 제대로 응답하는지만 궁금할뿐이다.이 경우, Service라는 것을 정의할 필요가 없다. 클라이언트로 전해줄 정적 데이터만 필요할 것이다.이런 경우 “Stubbing한다”라고 표현할 수 있다. Stub - 단순한 테스트용이라, 대체한 객체에 대한 정확한 검증하지 않음 ex) 인메모리로 가상 데이터 Mock - 테스트 대상이 의존하는 객체를 사용하고 동일한 역할을 흉내내고 있는지까지 검증 이 데이터에 실제 사용하려는 DB에 정확하게 동작하는가 Mockito에선 when 메소드를 이용해서 스터빙을 지원하고 있다.스터빙을 할 수 있는 방법은 OngoinStubbing, Stubber를 쓰는 방법 2가지가 있다.OngoingStubbing 메소드OngoingStubbing 메소드란 when에 넣은 메소드의 리턴 값을 정의해주는 메소드이다.when({스터빙할 메소드}).{OngoingStubbing 메소드}; 메소드명 설명 thenReturn 스터빙한 메소드 호출 후 어떤 객체를 리턴할 건지 정의 thenThrow 스터빙한 메소드 호출 후 어떤 Exception을 Throw할 건지 정의 thenAnswer 스터빙한 메소드 호출 후 어떤 작업을 할지 custom하게 정의, mockito javadoc을 보면 이 메소드를 굳이 사용하지 말고 thenReturn, thenThrow 메소드 사용을 추천하고 있다. thenCallRealMethod 실제 메소드 호출 Stubber 메소드{Stubber 메소드}.when({스터빙할 클래스}).{스터빙할 메소드} 메소드명 설명 doReturn 스터빙 메소드 호출 후 어떤 행동을 할 건지 정의 doThrow 스터빙 메소드 호출 후 어떤 Exception을 throw할  건지 정의 doAnswer 스터빙 메소드 호출 후 작업을 할지 custom하게 정의 doNothing 스터빙 메소드 호출 후 어떤 행동도 하지 않게 정의 doCallRealMethod 실제 메소드 호출 테스트에 사용할 스텁 만들기when(Mock_객체의_메소드).thenReturn(리턴값);when(Mock_객체의_메소드).thenThrow(예외);스텁은 필요할 때만 만드는 것이 원칙이다. 메소드 호출 여부를 검증만 할 때는 사용하지 않는다.아래처럼 내부에서 인스턴스를 생성해서 사용하기 때문에 매개변수를 제어 못하는 경우가 있다.RegistryDto registry1 = new RegistryDto();registry1.setTitle(\"첫 번째\");registry1.setMain(\"1\");제어할 수 없는 매개변수는 any()를 이용하여 처리한다.when(registryService.postUpload(any(), user)).thenReturn(saveRegistry);검증스터빙한 메소드를 검증하는 방법verify 메소드를 이용해서 스터빙한 메소드가 실행됐는지, n번 실행됐는지, 실행이 초과되지 않았는지 등 다양하게 검증해볼 수 있다.verify(T mock, VerificationMode mode)VerificationMode는 검증할 값을 정의하는 메소드이다. 메소드명 설명 (테스트 내에서~) times(n) 몇 번이 호출됐는지 검증 never 한 번도 호출되지 않았는지 검증 atLeastOne 최소 한 번은 호출됐는지 검증 atLeast(n) 최소 n 번이 호출됐는지 검증 atMostOnce 최대 한 번이 호출됐는지 검증 atMost(n) 최대 n 번이 호출됐는지 검증 calls(n) n번이 호출됐는지 검증 (InOrder랑 같이 사용해야 함) only 해당 검증 메소드만 실행됐는지 검증 timeout(long mills) n ms 이상 걸리면 Fail 그리고 바로 검증 종료 after(long mills) n ms 이상 걸리는지 확인timeout과 다르게 시간이 지나도 바로 검증 종료가 되지 않는다. description 실패한 경우 나올 문구 실습Service test 코드에는 Service가 주된 test가 되어야 한다.그 말은 repository는 mock을 통해 가짜 객체를 만들어 사용하는 것이다.이 전에는 @Autowired를 이용해서 Service와 Repository를 사용했었다.@SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.RANDOM_PORT)@Transactionalclass RegistryServiceTest { @Autowired RegistryRepository registryRepository; @Autowired UserRepository userRepository; @Autowired RegistryServiceImpl registryService; @Test void register() throws Exception { //given User user = User.builder() .username(\"username\") .nickname(\"nickname\") .password(\"password\") .email(\"email\") .build(); User saveUser = userRepository.save(user); UserDetailsImpl userDetails = new UserDetailsImpl(saveUser); RegistryDto registry1 = new RegistryDto(); registry1.setTitle(\"첫 번째\"); registry1.setMain(\"1\"); RegistryDto registry2 = new RegistryDto(); registry2.setTitle(\"두 번째\"); registry2.setMain(\"2\"); //when Registry saveRegistry1 = registryService.postUpload(registry1, userDetails); Registry saveRegistry2 = registryService.postUpload(registry2, userDetails); //then Assertions.assertThat(registry1.getTitle()).isEqualTo(saveRegistry1.getTitle()); Assertions.assertThat(registry2.getTitle()).isEqualTo(saveRegistry2.getTitle()); }}Mockito 적용하기 @Mock mock 객체를 만들어서 반환한다. @InjectMocks @Mock이나 @Spy 객체를 자신의 멤버 클래스와 일치하면 주입시킨다. @Spy 실제 객체를 생성하고 필요한 부분에만 mock처리하여 검증을 진행할 수 있다. @ExtendWith(MockitoExtension.class) // 1번class RegistryServiceTest { @Mock UserRepository userRepository; @Mock RegistryRepository registryRepository; @InjectMocks RegistryServiceImpl registryService; @Test void mockito_test(){ assertThat(registryService).isNotNull(); } @Test void register() throws Exception { //given List&lt;String&gt; role = Collections.singletonList(\"ROLE_USER\"); User user = User.builder() .name(\"username\") .nickname(\"nickname\") .password(\"password\") //.email(\"email\") .roles(role) .build(); //userRepository.save(user); // 2번 RegistryDto registryDto = new RegistryDto(); registryDto.setTitle(\"첫 번째\"); registryDto.setMain(\"1\"); Registry saveRegistry = registryDto.toEntity(user); when(registryRepository.save(any(Registry.class))).thenReturn(saveRegistry); // 3번 //when Registry registry = registryService.postUpload(registryDto, user); verify(registryRepository).save(any(Registry.class)); // 4번 //then Assertions.assertThat(registryDto.getTitle()).isEqualTo(registry.getTitle()); // 5번 Assertions.assertThat(registryDto.getMain()).isEqualTo(registry.getMain()); }}1번@Mock 을 사용하기 위해서는 @ExtendWith(MockitoExtension.class)를 사용한다.통합 테스트로 진행하는 것이 아니므로 @SpringBootTest와 @Transactional을 삭제했다.2번userRepository.save(user);를 주석처리한 이유는 RegistryService를 test 하는 코드를 작성하는 것이기 때문에userRepository.save(user)는 성공했다고 가정하고 진행하므로 필요없는 코드이다.3번when(registryRepository.save(any(Registry.class))).thenReturn(saveRegistry);test의 registryRepository와 실제 ServiceImpl의 registryRepository가 같아야 하므로 any()를 넣어준다.any안에 class를 안넣어줘도 되긴하지만 넣어줬다.4번verify(registryRepository).save(any(Registry.class));Stubbing을 해줬으니 검증을 해본다.5번Assertions.assertThat(registryDto.getTitle()).isEqualTo(registry.getTitle());service를 test하는 것이므로 saveRepository를 기댓값으로 넣지 않게 주의한다.Mockito 알아보기 (부제 : BDD) [Spring boot TEST] Mockito input을 그대로 리턴하기 [SpringBoot]@Mock,@MockBean 차이가 뭘까? [JUnit/Spring] Mockito annotion 차이(@Mock , @MockBean , @Spy , @SpyBean) 모키토 프레임워크(Mockito framework) [Java] Mockito 사용법 (3) - 스터빙 (Stubbing) (OngoingStubbing, Stubber) [Java] Mockito 사용법 (4) - 검증 (Verify) Unit Test에 나오는 Fixture와 Mock은 무엇일까? [TDD] Fixture와 Mock이란? Mockito란?" }, { "title": "Session과 jwt", "url": "/posts/Session%EA%B3%BC-JWT/", "categories": "Study", "tags": "study, summary, 강의", "date": "2022-12-28 00:00:00 +0900", "snippet": "JWT 강의들 대충 따라하면 님들 코딩인생 끝남 강의를 보고 정리했다.회원기능을 구현해서 로그인 한 사람만 해당 사이트를 보여줄 수 있게 하려고 한다.여기서 session과 token 두 가지 방법 중 하나를 이용해서 구현이 가능하다.둘다 회원인증의 기본적인 동작 방식은 유사하다.user가 로그인을 하면 서버가 user한테 입장권 하나 발급해준다.사이트에서 어떤 서비스를 제공할 때 입장권이 필요하다고 요청을 하면user가 입장권을 제출하고 문제가 없으면 해당 서비스를 제공하게 된다.session과 token은 입장권에 써있는 정보가 다르다.session입장권에 써있는 정보가 별로 없다. ex) 발급번호 하나 정도만 적혀있다.user가 입장권을 제시하면 서버가 메모리나 db에 따로 만들어둔 입장권 발급 목록에서입장권의 발급번호를 조회한 다음에 문제가 없으면 user를 통과시켜준다.jwt입장권에 써있는 정보가 많다. ex) 회원명, 이메일, 발급일, 유효기간 등등이 적혀있다.서버는 입장권을 검사를 할 때 입장권 자체 하나만을 보고 유효기간이나 다른 문제가 없다면 user를 통과시켜준다.장점stateless하다.회원이 많아질 수록 서버에 부담이 덜해진다.기존의 session방식은 회원이 입장권을 제시할 때마다 db를 조회해봐야하므로 동시에 접속하는 회원이 많아지면 힘들어진다.하지만 jwt방식은 user가 입장권을 제시하면 입장권 자체만 확인하면 되므로 처리가 매우 빨라진다.이러한 장점이 있어서 jwt로 회원기능을 구현하는 것이다.주의할 점jwt를 쓰는 곳이 많다보니 이곳저곳에 있는 것들을 보고 그대로 막 쓰면 보안 이슈가 생긴다.jwt는 아래와 같이 생겼다.1. HEADER의 alg : none 공격none으로 사용했을 때 간혹 어떤 서버들은 입장이 가능하다.→ HS256으로 사용한다.2. JWT는 변환이 쉽다.decoding이 매우 쉽다.따라서 민감한 user 정보를 그대로 넣으면 안되고 최소한의 정보만 담는 것이 좋다.3. secret key 문제대충 적으면 안된다.짧은 간단한 문자열로 적으면(ex. secret, secret key) 때려 맞추기 쉬워서 서버가 뚫린다.따라서 key를 매우 길게 설정하고 공유를 하지 않는다.또는 생성용 키와 검증용 키 2개를 사용한다. (private key + public key)4. jwt 탈취어떤 user의 jwt 입장권을 탈취하는 경우이 부분은 헬스장 입장권 잃어버리면 잃어버린 사람 책임이므로 굳이 깊게 생각할 필요는 없다.카드 회사의 경우 카드 잃어버리면 사용정지 시키듯이 입장권 사용을 정지 시키는 조치를 취할 수도 있다.하지만 jwt 방식은 구조상 입장권을 회수하거나 정지시키기 어렵다. (stateless jwt는 원래 못한다.)solution1. 훔치기 어렵게 만들어 둔 저장소를 사용한다. ( HttpOnly cookie )2. 입장권 black list를 만든다.특정 입장권은 입장이 불가능한 목록을 만든다.그래서 누가 입장권을 제시할 때 마다 검사를 한다.그런데 이런 식으로 코드를 작성하게 되면 jwt를 쓰는 장점이 없어진다. (session 방식이랑 별 차이가 없다.)3. jwt 유효기간 짧게 설정이 경우 입장권 재 발급을 위한 refresh token을 따로 운영을 해야한다.그리고 refresh token이 있으면 유효기간이 끝날 때 마다 새로 jwt를 발급받을 수 있다.refresh token이 탈취당하는 경우도 있기 때문에 Refresh token rotation이라는 방법을 쓰는게 안전하다. (refresh token은 언제나 1회용)결론대부분의 서비스들은 session 방식으로 회원 인증을 구현 하는 것이 맞다.(간단함)회원이 1억명이거나 회원 입장권 조회하는 것이 매우 힘이 들거나마이크로 서비스 같은 것들이 많다면 jwt를 쓰는 게 나을 수도 있다.보안이 중요한 서비스를 만들 때 jwt를 대충 갖다 쓰는 곳은 없다.다른 업체의 인증 서비스를 이용할 수도 있다.따라서 jwt를 쓰던 session을 쓰던 다른 기능을 도입할 때는 장단점을 파악해서 도입을 해야한다." }, { "title": "N+1 문제", "url": "/posts/N+1-%EB%AC%B8%EC%A0%9C/", "categories": "Project", "tags": "JPA, study, project, DB", "date": "2022-12-25 00:00:00 +0900", "snippet": "JPA의 N+1 문제1 : N 매핑을 하면서 나타날 수 있는 N+1 문제에 대해 알아본다.N+1 문제란?N+1이란 엔티티 하나를 조회하기 위해서 연관된 엔티티까지 조회 쿼리문이 N+1번 날라간다.이로 인해 시스템에 심각한 성능 저하가 일어날 수 있다.이러한 부분을 N+1 문제라고 한다.N + 1 문제는 연관관계가 설정된 엔티티 사이에서 한 엔티티를 조회하였을 때조회된 엔티티의 개수(N 개)만큼 연관된 엔티티를 조회하기 위해 추가적인 쿼리가 발생하는 문제를 의미한다.N + 1에서 1은 한 엔티티를 조회하기 위한 쿼리의 개수이며,N은 조회된 엔티티의 개수만큼 연관된 데이터를 조회하기 위한 추가적인 쿼리의 개수를 의미한다.☑️ 엔티티 조회 쿼리(1 번) + 조회된 엔티티의 개수(N 개)만큼 연관된 엔티티를 조회하기 위한 추가 쿼리 (N 번)참고로 LAZY 로딩을 사용할 때 해당 Entity가 영속 상태여야 한다.→ 쿼리 실행 시점에서 영속성 컨텍스트에 엔티티가 관리되어야 한다.영속성 컨텍스트란, JPA에서 엔티티들을 관리하기 위한 논리적인 저장소로,영속성 컨텍스트에 의해 관리되는 엔티티들은 데이터베이스에 쿼리를 실행하거나 변경사항을 반영할 때 이를 관리하고 최적화한다.LAZY 로딩을 사용하는 경우,연관된 엔티티들은 실제로 필요한 시점까지 데이터베이스에서 조회되지 않기 때문에 영속성 컨텍스트에 관리되고 있어야 한다.그렇지 않으면 해당 연관된 엔티티들을 조회하는 과정에서 영속성 컨텍스트가 없어서 LazyInitializationException이 발생할 수 있다.EAGER 로딩을 사용하는 경우에는 엔티티를 조회할 때 연관된 다른 엔티티들도 한꺼번에 데이터베이스에서 함께 조회되기 때문에영속성 컨텍스트가 없더라도 상관없이 엔티티와 함께 연관된 Entity들까지 모두 가져오게 된다.EAGER 로딩을 사용하는 경우에는영속성 컨텍스트에 해당 Entity와 함께 연관된 엔티티들이 모두 영속상태가 아니어도 문제가 발생하지 않는다.→ @Transactional 어노테이션을 달아 트랜잭션 범위를 정해준다.발생fetch = FetchType.EAGER로 설정하게 되면 N+1 문제가 발생된다.fetch = FetchType.LAZY로 설정하면 N+1 문제는 발생하지 않지만 해당 객체에 대해 전부 조회하는 경우에 N+1 문제가 발생한다.FetchType을 변경하는 것은 단지 N+1 발생 시점을 연관관계 데이터를 사용하는 시점으로 미룰지,아니면 초기 데이터 로드 시점에 가져오느냐에 차이만 있는 것이다.결국 fetch = FetchType.EAGER or fetch = FetchType.LAZY로 설정하는 것과 관계 없이 N+1 문제가 발생된다.예시Registry와 Comment는 (1:N) 관계이다.하나의 게시글에 여러 개의 댓글이 있는 상황에서 게시글을 조회할 때 Eager 로딩으로 설정된 경우,게시글 1개를 가져오기 위해 추가적으로 댓글들도 함께 가져오게 된다.→ 게시글 1개를 가져오는 쿼리 1개와 댓글을 가져오는 쿼리 N 개가 실행되어 총 N + 1 개의 쿼리가 발생하게 된다.code해당 블로그를 통해 코드를 작성했다.@Testvoid test(){ System.out.println(\"------------ Registry 전체 조회 요청 ------------\"); List&lt;Registry&gt; registry = registryRepository.findAll(); System.out.println(\"------------ Registry 전체 조회 완료. [1번의 쿼리 발생]------------\\n\\n\"); System.out.println(\"------------ Registry title &amp; main 조회 요청 ------------\"); registry.forEach(it -&gt; System.out.printf(\"Registry 제목: [%s], Registry 내용: [%s]%n\", it.getTitle(), it.getMain())); System.out.println(\"------------ Registry 제목 &amp; 내용 조회 완료. [추가적인 쿼리 발생하지 않음]------------\\n\\n\"); System.out.println(\"------------ Registry에 달린 comment 내용 조회 요청 [조회된 Registry의 개수 만큼 추가적인 쿼리 발생]------------\"); registry.forEach(post -&gt; { post.getComments().forEach(comment -&gt; { System.out.printf(\"Registry 제목: [%s], COMMENT 내용: [%s]\\n\", comment.getRegistry().getTitle(), comment.getComment()); }); }); System.out.println(\"\\n------------ Registry에 달린 comment 내용 조회 완료 ------------\\n\\n\");}기존에 데이터가 있어서 확인해보면 게시글 하나당 댓글을 조회하는 쿼리가 계속 발생하는 것을 볼 수 있다.= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =매핑을 FetchType.LAZY 로 설정한다고 하더라도, 게시글을 조회할 때 댓글들은 아직 로딩되지 않은 상태이기 때문에게시글과 댓글들 간의 연관관계가 필요할 때마다 추가 쿼리가 발생하여 N + 1 문제가 발생할 수 있다.이 경우 N+1번의 쿼리가 발생하는 것이다. Registry 조회 - 1번 Comment의 갯수(각 Registry가 가지고 있는 Comment 조회) - N번→ 쿼리가 발생하는 시점만 달라질 뿐, 전체적인 쿼리의 수는 동일하다.findAll()메서드를 호출하게 되면 아래와 같이 실행된다.EAGER JPQL에서 동작한 쿼리를 통해서 객체에 데이터가 바인딩 된다.그 이후 JPA에서는 글로벌 패치 전략(즉시 로딩)을 받아들여 해당 객체 대해서 추가적인 LAZY 로딩으로 N+1을 발생시킨다.LAZY 동일하게 객체에 데이터가 바인딩되지만(JPA가 글로벌 패치 전략을 받아들이지만)LAZY 로딩이기 때문에 추가적인 SQL을 발생시키지 않는다.하지만 LAZY로 추가적인 작업을 진행하게되면 결국 N+1 문제가 발생하게 된다.해결방법fetch join, @EntityGraph로 해결이 가능하다.(그러나 페이징은 진행할 수 없으며,둘 이상의 컬렉션을 fetch join하는 데이터가 부정합하게 조회되기 때문에 이를 사용하지 않는 것이 좋다.)OneToMany 관계에서는 @BatchSize 혹은 @Fetch(FetchMode.SUBSELECT)로 해결한다.1. Fetch Join조인할 때 연관된 엔티티나 컬렉션를 함께 조회하려고 할 때 사용한다 결과는 EAGER와 똑같지만 과정은 다르다.EAGER의 경우에는 N+1 쿼리가 발생하지만 Fetch Join의 경우에는 한번이 쿼리문으로 해결이 가능하다.public interface RegistryRepository extends JpaRepository&lt;Registry, Long&gt; { @Query(\"select r from Registry r join fetch r.comments\") List&lt;Registry&gt; findAll();}Spring Data JPA 에서는 @Query 어노테이션을 이용하여 JPQL를 생성할 수 있다.사용하는 방법은 위와 동일하게 join fetch 뒤에 연관된 entity나 컬렉션을 적어주면 된다.fetch 키워드를 사용하게 되면 연관된 entity나 collection을 한 번에 같이 조회할 수 있다.→ fetch join을 사용하게 되면 연관된 entity는 프록시가 아닌 실제 entity를 조회하게 되므로연관관계 객체까지 한 번의 쿼리로 가져올 수 있다.하지만 collection을 fetch join하면 페이징 API를 사용할 수 없으며, 둘 이상 collection을 fetch 할 수 없다.2. EntityGraph@EntityGraph도 마찬가지로EntityGraph 상에 있는 Entity들의 연관관계 속에서 필요한 엔티티와 컬렉션을 함께 조회하려고 할 때 사용한다.fetch join을 편하게 사용하도록 도와주는 기능public interface RegistryRepository extends JpaRepository&lt;Registry, Long&gt; { @EntityGraph(attributePaths = \"comments\") List&lt;Registry&gt; findAll();}*중괄호는 넣어도 되고 안넣어도 되지만 여러 속성을 지정할 경우 넣어줘야한다. ex)attributePaths = {\"registry\", \"comment\"}Registry에서 comments로 설정했기 때문에 @EntityGraph(attributePaths = {\"comments\"})로 설정했다.@OneToMany(mappedBy = \"registry\", cascade = CascadeType.ALL, orphanRemoval = true)private List&lt;Comment&gt; comments = new ArrayList&lt;&gt;();Spring Data JPA에서 적용하려는 메소드 위에 @EntityGraph 어노테이션을 달고 옵션을 준다attributePaths는 같이 조회할 연관 엔티티명을 적으면 된다. ,(콤마)를 통하여 여러 개를 줄 수도 있다.type은 EntityGraphType.LOAD, EntityGraphType.FETCH 2가지가 있다. LOAD : attributePaths에 정의한 엔티티들은 EAGER, 나머지는 글로벌 패치 전략에 따라 패치한다. FETCH : attributePaths에 정의한 엔티티들은 EAGER, 나머지는 LAZY로 패치한다.@EntityGraph를 사용하여 특정 연관 관계를 Eager 로딩으로 설정하면,해당 연관 관계를 사용하는 쿼리 실행 시점에 모든 연관된 엔티티를 함께 조회하게 된다.이는 기본적으로 Eager 로딩과 동일한 효과를 가지지만, Eager 로딩과 다른 점도 있다.Eager 로딩은 엔티티 클래스 자체에 설정되는 것이고, @EntityGraph는 특정 쿼리 메서드에만 적용할 수 있는 기능이다.즉, 특정 쿼리 메서드에서만 Eager 로딩을 수행하고 나머지 경우에는 LAZY 로딩을 유지할 수 있다.comment로 적용해보기@EntityGraph 적용 전@EntityGraph 적용 후= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =join fetch와 @EntityGraph 사용join fetch와 @EntityGraph 사용 할 경우 출력되는 쿼리Join Fetch@Entity GraphJoin Fetch는 Inner Join, Entity Graph는 Outer Join이라는 차이점이 있다.공통적으로 카테시안 곱(Cartesian Product)이 발생하여 Comment의 수만큼 Registry가 중복 발생하게된다.해결방법1. 1:N 필드의 타입을 Set으로 선언하기@OneToMany(mappedBy = \"registry\", cascade = CascadeType.ALL, orphanRemoval = true)@JsonIgnore@ToString.Excludeprivate List&lt;Comment&gt; comments = new LinkedHashSet&lt;&gt;();Set이 순서가 보장되지 않기에 LinkedHashSet을 사용하여 순서를 보장한다.2. distinct를 사용해서 중복 제거하기join fetch@Query(\"select DISTINCT r from Registry r join fetch r.comments\")List&lt;Registry&gt; findAll();@EntityGraph@EntityGraph(attributePaths = \"comments\")@Query(\"select DISTINCT r from Registry r\")List&lt;Registry&gt; findAllEntityGraph();차이 확인해보기List&lt;Registry&gt; registry = registryRepository.findAll();System.out.println(\"registry size : \" + registry.size());실제 db에서 registry와 comment가 각각 6개, 17개의 데이터가 있다.DISTINCT를 적용 붙이기 전에는 registry size가 17로 출력되었는데DISTINCT를 적용하고 나서는 registry size가 6으로 출력되었다.db join 때문에 각 regisry와 연결된 comment가 join 되면서 중복된 값들까지 포함하여 17개의 결과가 나왔다.DISTINCT를 적용하면 중복을 제거하기 때문에 registry만을 조회하므로registry의 개수에 해당하는 6개의 결과가 나오게 된 것이다.→ comment는 조회 결과에 영향을 미치지 않게 된다.registry와 comment에 각각 1개씩 db를 추가하여 실행해봤을 때DISTINCT를 적용하기 전후 각각 registry의 size는 7, 18로 나왔다.또한 join fetch를 적용했을 때는 여전히 registry의 size가 6으로 나왔고entityGraph로 적용했을 때는 실제 db 개수에 맞는 7이 나왔다.이유는 정확히 모르겠으나 join fetch를 적용했을 때 중복된 registry 데이터가 하나 제거되어 6개가 나온게 아닐까?EntityGraph는 실제 db와 일치하는 7개의 결과가 나오니 EntityGraph를 적용하는게 맞을 것 같다. join fetch: INNER JOIN 방식으로 데이터를 가져오면서 중복된 결과가 있을 경우, distinct를 사용하여 중복을 제거한다. EntityGraph: 로딩 전략을 지정한 대로 연관 엔티티를 로딩한다. 예를 들어 @EntityGraph에서는 comments를 제외하고 registry만 로딩하므로 중복 문제가 발생하지 않는다. 3. Batch Size@BatchSize는 Hibernate에서 제공하는 기능으로,쿼리를 실행할 때 지정한 크기만큼 일괄 처리(Batch)하여 데이터를 가져오는 방법이다.spring.jpa.properties.hibernate.default_batch_fetch_size = 10 or@BatchSize 을 통해서 설정한 size 만큼 데이터를 미리 로딩 한다.@BatchSize(size = 10)@OneToMany(mappedBy = \"registry\", cascade = CascadeType.ALL, orphanRemoval = true)private List&lt;Comment&gt; comments = new ArrayList&lt;&gt;();연관된 엔티티를 10개씩 가져올 때마다 1번의 쿼리를 실행한다.즉, 연관된 엔티티를 10개씩 묶어서 가져오는 방식이다.즉 연관된 엔티티를 조회할때 size 만큼 where in 쿼리를 통해서 조회하게되고 size를 넘어가게 되면 추가로 where in 쿼리를 진행한다.4. @Fetch(FetchMode.SUBSELECT)연관된 엔티티들을 서브쿼리를 통해 한 번에 조회하는 방식이다.기본 엔티티와 연관된 모든 엔티티들을 하나의 쿼리로 조회하여 한 번에 가져오는 것이다.서브쿼리를 사용한 FETCH SUBSELECT는 기본적으로 엔티티만 가져온 후,연관된 엔티티들을 실제로 필요한 시점에 추가적인 쿼리를 통해 조회하는 방식이다.엔티티를 가져올 때 불필요한 데이터를 최소화하면서, 필요한 시점에 추가 쿼리를 통해 연관된 엔티티를 조회하는 방식으로 N+1 문제를 해결한다.반면, EAGER 로딩은 한 번의 쿼리로 모든 연관된 엔티티를 함께 가져오는 방식이다.따라서 한 번에 필요한 모든 데이터를 가져오므로, FETCH SUBSELECT와 달리 추가 쿼리 없이 모든 연관된 엔티티를 조회할 수 있다.@Fetch(FetchMode.SUBSELECT)@OneToMany(mappedBy = \"registry\", cascade = CascadeType.ALL, orphanRemoval = true)private List&lt;Comment&gt; comments = new ArrayList&lt;&gt;();서브쿼리를 통해 N + 1 문제를 해결하는 것을 확인할 수 있다.@BatchSize와 @Fetch(FetchMode.SUBSELECT)는 모두 N+1 문제를 해결하기 위한 방법이지만,@BatchSize는 여러 번의 쿼리를 실행할 수 있고,FETCH SUBSELECT는 한 번의 쿼리로 모든 연관된 엔티티를 가져온다는 점에서 차이가 있다.5. QueryBuilderQuery를 실행하도록 지원해주는 다양한 플러그인이 있다.대표적으로 Mybatis, QueryDSL, JOOQ, JDBC Template 등이 있다.이를 사용하면 로직에 최적화된 쿼리를 구현할 수 있다.// QueryDSL로 구현한 예제return from(user).leftJoin(user.comments, comment) .fetchJoin()결론처음엔 JPA의 N + 1 문제라는 것이 무엇인지 정확히 알지 못했다.이번 연관관계 매핑으로 인해 로그에서 N+1의 문제를 볼 수 있었고 자연스럽게 N+1 문제에 대해 공부할 수 있는 시간이 되었다. N+1 문제는 하나의 엔티티를 조회할 때 연관된 엔티티들을 추가로 조회하면서 발생하는 문제다. → 상위 엔티티를 조회한 후 연관된 하위 엔티티를 사용할 때마다 별도의 쿼리가 추가로 실행되어 성능 저하를 발생시킨다. N+1은 JPA를 사용하면서 연관관계를 맺는 엔티티를 사용한다면 한번 쯤은 부딪힐 수 있는 문제다. Fetch Join이나 EntityGraph를 사용한다면 Join문을 이용하여 하나의 쿼리로 해결할 수 있지만 중복 데이터 관리(카테시안곱)가 필요하고 FetchType을 어떻게 사용할지에 따라 달라질 수 있다. BatchSize는 연관관계의 데이터 사이즈를 정확하게 알 수 있다면 최적화할 수 있는 size를 구할 수 있겠지만 사실상 연관 관계 데이터의 최적화 데이터 사이즈를 알기는 쉽지 않다. @Fetch(FetchMode.SUBSELECT)는 상위 엔티티와 연관된 모든 하위 엔티티들을 하나의 서브 쿼리로 조회한다. JPA 만으로는 실제 비즈니스 로직을 모두 구현하기 부족할 수 있다. 간단한 구현은 JPA를 사용하여 프로젝트의 퍼포먼스를 향상 시킬수 있겠지만 다양한 비즈니스 로직을 복잡한 쿼리를 통해서 구현하다보면 다양한 난관에 부딪힐 수 있다. 그리고 불필요한 쿼리도 항상 조심해야 한다. 그러므로 QueryBuilder를 함께 사용하는 것을 추천한다. reference JPA N+1 문제 및 해결방안 [JPA] N+1 문제가 발생하는 여러 상황과 해결방법 JPA N+1 발생원인과 해결 방법 Spring JPA(ORM)의 N+1 쿼리 문제 해결 [JPA] N+1가 발생하는 이유와 어떻게 해결하는지에 대해서 학습하기 N+1 문제" }, { "title": "Proxy", "url": "/posts/Proxy/", "categories": "Network", "tags": "Network, study, project, Java, JPA", "date": "2022-12-24 00:00:00 +0900", "snippet": "프록시란?프록시(Proxy)란 ‘대리’라는 의미로, 네트워크 기술에서는 프로토콜에 있어서 대리 응답 등에서 친숙한 개념이다.보안 분야에서는 주로 보안상의 이유로 직접 통신할 수 없는 두 점 사이에서 통신을 할 경우그 상이에 있어서 중계기로서 대리로 통신을 수행하는 기능을 가리켜 ‘프록시’,그 중계 기능을 하는 것을 프록시 서버라고 부른다.프록시 서버서버와 클라이언트 사이에서 클라이언트가 자신을 통해다른 네트워크 서비스에 간접적으로 접속할 수 있게 해주는 컴퓨터 시스템이나 응용 프로그램을 말한다.프록시 서버에서의 캐싱캐시 안에 정보를 담아두고, 캐시 안에 있는 정보를 요구하는 요청에 대해 다시 저 멀리 있는 원격 서버에 요청하지 않고캐시 안에 있는 데이터를 활용하는 것을 말한다.이를 통해 캐시 안에 있는 정보를 요구하는 요청에 대해서는 원격 서버에 접속하여 데이터를 가져올 필요가 없게 됨으로써전송 시간을 절약을 할 수 있다.또, 불필요하게 외부와 연결하지 않기 때문에 트래픽을 줄일 수 있다(→ 네트워크 병목 현상 방지 효과)는 장점이 있다.프록시 서버란 서버 앞단에 둬서 캐싱, 로깅, 데이터 분석을 서버보다 먼저 하는 서버를 말한다.이를 통해 포트 번호를 바꿧 사용자가 실제 서버의 포트에 접근하지 못하게 할 수 있으며공격자의 DDOS 공격을 차단하거나 CDN을 프록시 서버로 달아서 캐싱 처리를 용이하게 할 수 있다.프록시 서버 종류서버의 위치에 따라 분류하면 크게 두 가지로 나눌 수 있다.Forward 프록시프록시 서버를 ‘클라이언트 호스트들과 접근하고자 하는 원격 리소스의 사이’에 위치시킨다. (인터넷보다 프록시 서버를 먼저 호출)일반적으로 프록시라고 하면 Forward Proxy 라고 한다.클라이언트가 서버에게 요청할때 직접 서버에 접근하지 않고 Forward 프록시 서버에게 요청하면Forward 프록시 서버가 해당 서버에게 접근하여 요청을 전달하고 결과를 클라이언트에게 전달해주는 방식이다.Forward 프록시는 캐시 기능을 사용하기 때문에 캐시 서버로 활용하여 성능을 향상시킬 수 있다.자주 사용되는 자원을 캐시에 저장해놓기 때문에 해당 자원 요청이 온다면 서버에게 갈 필요 없이 프록시 서버 자체에서 처리가 가능하다.클라이언트가 서버를 직접 접근하지 못하기 때문에 접근 가능한 사이트를 제한할 수 있으므로 보안을 향상시킬 수 있다.즉, 클라이언트는 서버를 알지만, 서버는 프록시를 통해 요청이 오기 때문에 클라이언트를 알지 못한다.서버가 응답받은 IP는 Forward 프록시 서버의 IP이기 때문에 클라이언트가 누군지 알 수 없다.Reverse 프록시클라이언트가 서버를 호출할 때 Reverse 프록시를 호출하게 되고 프록시 서버가 서버를 요청하여 받은 응답을 클라이언트에게 전달하는 방식이다.내부 인트라넷에 있는 서버를 호출하기 위해서 인터넷 망에 있는 클라이언트가 Reverse 프록시 서버에 요청하여 응답을 받는 방식이다.Reverse 프록시는 서버가 누구인지 감추는 역할을 해준다.마찬가지로 클라이언트는 내부 서버를 접근하지 못하기 때문에 보안과 성능을 향상시킬 수 있다.Forward 프록시 서버와는 반대로 내부 서버는 클라이언트를 알지만, 클라이언트는 프록시를 통해 내부 서버를 접근하기 때문에 내부 서버를 알지 못한다.예를 들어 보안을 위해 Reverse 프록시 서버는 HTTPS 프로토콜로 접근 가능하도록 하여 보안을 강화한다.하지만 내부 서버는 자신에게 오는 요청은 Reverse 프록시 서버의 HTTPS 프로토콜로 한번 걸러지기 때문에 HTTP 프로토콜로 처리하면 된다.또한, 여러개의 내부 서버를 둘 수 있기 때문에 로드 밸런싱이나 서버 확장을 통해 트래픽을 분산시킬 수 있다.프록시 서버 장점1. 보안프록시 서버를 사용하면 클라이언트나 서버 모두 IP를 숨길 수 있는 방법이 생긴다.실제 서버 또는 클라이언트의 IP를 숨기고 프록시 서버의 IP만 공개함으로써 해킹을 대비할 수 있다.2. 성능프록시 서버를 사용하여 캐싱 기능과 트래픽 분산으로 성능 향상을 가져올 수 있다.캐싱 기능은 자주 사용되는 동일한 요청을 캐싱하여 재활용하는 방식이다.실제 서버로 다시 호출하지 않고 프록시 서버가 대신 응답을 주어 서버의 자원 사용을 줄여주게 된다.3. 트래픽 분산일부 프록시 서버는 로드 밸런싱도 제공하여 여러 대의 분산된 서버가 있다면 서버의 트랙픽을 분산시켜 준다.그리고 앤드 포인트(URL)마다 호출하는 서버를 설정할 수 있어 역할에 따라 서버의 트래픽을 분산할 수도 있다.프록시 객체어떠한 대상의 기본적인 동작의 작업을 가로챌 수 있는 객체를 뜻한다.JPA 에서의 프록시실제 Entity 객체 대신에 사용되는 객체로서 실제 Entity 클래스와 상속 관계 및 위임 관계에 있다.프록시 객체는 실제 Entity 클래스를 상속 받아서 만들어지므로 실제 Entity 겉모습이 같다.지연 로딩을 사용하면 실제 Entity 객체 대신 가짜 객체가 필요한데 이것이 프록시 객체이다.프록시 객체는 실제 객체에 대한 참조(target)를 보관한다.프록시 객체의 메소드를 호출하면 프록시 객체는 실제 객체의 메소드를 호출한다. (이때 실제 db에서 조회한다.)entityManager.getReference(): 데이터베이스 조회를 미루는 가짜(프록시) Entity 객체 조회프록시 객체의 초기화초기에 target은 null이고, 영속성 컨텍스트에 초기화를 요청한다.이후 영속성 컨텍스트는 DB를 조회해서 실제 Entity 객체를 생성하여 target에 연결시켜준다.target으로 실제 객체와 연결되면, 실제 객체의 메서드를 호출한다.특징프록시 객체는 처음 사용할때 한번만 초기화한다.프록시 객체를 초기화할 때, 프록시 객체가 실제 Entity로 바뀌는것이 아니다.초기화되면 프록시 객체를 통해서 실제 Entity에 접근이 가능한 것이다.프록시 객체는 원본 Entity를 상속받기 때문에, 타입체크시 주의해야한다. ( == 대신 instance of 사용)프록시 객체와 원본 객체는 == 비교시에 타입이 각각 프록시타입과 실제 타입으로 다르다.실제 Entity 조회 후 프록시 객체를 조회하는 경우→ 영속성 컨텍스트에 찾는 Entity가 이미 있으면 entityManager.getReference()를 호출해도 실제 Entity가 반환된다.이미 영속성 컨텍스트에 올라가있기 때문에 굳이 프록시를 가져올 이유가없다.성능 최적화 입장에서도 영속성 컨텍스트에 올라간 실제 Entity를 가져오면 된다.프록시 객체를 조회 후 실제 Entity를 조회하는 경우반대의 상황도 같다 (프록시가 먼저 초기화됐으면, entityManager.find()를 호출해도 프록시 객체가 반환된다)영속성 컨텍스트의 도움을 받을 수 없는 준영속 상태일 때, 프록시를 초기화하면 문제 발생아래 코드와 같이 em.detach()나 em.close(), em.clear()로 영속성 컨텍스트에서 detach시키거나 닫아서준영속 상태에서 getUsername을 호출하면 LazyInitializationException 예외가 발생한다.Eager &amp; LazyEntity를 조회하고 항상 연관된 Entity가 사용되는 것이 아니다.JPA는 Entity가 실제로 사용되기 전까지 데이터베이스 조회를 지연할 수 있도록 제공하는데 이를 지연 로딩이라 한다.실제 사용하는 시점에 데이터베이스에서 필요한 데이터를 가져오는 것이다.Fetch 기본 전략 @ManyToOne, @OneToOne : 즉시 로딩 (EAGER LODING) @OneToMany, @ManyToMany : 지연 로딩 (LAZY LOADING)즉시 로딩(EAGER LODING)Entity를 조회할 때 자신과 연관되는 Entity를 join을 통해 함께 조회하는 방식을 말한다.Entity를 조회할 때 연관된 Entity를 함께 조회한다.즉시 로딩을 사용하고 싶다면 연관 관계 매핑의 fetch 속성을 FetchType.EAGER로 지정하면 된다.즉시 로딩하여 가져오기 때문에 프록시를 쓸 일이 없다. 이미 초기화가 다 끝나있는 상태이다.Comment Entity를 조회하는 find() method를 호출할 때 join이 일어나며 그 때 Registry도 조회하는 것을 볼 수 있다.즉시 로딩에서 Hibernate는 SELECT 쿼리를 2번 실행하는 것보다 성능 최적화를 위해 join을 수행한다.🐣 application.properties에 아래 코드를 추가하면 위와 같은 형식으로 볼 수 있다.# SQL outputspring.jpa.properties.hibernate.format_sql=true# show sql consolespring.jpa.show-sql=trueEAGER LODING에서 outer join을 사용한 이유는 외래키가 null이 허용되기 때문이다.@JoinColumn 어노테이션에서 nullable 속성을 추가할 수 있는데, 기본 값으로 true를 갖는다.따라서 @JoinColumn(name=\"registry_id\", nullable=false) 로 수정하면 즉시 로딩 할 때 outer join이 아닌 inner join을 수행한다.outer join보다 inner join이 성능이 더 좋다는 것을 감안하여 외래키의 null 허용 여부를 결정해야한다.즉시 로딩 주의점 @ManyToOne, @OneToOne optional = false : 내부 조인 optional = true : 외부 조인 @OneToMany, @ManyToMany optional = false : 외부 조인 optional = true : 외부 조인 지연 로딩(LAZY LOADING)지연 로딩이란 자신과 연관된 Entity를 실제로 사용할 때 연관된 Entity를 조회( SELECCT )하는 것을 말한다.연관된 Entity를 실제로 사용할 때 조회한다.연관 관계 매핑의 fetch 속성을 FetchType.LAZY로 지정하면 사용할 수 있다.@ManyToOne(fetch = FetchType.LAZY)지연로딩을 하기 위해서는 프록시라는 것이 필요하다.실제 데이터가 필요한 순간에서야 데이터베이스를 조회해 프록시 객체를 초기화한다. Entity를 사용하는 시점에 초기화가 된다.(DB조회)만약 영속성 컨텍스트에 객체가 이미 존재한다면 프록시 객체가 아닌 실제 객체를 사용한다.오류지연 로딩으로 설정하면 에러가 나타나는 경우가 있다.No serializer found for class org.hibernate.proxy.pojo.bytebuddy.ByteBuddyInterceptor and no properties discovered to create BeanSerializer필요가 없으면 조회를 안해서 비어있는 객체를 serializer 하려고 해서 발생되는 문제이다.여기서부터는 내가 이해한 방향이다.@RestController의 경우 @ResponseBody로 객체를 반환해 줄 때 JSON 형태로 변환한다.따라서 JSON 형태로 리턴해 주는 시점에서 에러가 발생한 것이다.Comment를 JSON으로 변환하는 과정에서 Registry를 serialize(직렬화) 해주려는 순간fetchType이 Lazy라서 실제 Registry 객체가 아닌프록시로 감싸져 있는 hibernateLazynitializer를 serialize하려 하기 때문에 문제가 발생한 것이다.→ default 값인 EAGER였다면 실제 매핑되어있는 Registry에 대한 조회가 이루어지고 실제 Registry 객체를 serialize 한다는 말이다.오류 해결하기이를 해결하는 방법은 대표적으로 3가지가 있다. application 파일에 spring.jackson.serialization.fail-on-empty-beans=false 설정해주기 오류가 나는 Entity의 LAZY 설정을 EAGER로 바꿔주기 오류가 나는 컬럼에 @JsonIgnore를 설정해주기 1.application 파일에 spring.jackson.serialization.fail-on-empty-beans=false 설정하는 경우에는 오류만 안나오도록 하는 것이다.근본적인 해결방법이 아닌 표면적인 방법이므로 근본적인 해결을 위해서는 JSON 형식으로 변환할지 말지에 대해 정해야한다.registry에 hibernateLazyInitializer 데이터가 추가된 걸 확인할 수 있다.2.LAZY 설정을 EAGER로 바꿔주는 경우에는 오류가 N+1문제가 발생할 수 있다.단순히 Comment 정보만 조회하더라도 Registry db까지 모두 조회하게 된다.3.오류가 나는 컬럼에 @JsonIgnore를 설정해주는 경우 해당 필드를 json으로 변경시 제외된다.registry에 관한 db가 제외되었다.참고로 각 Entity에 @JsonIgnoreProperties({\"hibernateLazyInitializer\", \"handler\"}) 를 설정해주는 방법도 있다.@JsonIgnore과 @JsonIgnoreProperties의 차이 @JsonIgnore 어노테이션은 클래스의 속성(필드, 멤버변수) 수준에서 사용 @JsonIgnoreProperties 어노테이션은 클래스 수준(클래스 선언 바로 위에)에 사용reference 프록시란? [JPA] 프록시, 즉시 로딩과 지연로딩 🙈[Spring JPA] 프록시( proxy )와 지연로딩🐵 [JPA] 프록시란? 지연로딩 vs 즉시 로딩란? Forward Proxy와 Reverse Proxy 차이점 포워드 프록시(Forward Proxy) vs 리버스 프록시(Reverse Proxy)[JPA] FetchType.Lazy로 인한 JSON 오류 [JPA]No serializer found for class org.hibernate.proxy.pojo.bytebuddy.ByteBuddyInterceptor and no properties discovered to create BeanSerializer [JPA]No serializer found for class org.hibernate.proxy.pojo.bytebuddy.ByteBuddyInterceptor and no properties discovered to create BeanSerializer @JsonIgnore, @JsonIgnoreProperties, @JsonIgnoreType차이점 [JPA] 프록시 Proxy &amp; LAZY,EAGER 로딩, 영속성 전이 CASCADE" }, { "title": "Postman login", "url": "/posts/Postman-Login/", "categories": "Project", "tags": "API, study, project, test", "date": "2022-12-18 00:00:00 +0900", "snippet": "PostmanFetchType.Lazy로 인한 오류를 해결하면서 응답받는 값을 체크하기 위해 Postman을 사용했다.그런데 하나 문제가 있었고 이를 기록했다.로그인 문제체크해야할 부분은 Comment이기 때문에 “/Comment” GET Method를 테스트를 진행했다.js에서 registryId(게시글 id)값을 주면 registryId에 해당하는 댓글들을 보여준다.그런데 postman에 http://localhost:8080/comment?idx=1을 send하면 html만 떴다.바로 “로그인” 문제였다.해당 페이지는 로그인을 해야 해당 페이지로 들어갈 수 있다.이 문제는 stackoverflow에 있는 글을 보고 해결할 수 있었다.쿠키 설정하기localhost에 쿠키 JSESSIONID 가 기본으로 세팅되어 있어서 value 값만 변경해줬다.cookie에 저장된 JSESSIONID의 value를 복사해서 아래에 붙여넣기 했다.쿠키 추가하기페이지 내에서 nickname을 확인하기 위해 Session Storage에 넣어 진행했기 때문에 Session Storage에 저장한 nickname도 추가했다.추가는 addCookie 눌러준후에 저장하는 방식 그대로 nickname=haedal blog;로 설정했다.해당 부분을 실행할 때는 로직을 수정할 때마다 프로그램 실행해서브라우저 켜고 로그인 후에 Cookies에서 JSESSIONID의 value를 복사해서 Postman에 설정된 JSESSIONID의 value를 수정했다.그런데 그냥 Postman에 로그인 API를 실행한 후 위 처럼 로그인을 해야 실행되는 페이지를 테스트 하면 된다." }, { "title": "Query did not return a unique result", "url": "/posts/query-did-not-return-a-unique-result/", "categories": "Error", "tags": "error", "date": "2022-12-17 00:00:00 +0900", "snippet": "query did not return a unique result:해당 오류는 Repository에서 Return 값을 Class로 받아 담을 수가 없어서 에러가 발생한 것이다.Repository의 Return 타입을 Class에서 List&lt;Class&gt; 로 받아주면 해결된다.// Commnet findAllByRegistry_Idx(Long idx);List&lt;Comment&gt; findAllByRegistry_Idx(Long idx);reference JPA query did not return a unique result 에러 해결방법" }, { "title": "연관관계 적용4 정리(코드 + mysql)", "url": "/posts/%EC%97%B0%EA%B4%80%EA%B4%80%EA%B3%84-%EC%A0%81%EC%9A%A94-%EC%A0%95%EB%A6%AC(%EC%BD%94%EB%93%9C-+-MySQL)/", "categories": "Project, JPA", "tags": "JPA, study, project", "date": "2022-12-15 00:00:00 +0900", "snippet": "연관관계 매핑 정리(코드 + MySQL)이 전에 연관관계 이론에 대해서 정리하고연관관계를 코드에 적용한 후 refactoring을 진행했다.그리고 그 과정에서 궁금했던 점도 해결했다.이번엔 마지막으로 한번 더 정리하는 겸으로 글을 작성했고 db에서 fk를 설정하는 방법에 대해 정리했다.관련 글 연관관계 연관관계 적용 연관관계 적용2(refactoring) 연관관계 적용3(궁금증 해결하기)Registry와 User 연관관계 매핑*코드 일부 생략1. User와 Registry는 1:N 관계다.User@Getter@NoArgsConstructor(access = AccessLevel.PROTECTED) @Entity // DB 테이블 역할을 한다.public class User extends Timestamped { // ID가 자동으로 생성 및 증가 @GeneratedValue(strategy = GenerationType.IDENTITY) @Id @Column(name = \"user_id\") private Long id; @Column(nullable = false) private String username; @Column(nullable = false) private String nickname; @Column(nullable = false) private String password; @Column(nullable = true) private String passwordConfirm; @Column(nullable = false) private String email; @OneToMany(mappedBy = \"user\") @JsonIgnore private List&lt;Registry&gt; registries = new ArrayList&lt;&gt;(); public void addRegistry(Registry registry){ this.registries.add(registry); if(registry.getUser() != this){ // Registry에서 설정한 User 변수명 : user registry.addUser(this); // Registry에서 설정한 메소드명 } } @Builder public User(String username, String nickname, String password, String email){ this.username = username; this.nickname = nickname; this.password = password; this.email = email; }}Registry@NoArgsConstructor(access = AccessLevel.PROTECTED)@Getter@Entity@ToStringpublic class Registry extends Timestamped { @GeneratedValue(strategy = GenerationType.IDENTITY) @Id @Column(name = \"registry_id\") private Long idx;// @Column(nullable = false)// private String nickname; @Column(nullable = false) private String title; @Column(nullable = false) private String main; @ManyToOne(fetch = FetchType.LAZY) @JsonIgnore @JoinColumn(name = \"user_id\", nullable = false) private User user; @Builder public Registry(String title, String main, User user) { //this.nickname = nickname; this.title = title; this.main = main; this.user = user; } public void addUser(User user) { // 기존에 연결된게 있을 경우 초기화 if(this.user != null) { this.user.getRegistries().remove(this); // User에서 설정한 Registry 변수명 : registries } this.user = user; // 무한 루프 안걸리게 하기 if (!user.getRegistries().contains(this)) { user.addRegistry(this); // User에서 설정한 메소드명 } }}2. RegistryServiceImpl - user 정보 담기게시글 작성은 로그인한 자신이기 때문에 front에서 받기 보다 로그인한 user 정보를 받아오기로 했다.public Registry setUpload(RegistryDto registryDto) throws IOException { return registryRepository.save(registryDto.toEntity());}🔽public Registry postUpload(RegistryDto registryDto, UserDetailsImpl userDetails) throws IOException { Registry registry = registryDto.toEntity(userDetails.getUser()); return registryRepository.save(registry);}3. db에 fk 반영하기ddl-auto 사용test용 db 라면 spring.jpa.hibernate.ddl-auto: update로 입력해서 반영할 수 있다.ddl-auto란?JPA에서는 기본적으로 Entity에 테이블을 매핑하면 쿼리를 사용하지 않고 값을 가져올 수 있다. create : SessionFactory 시작시 스키마를 삭제하고 다시 생성 create-drop : SessionFactory 종료 시 스키마를 삭제 update : SessionFactory 연결된 DB와 비교하여 추가된 항목은 추가하고 만약 같은 변수명이면 오류발생 validate : SessionFactory 시작시 객체구성과 스키마가 다르다면 예외 발생 none: 아무것도 안함*실제 서비스 배포시에는 create, create-drop, update 와 같은 옵션을 사용하면 안되지만 개발 초기 테스트시에는 유용하게 사용할 수 있다.ddl-auto의 경우 초기 DB 설정 및 간단한 테스트에서만 쓰는게 좋다. JPA ddl-auto 설정과 더미데이터 생성 방법쿼리문으로 fk 설정하기예시로 Registry대신 Comment에 user_id를 fk로 추가해봤다.comment table에 user table의 pk인 user_id를 fk로 추가하는 쿼리문alter table commentaddforeign key (user_id)references user (user_id);fk로 변경된 것을 확인할 수 있다." }, { "title": "Findbyid vs getreferencebyid", "url": "/posts/findById-vs-getReferenceById/", "categories": "Project", "tags": "JPA, study, project, spring, Exception", "date": "2022-12-12 00:00:00 +0900", "snippet": "findById() vs getReferenceById()findById()는 EAGER방식의 조회기법이라면 getReferenceById(ID)는 LAZY방식으로 조회된다.getReferenceById(ID) 는 실제 테이블을 조회하는 대신 프록시 객체만 가져온다.프록시 객체만 있는 경우 ID 값을 제외한 나머지 값을 사용하기 전까지는 실제 DB 에 액세스 하지 않기 때문에 SELECT 쿼리가 날아가지 않는다.findById()를 사용하면 DB 에 바로 액세스해서 데이터를 가져온다.실제 DB 에 접근하냐 하지 않냐는 성능에 영향이 갈 수 있다.단순히 특정 엔티티의 ID 값만 필요한 경우에는 모든 데이터를 가져올 필요가 없다.연관 관계를 갖는 엔티티를 저장할 때, 연관된 엔티티 조회시 getReferenceById(ID)를 사용하는 것이 성능 개선에 도움이 된다.*상황에 따라 적절한 메소드를 사용하면 된다.testComment와 Registry로 test를 해봤다. (N:1)Comment → Registry 가 LAZY 관계이면Comment 테이블을 조회하는 시점에 registryId가 이미 FK로 Comment 테이블의 값에 포함되어 있다.JPA는 이 값으로 Registry의 프록시 객체를 만들기 때문에 프록시 객체는 내부에 이미 registryId를 가지고 있다.따라서 이 경우 registryId를 조회할 때는 프록시를 초기화 하지 않는다.findById()System.out.println(\" = = = = = = = = = = == = = = = = = = = = = \");System.out.println(\"findById\");System.out.println(registryRepository.findById(commentDto.getRegistryIdx()));System.out.println();findById()를 사용하니 select 쿼리가 떴다.getReferenceById()System.out.println(\" = = = = = = = = = = == = = = = = = = = = = \");System.out.println();System.out.println(\"getReferenceById\");System.out.println(registryRepository.getReferenceById(commentDto.getRegistryIdx()));System.out.println();System.out.println(\" == = = = = = = = == = = = = = 끝 = = = = = = = == = = = = \");getReferenceById()를 사용하니 실제로 SELECT 쿼리가 날아가지 않는다.전체 코드public Comment setComment(CommentDto commentDto) { System.out.println(\"쀼뷰뷰뷰ㅠ븁\"); Registry registry = registryRepository.getReferenceById(commentDto.getRegistryIdx()); System.out.println(); System.out.println(\" = = = = = = = = = = == = = = = = = = = = = \"); System.out.println(\"findById\"); System.out.println(registryRepository.findById(commentDto.getRegistryIdx())); System.out.println(); System.out.println(\" = = = = = = = = = = == = = = = = = = = = = \"); System.out.println(); System.out.println(\"getReferenceById\"); System.out.println(registryRepository.getReferenceById(commentDto.getRegistryIdx())); System.out.println(); System.out.println(\" == = = = = = = = == = = = = = 끝 = = = = = = = == = = = = \"); Comment comment = commentDto.toEntity(registry); Comment save = commentRepository.save(comment); return save;}예외 처리Negative Test를 작성하면서 getReferenceById()에 관한 예외 처리를 생각하게 되었다.CommentService.java@Overridepublic Comment postComment(CommentRequestDto commentDto) { Registry registry = registryRepository.getReferenceById(commentDto.getRegistryIdx()); User user = userRepository.findByNickname(commentDto.getNickname()).orElseThrow(UserNotFoundException::new); Comment comment = commentDto.toEntity(registry, user); Comment save = commentRepository.save(comment); return save;}본 코드에서 findByNickname만 사용하는게 아니라 그 위 코드 getReferenceById로도 값을 찾는다.userRepository.findByNickname()에 exception 처리가 되어있지만registryRepository.getReferenceById()에는 exception 처리가 되어있지 않다.그래서 문득 예외상황에 대한 test 코드를 작성하면서 registry의 idx값도 존재하지 않을 수도 있을텐데? 싶었다.getReferenceById??@Overridepublic Comment postComment(CommentRequestDto commentDto) { System.out.println(\" = = = = = = = = = = = postComment 시작 = = = = = = = = = = = \"); Registry registry = registryRepository.getReferenceById(commentDto.getRegistryIdx()); System.out.println(\"registry.getIdx() : \" + registry.getIdx()); System.out.println(\" = = = = = = registry = = = = = = = = \"); System.out.println(\"registry : \" + registry); System.out.println(\" = = = = = = registryRepository.existsById = = = = = = = = = \"); registryRepository.existsById(commentDto.getRegistryIdx()); System.out.println(\" = = = = = = = = = = = = = = = = = = = = = = \");}getReferenceById()를 사용하면 실제 테이블을 조회하는 대신 프록시 객체만 가져온다.프록시 객체만 있는 경우 ID 값을 제외한 나머지 값을 사용하기 전까지는 실제 DB 에 액세스 하지 않기 때문에 SELECT 쿼리가 날아가지 않는다.그렇기 때문에 registry.getIdx()에서는 쿼리문이 로그에 찍히지 않지만registry 자체로 출력할 때는 로그에 select문이 찍히는 것을 볼 수 있다. (*existsById는 참고로 출력해봤다.)그러므로 id 값만 사용할 것이라면 findById()보다는 getReferenceById(ID)를 쓰는게 쿼리가 덜 날라가기 때문에 좋을 것이다.그런데 문제가 있다.id값이 있는지 없는지를 따지는게 아니라 그냥 그 값을 가져온다.public Comment postComment(CommentRequestDto commentDto) { System.out.println(\" = = = = = = = = = = = postComment 시작 = = = = = = = = = = = \"); Registry registry = registryRepository.getReferenceById(commentDto.getRegistryIdx()); System.out.println(\"registry.getIdx() : \" + registry.getIdx()); if(registry.getIdx() == null) { System.out.println(\"hello\"); } User user = userRepository.findByNickname(commentDto.getNickname()).orElseThrow(UserNotFoundException::new); Comment comment = commentDto.toEntity(registry, user); Comment save = commentRepository.save(comment); return save;}registry의 없는 idx값을 test하였으나 registry.getIdx() : 40로 출력이 되고 아래와 같이 에러가 떴다.returnfindById()매개변수로 전달된 ID에 해당하는 entity를 반환하거나, 해당하는 entity가 없을 경우 Optional.empty()를 반환한다.즉, 탐색 결과가 없더라도 내부에서 예외를 발생시키지 않는다.Throws를 살펴보면, ID가 null일 경우엔 IllegalArgumentException이 발생할 수 있다.getReferenceById()Optional&lt;T&gt; 가 아닌 T가 반환값이다.즉, 매개변수로 전달된 ID에 해당하는 entity를 반환하되, 없을 경우 내부에서 예외를 발생시킨다.특정 대상이 존재하지 않을 때의 커스텀 예외를 XXNotFoundException이라고 할 수 있다.예외 처리 코드 작성*Custom Exception 정리 글@RestControllerAdvicepublic class CustomExceptionHandler { @ExceptionHandler(SQLException.class) public ResponseEntity&lt;ErrorResponseEntity&gt; handleSQLException(){ return ErrorResponseEntity.toResponseEntity(ErrorCode.DATABASE_ERROR); }}@ExceptionHandler를 이용해 Controller에 예외 처리 메소드를 추가했다.@ExceptionHandler 에 설정한 예외가 발생하면 handler가 실행된다. → SQLException 예외를 처리하기 위해 작성🐣 @Controller, @RestController가 아닌 @Service 나 @Repository 가 적용된 Bean에서는 사용할 수 없다.@ControllerAdvice는 @Controller 어노테이션이 있는 모든 곳에서의 예외를 잡을 수 있도록 해준다.@ControllerAdvice 안에 있는 @ExceptionHandler는 모든 컨트롤러에서 발생하는 예외상황을 잡을 수 있다.🐣 @ControllerAdvice + @ResponseBody → @RestControllerAdvice : @ControllerAdvice + 객체를 반환할 수 있다.위와 같이 작성하면 없는 id값을 가지고 조회할 때 위처럼 에러가 뜨는 것이 아니라 예외처리가 되어 아래와 같이 출력된다.LAZY 오류LAZY를 사용하다보면 아래와 같은 오류를 볼 수 있다.No serializer found for class org.hibernate.proxy.pojo.bytebuddy.ByteBuddyInterceptor and no properties discovered to create BeanSerializerLAZY 옵션은 필요할때 조회를 해오는 옵션인데위 에러는 필요가 없으면 조회를 안해서 비어있는 객체를 serializer 하려고 해서 발생되는 문제이다.대표적으로 3가지 해결방법이 있지만 3번을 추천한다. 나머지는 근본적인 해결방법이 아니다. (*자세한 내용은 Proxy에서 다룰 예정이다.) application 파일에 spring.jackson.serialization.fail-on-empty-beans=false 설정해주기 오류가 나는 엔티티의 LAZY 설정을 EAGER로 바꿔주기 오류가 나는 컬럼에 @JsonIgnore를 설정해주기 getReferenceById version버전에 따라서 getReferenceById()로 나타나지 않을 수 있다.spring boot version 2.5 미만의 경우 getOne()을 사용하고spring boot version 2.7 미만의 경우 getOne(ID) is deprecated 되고 getById(ID)로 대체 되었다.그리고 spring boot version 2.7 이상 부터는 getById() 대신 getReferenceById(ID)로 대체 되었다.spring boot version 2.7 미만spring boot version 2.7 이상reference find vs get (네이밍 컨벤션과 JPA에서의 내부 동작 차이) ExceptionHandler 와 ControllerAdvice" }, { "title": "Dto⇄entity", "url": "/posts/dto-entity/", "categories": "Project", "tags": "spring, study, project", "date": "2022-12-11 00:00:00 +0900", "snippet": "public Registry(RegistryDto registryDto) { this.title = registryDto.getTitle(); this.main = registryDto.getMain(); this.nickname = registryDto.getNickname();}위 코드를 뭐라고 부를까? RegisttyDto에 대한 생성자라고 부를 수 있다.그런데 이 부분에 대한 코드들을 다른 블로그에서 찾기 어려웠다.그 이유는 바로 해당 코드를 쓰지 않는다는 것이다.toEntity()엔티티에 registryDto에 대한 생성자를 쓰면 안된다.하위 레이어를 의존하는 것을 기본으로 하기 때문이다.그리고 해당 블로그들이 공통적으로 쓰는 것은 toEntity()였다.Controller &gt; Service &gt; RepositoryEntity는 최하위이기 때문에 최하위에서 dto를 사용하기 보다는dto에서 Entity를 사용하는 것이 낫다라고 판단하는 것이다.dto에서 entity로 변경할 때 toEntity()를 사용한다.→ post, update에서 주로 쓴다.🐣 entity를 보여주기보다 보안적으로 dto로 해서 보여주는게 낫다.프로젝트에 적용하기Registry(게시글)DTO (코드 추가)public class RegistryDto { private String nickname; private String title; private String main; // dto → entity public Registry toEntity(){ return Registry.builder() .nickname(nickname) .title(title) .main(main) .build(); }}Entity (코드 제거)public class Registry extends Timestamped { // 코드 생략 @OneToMany(mappedBy = \"registry\") @JsonIgnore private List&lt;Comment&gt; comments = new ArrayList&lt;&gt;(); // 코드 제거// public Registry(RegistryDto registryDto) {// this.title = registryDto.getTitle();// this.main = registryDto.getMain();// this.nickname = registryDto.getNickname();// }}ServiceImplpublic Registry setUpload(RegistryDto registryDto) throws IOException { Registry registry = new Registry(registryDto); registryRepository.save(registry); return registry;}🔽 아래 코드로 변경public Registry setUpload(RegistryDto registryDto) throws IOException { return registryRepository.save(registryDto.toEntity());}Comment(댓글)DTO (코드 추가)public class CommentDto { private String nickname; private String comment; private Long registryIdx; // dto → entity public Comment toEntity() { return Comment.builder() .nickname(nickname) .comment(comment) .build(); }}Entity (코드 제거)public class Comment extends Timestamped { // 코드 생략 @ManyToOne @JoinColumn(name = \"registry_id\", nullable = false) private Registry registry; // 코드 제거// public Comment(CommentDto commentDto) {// this.nickname = commentDto.getNickname();// this.comment = commentDto.getComment();// Long registryIdx = commentDto.getRegistryIdx();// }}ServiceImpl public Comment setComment(CommentDto commentDto) { Registry registryId = registryRepository.getById(commentDto.getRegistryIdx()); Comment comment = Comment.builder() .comment(commentDto.getComment()) .nickname(commentDto.getNickname()) .registry(registryId) .build(); // 연관관계 매핑 Registry registry = registryRepository.findById(comment.getRegistry().getIdx()).get(); comment.setRegistry(registry); commentRepository.save(comment); return comment; }🔽 아래 코드로 변경 public Comment setComment(CommentDto commentDto) { Registry registry = registryRepository.getById(commentDto.getRegistryIdx()); Comment comment = commentDto.toEntity(); comment.setRegistry(registry); Comment save = commentRepository.save(comment); return save; }refactoring위에서 수정한 코드에서 refactoring을 진행했다. 👉🏻 객체 넣기DTOpublic class CommentDto { private String nickname; private String comment; private Long registryIdx; // dto → entity public Comment toEntity() { return Comment.builder() .nickname(nickname) .comment(comment) .build(); }}🔽 refactoringpublic Comment toEntity(Registry registry) { return Comment.builder() .nickname(nickname) .comment(comment) .registry(registry) .build();}ServiceImpl public Comment setComment(CommentDto commentDto) { Registry registry = registryRepository.getById(commentDto.getRegistryIdx()); Comment comment = commentDto.toEntity(); comment.setRegistry(registry); Comment save = commentRepository.save(comment); return save; }🔽 refactoringpublic Comment setComment(CommentDto commentDto) { Registry registry = registryRepository.findById(commentDto.getRegistryIdx()).orElseThrow(); Comment comment = commentDto.toEntity(registry); Comment save = commentRepository.save(comment); return save;}of이번엔 toEntity의 반대인 entity → dto를 작성해봤다.아까는 dto에서 entity로 변경할 때 toEntity()를 사용했다면 이번에는 entity에서 dto로 변경하기 위해 of를 활용했다.🐣 주로 responseDto에서 활용을 하는 것 같다.of 작성하기@Getter@AllArgsConstructor@NoArgsConstructor@Builderpublic class ResRegistryDto { private Long idx; private String title; private String main; private LocalDateTime createdAt; private LocalDateTime modifiedAt; private String nickname; // entity → dto public static ResRegistryDto of(Registry registry){ return ResRegistryDto.builder() .idx(registry.getIdx()) .title(registry.getTitle()) .main(registry.getMain()) .createdAt(registry.getCreatedAt()) .modifiedAt(registry.getModifiedAt()) .nickname(registry.getUser().getNickname()) .build(); }}이렇게 of를 작성한 이유는 entity를 보호하기 위해서이다.entity로 쓰면 db 내용을 전부 들여다 볼수 있기 때문에 객체 자체 대신 풀어써서 사용했다.of 활용하기public ResRegistryDto getIdxRegistry(Long idx) throws NullPointerException { Registry getIdxRegistry = registryRepository.findById(idx).orElseThrow( () -&gt; new NullPointerException(\"해당 게시글 없음\") ); return ResRegistryDto.of(getIdxRegistry);}of를 사용하므로써 유지보수에 좋다.변수가 중간에 제거될 수도 있고 변수 명이 바뀔 때of를 사용하지 않는다면 해당 로직을 찾아서 일일히 변경해야하는데 of를 사용하면 한번에 수정이 가능하다.ex) of를 사용하지 않는다면 더 이상 title을 사용하지 않을 때 ResRegistryDto의 title을 쓰는 코드를 찾아서 일일히 수정해야한다.toEntity와 of@Setter@Getter@AllArgsConstructor@NoArgsConstructorpublic class RegistryDto { private String title; private String main; private Long userIdx; // dto → entity public Registry toEntity(User user){ return Registry.builder() .user(user) .title(title) .main(main) .build(); }}@Getter@AllArgsConstructor@NoArgsConstructor@Builderpublic class ResRegistryDto { private Long idx; private String title; private String main; private LocalDateTime createdAt; private LocalDateTime modifiedAt; private String nickname; // entity → dto public static ResRegistryDto of(Registry registry){ return ResRegistryDto.builder() .idx(registry.getIdx()) .title(registry.getTitle()) .main(registry.getMain()) .createdAt(registry.getCreatedAt()) .modifiedAt(registry.getModifiedAt()) .nickname(registry.getUser().getNickname()) .build(); }}toEntity()는 static을 붙이지 않았고 of는 static을 붙였다.toEntity()에서 title과 main은 자기 객체에 있는 값을 활용한다.특정 필드에 접근 하기 때문에 static을 사용할 수 없다.pr - [refactoring] toEntitypr - ResponsetDto(of)" }, { "title": "Optional", "url": "/posts/Optional/", "categories": "Project", "tags": "study, project, Java, summary", "date": "2022-12-08 00:00:00 +0900", "snippet": "OptionalOptional을 찾아보게 된 이유Repository.findById()List&lt;Long&gt; allByIdx = registryRepository.findAllByIdx();List&lt;Long&gt; temp = new LinkedList&lt;&gt;();temp.addAll(allByIdx); List&lt;Optional&lt;Registry&gt;&gt; result = new ArrayList&lt;&gt;();if (temp.isEmpty()) { Registry registry = new Registry(\"admin\", \"admin\",\"admin\"); result.add(Optional.ofNullable(registry));}if (temp.toArray().length &gt; 10) { for (int i = 0; i &lt; 10; i++) { result.add(registryRepository.findById(temp.get(i))); }} else { for (int i = 0; i &lt; temp.toArray().length; i++) { result.add(registryRepository.findById(temp.get(i))); }}프로젝트 기능 수정을 하기 위해 작성했던 코드 중 일부 생략된 코드이다.내가 의문이 들었던 것은 registryRepository.findById를 작성할 때 Optional로 줘야 하는 부분이다.그냥 List&lt;Registry&gt; result로 하면 안되나? 싶었는데 Optional을 생략하면 에러가 떴고 IDE에서 Optional로 바꿔주었다.그래서 그 이유를 찾아보았고 이론에 대해서도 정리를 해보게 되었다.JPA해당 Repository가 상속받고 있는 JpaRepository interface에 들어가봤다.JpaRepository 인터페이스에서 find와 관련된 메서드는 CrudRepository를 참고하라고 한다.CrudRepository interface에 findById 메소드를 확인해보니 return값이 Optional 타입으로 고정되어있다.원인은 바로 CrudRepository interface의 return값이 Optional로 주어져서였다.이 부분은 아래 링크에 자세히 정리해서 넘어간다.더 알아보기 👉🏻 Spring Data JPAOptional 이란?Java8에서는 Optional&lt;T&gt; 클래스를 사용해 NPE(NullPointerException)를 방지할 수 있도록 도와준다.Optional&lt;T&gt;는 null이 올 수 있는 값을 감싸는 Wrapper 클래스로, 참조하더라도 NPE가 발생하지 않도록 도와준다.Optional 클래스는 아래와 같은 value에 값을 저장하기 때문에 값이 null이더라도 바로 NPE가 발생하지 않으며,클래스이기 때문에 각종 메소드를 제공해준다.Optional 적용해보기Optional.empty() : 값이 null인 경우Optional은 Wrapper 클래스이기 때문에 값이 없을 수도 있는데, 이때는 Optional.empty()로 생성할 수 있다.Optional&lt;String&gt; optional = Optional.empty();System.out.println(optional); // Optional.emptySystem.out.println(optional.isPresent()); // false🐣 isPresent 메서드로 현재 Optional이 보유한 값이 null인지 아닌지를 확인할 수 있다.위에서 보았듯이 Optional 클래스는 내부에서 static 변수로 EMPTY 객체를 미리 생성해서 가지고 있다.이러한 이유로 빈 객체를 여러 번 생성해줘야 하는 경우에도 1개의 EMPTY 객체를 공유함으로써 메모리를 절약하고 있다.Optional.of() : null 값을 허용하지 않음만약 어떤 데이터가 절대 null이 아니라면 Optional.of()로 생성할 수 있다.만약 Optional.of()로 null을 저장하려고 하면 NullPointerException이 발생한다.// Optional의 value는 절대 null이 아니다.Optional&lt;String&gt; optional = Optional.of(\"COCO\");Optional.ofNullbale() : null 값을 허용만약 어떤 데이터가 null이 올 수도 있고 아닐 수도 있는 경우에는 Optional.ofNullbale()로 생성할 수 있다.그리고 이후에 orElse 또는 orElseGet 메소드를 이용해서 값이 없는 경우라도 안전하게 값을 가져올 수 있다.// Optional의 value는 값이 있을 수도 있고 null 일 수도 있다.Optional&lt;String&gt; optional = Optional.ofNullable(getName());String name = optional.orElse(\"anonymous\"); // 값이 없다면 \"anonymous\" 를 리턴Optional에서 값 가져오기Optional에서는 값을 가져올 때 자주 사용되는 메서드 orElseGet, orElse 가 있다.null 값 체크를 할 수 있음과 동시에 null 값일 경우 간단한 코드로 처리할 수 있어코드의 가독성이 좋아지고 코드 생산성이 올라간다는 장점이 있다.orElseGet은 Optional이 가지고 있는 값이 null일 경우에만 orElseGet에 주어진 함수를 실행하지만orElse는 null값 유무와 상관없이 사용하게 되어있다.orElse와 orElseGet orElse : 파라미터로 값을 받는다. orElseGet : 파라미터로 함수형 인터페이스(함수)를 받는다.import java.util.Optional;public class OptionalPrac { private static final String emptyStr = \"Empty\"; public void useOrElse() { String result = Optional.ofNullable(emptyStr) .orElse(getbeep()); System.out.println(result); } public void useOrElseGet() { String result = Optional.ofNullable(emptyStr) .orElseGet(this::getbeep); System.out.println(result); } public String getbeep() { System.out.println(\"beep !\"); return \"sound\"; } public static void main(String[] args) { OptionalPrac test = new OptionalPrac(); System.out.println(\" &lt; orElse &gt; \"); test.useOrElse(); System.out.println(); System.out.println(\" = = = = = = = = = = = = = \"); System.out.println(); System.out.println(\" &lt; orElseGet &gt; \"); test.useOrElseGet(); }}출력 &lt; orElse &gt; beep !Empty = = = = = = = = = = = = = &lt; orElseGet &gt; Empty출력 순서 방식OrElse Optional.ofNullable로 “EMPTY”를 갖는 Optional 객체 생성 getbeep()가 실행되어 반환값을 orElse 파라미터로 전달 orElse가 호출되고 “EMPTY”가 null이 아니므로 “EMPTY”를 그대로 가진다.OrElseGet Optional.ofNullable로 “EMPTY”를 갖는 Optional 객체 생성 getbeep() 함수 자체를 orElseGet 파라미터로 전달 orElseGet이 호출되고 “EMPTY”가 null이 아니므로 “EMPTY”를 그대로 가지며 getbeep()이 호출되지 않는다.orElseGet에서는 파라미터로 넘어간 값인 getbeep 함수가 null이 아니므로 .get에 의해 함수가 호출되지 않는다.만약 Optional의 값으로 null이 있다면,다음과 같은 흐름에 의해 orElseGet의 파라미터로 넘어온 getbeep()이 실행될 것이다. public void useOrElseGet() { Object result = Optional.ofNullable(null) .orElseGet(this::getbeep); System.out.println(result); } public String getbeep() { System.out.println(\"beep !\"); return \"sound\"; } public static void main(String[] args) { OptionalPrac test = new OptionalPrac(); System.out.println(\" &lt; orElseGet &gt; \"); test.useOrElseGet(); } &lt; orElseGet &gt; beep !soundorElse와 orElseGet의 차이점 및 사용법 정리orElse 파라미터로 값을 필요로한다. 값이 미리 존재하는 경우에 사용한다.orElseGet 파라미터로 함수(함수형 인터페이스)를 필요로 한다. 값이 미리 존재하지 않는 거의 대부분의 경우에 orElseGet을 사용하면 된다.정리Optional은 null 또는 값을 감싸서 NPE(NullPointerException)로부터 부담을 줄이기 위해 등장한 Wrapper 클래스이다.Optional은 값을 Wrapping하고 다시 풀고, null 일 경우에는 대체하는 함수를 호출하는 등의 오버헤드가 있으므로 잘못 사용하면 시스템 성능이 저하된다.그렇기 때문에 메소드의 반환 값이 절대 null이 아니라면 Optional을 사용하지 않는 것이 좋다.즉, Optional은 메소드의 결과가 null이 될 수 있으며, null에 의해 오류가 발생할 가능성이 매우 높을 때 반환값으로만 사용되어야 한다.또한 Optional은 파라미터로 넘어가는 등이 아니라 반환 타입으로써 제한적으로 사용되도록 설계되었다.reference [JPA] 리턴타입이 옵셔널(Optional)인 이유는? [Java] Optional이란? Optional 개념 및 사용법 - (1/2) [Java] Java Optional (자바 옵셔널) 정리, 예제모음" }, { "title": "Spring data jpa", "url": "/posts/Spring-Data-JPA/", "categories": "Project", "tags": "JPA, study, project, Java, summary", "date": "2022-12-03 00:00:00 +0900", "snippet": "Spring Data JPARepository.findById()List&lt;Long&gt; allByIdx = registryRepository.findAllByIdx();List&lt;Long&gt; temp = new LinkedList&lt;&gt;();temp.addAll(allByIdx); List&lt;Optional&lt;Registry&gt;&gt; result = new ArrayList&lt;&gt;();if (temp.isEmpty()) { result = Collections.emptyList();}if (temp.toArray().length &gt; 10) { for (int i = 0; i &lt; 10; i++) { result.add(registryRepository.findById(temp.get(i))); }} else { for (int i = 0; i &lt; temp.toArray().length; i++) { result.add(registryRepository.findById(temp.get(i))); }}프로젝트 기능 수정을 하기 위해 작성했던 코드 중 일부 생략된 코드이다.내가 의문이 들었던 것은 registryRepository.findById를 작성할 때 Optional로 줘야 하는 부분이다.그냥 List&lt;Registry&gt; result로 하면 안되나? 싶었는데 Optional을 생략하면 에러가 떴고 IDE에서 Optional로 바꿔주었다.그래서 그 이유를 찾아보게 되었다.JPA해당 Repository가 상속받고 있는 JpaRepository interface에 들어가봤다.JpaRepository 인터페이스에서 find와 관련된 메서드는 CrudRepository를 참고하라고 한다.CrudRepository interface에 findById 메소드를 확인해보니 return값이 Optional 타입으로 고정되어있다.원인은 바로 CrudRepository interface의 return값이 Optional로 주어져서였다.JPA 구조JpaRepository는 PaingAndSortingRepository, QueryByExampleExecutor를 상속하고 있다.CrudRepository가 조부모, PagingAndSortingRepository가 부모, JpaRepository가 자식의 관계이다.우리가 만든 Repository는 JpaRepository를 상속받는다.모든 인터페이스가 &lt;T, ID&gt; 두 개의 제네릭 타입을 사용하는 것을 볼 수 있는데,T는 Entity의 타입 클래스를, ID는 식별자(PK)의 타입을 의미한다.이 때, ID에 해당하는 타입은 반드시 java.io.Serializable 인터페이스 타입이어야만 한다.*Serializable : 직렬화Serializable 인터페이스 타입??아래 diagram을 보면 Long, String은 Serializable interface를 구현하고 있다.우연하게도 Integer, Long, Double, Float, Boolean의 다이어그램을 보니Primitive Type(기본 자료형)이 Serializable interface를 구현하고 있다. (+ String)Long String List 최상위 부모인 Repository를 CrudRepository가 상속받아 확장시키고,이를 PagingAndSortingRepository가, 그리고 이를 또 JpaRepository가 상속받아 확장시킨 것을 볼 수 있다.실제 주로 사용하는 것은 CRUD(Create, Read, Update, Delete) 작업을 위주로 하는 CrudRepository 인터페이스나페이징 처리, 검색 처리 등을 할 수 있는 PagingAndSortingRepository 인터페이스다.CrudRepository조부모 인터페이스인 CrudRepository에는 다음과 같은 메소드들을 제공한다.reference [JPA] 리턴타입이 옵셔널(Optional)인 이유는? [Spring Framework] Spring Data JPA Repository [JPA] CrudRepository vs JpaRepository [Spring Data JPA] Repository 생성 [JPA] JpaRepository vs CrudRepository(1) - Paging과 Sorting / QueryExampleExecutor" }, { "title": "연관관계 적용3(궁금증 해결하기)", "url": "/posts/%EC%97%B0%EA%B4%80%EA%B4%80%EA%B3%84-%EC%A0%81%EC%9A%A93(%EA%B6%81%EA%B8%88%EC%A6%9D-%ED%95%B4%EA%B2%B0%ED%95%98%EA%B8%B0)/", "categories": "Project, JPA", "tags": "JPA, study, project, question", "date": "2022-11-27 00:00:00 +0900", "snippet": "문제 상황일대다 관계인 Registry와 Comment 연관관계 매핑을 마치고 Comment에 있던 registryId와 registryNickname 필드를 없앴다. 👉🏻 연관관계 적용2(refactoring)(매핑으로 인해 Comment.getRegistry().getIdx() 하면 되므로)그래서 해당 필드를 없애면서 수정해야 할 코드들을 고치고 있다가 궁금한 점이 생겼고 정리해봤다.의문점(postComment)댓글을 post할 때 js에서 form 형태로 보냈다.// jslet form_data = newFormData()form_data.append(\"comment\", $(\"#comment\").val())form_data.append(\"nickname\", nickname)form_data.append(\"registryId\",$(\"#RegistryId\").html())form_data.append(\"registryNickname\",$(\"#user\").text()) 위 코드를 아래로 변경했는데 registryId로 보내던 것을 registry로 보내고 dto를 엔티티로 수정했다.// jslet form_data = new FormData()form_data.append(\"comment\", $(\"#comment\").val())form_data.append(\"nickname\", nickname)form_data.append(\"registry\",$(\"#RegistryId\").html()) // 👈🏻dtopublic class CommentDto { private String nickname; private String comment; private Registry registry; // 👈🏻 연관관계 매핑 후 수정// private Long registryId;// private String registryNickname;}Commentpublic Comment(CommentDto commentDto) { this.nickname = commentDto.getNickname(); this.comment = commentDto.getComment(); this.registry = commentDto.getRegistry();// this.registryId = commentDto.getRegistryId();// this.registryNickname = commentDto.getRegistryNickname();}그런데 이렇게 RegistryId로 보내던 것을 registry로 보내고 dto에 Registry로 담아봤는데 성공했다. (😮?)나는 이 부분이 의문이 들었고 왜 그런건지 알고 싶었다.id가 pk라서 알아서 해당 id에 해당하는 db를 가져오는걸까?어떻게 id인줄 아는걸까??참고로 보통은 dto에 엔티티를 넣지 않는다고 한다. (이 부분은 아래에서 다룰 예정!)🐣 dto에 엔티티를 넣지 않고 id를 받아서 서버에서 해당 id를 조회하고 유효성 검사한 다음에 저장할 때 넣어준다.❓ 왜 dto에 entity를 넣으면 안되는걸까?dto에 객체를 넣어도 되지만 entity는 넣어주면 안된다.Entity와 Dto를 분리하기 위해서 작성하면 안된다.Entity와 Dto를 분리하는 이유는 DB와 View 사이의 역할 분리를 위해서 테이블에 매핑되는 정보와 실제 View에서 요청되는 정보가 다를 경우 테이블에 필요한 정보에 맞게 데이터를 변환하는 로직이 필요할 수 있는데, 해당 로직이 Entity에 들어가게 되는 것은 일반적으로 생각해도 깔끔하지 못하다. DB로부터 조회된 Entity를 그대로 View로 넘기게 되었을 때 불필요한 정보 및 노출되면 안 되는 정보까지 노출될 수 있고,이를 막기 위한 로직을 따로 구현해야 한다. Dto가 일회성으로 데이터를 주고받는 용도로 사용되는 것과 다르게 Entity의 생명주기(Life Cycle)도 전혀 다르다. DTO(Data Transfer Object)는 Entity 객체와 달리 각 계층끼리 주고받는 우편물이나 상자의 개념이다. 순수하게 데이터를 담고 있다는 점에서 Entity 객체와 유사하지만, 목적 자체가 전달이므로 읽고, 쓰는 것이 모두 가능하고, 일회성으로 사용되는 성격이 강하다. JPA를 이용하게 되면 Entity 객체는 단순히 데이터를 담는 객체가 아니라 실제 데이터베이스와 관련된 중요한 역할을 하며,내부적으로 EM(EntityManager)에 의해 관리되는 객체다.출처 역할 분리를 위한 Entity, DTO 개념과 차이점문제를 해결하면서 2가지 방법으로 보낼 수 있다는 것을 알게 되었다. 위 처럼 registry로 보내기 registry의 id값으로 보내기먼저 1번을 얘기하면서 궁금증을 해결해본다.registry로 보내기frontlet form_data = new FormData()form_data.append(\"comment\", $(\"#comment\").val())form_data.append(\"nickname\", nickname)form_data.append(\"registry\", $(\"#RegistryId\").html())for (let key of form_data.keys()) { console.log(key, \":\", form_data.get(key));}front에서 3개의 데이터를 보낸다.CommentController에서 받는 값을 출력시켜봤다.front에서 id값만 보냈는데 dto에서는 객체로 보낸다.Postman으로 실행하기위 처럼 데이터를 주고 실행을 시켜보니 콘솔에 아래와 같이 찍혀있었다.콘솔을 통해 바인딩 할때(form에서 객체로 바꿔줄 때) 객체(registry)로 보내면 알아서 id값을 체크한다.그래서 알아서 db를 갖고 올수 있었던 것이었다.이를 활용해서 코드를 작성하면 ServiceImpl에서 findById같은 코드를 생략해도 되는 것이다.→ repository 의존도를 낮춰줄 수 있다.Registry registry = registryRepository.findById(comment.getRegistry().getIdx()).orElseThrow();comment.setRegistry(registry);그렇게 작성하기 위해선 몇가지 코드가 추가로 작성되어야 한다.Dto에 Entity를 넣어야 하기 때문에 RequestDto와 ResponseDto가 있어야 하고RequestDto에는 사용자에게 보여지는 Dto가 아니기 때문에 Entity를 넣어줘도 상관이 없을 듯하다.또한 예외처리가 필수적으로 이루어져야한다.게시글이 없는 경우엔 댓글을 작성할 수 없다. → db에 없는 게시글 id를 줄 경우 예외 처리또한 데이터가 없는 경우에도 댓글을 작성할 수 없다. → id값을 front에서 주지 않을 때 예외 처리이 경우를 예외처리를 해야 정상적으로 동작하는 것을 볼 수 있을 것이다.어떻게 작성하냐 선택의 차이인 것 같다.아래는 registry가 아닌 registry의 id값으로 보내는 방법이다.registry의 id값으로 보내기js에서 registry의 id값으로 명시해서 보냈다.// jslet form_data = newFormData()form_data.append(\"comment\", $(\"#comment\").val())form_data.append(\"nickname\", nickname)form_data.append(\"registry.idx\",$(\"#RegistryId\").html())controller@PostMapping(\"/comment\")public Comment setComment(@ModelAttribute CommentDto commentDto) { return commentService.setComment(commentDto);}@ModelAttribute는 클라이언트로부터 일반 HTTP 요청 파라미터나 multipart/form-data 형태의 파라미터를 받아 객체로 사용하고 싶을 때 사용한다.@ModelAttribute로 form에서 registry.idx로 보내면 해당 값을 받기 위해서 setter를 작성해야한다.// Registry.javapublic void setIdx(Long idx) { this.idx = idx;}그 외의 필드 값은 생성자를 작성해야 한다.registry.idx로 보냈을 때 성공하려면 id에 대한 setter가 있어야 하며registry.idx 말고 registry(객체)로만 줬을 때 바인딩 시켜주는 것은 생성자 역할이다.→ 필드명으로 주고 싶으면 setter고 객체 자체로 주려면 생성자 역할이다 라는 얘기🐣 id값은 생성자 작성 안해도 된다.( id는 자동으로 생성되는 auto_increment 쓰므로)registry.idx: 100 과 같이 넣어주려면 Registry클래스에 setter가 있어야 한다.(Comment.java 아님)👉🏻 Commemt의 외래키에 registry id 넣게 하기 위함testidx와 nickname에서는 setter가 맞는지 확인해보자setter를 작성하고 test를 했더니 아래와 같이 나왔다. public void setIdx(Long idx) { this.idx = idx; } public void setNickname(String nickname) { this.nickname = nickname; }//jslet form_data = newFormData()form_data.append(\"comment\", $(\"#comment\").val())form_data.append(\"nickname\", nickname)form_data.append(\"registry.idx\",$(\"#RegistryId\").html())form_data.append(\"registry.nickname\",$(\"#user\").text())post는 되었지만 registry 객체에 title, main이 null로 뜨는 것을 볼 수 있다.setter로 id, nickname 값만 넣어서 나머지 필드는 null로 뜨는 것이다.registry.~~는 setter로 동작해서 값을 넣어준다.라는 것을 알게 되었다.만약 idx에 대해서만 setter를 설정하면 js에서 idx값과 nickname을 전달해도 idx 값만 받아온다.수정db에는 fk값인 registryId만 있으면 되므로 권장하는 방향인 Dto에 Entity가 아닌 Long으로 받게 수정해본다.js에서 전달할 값을 registryIdx로 설정했다.let form_data = new FormData()form_data.append(\"comment\", $(\"#comment\").val())form_data.append(\"nickname\", nickname)form_data.append(\"registryIdx\",$(\"#RegistryId\").html()) // 👈🏻CommentDto이를 받을 dto에서도 똑같이 registryIdx로 작성한다.public class CommentDto { private String nickname; private String comment; private Long registryIdx; // 👈🏻}Commententity에서 dto에 대한 생성자를 수정한다.필드에 registryIdx가 없기 때문에 this를 사용하지 않는다.public Comment(CommentDto commentDto) { this.nickname = commentDto.getNickname(); this.comment = commentDto.getComment(); Long registryIdx = commentDto.getRegistryIdx(); // 👈🏻}idx를 가지고 comment에 set 해줘야 하므로 Registry에 idx값만 담는 생성자를 작성해야겠지? 라고 생각하면 안된다🙅🏻‍♀️id는 생성자 만들지 않는다.Repository를 이용해서 findById() 후 해당 id의 Registry를 가져와서 comment에 set 해주면 된다.find vs get그런데 findById() 보다 더 나은 방법이 있다는 것을 해당 블로그 글을 보고 알게 되었다.findById vs getReferenceById 글을 따로 정리했다.요약하자면 getReferenceById()는 실제 테이블을 조회하는 대신 프록시 객체만 가져오기 때문에ID값을 제외한 나머지 값을 사용하기 전까지는 SELECT 쿼리가 발생하지 않는다.Optional&lt;T&gt; findById(ID id) : (탐색함) 탐색 결과가 없을 수 있고 내부 예외 발생이 없다.T getReferenceById(ID id) : (가져옴) 가져오려는 대상이 없을 시, 내부에서 예외 발생한다. (EntityNotFoundException)getReferenceById는 EntityManager#getReference 를 사용하며, 조회된 entity 내부값 접근 전까지 lazy loading 처리한다.ServiceImplRegistry registry = registryRepository.getReferenceById(commentDto.getRegistryIdx());Comment comment = Comment.builder() .comment(commentDto.getComment()) .nickname(commentDto.getNickname()) .registry(registryId) .build();마치면서…왜 js에서 registry로 값을 보냈을 때 어떻게 id인지 알고 db를 갖고오는지 정확히 알지 못했는데객체로 보낼 때 id값을 받아서 db를 가져오는 것을 보고 2가지 방법으로 댓글을 post하는 방법을 알아냈다.또한, 이번 기회에 findById()말고도 getReferenceById()가 있다는 것을 알게 되었다.reference JPA 의 getById() vs findById() [JPA] 연관 관계를 가진 엔티티 저장 방식 개선 (불필요한 select문 제거) find vs get (네이밍 컨벤션과 JPA에서의 내부 동작 차이)연관관계 목차 연관관계 연관관계 적용 연관관계 적용2(refactoring) 연관관계 적용3(궁금증 해결하기) 👈 연관관계 적용4 정리(코드 + MySQL)" }, { "title": "연관관계 적용2(refactoring)", "url": "/posts/%EC%97%B0%EA%B4%80%EA%B4%80%EA%B3%84-%EC%A0%81%EC%9A%A92(refactoring)/", "categories": "Project, JPA", "tags": "JPA, study, project", "date": "2022-11-22 00:00:00 +0900", "snippet": "연관관계 적용2이전(연관관계 적용)에 Registry와 Comment 연관관계 매핑을 해서 값을 세팅했다.이제 refactoring을 통해서 매핑 하기 전에 작성한 registryId와 registryNickname은 필요없으므로 코드를 수정하기로 했다.*pr 👉🏻 연관관계 refactoring test 코드 수정 본 코드 수정 Controller ServiceImpl Repository Entity(builder() 적용) Dto front 수정 ajax data 수정 (put, delete) form data 수정 (post) registryId와 registryNickname 제거Entity@Setter@Getter@NoArgsConstructor@Entitypublic class Comment extends Timestamped { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) @Column(name = \"comment_id\") private Long idx; @Column(nullable = false) private String nickname; @Column(nullable = false) private String comment; @ManyToOne @JoinColumn(name = \"registry_id\") private Registry registry; public void setRegistry(Registry registry) { if(this.registry != null) { this.registry.getComments().remove(this); } this.registry = registry; if (!registry.getComments().contains(this)) { registry.addComment(this); } } public Comment(CommentDto commentDto) { this.nickname = commentDto.getNickname(); this.comment = commentDto.getComment(); }}CommentDtopublic class CommentDto { private String nickname; private String comment;}Repository더 이상 registryId를 사용할 수 없으니 메소드명을 수정한다.public interface CommentRepository extends JpaRepository&lt;Comment, Long&gt; { List&lt;Comment&gt; findAllByRegistryId(Long idx);}⬇️public interface CommentRepository extends JpaRepository&lt;Comment, Long&gt; { List&lt;Comment&gt; findAllByRegistry_Idx(Long idx);}이대로 실행을 하면 문제가 없을 것 같지만 에러가 뜬다.문제 코드CommentServiceImpl의 post 코드에서Registry registry = registryRepository.findById(comment.getRegistry().getIdx()).get();해당 부분이 에러가 떴다.Cannot invoke “domain.Registry.getIdx()” because the return value of “domain.Comment.getRegistry()” is null왜 null이 나오는건지 잘 파악이 안되서 test 코드부터 refactoring을 해보면서 어떻게 작성을 해야할지 감을 잡기로 했다.참고로 .get() 보다 .orElseThrow()를 쓰는 것을 권장한다.orElseThrow() 메소드 : 저장된 값이 존재하면 그 값을 반환하고, 값이 존재하지 않으면 인수로 전달된 예외를 발생시킨다.👉🏻 .get()을 안써도 .orElseThrow() 를 이용해서 값을 가져올 수 있고 예외 처리도 가능하기 때문이다.Registry registry = registryRepository.findById(comment.getRegistry().getIdx()).orElseThrow();Optional 클래스test 코드test 코드에서는 2가지 위주로 수정을 진행했다. registryId와 registryNickname을 제거한다. Comment에 Registry를 넣어준다.1. registryId, registryNickname 제거Comment comment = new Comment();comment.setComment(\"❤️🧡💛💚💙💜🤎🖤\");comment.setNickname(\"우헤헤\");//comment.setRegistryId(5L);//comment.setRegistryNickname(\"pop\");2. Comment에 Registry를 넣어준다.수정 전 @BeforeEach void beforeEach() { SignupRequestDto userDto = new SignupRequestDto(\"test1\", \"test1\", \"d\",\"d\",\"d\"); User user = userService.registerUser(userDto); this.nowUser = new UserDetailsImpl(user); // 게시글 RegistryDto registryDto = new RegistryDto(\"test1\",\"타이틀\",\"본문\"); Registry saveRegistry = new Registry(registryDto); this.registry = registryRepository.save(saveRegistry); // 댓글 this.commentDto = new CommentDto(); this.commentDto.setComment(\"comment\"); this.commentDto.setNickname(nowUser.getUsername()); this.commentDto.setRegistryId(registry.getIdx()); this.commentDto.setRegistryNickname(registry.getNickname()); // 작성자 }수정 후 @BeforeEach void beforeEach() { SignupRequestDto userDto = new SignupRequestDto(\"test1\", \"test1\", \"d\",\"d\",\"d\"); User user = userService.registerUser(userDto); this.nowUser = new UserDetailsImpl(user); // 게시글 RegistryDto registryDto = new RegistryDto(\"test1\",\"타이틀\",\"본문\"); Registry saveRegistry = new Registry(registryDto); this.registry = registryRepository.save(saveRegistry); // 댓글 this.commentDto = new CommentDto(); this.commentDto.setComment(\"comment\"); this.commentDto.setNickname(nowUser.getUsername()); this.commentDto.setRegistry(saveRegistry); // 👈🏻 }post 수정 전 @Test void saveComment() throws IOException { // given // when Comment comment = commentService.setComment(commentDto); // then Comment commentTest = commentRepository.findById(comment.getIdx()).orElseThrow( () -&gt; new NullPointerException(\"comment 생성 x\") ); assertEquals(\"comment의 id값이 일치하는지 확인\", comment.getIdx(), commentTest.getIdx()); assertEquals(\"comment의 nickname이 일치하는지 확인\", comment.getRegistryNickname(), registry.getNickname()); }post 수정 후 @Test void saveComment() throws IOException { // given // when Comment comment = commentService.setComment(commentDto); // then Comment commentTest = commentRepository.findById(comment.getIdx()).orElseThrow( () -&gt; new NullPointerException(\"comment 생성 x\") ); assertEquals(\"comment의 id값이 일치하는지 확인\", comment.getIdx(), commentTest.getIdx()); assertEquals(\"comment의 nickname이 일치하는지 확인\", comment.getRegistry().getNickname(), registry.getNickname()); // 👈🏻 }put 수정 전 @Test @DisplayName(\"comment 수정\") void updateComment() throws IOException { Comment comment = commentService.setComment(commentDto); CommentDto commentDtoEdit = new CommentDto(); commentDto.setComment(\"comment-edit\"); //when Comment commentTest = commentService.updateComment(comment.getIdx(), comment.getRegistryId(), commentDtoEdit, nowUser); //then assertEquals(\"Comment Id 값이 일치하는지 확인.\", comment.getIdx(), commentTest.getIdx()); assertEquals(\"Comment 내용이 업데이트 되었는지 확인\", commentDtoEdit.getComment(), commentTest.getComment()); }put 수정 후 @Test @DisplayName(\"comment 수정\") void updateComment() throws IOException { Comment comment = commentService.setComment(commentDto); CommentDto commentDtoEdit = new CommentDto(); commentDto.setComment(\"comment-edit\"); //when Comment commentTest = commentService.updateComment(comment.getIdx(), comment.getRegistry().getIdx(), commentDtoEdit, nowUser); // 👈🏻 //then assertEquals(\"Comment Id 값이 일치하는지 확인.\", comment.getIdx(), commentTest.getIdx()); assertEquals(\"Comment 내용이 업데이트 되었는지 확인\", commentDtoEdit.getComment(), commentTest.getComment()); }delete 수정 전 @Test @DisplayName(\"comment 삭제 성공\") void deleteComment() throws IOException { // given Comment comment = commentService.setComment(commentDto); //when commentService.deleteComment(comment.getIdx(), comment.getRegistryId(), commentDto, nowUser); // then Optional&lt;Comment&gt; commentTest = commentRepository.findById(comment.getIdx()); if (commentTest.isPresent()) throw new IllegalArgumentException(\"Comment 가 정상적으로 삭제되지 않았습니다.\"); else assertEquals(\"Comment 가 비어있다.\", Optional.empty(), commentTest); }delete 수정 후 @Test @DisplayName(\"comment 삭제 성공\") void deleteComment() throws IOException { // given Comment comment = commentService.setComment(commentDto); //when commentService.deleteComment(comment.getIdx(), comment.getRegistry().getIdx(), commentDto, nowUser); // 👈🏻 // then Optional&lt;Comment&gt; commentTest = commentRepository.findById(comment.getIdx()); if (commentTest.isPresent()) throw new IllegalArgumentException(\"Comment 가 정상적으로 삭제되지 않았습니다.\"); else assertEquals(\"Comment 가 비어있다.\", Optional.empty(), commentTest); }id가 1인 댓글 _ 수정 전 @BeforeEach void beforeEach() { commentDto = new CommentDto(\"commentNickname\", \"testComment\", 1L,\"registryNickname\"); comment = new Comment(commentDto); } @Test @DisplayName(\"id가 1인 댓글\") void showComment() throws IOException { //given RegistryDto registry = new RegistryDto(); registry.setTitle(\"첫 번째\"); registry.setMain(\"1\"); registry.setNickname(\"nickname\"); CommentDto comment = new CommentDto(); comment.setComment(\"funfun\"); comment.setNickname(\"hh\"); comment.setRegistryId(1L); comment.setRegistryNickname(\"nickname\"); CommentDto comment1 = new CommentDto(); comment1.setComment(\"wow\"); comment1.setNickname(\"hh\"); comment1.setRegistryId(1L); comment1.setRegistryNickname(\"nickname\"); //when Registry saveRegistry = registryRepository.save(new Registry(registry)); Comment saveComment = commentRepository.save(new Comment(comment)); Comment saveComment1 = commentRepository.save(new Comment(comment1)); //then Long idx = saveRegistry.getIdx(); List&lt;Comment&gt; results = commentRepository.findAllByRegistryId(idx); assertThat(saveComment.getComment()).isEqualTo(results.get(0).getComment()); assertThat(saveComment1.getComment()).isEqualTo(results.get(1).getComment()); }id가 1인 댓글 _ 수정 후 @BeforeEach void beforeEach() { Registry registry = new Registry(); // 👈 registry.setNickname(\"registryNickname\"); registry.setTitle(\"registryTitle\"); registry.setMain(\"registryMain\"); commentDto = new CommentDto(\"commentNickname\",\"comment\", registry); comment = new Comment(commentDto); } @Test @DisplayName(\"id가 1인 댓글\") void showComment() throws IOException { //given RegistryDto registry = new RegistryDto(); registry.setTitle(\"첫 번째\"); registry.setMain(\"1\"); registry.setNickname(\"nickname\"); CommentDto comment = new CommentDto(); comment.setComment(\"funfun\"); comment.setNickname(\"hh\"); CommentDto comment1 = new CommentDto(); comment1.setComment(\"wow\"); comment1.setNickname(\"hh\"); //when Registry saveRegistry = registryRepository.save(new Registry(registry)); comment.setRegistry(saveRegistry); // 👈🏻 comment1.setRegistry(saveRegistry); // 👈🏻 Comment saveComment = commentRepository.save(new Comment(comment)); Comment saveComment1 = commentRepository.save(new Comment(comment1)); //then Long idx = saveRegistry.getIdx(); List&lt;Comment&gt; results = commentRepository.findAllByRegistry_Idx(idx); // 👈🏻 assertThat(saveComment.getComment()).isEqualTo(results.get(0).getComment()); assertThat(saveComment1.getComment()).isEqualTo(results.get(1).getComment()); }null 해결하기test 코드를 먼저 수정하다보니 Comment의 값을 저장하기 전에 Registry를 먼저 저장한 후에registry.idx()의 값을 가져오고 해당 값을 Comment에 set하여 저장을 해야지 제대로 db에 저장이 될텐데Registry의 값을 넣어주지 않아서 에러가 뜨는 것 같다라는 생각이 들었다.(* IDENTITY에 의해서 id는 저장이 된 후에 알 수 있으므로 DB에 값을 넣기 전까지는 기본키를 모른다.)기존에 작성한 Controller를 보면 post는 form 형태로 데이터를 받기 때문에 dto에 Registry값이 있어야 하고put과 delete는 기존 db가 있기 때문에 오류를 체크하는 정도로만 registry를 활용하기 때문에해당 파라미터로 받는 registryId만 있으면 될 것 같다라고 판단, fornt만 수정하고 기존 코드를 유지하기로 했다.Controller @PostMapping(\"/comment\") public Comment setComment(@ModelAttribute CommentDto commentDto) { return commentService.setComment(commentDto); } @GetMapping(\"/comment\") public List&lt;Comment&gt; getComment(@RequestParam Long idx){ return commentService.getComment(idx); } @PutMapping(\"/comment/{commentId}/registry/{registryId}\") public Comment updateComment(@PathVariable Long commentId, @PathVariable Long registryId, @RequestBody CommentDto commentDto, @AuthenticationPrincipal UserDetailsImpl userDetails) throws AccessDeniedException { return commentService.updateComment(commentId, registryId, commentDto, userDetails); } @DeleteMapping(\"/comment/{commentId}/registry/{registryId}\") public void deleteComment(@PathVariable Long commentId, @PathVariable Long registryId, @RequestBody CommentDto commentDto, @AuthenticationPrincipal UserDetailsImpl userDetails)throws AccessDeniedException { commentService.deleteComment(commentId, registryId, commentDto, userDetails); }post값을 받기 위해서는 dto에 registry를 받을 수 있어야 한다.따라서 Comment와 CommentDto를 수정한다.Commentpublic Comment(CommentDto commentDto) { this.nickname = commentDto.getNickname(); this.comment = commentDto.getComment(); this.registry = commentDto.getRegistry(); // 👈🏻}CommentDtopublic class CommentDto { private String nickname; private String comment; private Registry registry; // 👈🏻}front에서 form을 보낼 때 dto와 변수 명이 같아야 한다.registry로 받아야 하므로 registryId를 아래와 같이 수정했다.let form_data = new FormData()form_data.append(\"comment\", $(\"#comment\").val())form_data.append(\"nickname\", nickname)form_data.append(\"registry\",$(\"#RegistryId\").html()) // 👈🏻test 해보니 post가 잘 되었다. 근데 registry에 registryId를 넣었는데 어떻게 id인지 아는걸까?이 부분은 연관관계 적용3(궁금증 해결하기) 에서 다뤘다.put, deletelet RegistryComment = { nickname: nickname, comment: comment, registryId: registryId, registryNickname: registryNickname}⬇️ 위 형태로 data에 보냈었는데 이제는 아래와 같이 보내는 것으로 수정했다.let RegistryComment = { nickname: nickname, comment: comment}@Builder보통 생성자를 통해 객체를 생성하는데 아래와 같이 작성한다.Registry registry = new Registry(\"nemo\", \"hi\", \"nice\");하지만 이에 단점들이 있어 객체를 생성하는 별도 builder를 두는 방법이 있다. 이를 builder pattern이라고 한다.1. 생성자 파라미터가 많을 경우 가독성이 좋지 않다.위 코드를 보면 nemo가 어떤 것을 의미하는지 알 수가 없다.builder pattern으로 구현하면 각 값들의 이름이 함수로 setting이 되어 각각 무슨 값을 의미하는지 알 수 있다.→ 생성자로 설정해야하는 값이 많을 경우에는 builder pattern을 쓰는 것이 가독성이 좋다.Registry registry = Registry.builder() .nickname(\"coco\") .title(\"hi\") .main(\"hello\") .build();2. 어떤 값을 먼저 설정하던 상관없다.생성자의 경우는 정해진 파라미터 순서대로 꼭 값을 넣어줘야한다.순서를 무시하고 값을 넣으면 에러가 발생하거나 엉뚱한데 값이 들어갈 수 있다.하지만 builder pattern은 빌더의 필드 이름으로 값을 설정하기 때문에 순서에 종속적이지 않다.그냥 쓰이는 곳에서 어떤 필드를 먼저 설정해야하는지 굳이 순서를 생각할 필요 없이 편하게 설정하면 된다.@Builder 적용builder pattern을 사용하려면 먼저 3가지 문제를 알아야 한다.1. @Setter를 사용하지 않는다.Setter는 그 의도가 분명하지 않고 객체를 언제든지 변경할 수 있는 상태가 되어서 객체의 안전성이 보장받기 힘들다.특히 엔티티에서는 @Setter를 사용 시 해당 변경 가능성이 어디서 누구에 의해 발생했는지 추적하기가 힘들어진다.때문에 값 변경이 필요한 경우 의미 있는 메소드를 생성하여 이를 사용하는 것이 좋다.2. @NoArgsConstructor(access = AccessLevel.PROTECTED)로 변경한다.기본 생성자(NoArgsConstructor)의 접근 제어를 PROCTECTED 로 설정하면 아무런 값도 갖지 않는 의미 없는 객체의 생성을 막게 된다.즉 무분별한 객체 생성에 대해 한번 더 체크할 수 있다.Registry registry = new Registry(); //컴파일 에러 발생@Builder를 사용하는 방법은 총 2가지다.1) 클래스에 @Builder를 붙이기2) 생성자에 @Builder를 붙이기아래 3번을 보고 1번과 2번 중 어느 것이 나을지 확인해본다.3. @AllArgsConstructor는 쓰지 않는다.클래스 레벨에서 @Builder와 @NoArgsConstructor를 함께 쓰면 오류가 발생한다.이를 해결하려면 모든 필드를 가지는 생성자를 만들어주어야 하는데 @AllArgsConstructor도 같이 써주게 된다.하지만 @AllArgsConstructor 는 위험하다.클래스에 존재하는 모든 필드에 대한 생성자를 자동으로 생성하는데, 인스턴스 멤버의 선언 순서에 영향을 받기 때문에 변수의 순서를 바꾸면 생성자의 입력 값 순서도 바뀌게 되어 검출되지 않는 치명적인 오류를 발생시킬 수 있다.그래서 @Builder를 사용하는 방법 2(생성자에 @Builder를 붙이기)를 사용해서@AllArgsConstructor를 쓰는 일이 없도록 한다.프로젝트에 실제 적용시키기Entity@NoArgsConstructor(access = AccessLevel.PROTECTED)@Getter@Entity@ToStringpublic class Registry extends Timestamped { @GeneratedValue(strategy = GenerationType.IDENTITY) @Id @Column(name = \"registry_id\") private Long idx; @Column(nullable = false) private String nickname; @Column(nullable = false) private String title; @Column(nullable = false) private String main; @OneToMany(mappedBy = \"registry\") @JsonIgnore private List&lt;Comment&gt; comments = new ArrayList&lt;&gt;(); public Registry(long idx, String nickname, String title, String main) { super(); } public void addComment(Comment comment) { this.comments.add(comment); if(comment.getRegistry() != this) { comment.setRegistry(this); } } public Registry(RegistryDto registryDto) { this.title = registryDto.getTitle(); this.main = registryDto.getMain(); this.nickname = registryDto.getNickname(); } @Builder public Registry(String nickname, String title, String main) { this.nickname = nickname; this.title = title; this.main = main; }}🐣 클래스가 아닌 생성자에 @Builder를 추가한 이유클래스에 @Builder를 쓰면 초기화가 안되서 에러가 뜨는데@AllArgsConstructor는 지양해야하기 때문에 클래스가 아닌 생성자에 넣었다.@AllArgsConstructor는 클래스에 존재하는 모든 필드에 대한 생성자를 자동으로 생성하는데,인스턴스 멤버의 선언 순서에 영향을 받기 때문에 두 변수의 순서를 바꾸면생성자의 입력 값 순서도 바뀌게 되어 검출되지 않는 치명적인 오류를 발생시킬 수 있다.test 코드@Testvoid registryTest() throws Exception {// Registry registry = new Registry();// registry.setTitle(\"hi\");// registry.setMain(\"hello\");// registry.setNickname(\"testCodeId\"); //given Registry registry = Registry.builder() .nickname(\"coco\") .title(\"hi\") .main(\"hello\") .build(); //when registryRepository.save(registry); //then Assertions.assertThat(\"hi\").isEqualTo(registry.getTitle()); Assertions.assertThat(\"hello\").isEqualTo(registry.getMain());}Comment.java에서 @Builder를 썼더니 Service에서 comment를 Update(C,R, U, D)하는 로직에 에러가 떴다.@Setter를 지우면서 comment.setComment()가 되지 않았던 것이다.// Setter 메소드 선언 방법public void setFieldName(타입 fieldName){ this.fieldName = fieldName;}// Getter 메소드 선언 방법public 리턴 타입 getFieldName(){ return fieldname;}그래서 해당 메소드가 Comment(객체) 중 comment(필드 명)만 담고 있는것을 확인하여 Comment.java와 ServiceImpl 코드를 수정했다.Update 하는 부분이므로 updateComment()로 작성했다.Commentpublic void updateComment(String comment) { this.comment = comment;}CommentServiceImplcomment.updateComment(commentDto.getComment());출처 빌더 패턴(Builder pattern)을 써야하는 이유, @Builder 올바른 JPA Entity, @Builder 사용법연관관계 목차 연관관계 연관관계 적용 연관관계 적용2(refactoring) 👈 연관관계 적용3(궁금증 해결하기) 연관관계 적용4 정리(코드 + MySQL)" }, { "title": "연관관계 적용", "url": "/posts/%EC%97%B0%EA%B4%80%EA%B4%80%EA%B3%84-%EC%A0%81%EC%9A%A9/", "categories": "Project", "tags": "DB, study, summary, project", "date": "2022-11-20 00:00:00 +0900", "snippet": "연관관계 매핑(1 : N)실제 프로젝트에 적용시켜본다.연관관계 목차 연관관계 이론 연관관계 적용 👈🏻 연관관계 적용2(refactoring) 연관관계 적용3(궁금증 해결하기) 연관관계 적용4 정리(코드 + MySQL)요약 @Column(name = “registry_id) 로 Registry id 컬럼에 이름을 명시해준다. Comment 의 Registry에 JoinColumn으로 참조할 컬럼명을 지정해 준다. Comment : Registry = N : 1 관계이기 때문에, Comment 의 Registry에는 @ManyToOne , Registry의 Comment는 @OneToMany mappedBy : 주인이 아닌 것을 지정 (양방향시 키를 관리할 주인이 누구인지 지정) mappedBy=\"(주인쪽에 자신이 매핑되어 있는 필드명)\" fetch = FetchType.LAZY : 지연로딩으로 필요에 의해서만 쿼리를 날려 조회할수 있게 설정매핑하기매핑할 객체는 Registry와 Comment다.연관관계 매핑 전까지는 직접 값을 넣어서 db에 넣어줬다.기존 코드에서 연관관계 매핑을 하면서 수정한 부분이 몇 군데 있다.(아래 코드는 수정 이후의 코드다.)Wrapper class로 수정 기존에 idx를 제외하고는 정수는 int로 설정했었다. 이럴 경우 문제가 생기는데 값이 null로 들어오면 원시 자료형은 기본 값이 들어와버린다. (ex. int = 0) 그렇게 되면 이게 null인지 모르므로 Wrapper 클래스인 Integer로 설정하게 되면 null 값으로 떠서 에러가 뜨므로 이러한 대비를 하는게 좋다. mysql에서 long은 bigint로 설정하면 된다.GenerationType 수정 auto_increment를 적용하기 위해 자연스럽게 계속 AUTO만 사용하고 있었는데 AUTO를 생성하면서 문제가 생겼고 IDENTITY로 바꿔줬다. 자세한 내용은 아래 글을 참고한다. GenerationtypeRegistry.java@AllArgsConstructor@NoArgsConstructor@Setter@Getter@Entity@ToStringpublic class Registry extends Timestamped { @GeneratedValue(strategy = GenerationType.IDENTITY) @Id @Column(name = \"Registry_Id\") private Long idx; @Column(nullable = false) private String nickname; @Column(nullable = false) private String title; @Column(nullable = false) private String main; public Registry(RegistryDto registryDto) { this.title = registryDto.getTitle(); this.main = registryDto.getMain(); this.nickname = registryDto.getNickname(); }}Comment.java@Setter@Getter@NoArgsConstructor@Entitypublic class Comment extends Timestamped { @GeneratedValue(strategy = GenerationType.IDENTITY) @Id @Column(name = \"COMMENT_ID\") private Long idx; @Column(nullable = false) private String nickname; @Column(nullable = false) private String comment; @Column(nullable = false) private Long registryIdd; @Column(nullable = false) private String registryNickname; public Comment(CommentDto commentDto) { this.nickname = commentDto.getNickname(); this.comment = commentDto.getComment(); this.registryId = commentDto.getRegistryId(); this.registryNickname = commentDto.getRegistryNickname(); }관계Registry와 Comment는 일대다 관계이다. (게시글 하나 당 여러 개의 댓글)매핑방향Registry와 Comment 두 도메인 서로 참조하고 있도록 양방향 매핑으로 진행한다.주인1:N 관계에서는 N이 주인이다.따라서 Comment가 주인이므로 매핑종류와 @JoinColumn을 작성해준다.@JoinColumn의 name은 pk를 fk로 설정해서 저장해둘 이름을 작성한다.@ManyToOne // 주인@JoinColumn(name = \"registry_id\")private Registry registry; fetch : 연관관계가 있는 도메인 로딩 전략 설정 옵션 EAGER[이거 로딩] : 즉시 로딩 LAZY[레이지 로딩] : 지연 로딩 ex) @ManyToOne(fetch = FetchType.LAZY) Comment를 불러올 때 연관관계인 Registry도 같이 즉시 조회하고 싶으면 EAGER를 사용하고 LAZY는 필요로 할 때만 쓰인다.default값 @OneToOne, @ManyToOne: EAGER @OneToMany, @ManyToMany: LAZY🐣 EAGER를 사용해 많은 데이터가 로딩되면 부하가 심해서 실무에서는 LAZY로 사용하는 것을 추천한다.🐣 연관관계 맺은것이 많이 써먹는 메소드가 많다면 EAGER를 사용하고 연관관계 맺은 것이 써먹는 게 없으면 LAZY를 사용한다.ex) User와 Registry의 1:N 관계에서 EAGER와 LAZY 쿼리문 차이🐣 1:N 관계에서는 N이 주인일 수 밖에 없는 이유는 RDBMS에서 여러 개의 데이터가 들어갈 수 없기 때문이다.자바에서 객체를 불러올 때는 가능하다.주인이 아닌 클래스(Registry.java)에는 mappedBy 속성으로 주인을 지정한다.일대다 혹은 다대일 매핑에서 일인 클래스에 다인 클래스를 컬렉션으로 적어준다.또한 일대다 컬렉션 타입 필드는 “초기화” 해줘야 한다.@OneToMany(mappedBy = \"registry\")@JsonIgnoreprivate List&lt;Comment&gt; comments = new ArrayList&lt;&gt;(); // 초기화mappedBy에서는 반대쪽 필드 명을 적는 것이다.Comment.java의 private Registry registry;에서 registry를 적은 것이다.초기화하이버네이트는 엔티티를 영속 상태로 만들 때, 컬렉션 필드를 하이버네이트에서 준비한 컬렉션으로 감싸서 사용한다.컬렉션을 효율적으로 관리하기 위해서이며, 이런 특징 때문에 컬렉션을 사용할 때 다음처럼 즉시 초기화해서 사용하는 것을 권장한다.초기화를 시키지 않으면 NullPointerException이 발생한다.CollectionCollection은 List, Set, Map이 있다. Collection : 자바가 제공하는 최상위 컬렉션이다. List : 순서가 있고, 중복을 허용한다. Set : 순서가 없고, 중복은 허용하지 않는다 Map : Key, Value로 되어있으며 키는 중복을 불허한다.양방향 매핑시 조심해야 할 것들 Ex: toString(), lombk , JSON 생성 라이브러리@ToStringComment를 문자열로 표현하기 위해 그 안에 Registry의 toString 을 실행한다.Registry안에 Comment가 있기때문에 Comment의 toString 실행 → Comment안에 Registry가 있기때문에 Profile의 toString 실행….이러한 무한 루프에 빠지게 되는데 이 무한 루프를 순환참조라고 한다.따라서, 양방향 매핑 시 @ToString에서 필드를 제외 시켜줘야한다. → @ToString.Exclude@RestController의 경우 @ResponseBody로 객체를 반환해 줄 때 JSON 형태로 변환해주는데이때도 마찬가지로 매핑된 필드를 제외해줘야한다. → @JsonIgnore매핑 적용하기Comment가 Registry를 가져올수는 있는데 값을 설정해주지 않아서 가져오려면 로직 작성이 필요하다.연관관계를 맺을 때 Registry에서는 Comment가, Comment에는 Registry 로직이 들어가야 하는데setter 어노테이션이 해줄 수 있지만 기본 setter만 해주기 때문에 연관관계 매핑 로직이 포함 되지 않아서 작성해줘야 한다.메소드명은 상관없지만 setter 로직이니깐 setRegistry로 작성했다.Comment.java@ManyToOne // 주이이인@JoinColumn(name = \"registry_id\")private Registry registry; public void setRegistry(Registry registry) { // 기존에 연결된게 있을 경우 초기화 if(this.registry != null) { this.registry.getComments().remove(this); } this.registry = registry; // 무한 루프 안걸리게 하기 if (! registry.getComments().contains(this)) { registry.addComment(this); }}registry.addComment(this); 코드는 아래 Registry에서 addComment()를 작성해 줬기 때문에 이를 활용하여 작성한 것이다.만약 작성하지 않았다면 registry.getComments().add(this); 로 작성해야 할 것이다.Registry.java@OneToMany(mappedBy = \"registry\")@JsonIgnoreprivate List&lt;Comment&gt; comments = new ArrayList&lt;&gt;();public void addComment(Comment comment) { this.comments.add(comment); // 무한 루프 안걸리게 하기 if(comment.getRegistry() != this) { comment.setRegistry(this); }}comments는 리스트 형태이므로 내장 함수인 add()를 활용해 더해준 것이다.🐣 기본 setter와 getterprivate 타입 fieldName// Getterpublic 리턴타입 getFieldName() { return fieldName;}// Setterpublic void setFieldName(타입 fieldName) { this.fieldName = fieldName;}MySQL 같은 RDBMS에 여러 개 데이터가 들어갈 수 없어서 N이 주인이 될 수밖에 없다.같은 이유로 여러 개 데이터가 들어갈 수 없기 때문에 add와 set 메소드 작성이 필요하다.만약 add와 set 메소드를 작성안했다면 값을 설정할 수 없다.ORM이 db 레코드를 객체로 바꿔주거나 객체를 레코드로 바꾸는 과정에서add와 set과 같이 값을 지정해주는 메소드가 없다면 여러 개의 데이터가 들어갈 수 없기 때문에 null로 저장된다.여러 개 데이터 저장 형식에는 List, Set, Map 등이 있다.코드 작성하기실제 비즈니스 로직에 연관관계 매핑 코드를 작성한다. @Transactional public Comment setComment(CommentDto commentDto) { Comment comment = new Comment(commentDto); commentRepository.save(comment); return comment; } @Transactional public Comment setComment(CommentDto commentDto) { Comment comment = new Comment(commentDto); // 연관관계 매핑 Registry registry = registryRepository.findById(comment.getRegistry().getIdx()).get(); comment.setRegistry(registry); commentRepository.save(comment); return comment; }test 코드 작성하기*참고로 객체 GenerationType이 AUTO이면 아래 test가 에러가 날 것이다.(IDENTITY로 수정한다.) 자세한 내용은 아래 글을 참고한다. Generationtype@DisplayName(\"H2를 이용한 TEST\")@DataJpaTestpublic class CommentandRegistryTest { @Autowired RegistryRepository registryRepository; @Autowired CommentRepository commentRepository; @Test void commentSave_Identity() { Registry registry = new Registry(); registry.setNickname(\"coco\"); registry.setTitle(\"안녕하세요\"); registry.setMain(\"hi\"); registryRepository.save(registry); Comment comment = new Comment(); comment.setComment(\"❤️🧡💛💚💙💜🤎🖤\"); comment.setNickname(\"우헤헤\"); comment.setRegistryId(5L); comment.setRegistryNickname(\"pop\"); comment.setRegistry(registry); commentRepository.save(comment); Comment savedComment = commentRepository.findById(1L).get(); Registry savedRegistry = savedComment.getRegistry(); Assertions.assertThat(\"coco\").isEqualTo(savedRegistry.getNickname()); Assertions.assertThat(\"❤️🧡💛💚💙💜🤎🖤\").isEqualTo(savedComment.getComment()); }}참고기존에 작성했던 Registry test 코드에서 매핑한 Comment 값이 없어 에러가 떴다.그래서 생성자 오버로딩을 통해서 기존 값이 오류가 나지 않게 했다. public Registry(long idx, String nickname, String title, String main) { super(); }super와 부모생성자 class가 인스턴스화 될때 생성자가 실행되면서 객체의 초기화를 한다. 그 때 자신의 생성자만 실행이 되는것이 아니고, 부모의 생성자부터 실행된다. public class Car{ public Car(){ System.out.println(\"Car의 기본생성자입니다.\"); } } public class Bus extends Car{ public Bus(){ System.out.println(\"Bus의 기본생성자입니다.\"); } } public class BusExam{ public static void main(String args[]){ Bus b = new Bus(); } } new 연산자로 Bus객체를 생성하면, Bus객체가 메모리에 올라갈때 부모인 Car도 함께 메모리에 올라간다. 생성자는 객체를 초기화 하는 일을한다. 생성자가 호출될 때 자동으로 부모의 생성자가 호출되면서 부모객체를 초기화 하게된다.super자신을 가리키는 키워드가 this 라면, 부모들 가리키는 키워드는 super super() 는 부모의 생성자를 의미한다. 부모의 생성자를 임의로 호출하지 않으면, 부모 class의 기본 생성자가 자동으로 호출된다. 아래처럼 호출해보면 위에서 super()를 호출하지 않을 때와 결과가 같다. public Bus(){ super(); System.out.println(\"Bus의 기본생성자입니다.\"); } super 키워드는 자식에서 부모의 메소드나 필드를 사용할 때도 사용한다. 부모 클래스의 생성자는 한 번만 호출할 수 있다.출처super와 부모생성자" }, { "title": "Generationtype", "url": "/posts/GenerationType/", "categories": "Study", "tags": "DB, study, summary", "date": "2022-11-16 00:00:00 +0900", "snippet": "GenerationTypetest 코드를 실행하면서 생긴 문제들이 GenerationType과 관련되어있어 이를 정리해봤다.GenerationType 에는 AUTO, IDENTITY, SEQUENCE, TABLE 이 있다.AUTOid 값을 null로 하면 DB가 알아서 AUTO_INCREMENT 해준다.기본 설정 값으로 각 데이터베이스에 따라 기본키를 자동으로 생성한다.insert 쿼리 전에 select, update 쿼리가 실행된다.기본 키 제약 조건 null이 아니다. 유일하다. 변하면 안된다방언에 따라 TABLE, IDENTITY, SEQUENCE 3개 중에 하나가 자동으로 지정된다.AUTO로 설정 시 MySQL : IDENTITY Hibernate 5.0부터는 MySQL의 AUTO는 IDENTITY가 아닌 TABLE을 기본 시퀀스 전략으로 선택한다. 관련 글 H2 : SEQUENCE정리이 전에 내가 Comment와 Registry를 AUTO로 설정했을 때내 버전은 5.0 이상인걸로 확인했으나 HIBERANTE SEQUENCE TABLE이 안나왔었다.그래서 해당 글이 맞는지 확신을 못했었는데 블로그 글을 보고 왜 안나왔는지 이유를 알 수 있었다.먼저 정리를 하자면 Spring Boot는 Hibernate의 id 생성 전략을 그대로 따라갈지 말지를 결정하는 useNewIdGeneratorMappings 설정이 있다.// HibernateProperties.java(2.x)/** * Whether to use Hibernate's newer IdentifierGenerator for AUTO, TABLE and SEQUENCE. * This is actually a shortcut for the \"hibernate.id.new_generator_mappings\" property. * When not specified will default to \"true\". */private Boolean useNewIdGeneratorMappings;private void applyNewIdGeneratorMappings(Map&lt;String, Object&gt; result) {\tif (this.useNewIdGeneratorMappings != null) {\t\tresult.put(AvailableSettings.USE_NEW_ID_GENERATOR_MAPPINGS, this.useNewIdGeneratorMappings.toString());\t}\telse if (!result.containsKey(AvailableSettings.USE_NEW_ID_GENERATOR_MAPPINGS)) {\t\tresult.put(AvailableSettings.USE_NEW_ID_GENERATOR_MAPPINGS, \"true\");\t}}Spring Boot 1.5에선 기본값이 false, Spring Boot 2.0부터는 true이다.Spring Boot 2.0 Migration GuideHibernate 5.0부터 MySQL의 AUTO는 IDENTITY가 아닌 TABLE을 기본 시퀀스 전략으로 선택된다.Spring Boot 1.5에선 Hibernate 5를 쓰더라도 AUTO를 따라가지 않기 때문에 IDENTITY가 선택되고, Spring Boot 2.0에선 true이므로 Hibernate 5를 그대로 따라가기 때문에 TABLE이 선택된다.만약 이를 해결하고 싶다면 2가지 방법이 있다.이 중 나는 1번을 적용하고 있어서 TABLE이 아닌 IDENTITY가 되었던 것이다.1. application.properties에서 아래와 같이 false로 설정한다.# do not share idspring.jpa.hibernate.use-new-id-generator-mappings= false2. @GeneratedValue의 전략을 GenerationType.IDENTITY로 지정한다IDENTITY기본키 생성을 db에게 위임하는 방식으로 id값을 따로 할당하지 않아도db가 자동으로 AUTO_INCREMENT를 하여 기본키를 생성해준다.id 값을 null로 하면 DB가 알아서 AUTO_INCREMENT 해준다.JPA는 보통 영속성 컨텍스트에서 객체를 관리하다가 트랜잭션 커밋 시점에 INSERT 쿼리문을 실행한다.하지만 IDENTITY 전략에서는 EntityManager.persist()를 하는 시점에 Insert SQL을 실행하여 DB에서 식별자를 조회해온다.그 이유는 영속성 컨텍스트는 1차 캐시에 PK와 객체를 가지고 관리를 하는데 기본키를 데이터베이스에게 위임했기 때문에EntityManager.persist() 호출 하더라도 DB에 값을 넣기 전까지 기본키를 모르고 있기 때문에 관리가 되지 않기 때문이다.AUTO_INCREMENT는 DB에 INSERT 쿼리문을 실행 한 이후에 ID값을 알 수 있다.영속성 관리 시점에서 1차캐시에 @Id값을 알 수 없다는 말이된다. (IDENTITY 전략은 AUTO_INCREMENT로 동작하기 때문)따라서 IDENTITY 에서는 EntityManager.persist()를 하는 시점에 insert 쿼리를 실행해DB에서 식별자를 조회하여 영속성 컨텍스트 1차 캐시에 값을 넣어주기 때문에 관리가 가능해진다.그렇기에 IDENTITY 에서는 지연쓰기가 제한된다 . (하지만 크게 성능 하락이 있거나 하지는 않다.)Sequence DB Sequence Object를 사용할 때 쓰인다. Current value를 서로 공유한다.(시퀀스 값을 공유해서 사용) 공용 시퀀스 테이블을 두고 모든 테이블의 id 시퀀스를 한 테이블에서 관리한다. Table키 생성 전용 테이블을 하나 만들어서 데이터베이스 시퀀스를 흉내내는 전략Hibernate_Sequence 생성모든 데이터 베이스에서 사용할 수 있지만, 성능이 떨어진다.문제 상황IDENTITY(EntityNotFoundException) @Test void commentSave() { Registry registry = new Registry(); registry.setIdx(3L); // 👈🏻 registry.setNickname(\"coco\"); registry.setTitle(\"안녕하세요\"); registry.setMain(\"hi\"); registryRepository.save(registry); Comment comment = new Comment(); comment.setComment(\"❤️🧡💛💚💙💜🤎🖤\"); comment.setNickname(\"우헤헤\"); comment.setRegistryId(5L); comment.setRegistryNickname(\"pop\"); comment.setRegistry(registry); commentRepository.save(comment); Comment savedComment = commentRepository.findById(1L).get(); Registry savedRegistry = savedComment.getRegistry(); Assertions.assertThat(\"coco\").isEqualTo(savedRegistry.getNickname()); Assertions.assertThat(\"❤️🧡💛💚💙💜🤎🖤\").isEqualTo(savedComment.getComment()); }nested exception is javax.persistence.EntityNotFoundException 에러가 떴다.IDENTITY로 설정 후 3L로 저장했을 때 3L을 갖고오지 못하는 이유는 auto_increment로 인해 1L로 저장이 된다.🐣 해당 에러는 데이터를 저장할 때 @OneToOne, @OneToMany.. 등의 annotation이 선언되어 있을 경우에 매핑된 id값이 0인 경우에 오류가 발생하는 경우가 있다. id값을 null 처리를 하게 되면 조회 할 수 있다. → idx 값 설정을 생략하라는 말AUTO(값을 제대로 못가져 오는 상황)pk를 1L로 저장을 하고 꺼내올 때 1L로 꺼내오려고 하면 에러가 뜨고 계속 2L로 가져오는 상황이 나타났다.@DataJpaTestpublic class CommentandRegistryTest { @Test void commentSave() { Registry registry = new Registry(); registry.setIdx(1L); registry.setNickname(\"coco\"); registry.setTitle(\"안녕하세요\"); registry.setMain(\"hi\"); registryRepository.save(registry); Comment comment = new Comment(); comment.setIdx(1L); comment.setComment(\"❤️🧡💛💚💙💜🤎🖤\"); comment.setNickname(\"우헤헤\"); comment.setRegistryId(5L); comment.setRegistryNickname(\"pop\"); comment.setRegistry(registry); commentRepository.save(comment); System.out.println(\"comment.getComment() : \" + comment.getComment()); Comment savedComment = commentRepository.findById(2L).get(); // ← Registry savedRegistry = savedComment.getRegistry(); System.out.println(\"savedComment : \" + savedComment); System.out.println(\"savedRegistry : \" + savedRegistry); System.out.println(\"(savedRegistry.getComments() : \" +savedRegistry.getComments()); }}Comment의 GenerationType을 AUTO로 설정했었는데 IDENTITY로 바꾸면서 정상적으로 1L로 값을 가져왔다.여기서 @DataJpaTest를 사용했기 때문에(H2) AUTO는 SEQUENCE이다.그러므로 Current value로 값을 공유해서 먼저 저장한 것이 l, 이후에 저장한 것이 2로 나오게 된 것이다.test 해보기왜 AUTO로 설정하면 값이 1L이 아닌 2L로 저장이 될까???Registry와 Comment 설정을 AUTO(@GeneratedValue(strategy = GenerationType.AUTO))로 하고아래 코드를 작성한 후 출력시켰다.@Test void autoTest() { Registry registry1 = new Registry(); registry1.setNickname(\"coco\"); registry1.setTitle(\"안녕하세요\"); registry1.setMain(\"hi\"); Comment comment1 = new Comment(); comment1.setComment(\"❤️🧡💛💚💙💜🤎🖤\"); comment1.setNickname(\"우헤헤\"); comment1.setRegistryId(5L); comment1.setRegistryNickname(\"pop\"); comment1.setRegistry(registry1); Registry savedRegistry1 = registryRepository.save(registry1); Comment savedComment1 = commentRepository.save(comment1); System.out.printf(\"%s idx : %d\\n\", \"comment\", savedComment1.getIdx()); System.out.printf(\"%s idx : %d\\n\", \"registry\", savedRegistry1.getIdx()); }둘다 1로 나올 것만 같았지만 결과는 1과 2로 나왔다.Current value로 값을 공유해서 먼저 저장한 것이 l, 이후에 저장한 것이 2로 저장한것이 아닐까 라는 생각으로Comment와 Registry를 하나씩 더 추가해봤다.저장된 순서대로 값이 출력되고 있었고 idx 값을 공유하고 있다고 판단할 수 있었다.H2 콘솔로 확인을 해봤다.H2applicationtest이번엔 Comment와 Registry를 SEQUENCE로 바꾸고 application을 실행해봤다.h2로 실행해보니 HIBERNATE_SEQUENCE가 생겼다. 그런데 2개를 변경했는데 HIBERNATE_SEQUENCE는 하나만 생긴 것을 볼 수 있다.*HIBERNATE_SEQUENCE 아래 SYSTEM_SEQUENCE는 기존에 있던 다른 클래스로 인해 생긴 것여기서 몇 가지를 파악할 수 있었다. AUTO로 설정하면 test 코드에서 Current value를 서로 공유하는 것을 볼 수 있었다. H2는 auto가 SEQUENCE이기 때문에 Current value를 공유하는 것을 볼 수 있다. application으로 실행하면 Syestem_Sequence가 떴고 test에서는 table hibernate_sequences가 생성되었다.이번에는 TABLE로 변경해봤다.MySQL이번엔 MySQL로 Test 해봤다.MySQL도 TEST 해본 결과 H2에서는 뜨던 SYSTEM_SEQUENCE가 뜨지 않고 SEQUENCE로 설정하거나 TABLE로 설정했을 시 HIBERNATE SEQUENCE가 뜨는 것을 볼 수 있었다.MySQL에는 시퀀스 기능이 없다고한다. 그래서 sequence전략 사용시 hibernate_sequence 테이블을 생성한다.이를 통해서 SEQUENCE와 TABLE의 차이는 HIBERANTE SEQUENCE TABLE을 만들지만 SEQUENCE는 Current value를 공유하고 table은 공유하지 않는다는 차이점도 파악할 수 있었다.정리EntityManager.persist()를 하는 시점에 기본키를 알면 AUTO, 모르면 IDENTITY 어떤 db냐에 따라서 AUTO가 바뀐다. 버전 차이에 따라서 AUTO 기본 값이 다르다. MySql, H2 DB인 경우 SEQUENCE일 때 Current value를 공유한다. GenerationType을 잘 모르는 상황에서 AUTO로 작성했을 때 어떻게 돌아가는지 모르는 경우 위험하다.따라서 직접 정해서 작성해주는 것이 좋은데 MySQL에서는 SEQUENCE 기능을 제공하지 않고 있다.사실상 TABLE과 IDENTITY인데 TABLE을 생성하기 보다는 IDENTITY로 하는게 낫다고 생각한다.그래서 AUTO 쓸 바에는 IDENTITY 쓴다.😂출처 @GeneratedValue 전략 (JPA) JPA @Id GenerationType.AUTO, IDENTITY 차이 [JPA] @GeneratedValue AUTO와 IDENTITY 차이점 [JPA] 기본키(PK) 매핑 방법 및 생성 전략 javax.persistence.EntityNotFoundException: Unable to find … with id 0 에러 엔티티 매핑 Spring Boot Data JPA 2.0 에서 id Auto_increment 문제 해결 Hibernate 기본키 전략은 무엇을 사용해야 할까?" }, { "title": "Binary search and linear search", "url": "/posts/Binary-Search-and-Linear-Search/", "categories": "Study", "tags": "study, summary, 자료구조, 알고리즘, 강의", "date": "2022-11-14 00:00:00 +0900", "snippet": "Binary Search(이진검색 알고리즘) &amp; Linear Search(선형검색 알고리즘)아래 강의를 보고 정리한 글이다. 검색 알고리즘? 기초개념 잡아드림. 10분 순삭.이 둘은 Search 알고리즘에 속해있다.🐣 다른 알고리즘으로는 Sorting이 있다. 정렬 알고리즘에서는 자료를 정리한다.Linear Search처음부터 끝까지 검색한다.배열이 커지면 커질수록 선형검색을 하는 시간이 길어진다.이것을 Linear Time Complexity(선형 시간 복잡도)라고 한다.→ input이 많으면 많을 수록 수행하는 시간 역시 선형적으로 증가한다이것보다 발전된 방법이 Binary Search(이진 검색 알고리즘)이다.Binary Search이진 검색에서 이진은 반으로 쪼개는 것을 의미한다.선형검색과 달리 이진검색에서는 인덱스 0부터 (처음부터) 검색을 하지 않는다.이진 검색에서는 중간에서 시작한다.정 가운데에 있는 숫자가 우리 목표 숫자보다 큰지 작은지를 본다. (n &gt; target?)만약 목표보다 크다면 아이템의 왼쪽으로 갈 것이다.input이 2배가 되어도 필요한 스텝은 2배가 되지 않는다.이진 검색은 매 스텝마다 절반의 아이템을 없애기 때문이다.10 items → 20 items 3 steps → 4 steps→ 우리의 자료가 2배가 되어도 작업을 수행하는데 필요한 스텝은 +1이 될 것이다.장점큰 사이즈의 데이터를 처리할 때 효과적이다.단점Binary Search는 모든 배열에 쓸 수 없고 정렬된 배열(Sorted Array)에서만 사용가능하다.Linear Search는 어느 배열에서도 가능하지만 Binary Search는 아니다.🐣 What is a Sorted Array? 배열이 순서대로 정렬된 경우를 뜻한다.정렬된 배열에 아이템을 추가하는 것은 정렬이 안된 경우보다 시간이 더 걸리지만정렬된 배열에서 검색을 하는 것은 정렬이 안된 경우보다 시간이 훨씬 빠르다.넣어야 할 값보다 큰 값을 찾기 위해 아이템들을 하나하나 비교해야하고이를 통해 포지션을 찾고 나면 해당 아이템 오른쪽에 있는 모든 것을 옮겨야한다. (넣어야 할 값보다 큰 값의 왼쪽에 넣어야하므로)하지만 이렇게 배열에 추가하고 정렬하는 것에 시간을 더 투자하면 검색을 하는 순간 빨라지게 된다.정리이진 검색은 거대한 배열을 다룰 때 효과적이다.그러나 이진 검색을 하고 싶다면 배열을 정리해야한다.검색을 많이 하는 상황이라면 정렬을 해야한다하지만 배열 정렬을 하려면 아이템 추가시 시간이 소요된다.이러한 관계를 인지해야한다." }, { "title": "@springboottest와 @datajpatest 차이", "url": "/posts/@SpringBootTest%EC%99%80-@DataJpaTest-%EC%B0%A8%EC%9D%B4/", "categories": "Study", "tags": "spring, study, summary", "date": "2022-11-13 00:00:00 +0900", "snippet": "@SpringBootTest와 @DataJpaTest 차이연관관계 매핑 test를 하기 위해 어노테이션 설정을 했다.이 전에 실제 db가 아닌 h2로 테스트 하기 위해서 test용 application으로 설정했었다.@TestPropertySource(locations = \"/application.properties\")또, @Transactional을 설정했는데 이를 한꺼번에 해주는 어노테이션이 있었다.🐣 @Transactional @Transactional을 사용하는 이유는 트랜잭션 처리를 하기 위해서다. 일련의 작업들을 묶어서 하나의 단위로 처리 자동으로 트랜잭션을 걸어서 테스트를 실행해주고 끝날 때는 rollback 처리를 해준다. 관련 글 @SpringBootTest full application config을 로드해서 통합 테스트를 진행하기 위한 어노테이션이다. ApplicationContext에 모든 Bean들을 등록한다. SpringBoot 어플리케이션을 실행했을 때와 동일하게 컨테이너에 Bean들을 등록한다. 설정해놓은 config, context, components를 모두 로드한다. DataSource bean을 그대로 사용하기 때문에 in-memory, 로컬, 외부 상관 없이 DB를 사용해서 테스트가 실행된다. 테스트할 때마다 DB가 롤백되지 않기 때문에 @Transactional을 추가로 설정해줘야 한다.@DataJpaTest @DataJpaTest 어노테이션은 JPA 관련 테스트 설정만 로드한다. Component Scan을 하지 않아 컨테이너에 @Component 빈들이 등록되지 않는다. JPA를 사용하여 데이터를 제대로 생성, 수정, 삭제하는지 등의 테스트가 가능하다. 기본적으로 in-memory embedded DB를 사용한다. (Replace.ANY;) @Transactional이 포함되어있다.@AutoConfigureTestDatabase@DataJpaTest에 있는 @AutoConfigureTestDatabase에 Replace.ANY;를 통해서실제 db를 사용하지 않고 테스트 db로 테스트 할 수 있다. (기본적으로 내장된 임베디드 데이터베이스를 사용한다.)Any 속성 외에도 AUTO_CONFIGURED와 NONE이 있다. ANY 자동 구성, 수동 구성된 DataSource 빈 모두 교체함 AUTO_CONFIGURED 자동 구성된 DataSource 빈만 교체함 NONE 어플리케이션에 기본 값으로 설정된 DataSource를 교체하지 않음 @DataJpaTest에서 in-memory 데이터베이스로 사용할 수 있는 db 유형EmbeddedConnection으로 제공하고 있는것은 H2, DERBY, HSQL을 제공하고 있다.실제 db를 사용하려면?@AutoConfigureTestDatabase(replace = AutoConfigureTestDatabase.Replace.NONE)를 작성한다.정리기존 프로젝트에서 @SpringBootTest를 사용한 test 코드를 작성했을 때db를 h2로 사용했을 때는 문제가 없었으나 mysql로 변경하면서@SpringBootTest 어노테이션이 존재하는 클래스는테스트를 실행하면 @SpringBootApplication 어노테이션을 검색하고@SpringBootApplication에서 설정된 값을 읽어와서, 테스트에서 사용하기 때문에 mysql로 연결이 되었다.테스트 코드에서는 기존 db대신 test용 임시 데이터로 사용해야 해서test용 application.properties에서 h2 설정을 하고 여러 어노테이션을 붙였었는데Jpa 관련 테스트를 할 때는 @DataJpaTest를 사용하는게 더 좋고 @SpringBootTest 보다 실행 속도가 더 빠르다.출처 Spring DB : DB 테스트 [Spring] @SpringBootTest vs @DataJpaTest [JPA] DataJpaTest: 테스트시에 실제 DB 사용하기 💥[@DataJpaTest] Error creating bean with name ‘dataSource’ 에러 스프링 부트 테스트 : @DataJpaTest [Spring Boot] @DataJpaTest vs @SpringBootTest 비교" }, { "title": "Oop", "url": "/posts/OOP/", "categories": "Study", "tags": "study, summary, 강의, Java", "date": "2022-11-11 00:00:00 +0900", "snippet": "OOP아래 강의를 보고 정리했다. 객체지향 프로그래밍? 문과도 이해쌉가능. 10분컷.객체지향 프로그래밍은 코드를 작성(정리)하는 방법이다.예시게임을 하는데 캐릭터 객체(object)가 필요하다.한명의 캐릭터만 만든다면 아래와 같이 코딩하면 된다.const character = { name : \"nana\", health : 75, skill : \"Programmer\",}하지만 그 숫자가 늘어나면 문제가 발생한다.const character = { name : \"nana\", health : 75, skill : \"Programmer\",}const character1 = { name : \"coco\", health : 95, skill : \"Legend\",}const character2 = { name : \"lula\", health : 85, skill : \"Normal\",}해당 캐릭터들은 모두 같은 속성을 가지고 있으며 다른 점은 데이터 뿐이다.여기서 문제는 캐릭터 구성에 대한 ‘구조’가 없다는 것이다.skill을 빼먹는다거나 오타가 날 수 있다.이렇게 코드 복제를 해서 캐릭터를 생성하는 것의 문제점은새로운 속성 ‘성별’을 추가하고 싶다면 일일히 하나씩 추가해야한다는 점이다.좋은 방법은 일종의 ‘캐릭터 팩토리’를 만드는 것이다.→ 데이터만 넣으면 적용해주는 함수가 있고 캐릭터 객체를 output으로 얻을 수 있게 해준다.→ 속성을 추가하고 싶으면 ‘캐릭터 팩토리’에서 속성 하나만 추가하면 된다.이것이 바로 Class의 개념이다.ClassClass는 객체를 위한 팩토리와 같은 것이다.👉🏻 같은 속성을 갖고 있지만 데이터는 다른 경우Class는 일종의 구조. 설계도로써 수많은 캐릭터들을 생산할 수 있다.캐릭터 객체가 어떻게 보여야 하는지에 대한 도면을 정의해준다.class Character { String name; int health; String skill; public Character(String name, int health, String skill) { this.name = name; this.health = health; this.skill = skill; } public static void main(String[] args) { Character na = new Character(\"na\", 75, \"Programmer\"); Character coco = new Character(\"Coco\", 95, \"Legend\"); Character lula = new Character(\"Lula\", 85, \"Normal\"); }}이제는 코드를 복사할 필요가 없다.또한 속성에 접근할 수도 있다.Character coco = new Character(\"Coco\", 95, \"Legend\");System.out.println(coco.health);Character coco = new Character(“Coco”, 95, “Legend”);의‘coco’를 캐릭터 클래스의 인스턴스 혹은 객체로 지정한다.여기서 인스턴스는 캐릭터 class를 사용한 후 얻을 수 있는 캐릭터에 속한다.Methodclass Character { String name; int health; String skill; public String greet() { return \"안녕하세요. \" + name + \"입니다.\"; }}greet()는 함수이지만 클래스 내에 있기 때문에 Method(메소드)라고 부른다.파라미터에 name을 주지 않아도 되는 이유는 필드에 변수 name을 선언하였고 생성자를 작성해서 name을 전달 받기 때문에 그 값을 받아 올 수 있으므로 파라미터를 작성하지 않아도 된다.생성자public Character(String name, int health, String skill) { this.name = name; this.health = health; this.skill = skill;}생성자는 멤버 변수의 초기화를 목적으로 가지는 함수 이므로 인수를 통해 값을 전달받을 수 있다.모든 캐릭터가 health를 100으로 시작하게끔 프로그래밍 할 수도 있다.public Character(String name, String skill) { this.name = name; this.health = 100; this.skill = skill;}this라는 단어는 캐릭터 클래스 내의 속성 및 메소드를 지칭하는 방법이다.상속(Inheritance)코드 중복을 줄이고 코드를 재사용 가능한 조각으로 나눌 수 있다.자식 클래스가 부모 클래스의 속성을 갖게 된다.Human.javaclass Human { String name; Integer arms; Integer legs; public Human(String name) { this.name = name; this.arms = 2; this.legs = 2; }}🐣 만일 arms = 2를 모든 사람한테 적용시킨다면 아래와 같이 작성하면 된다.class Human { String name; static final Integer arms = 2; Integer legs; public Human(String name) { this.name = name; this.legs = 2; }}Baby.javaclass Baby { String name; Integer arms; Integer legs; boolean cute; public Baby(String name) { this.name = name; this.arms = 2; this.legs = 2; this.cute = true; } String cry() { return \"waa\"; }}Teenager.javaclass Teenager { String name; Integer arms; Integer legs; boolean emotional; public Teenager(String name) { this.name = name; this.arms = 2; this.legs = 2; this.emotional = true; } String curse() { return \"#$!$@#$@#$@\"; }}여기서 코드 중복이 일어난다.모든 클래스에 this.name, this.arms, this.legs를 적는 대신this.name, this.arms, this.legs를 가진 클래스에서 확장 하면 된다.해당 클래스는 ‘Human’이 된다.Baby.javaclass Baby extends Human { boolean cute; public Baby(String name) { super(name); this.cute = true; } String cry() { return \"waa\"; }}Teenager.javaclass Teenager extends Human { boolean emotional; public Teenager(String name) { super(name); this.emotional = true; } String curse() { return \"#$!$@#$@#$@\"; }}Baby, Teenager 클래스가 Human 클래스의 속성을 모두 갖고 추가적으로 그들만의 다른 속성을 갖기를 원한다는 뜻이다.코드 동작 시키기Human의 이름을 정해주면 해당 코드는 동작한다.단, Baby, Teenager 클래스에서 Human의 메소드를 호출하려면 해당 클래스에서 Super method 라는 것을 호출해야한다.class Baby extends Human { boolean cute; public Baby(String name) { super(name); this.cute = true; } String cry() { return \"waa\"; } public static void main(String[] args) { Baby baby = new Baby(\"coco\"); System.out.println(baby.name); System.out.println(baby.arms); System.out.println(baby.legs); System.out.println(baby.cute); System.out.println(baby.cry()); }}" }, { "title": "함수형 프로그래밍", "url": "/posts/%ED%95%A8%EC%88%98%ED%98%95-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/", "categories": "Study", "tags": "study, summary, 강의", "date": "2022-11-10 00:00:00 +0900", "snippet": "함수형 프로그래밍아래 강의를 보고 정리한 글이다. 연봉이 떡상한다고? 함수형 프로그래밍! 10분만에 이해하기. 함수형 프로그래밍이 뭔가요?함수형 프로그래밍은 코드 작성 스타일이라고 할 수 있다.함수형 방식에서는 버그 자체가 발생하기 어렵다.명령형(imperative)코드와 선언형(declarative)코드를 살펴본다.선언형(declarative)코드선언형 코드는 원하는 결과값을 선언하는 것이다. 이거는 이거다. input만 똑같으면 절대 다른 요인에 의한 변수가 없다.대표적인 예로 css가 있다.배경색을 바꾸고 싶으면 background-color : blue;라고 적으면 된다. *원하는 결과를 얻기 위한 단계를 작성하지 않았다.명령형(imperative)코드그 결과값에 어떻게 도달하느냐에 관한 것이다. 너는 이렇게 하고 이렇게 하고 이렇게 해코드 예시text 문자열에서 공백을 제거하고 0으로 대체하는 함수를 만든다고 가정한다.명령형(imperative)코드let name = \"안녕하세요 haedal blog 입니다.\"console.log(spaceToZero(name))function spaceToZero(text) { let result = \"\" ; for (let i=0; i &lt; text.length; i++) { if (text[i] === \" \") { result += \"0\"; } else { result += text[i]; } } return result;} 최종 결과를 보유할 변수를 만들고 있다. 완료 후 결과를 리턴한다.→ 요구사항을 충족하는데 필요한 모든 단계를 하나씩 적고 있다.선언형(declarative)코드function spaceToZero(text) { return text.replaceAll(\" \", \"0\");} replaceAll이라는 메소드를 사용했다. 첫 번째 인수는 바꾸고 싶은 텍스트, 두번째 인수는 이를 무엇으로 바꿀 것인가→ 명령함수와 동일한 결과를 갖지만 읽기가 더 쉽고 함수가 무슨 역할을 하는지 이해하기 편하다.replaceAll 함수의 내부 작업에서는 이전에 작성한 명령형 코드가 있을 수 있다.그래서 모든 선언형 코드는 명령 코드 위에 쓰여진다고 말할 수 있다.명령형 방식에서 코드가 길어지는 것 외에 또 다른 문제점은 요구 사항의 구현이 개발자에게 달려 있기 때문에 코드를 원하는대로 작성하다보면 버그나 실수가 생길 수 있다.또, 함수가 정확히 무엇을 하려고 하는지 한줄 한줄 읽어야 하므로 다른 팀원들이 이해하기 어려울 수도 있다.정리함수형 프로그래밍은 코드 스타일의 차이다.메소드를 구현해서 다른 곳에서 쓰이면 “선언형“인 것이고해당 메소드를 구현한 전체 코드가 “명령형“이다." }, { "title": "Print", "url": "/posts/print/", "categories": "Study", "tags": "study, summary, Java", "date": "2022-11-10 00:00:00 +0900", "snippet": "print강의에서 나오는 파이썬 코드를 자바 코드로 바꾸면서 정리하던 도중에파이썬에서는 바로 출력할 수 있는 것을 자바에서는 불가능 한 것을 보고 짧게 정리해봤다.코드def print_twice(arr) : for n in arr : for x in arr : print(x, n)위 코드를 자바 코드로 바꾸려고 하면 아래와 같이 에러가 뜬다.1번은 안되고 2번은 되는 이유는 뭘까?그 이유는 파이썬은 구현되어있는데 자바는 구현이 안되어 있기 때문이다.🤔 그게 무슨말이지??System.out.println 을 타고 들어가면 오버라이드 된게 뜬다. public void println(int x) { if (getClass() == PrintStream.class) { writeln(String.valueOf(x)); } else { synchronized (this) { print(x); newLine(); } } }해당 코드들을 보면 println은 하나만 출력된다.그래서 String이든 int든 여러 개를 출력 시키려고 하면 에러가 뜨기 때문에둘다 출력 시키려고 하면 2번과 같이 문자열 포매팅을 써서 출력 시키는 것이다.String[] arr = {\"hae\", \"dal\", \"coco\", \"lulu\", \"hihi\", \"lala\", \"inging\"}; public void printAll() { for(int i=0; i&lt;arr.length; i++) { for(int j=0; j&lt;arr.length; j++) { System.out.printf(\"%d, %d\", i, j); //System.out.println(String.format(\"%d, %d\", i, j)); } }}🐣 return값도 하나 씩만 출력시키므로 2개 이상 return 하고 싶으면 Map, Dto, Vo 같은 객체를 만들어서 보내면 된다." }, { "title": "Big o", "url": "/posts/Big-O/", "categories": "Study", "tags": "study, summary, 자료구조, 알고리즘, 강의", "date": "2022-11-09 00:00:00 +0900", "snippet": "Big O참고로 아래 영상을 보면서 정리한 글이다. 개발자라면 이제는 알아야하는 Big O 설명해드림. 10분컷.알고리즘 스피드의 표현법같은 알고리즘 이라도 컴퓨터라는 하드 웨어에 따라서 컴퓨터 마다 속도가 다를 수 있다.그렇기 때문에 “빠르다”, “느리다” 라는 “시간”으로 표현하지 않는다.👉🏻 알고리즘 스피드는 “완료까지 걸리는 절차의 수”로 결정 된다.Linear Search(선형 검색)선형 검색은 한 개씩 검색을 한다. 데이터가 10개면 해당 값을 찾기 까지 10개 스텝이 필요하다.→ input size = N 이라면 선형 알고리즘은 N steps 가 요구된다.→ 선형 검색의 시간 복잡도는 O(n)을 갖는다.이렇듯 Big O를 사용하면 시간 복잡도를 빠르게 설명할 수 있다.O(1) : constant timeinput size에 관계 없이 step이 정해진 알고리즘public class BigO { String[] arr = {\"hae\", \"dal\", \"coco\", \"lulu\", \"hihi\", \"lala\", \"inging\"}; public void printFirst() { System.out.println(arr[0]); // 배열의 첫 번째 요소 출력 } public static void main(String[] args) { BigO bigO = new BigO(); bigO.printFirst(); }}input size = 7이고 해당 함수는 1번이면 실행이 끝난다.input size가 100개가 된다 해도 끝내는 것은 1번이면 된다.→ input이 얼마나 큰지 작은지에 관계 없이 해당 함수는 동일한 수의 스텝이 필요하다.→ 이 함수의 시간 복잡도는 constant time (상수시간) 이라고 할 수 있다.N이 크기에 관계 없이 끝내는데 동일한 숫자의 스텝이 필요하다.이것을 Big O로 표현하면 O(1)이다.만약 출력을 2번 하면 2개의 스텝이 필요하므로 시간 복잡도는 O(2)가 될까?public void printFirst() { System.out.println(arr[0]); System.out.println(arr[0]);}답은 ❌로 시간 복잡도는 O(1)이다.Big O는 함수의 디테일에 신경을 쓰지 않고 input size에 따라 어떻게 이 함수가 작동하는지를 본다.해당 함수는 input size에 관계없이 정해진 숫자에 따라 작동한다.따라서 출력을 여러 번 시켜도 O(1)이 된다.🐣 Big O는 상수(constant)에 신경을 쓰지 않는다!O(N)public class BigO { String[] arr = {\"hae\", \"dal\", \"coco\", \"lulu\", \"hihi\", \"lala\", \"inging\"}; public void printAll() { for(int i=0; i&lt;arr.length; i++) { System.out.println(i); } } public static void main(String[] args) { BigO bigO = new BigO(); bigO.printAll(); }}이번에는 각 값들을 모두 출력시키는 함수다. → 배열 사이즈가 7이라면 7번 출력 시킨다.만약 배열이 N개라면 N개 스텝으로 나올 것이다. (input이 증가하면 step도 증가한다.)이를 Big O로 표현하면 O(N)이다.🐣 함수를 반복해도 O(2N)이 아니라 O(N)이다. (상수는 버린다.)O(n^2)루프 안의 루프안에서 함수를 실행시켰다.public void printAll() { for(int i=0; i&lt;arr.length; i++) { for(int j=0; j&lt;arr.length; j++) { System.out.printf(\"%d, %d\", i, j); } }}배열의 각 값에 대해 루프를 반복하여 실행input이 7개 라면 완성하는데 49번의 스텝이 필요하다.👉🏻 시간 복잡도는 input의 n^2이다.O(logN) : Logarithmic time(로그 시간)*로그(logarithm)는 지수(exponent)의 정 반대다.이진 검색 알고리즘 설명할 때 쓰인다. (이진 검색은 정렬되지 않은 배열에 사용할 수 없다.)이진 검색은 각 프로세스의 스텝을 매번 절반으로 나눠서 진행하기 때문에 input size가 2배가 되어도 스텝은 1밖에 증가를 안한다.10 items → 20 items and 3 steps → 4 steps👉🏻 시간 복잡도는 O(log N)선형 시간보다는 빠르고 상수 시간보다는 느리다.🐣 Big O에서는 base를 쓰지 않는다.5 = log2(32)에서 32의 밑이 2인데 Big O의 특성상 및 숫자는 사라진다.5 = log (32)정리" }, { "title": "Linkedlist 코드 구현", "url": "/posts/LinkedList-%EC%BD%94%EB%93%9C-%EA%B5%AC%ED%98%84/", "categories": "", "tags": "", "date": "2022-11-08 00:00:00 +0900", "snippet": "code단일 연결 리스트데이터와 다른 노드를 가리킬 주소 데이터를 담을 객체가 필요하다. → 노드(node)사용자가 저장할 데이터는 data 변수에 담기고, reference 데이터(참조 데이터)는 다음에 연결할 노드를 가리키는 데이터가 담긴다.위와같은 노드들이 여러개가 연결 되어있는 것을 연결 리스트, 즉 LinkedList라고 한다.이렇게 연결된 노드들에서 ‘삽입‘을 한다면 링크만 바꿔주면 되기 때문에 매우 편리하며,반대로 ‘삭제‘를 한다면 삭제 할 노드에 연결 된 이전노드에서 링크를 끊고 삭제할 노드의 다음 노드를 연결해주면 된다.Node 구현가장 기본적인 데이터를 담을 Node 클래스를 먼저 구현해줘야한다.class Node&lt;E&gt; { E data; Node&lt;E&gt; next; // 다음 노드객체를 가리키는 래퍼런스 변수 Node(E data) { this.data = data; this.next = null; }}next 가 앞서 그림에서 보여주었던 Reference 변수다.다음 노드를 가리키는 변수이며, ‘노드 자체’를 가리키기 때문에 타입 또한 Node&lt;E&gt;타입으로 지정해주어야 한다.그리고 위 노드를 이용하기 위한 단일 연결리스트(Singly LinkedList)를 구현하면 된다.List Interfacepublic interface List&lt;E&gt; { boolean add(E value); void add(int index, E value); E remove(int index); boolean remove(Object value); E get(int index); void set(int index, E value); boolean contains(Object value); int indexOf(Object value); int size(); boolean isEmpty(); public void clear(); } boolean add(E value); 리스트에 요소를 추가한다. @param : value 리스트에 추가할 요소 @return : 리스트에서 중복을 허용하지 않을 경우에 리스트에 이미 중복되는 요소가 있을 경우 {@code false}를 반환하고, 중복되는 원소가 없을경우 {@code true}를 반환 void add(int index, E value); 리스트에 요소를 특정 위치에 추가한다. 특정 위치 및 이후의 요소들은 한 칸씩 뒤로 밀린다. @param : index 리스트에 요소를 추가할 특정 위치 변수 @param : value 리스트에 추가할 요소 E remove(int index); 리스트의 index 위치에 있는 요소를 삭제한다. @param : index 리스트에서 삭제 할 위치 변수 @return : 삭제된 요소를 반환 boolean remove(Object value); 리스트에서 특정 요소를 삭제합니다. 동일한 요소가 여러 개일 경우 가장 처음 발견한 요소만 삭제된다. @param : value 리스트에서 삭제할 요소 @return : 리스트에 삭제할 요소가 없거나 삭제에 실패할 경우 {@code false}를 반환하고 삭제에 성공할 경우 {@code true}를 반환 E get(int index); 리스트에 있는 특정 위치의 요소를 반환한다. @param : index 리스트에 접근할 위치 변수 @return : 리스트의 index 위치에 있는 요소 반환 void set(int index, E value); 리스트에서 특정 위치에 있는 요소를 새 요소로 대체한다. @param : index 리스트에 접근할 위치 변수 @param : value 새로 대체할 요소 변수 boolean contains(Object value); 리스트에 특정 요소가 리스트에 있는지 여부를 확인한다. @param : value 리스트에서 찾을 특정 요소 변수 @return : 리스트에 특정 요소가 존재할 경우 {@code true}, 존재하지 않을 경우 {@code false}를 반환 int indexOf(Object value); 리스트에 특정 요소가 몇 번째 위치에 있는지를 반환한다. @param : value 리스트에서 위치를 찾을 요소 변수 @return : 리스트에서 처음으로 요소와 일치하는 위치를 반환, 만약 일치하는 요소가 없을경우 -1 을 반환 int size(); 리스트에 있는 요소의 개수를 반환 @return : 리스트에 있는 요소 개수를 반환 boolean isEmpty(); 리스트에 요소가 비어있는지를 반환한다. @return : 리스트에 요소가 없을경우 {@code true}, 요소가 있을경우 {@code false}를 반환 public void clear(); 리스트에 있는 요소를 모두 삭제한다. SingleLinked 클래스List 인터페이스를 implements 해준다.public class SingleLinked&lt;E&gt; implements List&lt;E&gt; { private Node&lt;E&gt; head; // 노드의 첫 부분 private Node&lt;E&gt; tail; // 노드의 마지막 부분 private int size; // 요소 개수 // 생성자 public SingleLinked() { this.head = null; this.tail = null; this.size = 0; }} Node head : 리스트의 가장 첫 노드를 가리키는 변수다. Node tail : 리스트의 가장 마지막 노드를 가리키는 변수다. size : 리스트에 있는 요소의 개수(=연결 된 노드의 개수) 처음 단일 연결리스트를 생성 할 때에는 아무런 데이터가 없으므로head와 tail이 가리킬 노드가 없기에 null로 초기화 및 size는 0으로 초기화해준다.search 메소드 구현단일 연결리스트이다보니 특정 위치의 데이터를 삽입, 삭제, 검색하기 위해서는처음 노드(head)부터 next변수를 통해 특정 위치까지 찾아가야 하기 때문에 search() 메소드를 작성한다.// 특정 위치의 노드를 반환하는 메소드private Node&lt;E&gt; search(int index) {\t\t // 범위 밖(잘못된 위치)일 경우 예외 던지기 if(index &lt; 0 || index &gt;= size) { throw new IndexOutOfBoundsException(); }\t\t Node&lt;E&gt; x = head;\t// head가 기리키는 노드부터 시작 \t\t for (int i = 0; i &lt; index; i++) { x = x.next;\t// x노드의 다음 노드를 x에 저장한다 } return x;}add 메소드 구현 가장 앞부분에 추가 - addFirst(E value) 가장 마지막 부분에 추가 (기본값) - addLast(E value) 특정 위치에 추가 - add(int index, E value) addFirst(E value) : 가장 앞부분에 추가public void addFirst(E value) { Node&lt;E&gt; newNode = new Node&lt;E&gt;(value); // 새 노드 생성 newNode.next = head; // 새 노드의 다음 노드로 head 노드를 연결 head = newNode; // head가 가리키는 노드를 새 노드로 변경 size++; if (head.next == null) { tail = head; }}if (head.next == null) {tail = head;}다음에 가리킬 노드가 없는 경우(=데이터가 새 노드밖에 없는 경우)데이터가 한 개(새 노드)밖에 없으므로 새 노드는 처음 시작노드이자 마지막 노드다.즉 tail = head 다.addLast(E value) : 가장 마지막 부분에 추가public boolean add(E value) { addLast(value); return true;} public void addLast(E value) { Node&lt;E&gt; newNode = new Node&lt;E&gt;(value); // 새 노드 생성 if (size == 0) { // 처음 넣는 노드일 경우 addFisrt로 추가 addFirst(value); return; } \t // 마지막 노드(tail)의 다음 노드(next)가 새 노드를 가리키도록 하고 // tail이 가리키는 노드를 새 노드로 바꿔준다. tail.next = newNode; tail = newNode; size++;}add(int index, E value) : 특정 위치에 추가@Overridepublic void add(int index, E value) { // 잘못된 인덱스를 참조할 경우 예외 발생 if (index &gt; size || index &lt; 0) { throw new IndexOutOfBoundsException(); } // 추가하려는 index가 가장 앞에 추가하려는 경우 addFirst 호출 if (index == 0) { addFirst(value); return; } // 추가하려는 index가 마지막 위치일 경우 addLast 호출 if (index == size) { addLast(value); return; }\t\t // 추가하려는 위치의 이전 노드 Node&lt;E&gt; prev_Node = search(index - 1);\t // 추가하려는 위치의 노드 Node&lt;E&gt; next_Node = prev_Node.next; // 추가하려는 노드 Node&lt;E&gt; newNode = new Node&lt;E&gt;(value);\t\t\t // 이전 노드가 가리키는 노드를 끊은 뒤 새 노드로 변경해준다. // 또한 새 노드가 가리키는 노드는 next_Node로 설정해준다. prev_Node.next = null; prev_Node.next = newNode; newNode.next = next_Node; size++; }remove 메소드 구현 가장 앞의 요소(head)를 삭제 - remove() 특정 index의 요소를 삭제 - remove(int index) 특정 요소를 삭제 - remove(Object value) remove() : 처음 노드 삭제remove() 는 ‘가장 앞에 있는 요소’를 제거하는 것이다.→ head 가 가리키는 요소만 없애주면 된다는 뜻public E remove() { Node&lt;E&gt; headNode = head; if (headNode == null) throw new NoSuchElementException();\t\t // 삭제된 노드를 반환하기 위한 임시 변수 E element = headNode.data;\t\t // head의 다음 노드 Node&lt;E&gt; nextNode = head.next;\t\t // head 노드의 데이터들을 모두 삭제 head.data = null; head.next = null;\t\t // head 가 다음 노드를 가리키도록 업데이트 head = nextNode; size--;\t\t // 삭제된 요소가 리스트의 유일한 요소였을 경우 그 요소는 head 이자 tail이었으므로 // 삭제되면서 tail도 가리킬 요소가 없기 때문에 size가 0일경우 tail도 null로 변환 if(size == 0) { tail = null; } return element;}리스트에 아무런 요소가 없는데 삭제를 시도하려는 경우 요소를 찾을 수 없기 때문에 NoSuchElementException() 예외를 던져주었다.remove(int index)remove(int index) 메소드는 사용자가 원하는 특정 위치(index)를 리스트에서 찾아서 삭제한다.*add(int index, E value) 와 정반대로 구현해주면 된다.삭제하려는 노드의 이전 노드의 next 변수를 삭제하려는 노드의 다음 노드를 가리키도록 해주면 된다.@Overridepublic E remove(int index) { // 삭제하려는 노드가 첫 번째 원소일 경우 if (index == 0) { return remove(); } // 잘못된 범위에 대한 예외 if (index &gt;= size || index &lt; 0) { throw new IndexOutOfBoundsException(); }\t\t Node&lt;E&gt; prevNode = search(index - 1); // 삭제할 노드의 이전 노드 Node&lt;E&gt; removedNode = prevNode.next; // 삭제할 노드 Node&lt;E&gt; nextNode = removedNode.next; // 삭제할 노드의 다음 노드 E element = removedNode.data; // 삭제되는 노드의 데이터를 반환하기 위한 임시변수\t // 이전 노드가 가리키는 노드를 삭제하려는 노드의 다음노드로 변경 prevNode.next = nextNode; // 만약 삭제했던 노드가 마지막 노드라면 tail을 prevNode로 갱신 if(prevNode.next == null) { tail = prevNode; }\t // 데이터 삭제 removedNode.next = null; removedNode.data = null; size--; return element;}*노드를 얻기 위해 기존에 작성했던 search() 메소드를 이용하면 쉽게 얻을 수 있다.remove(Object value)remove(Object value) 메소드는 사용자가 원하는 특정 요소(value)를 리스트에서 찾아서 삭제한다.remove(int index) 메소드하고 동일한 메커니즘으로 작동한다.다만 고려해야 할 점은 ‘삭제하려는 요소가 존재하는지’를 염두해두어야 한다. 예로들어 삭제하려는 요소를 찾지 못했을 경우 false를 반환해주고, 만약 찾았을 경우 remove(int index) 와 동일한 삭제 방식을 사용하면 된다.@Overridepublic boolean remove(Object value) { Node&lt;E&gt; prevNode = head; boolean hasValue = false; Node&lt;E&gt; x = head; // removedNode \t\t // value 와 일치하는 노드를 찾는다. for (; x != null; x = x.next) { if (value.equals(x.data)) { hasValue = true; break; } prevNode = x; } // 일치하는 요소가 없을 경우 false 반환 if(x == null) { return false; } // 만약 삭제하려는 노드가 head라면 기존 remove()를 사용 \t if (x.equals(head)) { remove(); return true; } else { // 이전 노드의 링크를 삭제하려는 노드의 다음 노드로 연결 prevNode.next = x.next; // 만약 삭제했던 노드가 마지막 노드라면 tail을 prevNode로 갱신 if(prevNode.next == null) { tail = prevNode; } x.data = null; x.next = null; size--; return true; }}부가기능get(int index)index 로 들어오는 값을 인덱스삼아 해당 위치에 있는 요소를 반환하는 메소드다.이전에 search() 메소드를 구현해놓았기 때문에 이를 이용했다.@Overridepublic E get(int index) { return search(index).data;}🐣 search() 내부에서 잘못된 위치일 경우 예외를 던지기 때문에 따로 예외처리를 해줄 필요는 없다.set(int index, E value)set 메소드는 기존에 index에 위치한 데이터를 새로운 데이터(value)으로 ‘교체’하는 것이다.결과적으로 index에 위치한 데이터를 교체하는 것이기 때문에 마찬가지로 search() 메소드를 사용하여 노드를 찾아내고, \t해당 노드의 데이터만 새로운 데이터로 변경해주면 된다.@Overridepublic void set(int index, E value) { Node&lt;E&gt; replaceNode = search(index); replaceNode.data = null; replaceNode.data = value;}indexOf(Object value)indexOf 메소드는 사용자가 찾고자 하는 요소(value)의 ‘위치(index)’를 반환하는 메소드다.찾고자 하는 요소가 중복된다면 가장 먼저 마주치는 요소의 인덱스를 반환한다.찾고자 하는 요소가 없다면요?” 이러한 경우 -1 을 반환한다.⭐ 객체끼리 비교할 때는 동등연산자(==)가 아니라 반드시 .equals() 로 비교해야 한다.객체끼리 비교할 때 동등연산자를 쓰면 값을 비교하는 것이 아닌 주소를 비교하는 것이기 때문에 잘못된 결과를 초래한다.@Overridepublic int indexOf(Object value) { int index = 0;\t for (Node&lt;E&gt; x = head; x != null; x = x.next) { if (value.equals(x.data)) { return index; } index++; }\t // 찾고자 하는 요소를 찾지 못했을 경우 -1 반환 return -1;}contains(Object value)사용자가 찾고자 하는 요소(value)가 존재 하는지 안하는지를 반환하는 메소드다.찾고자 하는 요소가 존재한다면 true를, 존재하지 않는다면 false를 반환한다.해당 요소가 존재하는지를 ‘검사’한다는 기능은 같기 때문에 indexOf 메소드를 이용하여만약 음수가 아닌 수가 반환되었다면 요소가 존재한다는 뜻이고, 음수(-1)이 나왔다면 요소가 존재하지 않는다는 뜻이다.@Overridepublic boolean contains(Object item) {\treturn indexOf(item) &gt;= 0;}size()모든 리스트 자료구조는 기본적으로 동적 할당을 전제로 한다.그만큼 요소들을 삽입, 삭제가 많아지면 사용자가 리스트에 담긴 요소의 개수가 몇 개인지 기억하기 힘들다.그렇기에 size 변수의 값을 반환해주는 메소드인 size()를 만들어 줄 필요가 있다.@Overridepublic int size() { return size;}\tisEmpty()현재 ArrayList에 요소가 단 하나도 존재하지 않고 비어있는지를 알려준다.리스트가 비어있을 경우 true를, 비어있지 않고 단 한개라도 요소가 존재 할 경우 false를 반환해주면 된다. → size가 요소의 개수였으므로 size == 0 이면 true, 0 이 아니면 false 라는 것@Overridepublic boolean isEmpty() { return size == 0;}clear()모든 요소들을 비워버리는 작업리스트에 요소를 담아두었다가 초기화가 필요할 때 쓸 수 있는 유용한 존재다. 또한 모든 요소를 비워버린다는 것은 요소가 0개라는 말로 size 또한 0으로 초기화해준다.이 때 그냥 객체 자체를 null 해주기 보다는 모든 노드를 하나하나 null 해주는 것이 자바의 가비지 컬렉터가 명시적으로 해당 메모리를 안쓴다고 인지하기 때문에 메모리 관리 효율 측면에서 조금이나마 더 좋다.@Overridepublic void clear() { for (Node&lt;E&gt; x = head; x != null;) { Node&lt;E&gt; nextNode = x.next; x.data = null; x.next = null; x = nextNode; } head = tail = null; size = 0;}구현한 단일 연결리스트의 경우 삽입, 삭제 과정에서 ‘링크’만 끊어주면 되기 때문에 매우 효율적이라는 것을 볼 수가 있다.반대로 모든 자료를 인덱스가 아닌 head부터 연결되어 관리하기 때문에 색인(access)능력은 떨어진다.코드 출처 → 자바 [JAVA] - Singly LinkedList (단일 연결리스트) 구현하기" }, { "title": "Binary search tree", "url": "/posts/Binary-Search-Tree/", "categories": "Study", "tags": "Data-Structure, study, summary", "date": "2022-11-08 00:00:00 +0900", "snippet": "이진 탐색 트리(Binary Search Tree)Binary Search Tree → Binary(이진), Search(탐색), Tree(트리) : 이분화된 탐색을 위한(혹은 특화된) 트리 자료구조이진Binary(이진) → 이분화 된다.트리 구조에서 특정한 형태로 제한을 하게 되는데, 모든 노드의 최대 차수를 2로 제한한 것이다.→ 각 노드는 자식노드를 최대 2개까지밖에 못갖는다.이를 ‘이진 트리(Binary Tree)‘라고 한다.탐색에 특화된 트리“부모 노드를 기준으로 왼쪽 자식 노드들은 부모 노드보다 값이 작으며, 오른쪽 자식 노드들은 부모 노드보다 값이 크다.”이렇게 구성하면 이진 탐색 트리가 되는 것이다.목적이진탐색 + 연결리스트이진탐색 : 탐색에 소요되는 시간복잡도는 O(logN), but 삽입,삭제가 불가능연결리스트 : 삽입, 삭제의 시간복잡도는 O(1), but 탐색하는 시간복잡도가 O(N)이 두가지를 합하여 장점을 모두 얻는 것이 `이진탐색트리’다.즉, 효율적인 탐색 능력을 가지고, 자료의 삽입 삭제도 가능하게 만든다.특징 각 노드의 자식이 2개 이하 각 노드의 왼쪽 자식은 부모보다 작고, 오른쪽 자식은 부모보다 크다. 중복된 노드가 없어야 한다.굳이 중복을 한다고 하면 왼쪽 노드 조건을 부모랑 같거나 작은으로 바꿀 수도 있고, 혹은 오른쪽 노드 조건을 부모랑 같거나 큰으로 바꾸면 된다. (단, 양쪽 노드 모두 같을경우를 적용하면 안된다)중복이 없어야 하는 이유?검색 목적 자료구조인데, 굳이 중복이 많은 경우에 트리를 사용하여 검색 속도를 느리게 할 필요가 없다. (트리에 삽입하는 것보다, 노드에 count 값을 가지게 하여 처리하는 것이 훨씬 효율적이다.)이진탐색트리의 순회는 ‘중위순회(inorder)’ 방식 (왼쪽 - 루트 - 오른쪽)중위 순회로 정렬된 순서를 읽을 수 있다.핵심 연산 검색 삽입 삭제 트리 생성 트리 삭제시간 복잡도 균등 트리 : 노드 개수가 N개일 때 O(logN) 편향 트리 : 노드 개수가 N개일 때 O(N)삽입, 검색, 삭제 시간복잡도는 트리의 Depth에 비례한다.삽입새로운 노드가 위치할 곳을 탐색하는 과정이 필요하다.1-1. 루트 노드에 값이 없는 경우는 트리가 없는 경우이므로 루트에 넣는다. 1-2. 루트에 값이 있고 삽입되는 값이 루트보다 작으면 왼쪽으로 탐색시킨다. 1-3. 루트에 값이 있고 삽입되는 값이 루트보다 크면 오른쪽으로 탐색시킨다.2. 해당 방향으로 탐색을 진행했을 때, 탐색 위치에 값이 없으면 해당 위치에 노드를 추가한다.삭제 삭제하려는 노드가 단말 노드인 경우 삭제하려는 노드가 한쪽 자식 노드만 가지는 경우 삭제하려는 노드가 모든 자식 노드를 가지는 경우 삭제하려는 노드가 단말 노드인 경우삭제하는 노드가 자식노드를 갖고 있지 않을 때 해당 노드만 삭제해주면 된다.삭제하려는 노드가 한쪽 자식 노드만 가지는 경우삭제하는 노드가 왼쪽 또는 오른쪽 자식 노드를 갖고 있을 때 자식노드를 삭제노드의 위치로 옮겨오면 된다.삭제하려는 노드가 모든 자식 노드를 가지는 경우삭제하는 노드가 왼쪽, 오른쪽 자식 노드 모두 갖고 있을 때방법 1. 삭제된 노드의 오른쪽 자식 노드에서 제일 작은 노드로 대체하는 방법방법 2. 삭제된 노드의 왼쪽 자식 노드에서 제일 큰 노드로 대체하는 방법🐣 삭제 노드의 오른쪽 노드는 무조건 왼쪽 노드를 타야하고 삭제 노드의 왼쪽 노드는 무조건 오른쪽 노드를 타야한다.탐색 전위 탐색 : Root, 왼쪽 자식 노드, 오른쪽 자식 노드 순서로 방문한다. 후위 탐색 : 왼쪽 자식 노드, 오른쪽 자식 노드, Root 순서로 방문한다. 중위 탐색 : 왼쪽 자식 노드, Root, 오른쪽 자식노드 순서로 방문한다.출처 이진 탐색 트리: 이론과 소개 이진 탐색 트리: 자바 언어로 구현하기 이진탐색트리 (Binary Search Tree) 자바 [JAVA] - Binary Search Tree (이진 탐색 트리) 구현하기읽으면 좋은 링크 이진탐색트리(Binary Search Tree) CH8. 트리(Tree) 3 (이진 트리의 순회 (Traversal))" }, { "title": "Tree", "url": "/posts/Tree/", "categories": "Study", "tags": "Data-Structure, study, summary", "date": "2022-11-07 00:00:00 +0900", "snippet": "Tree트리는 값을 가진 노드(Node)와 이 노드들을 연결해주는 간선(Edge)으로 이루어져있다.그림 상 데이터 1을 가진 노드가 루트(Root) 노드다.모든 노드들은 0개 이상의 자식(Child) 노드를 갖고 있으며 보통 부모-자식 관계로 부른다.트리에는 사이클이 존재할 수 없다.💬 사이클?시작 노드에서 출발해 다른 노드를 거쳐 다시 시작 노드로 돌아올 수 있다면 사이클이 존재한다고 한다. 부모 노드(parent node) : 자기 자신(노드)과 연결 된 노드 중 자신보다 높은 노드를 의미 (ex. 5의 부모노드 : 2) 자식 노드(child node) : 자기 자신(노드)과 연결 된 노드 중 자신보다 낮은 노드를 의미 (ex. 3의 자식노드 : 6, 7) 루트 노드 (root node) : 일명 뿌리 노드라고 하며 루트 노드는 하나의 트리에선 하나밖에 존재하지 않고, 부모노드가 없다. 위에선 1이 뿌리노드다. 단말 노드(leaf node) : 리프 노드라고도 불리며 자식 노드가 없는 노드를 의미한다. 위 이미지에서 8, 9, 10, 11, 13, 14 노드가 단말노드다. 형제 노드(sibling node) : 부모가 같은 노드를 말한다. (ex. 4, 5는 모두 부모노드가 2이므로 4, 5는 형제노드다.) 깊이(depth) : 특정 노드에 도달하기 위해 거쳐가야 하는 ‘간선의 개수’를 의미 (ex. 5의 깊이 : 1 → 2 → 5 이므로 깊이는 2가 됨) 레벨(level) : 특정 깊이에 있는 노드들의 집합을 말하며, 구현하는 사람에 따라 0 또는 1부터 시작한다. → 1 노드를 0 레벨이라 하고 2와 3의 노드 레벨을 1 레벨이라고 할 수도 있고 1 노드를 1레벨이라고 하면 2와 3 노드는 2레벨이 된다. 차수(degree) : 특정 노드가 하위(자식) 노드와 연결 된 개수 (ex. 4의 차수 = 2 {8, 9} ) 높이 : 트리의 높이는 루트 노드부터 리프 노드까지 거리 중 가장 긴 거리를 의미하며 위의 트리 높이는 3이다. 🐣 V - 1 = E : 간선 수 = 노드 수 - 1트리 순회 방식🐣 root를 기준으로 root가 앞에 있으면 전위, 뒤에 있으면 후위 중간에 있으면 중위로 알면 쉽다.전위 순회(pre-order)각 루트(Root)를 순차적으로 먼저 방문하는 방식이다. (Root → 왼쪽 자식 → 오른쪽 자식)1 → 2 → 4 → 8 → 9 → 5 → 10 → 11 → 3 → 6 → 13 → 7 → 14중위 순회(in-order)왼쪽 하위 트리를 방문 후 루트(Root)를 방문하는 방식이다. (왼쪽 자식 → Root → 오른쪽 자식)8 → 4 → 9 → 2 → 10 → 5 → 11 → 1 → 6 → 13 → 3 →14 → 7후위 순회(post-order)왼쪽 하위 트리부터 하위를 모두 방문 후 루트(Root)를 방문하는 방식이다. (왼쪽 자식 → 오른쪽 자식 → Root)8 → 9 → 4 → 10 → 11 → 5 → 2 → 13 → 6 → 14 → 7 → 3 → 1레벨 순회(level-order)루트(Root)부터 계층 별로 방문하는 방식이다.1 → 2 → 3 → 4 → 5 → 6 → 7 → 8 → 9 → 10 → 11 → 13 → 14코드로 보기class Node { int data; Node left; Node right;}class Tree { public Node root; public void setRoot(Node node) { // 루트 노드 this.root = node; } public Node getRoot() { return root; } public Node createNode(Node left, int data, Node right) { Node node = new Node(); node.data = data; node.left = left; node.right = right; return node; } // 중위 순회 Inorder = Left -&gt; Root -&gt; Right public void inOrder(Node node) { if(node != null) { inOrder(node.left); // left System.out.print(node.data + \" → \"); // 루트 inOrder(node.right); // right } } // 전위순회 Preorder = Root -&gt; Left -&gt; Right public void preOrder(Node node) { if(node != null) { System.out.print(node.data + \" → \"); // root preOrder(node.left); // left preOrder(node.right); // right } } //후위순회 Postorder = Left -&gt; Right -&gt; Root public void postOrder(Node node) { if(node != null) { postOrder(node.left); // left postOrder(node.right); // right System.out.print(node.data + \" → \"); // root } }}public class Main { public static void main(String[] args) { Tree t = new Tree(); Node n14 = t.createNode(null, 14, null); Node n13 = t.createNode(null, 13, null); Node n9 = t.createNode(null, 9, null); Node n8 = t.createNode(null, 8, null); Node n7 = t.createNode(n14, 7, null); Node n6 = t.createNode(null, 6, n13); Node n11 = t.createNode(null, 11, null); Node n10 = t.createNode(null, 10, null); Node n4 = t.createNode(n8, 4, n9); Node n5 = t.createNode(n10, 5, n11); Node n2 = t.createNode(n4, 2, n5); Node n3 = t.createNode(n6, 3, n7); Node n1 = t.createNode(n2, 1, n3); t.setRoot(n1); // 루트 노드 System.out.println(\"전위 순회\"); t.preOrder(t.getRoot()); System.out.println(); System.out.println(\"중위 순회\"); t.inOrder(t.getRoot()); System.out.println(); System.out.println(\"후위 순회\"); t.postOrder(t.getRoot()); }}출처 Tree 자바 [JAVA] - Binary Search Tree (이진 탐색 트리) 구현하기 [자료구조] 트리(Tree)의 개념 | 이진 트리, 전 이진 트리, 완전 이진트리, 포화 이진 트리, 이진 탐색트리" }, { "title": "Heap", "url": "/posts/Heap/", "categories": "Study", "tags": "Data-Structure, study, summary", "date": "2022-11-02 00:00:00 +0900", "snippet": "Heap “우선순위 Queue”를 위해 만들어진 자료구조우선순위 Queue 데이터들이 우선순위를 가지고 있다. 우선순위가 높은 데이터가 먼저 나간다. 배열,연결리스트,힙으로 구현 가능 힙이 가장 효율적(삽입,삭제 : O(logN)) public static void main(String[] args) { PriorityQueue&lt;Integer&gt; q = new PriorityQueue&lt;Integer&gt;(); q.offer(200); q.offer(50); q.offer(93); q.offer(7); q.offer(80); System.out.println(q.poll()); // 7 System.out.println(q.poll()); // 50 System.out.println(q.poll()); // 80 System.out.println(q.poll()); // 93 System.out.println(q.poll()); // 200 }특징 우선순위 개념 + Queue 완전 이진트리 기반의 자료구조 → 여러값 중 최대값, 최소값을 빠르게 찾아내도록 만들어진 구조 HeapTree는 중복된 값 허용 (이진트리는 x) 반정렬 상태 node와 level을 보기 때문에 정렬이 아닌 반정렬이라고 하는 것 같다. 트리 Root : 부모가 없는 최상단 노드 Leaf : 자식이 없는 말단 노드이진 트리 각 노드에 최대 두 개의 자식을 갖을 수 있는 트리이진 탐색 트리 모든 노드가 특정 순서를 따르는 속성이 있는 이진 트리종류최대 힙 부모 노드의 키 값이 자식 노드의 키 값보다 크거나 같은 완전 이진 트리 부모 노드의 값(key 값) ≥ 자식 노드의 값(key 값)최소 힙 부모 노드의 키 값이 자식 노드의 키 값보다 작거나 같은 완전 이진 트리 부모 노드의 값(key 값) ≤ 자식 노드의 값(key 값)구현힙을 저장하는 표준적인 자료구조는 배열이다.구현을 쉽게 하기 위해 배열의 첫번째 인덱스인 0은 사용되지 않는다.특정 위치의 노드 번호는 새로운 노드가 추가되어도 변하지 않는다.(ex. 루트 노드(1)의 오른쪽 노드 번호는 항상 3)💬 배열?연결리스트로도 구현이 가능하긴 하지만, 문제는 특정 노드의 '검색', '이동' 과정이 조금 더 번거롭기 때문이다.배열의 경우는 특정 인덱스에 바로 접근할 수가 있기 때문에 좀 더 효율적이기도 하다.특징배열로 구현할 경우(min heap) 구현의 용이함을 위해 시작 인덱스(root)는 1 부터 시작한다. 각 노드와 대응되는 배열의 인덱스는 ‘불변한다’성질(부모 노드와 자식 노드 관계) 부모 index = (자식 index) / 2 왼쪽 자식 index = (부모 index) * 2 오른쪽 자식 index = (부모 index) * 2 + 1ex) index 3 의 왼쪽 자식 노드를 찾고 싶다면 3 × 2를 해주면 된다. 즉 index 6 이 index 3 의 자식 노드라는 것이다.반대로 index 5의 부모 노드를 찾고 싶다면 5 / 2 를 해주면 된다.(몫만 취함) 그러면 2 이므로 index 2가 index 5의 부모노드라는 것이다.삽입 힙에 새로운 요소가 들어오면 일단 새로운 노드를 힙의 마지막 노드에 삽입 새로운 노드를 부모 노드들과 교환최대 힙“부모 ≤ 자식” 조건으로 swap최소 힙“부모 ≥ 자식” 조건으로 swap 가장 마지막 위치에 노드 추가 부모 노드와 비교하여 작은 노드가 상위 레벨에 있도록 swap (완전한 구조가 될때까지 반복)삭제 최대 힙에서 최대값은 루트 노드이므로 루트 노드가 삭제된다. (최대 힙에서 삭제 연산은 최대값 요소를 삭제하는 것) 삭제된 루트 노드에는 힙의 마지막 노드를 가져온다. 힙을 재구성 (연산 실행)활용 시뮬레이션 시스템 작업 스케줄링 수치해석 계산" }, { "title": "Queue", "url": "/posts/Queue/", "categories": "Study", "tags": "Data-Structure, study, summary", "date": "2022-11-01 00:00:00 +0900", "snippet": "큐(Queue)큐는 먼저 집어 넣은 데이터가 먼저 나오는 성질(FIFO : 선입선출, First In First Out)을 지닌 자료 구조이며,나중에 집어 넣은 데이터가 먼저 나오는 스택과 반대되는 개념을 가졌다.삽입 및 삭제에 O(1), 탐색에 O(n)이 걸린다.Enqueue : 큐 맨 뒤에 데이터 추가Dequeue : 큐 맨 앞쪽의 데이터 삭제기본연산 front : deQueue 할 위치 기억 rear : enQueue 할 위치 기억enQueue() 데이터를 넣는 연산 데이터가 들어오면 rear는 새로 들어온 데이터가 된다. (R -&gt; R’)dnQueue() 데이터를 빼는 연산 데이터가 나가면 front는 다음 데이터가 된다. (F -&gt; F’)isEmpty() 데이터가 비었는지 확인 front == rearisFull() 데이터가 꽉 차있는지 확인 rear == QueueSizePeek() 가장 첫번째 데이터를 반환하되 삭제는 하지 않는다. 다음 출력 값이 미리 알아보는 역할자바 속 QueueQueue 선언Queue&lt;Integer&gt; queue = new LinkedList&lt;&gt;(); //int형 queue 선언, linkedlist 이용Queue&lt;String&gt; queue = new LinkedList&lt;&gt;(); //String형 queue 선언, linkedlist 이용자바에서 큐는 LinkedList를 활용하여 생성해야한다.(가장 대중적이고, 배열로 구현하는 큐에 비해 쉬운편)Queue Interface에 선언 할 메소드 추가(enqueue) : Queue명.offer(값); 추가(enqueue) : Queue명.add(값); 큐가 꽉 차서 추가할 수 없는 경우에는 에러가 출력 삭제(dequeue) : Queue명.remove(); 삭제(dequeue) : Queue명.poll(); 값을 반환하고 제거. 큐가 비어있으면 null을 반환 검사 : Queue명.peek(); 검사 : Queue명.element(); 다음에 출력될 값을 확인 Queue에서 다 뽑아내거나 Queue가 비어있으면 에러가 출력Queue&lt;Integer&gt; queue = new LinkedList&lt;&gt;(); //int형 queue 선언 queue.offer(1); // queue에 값 1 추가 queue.offer(2); // queue에 값 2 추가 queue.offer(3); // queue에 값 3 추가 queue.poll(); // queue에 첫번째 값을 반환하고 제거 비어있다면 null queue.remove(); // queue에 첫번째 값 제거 queue.clear(); // queue 초기화public class Main { public static void main(String[] args) { Queue&lt;Integer&gt; queue = new LinkedList&lt;Integer&gt;(); for (int i = 1; i &lt;= 10; i++) { queue.offer(i); } while(!queue.isEmpty()) { int element = queue.poll(); System.out.println(element); } }}1 2 3 4 5 6 7 8 9 10 순서대로 출력된다.코드큐의 구조는 한쪽에서는 삽입만 일어나고 한쪽에서는 삭제만 하는 자료구조다.→ 먼저 들어간 것이 먼저 나오는 FIFO 구조 ex) 줄서기, 프린터 출력 등등즉, 큐는 항상 첫 번재 저장된 데이터를 삭제하므로,ArrayList와 같은 배열 기반의 자료구조를 사용하게 되면 빈공간을 채우기 위해서 데이터의 복사가 발생하므로 매우 비효율적이다.그래서 Queue는 ArrayList보다 데이터의 추가/삭제가 쉬운 LinkedList로 구현하는 것이 적합하다.LinkedList LinkedList를 기반으로 Queue를 구현하기에 앞서 가장 기본적인 데이터를 담을 Node 클래스를 먼저 구현한다.Nodeclass Node&lt;E&gt; { E data; Node&lt;E&gt; next; // 다음 노드를 가리키는 역할을 하는 변수\t Node(E data) { this.data = data; this.next = null; }}interface// 자바 Queue Interface// Queue는 ArrayQueue, LinkedQueue, Deque, PriorityQueue 에 의해 구현 public interface Queue&lt;E&gt; { boolean offer(E e); E poll(); E peek();\t} boolean offer(E e); : 큐의 가장 마지막에 요소를 추가 @param : e 큐에 추가할 요소 @return : 큐에 요소가 정상적으로 추가되었을 경우 true를 반환 E poll(); : 큐의 첫 번째 요소를 삭제하고 삭제 된 요소를 반환 @return : 큐의 삭제 된 요소 반환 E peek(); : 큐의 첫 번째 요소를 반환 @return : 큐의 첫 번째 요소 반환 Queue 클래스 및 생성자 구성하기public class LinkedListQueue&lt;E&gt; implements Queue&lt;E&gt; { private Node&lt;E&gt; head; private Node&lt;E&gt; tail; private int size;\t public LinkedListQueue() { this.head = null; this.tail = null; this.size = 0; }} head : 큐에서 가장 앞에있는 노드 객체를 가리키는 변수 tail : 큐에서 가장 뒤에있는 노드 객체를 가리키는 변수 size : 큐에 담긴 요소의 개수처음 큐를 생성할 때는 아무런 데이터가 없으므로 head와 tail은 가리킬 노드가 없는상태이므로 null로 초기화해주고,size 또한 0으로 초기화 해준다.offer() : 데이터 추가Queue에 데이터를 추가하는 메소드(맨 뒤에 데이터 추가)*리스트로 치면 add(E value)와 같은 역할기본 삽입 : offer(E item) _ 가장 마지막 부분에 추가@Overridepublic boolean offer(E value) { Node&lt;E&gt; newNode = new Node&lt;E&gt;(value);\t\t // 비어있을 경우 if(size == 0) { head = newNode; } // 그 외의 경우 마지막 노드(tail)의 다음 노드(next)가 새 노드를 가리키도록 한다. else { tail.next = newNode; }\t // tail이 가리키는 노드를 새 노드로 바꿔준다. tail = newNode; size++; return true;}큐에 아무 요소들이 없을 때. 즉 size가 0일 때는 새 요소가 head이자 tail이 된다.그렇기 때문에 큐가 비어있을 경우에는 head를 새 노드를 가리키도록 해야하고 그 외에는 이미 요소가 있다는 의미이므로tail이 가리키는 요소의 다음 노드(tail.next)를 새 노드를 가리키도록 한 뒤 tail이 가리키는 노드를 새 노드를 가리키도록 한다.데이터 삭제리스트에서의 remove()와 같은 역할로 가장 앞에있는 위치에 있는 요소인 head 요소를 삭제하면 된다.remove() 같은 경우 삭제 할 요소가 없으면 NoSuchElementException() 예외를 던진다.반대로 poll()의 경우는 삭제 할 요소가 없다면 null을 반환한다는 차이점이 있다.1. poll()@Overridepublic E poll() {\t\t // 삭제할 요소가 없을 경우 null 반환 if(size == 0) { return null; }\t\t // 삭제될 요소의 데이터를 반환하기 위한 임시 변수 E element = head.data;\t\t // head 노드의 다음노드 Node&lt;E&gt; nextNode = head.next;\t\t // head의 모든 데이터들을 삭제 head.data = null; head.next = null;\t\t // head 가 가리키는 노드를 삭제된 head노드의 다음노드를 가리키도록 변경 head = nextNode; size--;\t\t return element;}2. remove()public E remove() {\t\t E element = poll();\t\t if(element == null) { throw new NoSuchElementException(); }\t\t return element;}조회가장 앞에 있는 데이터(head.data)를 삭제하지 않고 확인만 하고싶을 때 쓰인다.poll() 메소드에서 삭제과정만 없는 것이 peek() 이다.1. peek()@Overridepublic E peek() {\t\t\t\t// 요소가 없을 경우 null 반환 if(size == 0) { return null; } return head.data;}head의 데이터를 그대로 반환하기만 하면 된다.2. element()public E element() {\t\t E element = peek();\t\t if(element == null) { throw new NoSuchElementException(); } return element;}peek() 메소드로 데이터를 얻은 뒤, 얻은 요소가 null 이라면 예외를 던진다.그 외 메소드size()현재 큐에 있는 요소의 개수를 알려준다.public int size() { return size;}isEmpty()현재 큐가 비어있는지를 확인 할 때 쓰인다.요소의 개수가 0개라면 비어있다는 뜻이므로, 비어있다면 true를, 비어있지 않다면 false를 반환한다.public boolean isEmpty() { return size == 0;\t}contains()현재 찾고자하는 요소가 큐에 들어가있는지를 알려주는 메소드public boolean contains(Object value) {\t\t // head 데이터부터 x가 null이 될 때까지 value랑 x의 데이터(x.data)랑 // 같은지를 비교하고 같을 경우 true를 반환한다. for(Node&lt;E&gt; x = head; x != null; x = x.next) { if(value.equals(x.data)) { return true; } } return false;}clear()Queue의 모든 요소를 비워버린다.public void clear() { for (Node&lt;E&gt; x = head; x != null; ) { Node&lt;E&gt; next = x.next; x.data = null; x.next = null; x = next; } size = 0; head = tail = null;}이 때는 모든 데이터를 명시적으로 null 처리를 해주는 것이 좋다.그리고 빈 공간은 초기 상태와 마찬가지로 head 와 tail와 size 모두 0으로 초기화 해준다.전체 코드public class LinkedListQueue&lt;E&gt; implements Queue&lt;E&gt; {\tprivate Node&lt;E&gt; front;\tprivate Node&lt;E&gt; rear;\tprivate int size;\tpublic LinkedListQueue() { // 초기화\t\tthis.front = null;\t\tthis.rear = null;\t\tthis.size = 0;\t}\t@Override\tpublic boolean enQueue(E value) {\t\tNode&lt;E&gt; newNode = new Node&lt;E&gt;(value);\t\tif (size == 0) { // 큐가 비어있을 경우\t\t\tfront = newNode; // 새 요소가 head이자 tail이 된다.\t\t}\t\t// 그 외의 경우 마지막 노드(rear)의 다음 노드(next)가 새 노드를 가리키도록 한다.\t\telse {\t\t\trear.next = newNode;\t\t}\t\t// rear이 가리키는 노드를 새 노드로 바꿔준다.\t\trear = newNode;\t\tsize++;\t\treturn true;\t}\t\t\t// 삭제\t@Override\tpublic E poll() { // 삭제할 요소가 없을 경우 null 반환\t\tif (size == 0) {\t\t\treturn null;\t\t}\t\t// 삭제될 요소의 데이터를 반환하기 위한 임시 변수\t\tE element = front.data;\t\t// head 노드의 다음노드\t\tNode&lt;E&gt; nextNode = front.next;\t\t// head의 모든 데이터들을 삭제\t\tfront.data = null;\t\tfront.next = null;\t\t// front 가 가리키는 노드를 삭제된 front 노드의 다음노드를 가리키도록 변경\t\tfront = nextNode;\t\tsize--;\t\treturn element;\t}\tpublic E remove() { // 삭제할 요소가 없으면 예외 발생\t\tE element = poll();\t\tif (element == null) {\t\t\tthrow new NoSuchElementException();\t\t}\t\treturn element;\t}\t\t\t\t// 조회 \t@Override\tpublic E peek() {\t\t// 요소가 없을 경우 null 반환\t\tif (size == 0) {\t\t\treturn null;\t\t}\t\treturn front.data;\t}\tpublic E element() { \t\tE element = peek();\t\tif (element == null) {\t\t\tthrow new NoSuchElementException();\t\t}\t\treturn element;\t}\t\t\t\t// 기타 메소드 \tpublic int size() { // 요소 개수\t\treturn size;\t}\tpublic boolean isEmpty() {\t\treturn size == 0;\t}\tpublic boolean contains(Object value) {\t\t// front 데이터부터 x가 null이 될 때까지 value랑 x의 데이터(x.data)랑\t\t// 같은지를 비교하고 같을 경우 true를 반환한다.\t\tfor (Node&lt;E&gt; x = front; x != null; x = x.next) {\t\t\tif (value.equals(x.data)) {\t\t\t\treturn true;\t\t\t}\t\t}\t\treturn false;\t}\tpublic void clear() {\t\tfor (Node&lt;E&gt; x = front; x != null; ) {\t\t\tNode&lt;E&gt; next = x.next;\t\t\tx.data = null;\t\t\tx.next = null;\t\t\tx = next;\t\t}\t\t// 초기화\t\tsize = 0;\t\tfront = rear = null;\t}\t\t\tpublic static void main(String[] args) {\t\tLinkedListQueue&lt;Integer&gt; queue = new LinkedListQueue&lt;Integer&gt;();\t\tqueue.enQueue(5);\t\tSystem.out.println(queue.peek());\t\tqueue.enQueue(1);\t\tSystem.out.println(queue.peek());\t\tqueue.enQueue(1);\t\tqueue.enQueue(3);\t\tqueue.remove();\t\tSystem.out.println(queue.peek());\t\tSystem.out.println(queue.size());\t\tSystem.out.println(queue.contains(5));\t\tqueue.clear();\t\tSystem.out.println(queue.size());\t\tSystem.out.println(queue.poll());\t}}출처 [Java]Queue가 ArrayList 대신 LinkedList를 사용하는 이유자바 [JAVA] - 연결리스트를 이용한 Queue (큐) 구현하기" }, { "title": "Stack", "url": "/posts/Stack/", "categories": "Study", "tags": "Data-Structure, study, summary", "date": "2022-10-31 00:00:00 +0900", "snippet": "Stack 가장 마지막으로 들어간 데이터가 가장 첫 번째로 나오는 성질(LIFO(후입선출), Last In First Out)을 가진 자료 구조이다. [JVM 함수 호출 스택, Stack Overflow 에러] 에서의 스택JVMpublic class JvmStack { public static void main(String[] args) { JvmStack jvmStack = new JvmStack(); jvmStack.add(); } public void add(){ minus(); mul(); } public void minus(){ System.out.println(\"minus\"); } public void mul(){ System.out.println(\"mul\"); }}특징 배열과 달리 index 같은 위치 값으로 접근할 수가 없다. 검색시. 제일 상위 값부터 검색해야 하므로 O(1)~O(n) 의 시간이 걸린다. 데이터 추가 및 삭제는 O(1) 배열처럼 원소들을 하나씩 밀어줄 필요가 없다. 한 쪽 끝에서만 자료를 넣고 뺄 수 있다. Stack이 List도 상속받고 있어 List의 메소드도 사용가능하다.기본연산 pop() : 스택에서 가장 위에 있는 항목을 제거한다. push(item) : item 하나를 스택의 가장 윗 부분에 추가한다. peek() : 스택의 가장 위에 있는 항목을 반환(조회)한다. pop 메소드와는 달리 스택에서 제거하지는 않는다. isEmpty() : 스택이 비어 있을 때에 true를 반환한다. clear() : 스택에 존재하는 모든 자료들을 삭제한다.push와 pop할 때는 해당 위치를 알고 있어야 하므로 기억하고 있는 ‘스택 포인터(SP)’가 필요하다.스택 포인터는 다음 값이 들어갈 위치를 가리키고 있다. (처음 기본값은 -1)public boolean isEmpty(){ return sp == -1;}push()item 하나를 스택의 가장 윗 부분에 추가pop()스택에서 가장 위에 있는 항목을 제거peek()스택의 가장 위에 있는 항목을 반환isEmpty()스택이 비어 있을 때에 true를 반환isFull()스택이 꽉차 있을 때 true를 반환코드class Stack{\tprivate int sp;\tprivate int stackSize;\tprivate char stackArr[];\t// 스택이 비어있는 상태인지 확인\t// 스택 포인터가 -1인 경우 데이터가 없는 상태이므로 true 아닌 경우 false를 return\tpublic boolean isEmpty(){\t\treturn sp == -1;\t}\t// 스택이 가득찬 상태인지 확인\t// 스택 포인터가 스택의 마지막 인덱스와 동일한 경우 true 아닌 경우 false를 return\tpublic boolean isFull(){\t\treturn sp == this.stackSize -1;\t}\t// 스택에 데이터를 추가\tpublic void push (char item){\t\tif(isFull()){\t\t\tSystem.out.println(\"Stack is full!\");\t\t}\t\telse{\t\t\tstackArr[++sp] = item; // sp 값이 먼저 증가된 후에 해당 코드 실행\t\t\tSystem.out.println(\"입력된 문자 : \" + item);\t\t}\t}\t// 스택의 최상위(마지막) 데이터 추출 후 삭제\tpublic char pop(){\t\tif (isEmpty()) {\t\t\tSystem.out.println(\"Deleting fail! Stack is empty!\");\t\t\treturn 0;\t\t} else {\t\t\tSystem.out.println(\"삭제된 문자 : \" + stackArr[sp]);\t\t\treturn stackArr[sp--]; // 해당 코드가 실행 된 후 sp 값 감소\t\t}\t}\t// 스택의 최상위(마지막) 데이터 추출\tpublic char peek(){\t\tif (isEmpty()){\t\t\tSystem.out.println(\"Peeking fail! Stack is empty!\");\t\t\treturn 0;\t\t}\t\telse {\t\t\tSystem.out.println(\"최상위 문자 조회 : \" + stackArr[sp]);\t\t\treturn stackArr[sp];\t\t}\t}\t// 스택 초기화\tpublic void clear(){\t\tif (isEmpty()){\t\t\tSystem.out.println(\"Stack is already empty!\");\t\t} else {\t\t\tsp = -1; // 스택 포인터 초기화\t\t\tstackArr = new char[this.stackSize]; // 새로운 스택 배열 생성\t\t\tSystem.out.println(\"Stack is clear!\");\t\t}\t}\t// 스택을 생성하는 생성자\tpublic Stack(int stackSize){\t\tsp = -1; // 스택 포인터 초기화\t\tthis.stackSize = stackSize; // 스택 사이즈 설정\t\tstackArr = new char[this.stackSize]; // 스택 배열 생성\t}\t// 스택에 저장된 모든 데이터를 출력\tpublic void printStack(){\t\tif (isEmpty()) {\t\t\tSystem.out.println(\"Stack is empty!\");\t\t} else {\t\t\tSystem.out.print(\"Stack elements : \");\t\t\tfor (int i =0; i&lt;=sp; i++) {\t\t\t\tSystem.out.print(stackArr[i] + \" \");\t\t\t}\t\t\tSystem.out.println();\t\t}\t}}public class StackTest {\tpublic static void main(String[] args) {\t\tScanner scanner = new Scanner(System.in); // 사용자로부터 키 입력을 받기 위해서는 System.in을 사용한다.\t\tSystem.out.print(\"스택 사이즈를 입력하세요. : \");\t\tint stackSize = scanner.nextInt(); // int nextInt() : 입력받은 값을 int 타입으로 반환\t\tStack stack = new Stack(stackSize);\t\tstack.push('A');\t\tstack.printStack();\t\tstack.push('B');\t\tstack.printStack();\t\tstack.push('C');\t\tstack.printStack();\t\tstack.pop();\t\tstack.printStack();\t\tstack.peek();\t\tstack.printStack();\t\tstack.clear();\t\tstack.printStack();\t}}// https://velog.io/@kungsboy/%EC%88%99%EC%A0%9C-Stack-%EA%B5%AC%ED%98%84동작 배열 스택스택에는 MAX_SIZE라는 최대 크기가 존재해야 한다.→ 스택 포인터와 MAX_SIZE를 비교해서 isFull 메소드로 비교해야되기 때문이다.최대 크기가 없는 스택을 만드려면?arraycopy를 활용한 동적배열 사용한다.(스택이 최대가 되면 스택 크기를 2배로 늘리는 방법이다.)활용 재귀 알고리즘 재귀적으로 함수를 호출해야하는 경우 임시 데이터를 스택에 넣어준다. 재귀함수를 빠져 나와 퇴각 검색(backtrack)을 할 때는 스택에 넣어 두었던 임시 데이터를 빼 줘야 한다. 스택은 이런 일련의 행위를 직관적으로 가능하게 해 준다. 또한 스택은 재귀 알고리즘을 반복적 형태(iterative)를 통해서 구현할 수 있게 해준다. 웹 브라우저 방문기록(뒤로가기) 실행 취소 역순 문자열 만들기 수식의 괄호 검사 후위 표기법 계산" }, { "title": "Java collection framework", "url": "/posts/Java-Collection-FrameWork/", "categories": "Study", "tags": "Data-Structure, study, summary", "date": "2022-10-27 00:00:00 +0900", "snippet": "Java Collection FrameWork자바에서 컬렉션 프레임워크(collection framework)란 다수의 데이터를 쉽고 효과적으로 처리할 수 있는 표준화된 방법을 제공하는 클래스의 집합을 의미한다.일정 타입의 데이터들이 모여 쉽게 가공 할 수 있도록 지원하는 자료구조들의 뼈대(기본 구조)자바에서 제공하는 Collection은 크게 3가지 인터페이스로 나뉘어있다.크게 List, Queue, Set(집합), Map, Stack으로 나뉘어 있다. 그리고 각 분야별로 ‘구현’ 된 것들이 있다. Iterable 이라 한다면 ‘반복 가능한’ 이라는 정도로 이해하면 된다.Collection Interface 상위에 Iterable 이 있는 이유 Iterable 인터페이스를 쓰는 모든 클래스들은 기본적으로 for-each 문법을 쉽게 사용할 수 있다. → 반복자로 구현되어 나오게 하는 것이다.선형자료구조선형 자료 구조란 요소가 일렬로 나열되어 있는 자료 구조를 말한다. Array LinkedList Vector Stack Queue비선형 자료구조일렬로 나열된 것이 아닌, 각 요소가 여러 개의 요소와 연결 된 형태 Graph Tree출처 자바 [JAVA] - 자바 컬렉션 프레임워크 (Java Collections Framework) 컬렉션 프레임워크의 개념 [Java] 자바 컬렉션 프레임워크(List, Set, Map) 총정리" }, { "title": "List", "url": "/posts/List/", "categories": "Study", "tags": "Data-Structure, study, summary", "date": "2022-10-26 00:00:00 +0900", "snippet": "ListList Interface는 대표적인 선형 자료구조로 주로 순서가 있는 데이터를 목록으로 이용할 수 있도록 만들어진 인터페이스다.List를 통해 구현된 클래스들은 ‘동적 크기’를 갖으며 배열처럼 사용할 수 있게 되어있다.→ 배열의 기능 + 동적 크기 할당List Interface를 구현하는 클래스 ArrayList LinkedList Vector (+ Vector를 상속받은 Stack) List Interface에 선언된 메소드 메소드 리턴 타입 설명 add(E e) boolean 요소를 추가한다. remove(Object o) boolean 지정된 객체와 같은 첫번째 객체를 삭제한다. contains(Object o) boolean 지정한 객체가 컬렉션에 있는지 확인한다. 있을 경우 true, 없을 경우 false를 반환 size() int 현재 컬렉션에 있는 요소 개수를 반환한다. get(int index) E 지정된 위치에 저장된 원소를 반환한다. set(int index,E elements) E 지정된 위치에 있는 요소를 지정된 요소로 바꾼다. isEmpty() boolean 현재 컬렉션에 요소가 없다면 true, 요소가 존재한다면 false를 반환 equals(Object o) boolean 지정된 객체와 같은지 비교한다. indexOf(Object o) int 지정된 객체가 있는 첫번째 요소의 위치를 반환한다. 만일 없을 경우 -1 반환 clear() void 모든 요소를 제거한다. ArrayList는 Object[] 배열을 사용하면서 내부 구현을 통해 동적으로 관리를 한다.LinkedList는 데이터(item)와 주소로 이루어진 클래스를 만들어 서로 연결하는 방식이다.Stack은 후입선출(LIFO : Last in First out)이라고 하는데, 짐을 쌓는다고 생각하면 쉽다.코드/* T는 객체 타입을 의미하며 기본적으로Integer, String, Double, Long 같은 Wrapper Class부터 사용자 정의 객체까지 가능하다.ex) LinkedList&lt;Integer&gt; list = new LinkedList&lt;&gt;();primitive type은 불가능하다.*/ // 방법 1ArrayList&lt;T&gt; arraylist = new ArrayList&lt;&gt;();LinkedList&lt;T&gt; linkedlist = new LinkedList&lt;&gt;();Vector&lt;T&gt; vector = new Vector&lt;&gt;();Stack&lt;T&gt; stack = new Stack&lt;&gt;(); // 방법 2List&lt;T&gt; arraylist = new ArrayList&lt;&gt;();List&lt;T&gt; linkedlist = new LinkedList&lt;&gt;();List&lt;T&gt; vector = new Vector&lt;&gt;();List&lt;T&gt; stack = new Stack&lt;&gt;(); // Stack은 Vector를 상속하기 때문에 아래와 같이 생성할 수 있다.Vector&lt;T&gt; stack = new Stack&lt;&gt;();출처 자바 [JAVA] - 자바 컬렉션 프레임워크 (Java Collections Framework)" }, { "title": "Linkedlist", "url": "/posts/LinkedList/", "categories": "Study", "tags": "Data-Structure, study, summary", "date": "2022-10-26 00:00:00 +0900", "snippet": "연결 리스트연결 리스트는 데이터를 감싼 노드를 포인터로 연결해서 공간적인 효율성을 극대화 시킨 자료 구조다.삽입과 삭제가 O(1)이 걸리며 탐색에는 O(n)이 걸린다.구조연결 리스트는 아래와 같이 노드와 포인터로 이루어져 있고 다음 노드와 연결되어 있다. 자료의 주소 값으로 노드를 이용해 서로 연결되어 있는 구조를 갖는다. → 메모리를 연속적으로 사용하지 않는다. 순차적 접근방식이다. → 특정 원소에 접근하기 위해서 처음부터 검색하면서 찾는다. 동적으로 삽입, 삭제가 편하다. 원소를 삽입할 경우 맨 앞 , 맨 뒤 삽입은 위치를 찾지 않아도 되서 시간 복잡도 O(1)이다. 중간 삽입은 이전 노드와 다음 노드의 위치를 알고 있는 경우 시간 복잡도는 O(1)이다. 하지만 탐색을 해야하는 경우 시간 복잡도 O(n)이다. 원소를 삭제할 경우 삽입과 마찬가지로 맨 앞, 맨 뒤 삭제는 시간 복잡도 O(1)이다. 중간 삭제는 시간 복잡도 O(n) 또는 O(1)이다. (삽입과 같음) 특정 위치에 있는 원소에 바로 접근이 불가능하다. (주소를 바로 알 수 없기 때문) 원하는 원소를 찾기 위해서 최소 한 번은 리스트를 순회해야하기 때문에 시간 복잡도는 O(n)이다. 메모리는 새로운 노드가 추가될 때 (Runtime) Heap 영역에 할당한다.종류prev 포인터와 next 포인터로 앞과 뒤의 노드를 연결시킨 것이 연결 리스트이며연결 리스트는 싱글 연결 리스트, 이중 연결 리스트, 원형 이중 연결 리스트가 있다.*맨 앞에 있는 노드를 헤드(head)라고 한다. 싱글 연결 리스트 : next 포인터만 가진다. 이중 연결 리스트 : next 포인터와 prev 포인터를 가진다. 원형 이중 연결 리스트 : 이중 연결 리스트와 같지만 마지막 노드의 next 포인터가 헤드 노드를 가리키는 것을 말한다.싱글 연결 리스트(Singly Linked List)자료들이 링크로 서로 연결되어 있는 형태 단방향 링크 이전 노드에 접근하기 위해선 첫 번째 노드부터 다시 순회해야한다. 각 노드 당 한 개의 포인터가 있고 포인터는 다음 노드의 위치를 가르킨다. 테일은 가장 마지막이므로 다음을 가리키는 포인터를 갖지 않는다.원형 연결 리스트(Circular Linked List)가장 마지막 자료가 가장 처음 자료와 연결되어 있는 형태단일 연결 리스트(Single Linked List)는 마지막 노드가 null을 가리킨다.이 마지막 노드가 첫 번째 노드를 가리키게 하면 원형 연결 리스트가 된다.🐣 단일 연결 리스트의 테일에 포인터가 추가된 형태로 테일의 포인터는 헤더를 가르켜 원형이 되도록 한다. 단방향 링크 마지막 노드와 첫 번째 노드가 연결된 원형 구조 이전 노드에 접근하기 위해서 계속 한 방향으로만 순회하면 된다.이중 연결 리스트(Doubly Linked List)앞 뒤 자료가 서로서로에게 양쪽으로 연결되어 있는 형태단일 연결 리스트는 포인터를 한 개 가지고 있어 다음 노드만 가리킬 수 있었다면이중 연결 리스트는 포인터를 두 개 가지고 있어 이전 노드와 다음 노드를 가리킨다. 양방향 링크 각 노드가 앞 뒤로 연결된다. 이전 노드에 직접 접근(Direct Access) 가능하다.이중 연결 리스트는 앞에서부터 요소를 넣는 push_front(), 뒤에서부터 요소를 넣는 push_back,중간에 요소를 넣는 insert() 등의 함수가 있다.특성 비교이전 노드에 대한 접근 연산 싱글 연결 리스트 : 이전노드를 접근할수 있는 방법이 없다. 무조건 가장 처음 노드부터 검색해야한다. 원형 연결 리스트 : 계속 가다보면 나의 이전 노드의 값을 찾을 수 있다. 이중 연결 리스트 : 이중으로 연결되어 있기 때문에 바로 이전 노드를 접근 할 수 있다.원형 이중 연결 리스트이중 연결 리스트와 원형 연결 리스트의 특성을 합친 개념이다.인접한 두개의 노드는 서로의 위치를 알고 있으며,맨 마지막 노드는 맨 앞의 노드인 HEAD 노드와 인접하게 되어 서로의 위치를 알게 된다.따라서 원형의 형태를 띄게 된다. HEAD에서 부터 시작해서 시계방향 또는 시계 반대방향으로 순환이 가능하다.codeSingly LinkedList 코드 직접 구현해보기J 팀원 코드 보기M 팀원 코드 보기Dal 클래스 생성이후에 예시로 사용될 클래스를 작성했다.class Dal{ private String name; private int age; public Dal(String name, int age) { this.name = name; this.age = age; }}LinkedList 선언LinkedList 선언은 ArrayList선언 방식과 같다.다만 LinkedList에서는 초기의 크기를 미리 생성할수는 없다.LinkedList list1 = new LinkedList(); // 타입 미설정 Object로 선언된다.LinkedList&lt;Integer&gt; num = new LinkedList&lt;Integer&gt;(); // 타입설정 int타입만 사용가능LinkedList&lt;Integer&gt; num2 = new LinkedList&lt;&gt;(); // new에서 타입 파라미터 생략가능LinkedList&lt;Integer&gt; list2 = new LinkedList&lt;Integer&gt;(Arrays.asList(1,2)); // 생성시 값 추가LinkedList 값 추가LinkedList&lt;Integer&gt; addList = new LinkedList&lt;Integer&gt;();addList.addFirst(5); // 가장 앞에 데이터 추가addList.addLast(17); // 가장 뒤에 데이터 추가addList.add(21); // 데이터 추가addList.add(1, 3); // index 1에 데이터 3 추가LinkedList에 값을 추가하는 방법은 여러 개가 있는데 대중적으로 add(index, value) 메소드를 사용한다.index를 생략하면 가장 마지막에 데이터가 추가된다.LinkedList&lt;Dal&gt; dal = new LinkedList&lt;Dal&gt;(); // 타입설정 Dal 객체만 사용가능Dal dal1 = new Dal(\"hae\", 1);dal.add(dal1);dal.add(new Dal(\"dal\", 2)); for(Dal d : dal) { // for문을 통한 전체출력 System.out.println(\"dal 이름 전체 출력 : \" + d.name);}LinkedList 값 삭제LinkedList&lt;Integer&gt; removeList = new LinkedList&lt;Integer&gt;(Arrays.asList(1,2,3,4,5));removeList.removeFirst(); // 가장 앞의 데이터 제거removeList.removeLast(); // 가장 뒤의 데이터 제거removeList.remove(); // 생략시 0번째 index제거removeList.remove(1); // index 1 제거removeList.clear(); // 모든 값 제거LinkedList 크기 구하기LinkedList&lt;Integer&gt; list = new LinkedList&lt;Integer&gt;(Arrays.asList(1,2,3));System.out.println(list.size()); // list 크기 : 3LinkedList 값 출력위에서 값을 출력 시키기 위해서 코드를 사용했었는데 이 코드만 다시 한번 보자면 아래와 같다.System.out.println(list.get(0)); // 0번째 index 출력 for(Integer i : list) { // for문을 통한 전체출력 System.out.println(i);} Iterator&lt;Integer&gt; iter = list.iterator(); // Iterator 선언while(iter.hasNext()){ // 다음값이 있는지 체크 System.out.println(iter.next()); //값 출력}LinkedList 값 검색System.out.println(list.contains(1)); // list에 1이 있는지 검색 : trueSystem.out.println(list.indexOf(1)); // 1이 있는 index반환 없으면 -1출처 원형 연결 리스트(circular linked list), 이중 연결 리스트(double linked list) [자료구조] Array VS LinkedList [자료구조] 연결 리스트의 종류 [Data Structure] 연결리스트에 대해 알아보자(Linked List) 원형 연결리스트, 이중 연결리스트, 이중 원형 연결리스트 - 자료구조 기초 [자료구조] 연결리스트의 종류와 특성 코드 출처 → [Java] 자바 LinkedList 사용법 &amp; 예제 총정리" }, { "title": "Array", "url": "/posts/Array/", "categories": "Study", "tags": "Data-Structure, study, summary", "date": "2022-10-24 00:00:00 +0900", "snippet": "배열자료형의 집합 같은 타입의 변수들로 이루어져있다. 크기가 정해져있다. 인접한 메모리 위치에 있는 데이터를 모아놓은 집합이다. 중복을 허용하고 순서(index)가 있다.🐣 index는 0부터 시작한다.시간 복잡도여기서 설명하는 배열은 ‘정적 배열’을 기반으로 설명한다.💬 정적 배열?배열은 연속해있는 자료의 집합이며 각 자료는 번호를 가진다. 번호는 n개를 원소로 가지는 배열일 때 순서대로 0 ~ n-1의 번호를 가지며 프로그래밍 언어에 따라서 1~n개를 가지는 배열도 짤 수 있다. 배열의 크기가 한번 정해지면 배열의 크기를 바꿀수 없다 배열의 크기를 바꾸려면 배열을 동적할당으로 할당해야한다. 탐색에 O(1)이 되어 랜덤 접근(random access)이 가능하다.삽입과 삭제에는 O(n)이 걸린다.삽입하는데 걸리는 시간은 O(1) 이 되지만 이미 있던 데이터를 전부 밀어버려야 한다.삭제 또한 하나를 삭제하면 그 공간만큼 당겨야 하므로 O(n)의 시간이 걸린다.랜덤 접근과 순차적 접근 Random Access: 어떤 요소에 바로 접근하는 것 Sequential Access: 어떤 요소에 접근할 때, 처음부터 차례차례 접근하는 것 직접 접근이라고 하는 랜덤 접근은 동일한 시간에 배열과 같은 순차적인 데이터가 있을 때 임의의 인덱스에 해당하는 데이터에 접근할 수 있는 기능이다.이는 데이터를 저장 된 순서대로 검색해야하는 순차적 접근과는 반대이다.배열의 필요성연관성 있는 데이터를 관리하기 편하다.int student0 = 88;int student1 = 72...int student99 = 96;배열로 바꾸기 int[] scores = {88, 72, ..., 96};코드로 보기배열은 자료형 타입 바로 옆에 [] 기호를 사용하여 표현한다.ex) int[] : int 자료형의 배열String[] dogs = {\"미니핀\", \"말티즈\", \"푸들\", \"포메\"};배열 생성2가지가 있다. 생성과 동시에 초기화 int[] arr1 = {11, 22, 33, 44}; 먼저 생성 후, 개별 초기화 int[] arr2 = new int[4]; arr2[0] = 11; arr2[1] = 22; arr2[2] = 33; arr2[3] = 44; 🐣 String[] weeks = new String[]; → 길이에 대한 숫자값이 없으므로 컴파일 오류가 발생한다.배열 사용법배열 내 값들은 변수명에 인덱스(index)를 표기하여 접근할 수 있다.ex) array[index]배열의 길이는 length를 통해 얻을 수 있다.int arr3 = {10, 20, 30, 40, 50};System.out.println(arr3.length);ex)// 0: 자바, 1: 수학, 2: 과학, 3: 영어double[] grades = {4.5, 3.5, 4.0, 3.0};// 자바 점수 읽기System.out.println(\"자바 = \" + grades[0]); // 자바 = 4.5// 자바 점수 변경grades[0] = 4.0;// 평균 구하기double sum = 0;for (int i = 0; i &lt; grades.length; i++) { sum += grades[i];}double avg = sum / grades.length; // 3.625 = 14.5 / 4System.out.printf(\"평점: %.2f\\n\", avg); // 평점: 3.63// %f : 실수형 출력// %.2f : 소수점 둘째 자리 출력출처 [면접을 위한 CS 전공지식 노트] 자바 배열이란? 01-자료구조: 배열(Array)-&gt;정적배열(Static Array) 03-06 배열 (Array) [CS스터디] Array와 LinkedList" }, { "title": "연관관계", "url": "/posts/%EC%97%B0%EA%B4%80%EA%B4%80%EA%B3%84/", "categories": "Study", "tags": "Java, study, summary, DB", "date": "2022-10-18 00:00:00 +0900", "snippet": "연관관계RDBMS는 정해진 데이터 스키마에 따라 데이터를 저장한다.NoSql은 json 형태의 도큐먼트 형식으로 데이터를 저장한다.🌹 RDBMS의 꽃 “연관관계”에 대해서 알아본다.연관관계 목차 연관관계 이론 👈🏻 연관관계 적용 연관관계 적용2(refactoring) 연관관계 적용3(궁금증 해결하기) 연관관계 적용4 정리(코드 + MySQL)💬 용어 PK (Primary Key) : 고유값, 기본 키, 식별 자 FK (Foreign Key) : 외래 키, 다른 테이블 레코드의 PK값을 참조한 값FK 값을 갖도록 설정한다. = 연관관계 매핑연관관계 매핑은 데이터베이스의 테이블 간의 관계를 객체 모델에 매핑하는 것을 의미한다.연관관계 매핑에는 아래 4가지 설정이 있어야 정상적인 동작이 된다. 연관관계 매핑 종류 객체 설정 매핑 방향(앙뱡향, 단방향) 비즈니스 로직연관관계 매핑 종류 OneToOne (1대1) OneToMany (1대N : 일대다) ManyToOne (N대1 : 다대일) ManyToMany (N대N : 다대다)🐣 : 다대다는 실무에서 사용하면 안된다.연관관계는 어떤 도메인 시점에서 보냐에 따라 달라진다.ex) Team과 Member 관계에서 Team의 시점에서는 하나의 Team에 여러 멤버가 올 수 있어 일대다 관계이고,Member 시점에서는 여러 멤버들이 한 Team에 소속될 수 있기때문에 다대일 관계이다.일대일 매핑Member와 Profile로 연관관계 매핑을 해볼 것이다.@Entity@Getter @Setter@ToStringpublic class Profile { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Long id; private String name; private int age;}@Entity@Getter @Setter@ToStringpublic class Member { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Long id; private String email;}Member와 Profile이 있다.멤버 한 명 당 하나의 프로필 정보를 가진다.Member - Profile : 멤버 도메인은 하나의 프로필을 갖는다. (@OneToOne : 일대일)매핑 방향 단방향 양방향매핑방향에는 단방향 매핑과 양방향매핑이 있다.단방향 매핑은 한쪽의 도메인이 다른 한쪽의 도메인을 참조하고 있는 것(FK를 가지고 있는 것)이고,양방향 매핑은 두 도메인 서로 참조하고 있는 것이다.member.getProfile() 만 가능 : 단방향 profile.getMember() 도 가능 : 양방향양방향 매핑 규칙객체의 두 관계중 하나를 연관관계의 주인으로 지정한다.연관관계의 주인만이 외래 키를 관리(등록, 수정)한다.🐣 수정, 접근을 양쪽 모두 가능하게 하고 싶다면 양방향으로 설정하면 된다.양방향으로 설정하기 위해서는 “mappedBy” 를 작성해줘야한다.mappedBy 설정은 주인이 누구인지 설정해주는 속성이다.만약 mappedBy 설정을 해주지 않으면, 단방향 2개와 같다.ex) @OneToOne(mappedBy = \"profile\")🐣 양방향 매핑시 주인만 FK를 가지고 있다.주인연관관계를 맺으면 주인이라는 개념이 적용된다.일반적으로 FK키를 가지고 있는 도메인을 주인으로 보고, 주인은 FK에 접근하여 읽고 쓰기가 가능하나 상대 도메인은 읽기만 가능하다.🐣1:N 관계에서는 N이 주인이다.MySQL 같은 RDBMS에 여러 개 데이터가 들어갈 수 없어서 N이 주인이 될 수밖에 없다. *자바에서 객체로 불러올땐 가능하다.“주인” 테이블에 세트로 매핑종류와 @JoinColumn을 작성해준다.@JoinColumn의 name은 pk를 fk로 설정해서 저장해둘 이름을 작성한다.위의 Member로 예시를 들면 관계의 주인은 Member 도메인이다.@OneToOne@JoinColumn(name = \"profile_id\")private Profile profile;1대1 매핑이므로 OneToOne을, Profile id를 Member의 fk 이름으로 profile_id로 설정했다.단방향 연관관계일대일 단방향 매핑@Entity@Getter @Setter@NoArgsConstructorpublic class Member { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Long id; private String email; @OneToOne @JoinColumn(name = \"profile_id\") private Profile profile;}🐣 Profile에 있는 필드를 모두 작성하기 보다 객체 하나로 연관관계를 맺는게 가장 좋다. @OneToOne 일대일 관계 매핑 어노테이션은 주인 도메인에서 사용한다. 참조할 도메인 컬럼에 붙여준다. 속성 fetch : 연관관계가 있는 도메인 로딩 전략 설정 옵션 EAGER[이거 로딩] : 즉시 로딩 LAZY[레이지 로딩] : 지연 로딩 ex) @OneToOne(fetch = FetchType.LAZY) Member를 불러올 때 연관관계인 Profile도 같이 즉시 조회하고 싶으면 EAGER를 사용한다. LAZY는 필요로 할 때만 쓰인다. default값 @OneToOne, @ManyToOne: EAGER @OneToMany, @ManyToMany: LAZY 🐣 EAGER를 사용해 많은 데이터가 로딩되면 부하가 심해서 실무에서는 LAZY로 사용하는 것을 추천한다. 🐣 연관관계 맺은것이 많이 써먹는 메소드가 많다면 EAGER를 사용하고 연관관계 맺은 것이 써먹는 게 없으면 LAZY 사용 ex) User와 Registry의 1:N 관계에서 EAGER와 LAZY 쿼리문 차이 optional : null 값을 넣을 수 있게할 것인지, 아닌지를 설정하는 옵션 true : nullable false : not null @OneToOne(optional = false) or @JoinColumn(optional = false) or @Column(nullable = false) @JoinColumn 매핑할 외래키를 설정한다. 어노테이션을 붙여주지않으면 엔티티를 매핑하는 중간 테이블이 생겨 관리 포인트가 늘어나 좋지 않다.test@DataJpaTestpublic class RelationshipMappingTest { @Autowired private MemberRepository memberRepository; @Autowired private ProfileRepository profileRepository; @Test @DisplayName(\"멤버 및 프로필 저장 테스트\") void memberSaveTest01() { /* * 멤버 저장시 프로필 정보가 필요하다. * 따라서, 프로필을 먼저 저장한 후 그 프로필을 멤버에 넣어주어야한다. */ // 프로필 객체 생성 Profile profile = new Profile(); profile.setId(1L); profile.setName(\"coco\"); profile.setAge(10); // 프로필 저장. profileRepository.save(profile); // 멤버 객체 생성 Member member = new Member(); member.setId(1L); member.setEmail(\"coco@gmail.com\"); // 멤버 프로필 설정 member.setProfile(profile); // ← // 멤버 저장. memberRepository.save(member); assertEquals(1, memberRepository.countById(1L)); assertEquals(1, profileRepository.countById(1L)); }}양방향 연관관계양방향 매핑 규칙 객체의 두 관계중 하나를 연관관계의 주인으로 지정한다. 주인은 mappedBy 속성을 사용하지 않는다. 주인이 아니면 mappedBy 속성으로 주인을 지정한다. 연관관계의 주인만이 외래 키를 관리(등록, 수정)한다.일대일 양방향 매핑@Entity@Getter @Setter@NoArgsConstructorpublic class Profile { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Long id; private String name; private int age; @OneToOne(mappedBy = \"profile\") // 👈🏻 private Member member;}mappedBy 설정은 주인이 누구인지 설정해주는 속성이다.주인이 아닌 엔티티에 설정해주며 반대쪽 필드 명을 적으면 된다.ex) Member.java의 private Profile profile; 에서 profile을 적은 것이다.mappedBy 설정을 해주지 않으면, 단방향 2개와 같다.🐣 양방향 매핑시 주인만 FK를 가지고 있다.값 설정하기profile에 member FK가 없지만, 양방향 관계를 맺었기 때문에 member 값을 가져올 수 있다.하지만, profile에 member를 설정해 주지 않았기 때문에 member를 가져올 수 없다.기존 Profile의 @Setterpublic void setProfile(Profile profile) { this.profile = profile;}🔽 양방향에서 Profile에 Member를 가져올수는 있는데 값을 설정해주지 않아서 가져오려면 로직 작성이 필요하다.Profile 도메인의 setMember()@Entity@Getter @Setter@NoArgsConstructorpublic class Profile { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Long id; private String name; private int age; @OneToOne(mappedBy = \"profile\") private Member member; public void setMember(Member member) { member.setProfile(this); // 👈🏻 this.member = member; }}🐣 Member에 적든 Profile에 적든 상관없다. Member 도메인에서 setProfile() 메서드 호출 시 profile에 member를 설정하던 Profile 도메인에서 setMember() 메서드 안에서 member에 profile을 설정하던 상관없다.Member 도메인의 setProfile()@Entity@Getter@Setter@NoArgsConstructorpublic class Member { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Long id; private String email; @OneToOne @JoinColumn(name = \"profile_id\") private Profile profile; public void setProfile(Profile profile) { profile.setMember(this); // 👈🏻 this.profile = profile; }}양방향 매핑 시 주의사항 @ToString, @ResponseBody@ToStringjava.lang.StackOverflowError: null해당 에러는 Lombok이 자동으로 만들어낸 ToString 메소드로 인해 발생하는 순환참조 때문이다.이 문제를 해결하기 위해서는 해당 클래스에서 참조하고 있는 클래스를 ToString에서 제외해 주어야 한다.Member를 문자열로 표현하기 위해 그 안에 Profile의 toString 을 실행한다.Profile안에 Member가 있기때문에 Member의 toString 실행 → Member안에 Profile이 있기때문에 Profile의 toString 실행….이러한 무한 루프에 빠지게 되는데 이 무한 루프를 순환참조라고 한다.따라서, 양방향 매핑 시 @ToString에서 필드를 제외 시켜줘야한다. (→ @ToString.Exclude)@ResponseBody또한, @RestController의 경우 @ResponseBody로 객체를 반환해 줄 때 JSON 형태로 변환해주는데이때도 마찬가지로 매핑된 필드를 제외해줘야한다. (→ @JsonIgnore)@Entity@Getter @Setter@ToString@NoArgsConstructorpublic class Profile { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Long id; private String name; private int age; @OneToOne(mappedBy = \"profile\") @ToString.Exclude @JsonIgnore private Member member; public void setMember(Member member) { member.setProfile(this); this.member = member; } public Profile(String name, int age) { this.name = name; this.age = age; }} DTO 활용이렇게 순환참조 발생을 막기위해 여러 어노테이션을 붙이다보면 가독성이 떨어지고 코드가 지져분해진다.DTO를 활용하면 필요한 필드만 유저에게 전달해줄 수 있기 때문에 순환참조를 방지할 수 있고 어노테이션을 붙여주지 않아도 되기 때문에 코드가 깔끔해진다는 장점도 있다.DTO를 활용했을때 이러한 장점 이외에도 도메인 객체를 그대로 유저에게 전달해주지 않고 필터링된 정보만 유저에게 전달해준다는 장점도 있다.test@Test@DisplayName(\"멤버 및 프로필 저장 필드 설정 테스트\")void memberSaveTest02() { /* * 멤버 저장시 프로필 정보가 필요하다. * 따라서, 프로필을 먼저 저장한 후 그 프로필을 멤버에 넣어주어야한다. */ // 프로필 객체 생성 Profile profile = new Profile(); profile.setId(1L); profile.setName(\"coco\"); profile.setAge(10); // 프로필 저장. profileRepository.save(profile); // 멤버 객체 생성 Member member = new Member(); member.setId(1L); member.setEmail(\"coco@gmail.com\"); // 멤버 프로필 설정 member.setProfile(profile); // 멤버 저장 memberRepository.save(member); Member savedMember = memberRepository.findById(1L).get(); Profile savedProfile = savedMember.getProfile(); System.out.println(savedMember); // Member(id=1, email=coco@gmail.com, profile=Profile(id=1, name=coco, age=10), team=null) System.out.println(savedProfile); // Profile(id=1, name=coco, age=10) System.out.println(savedProfile.getMember()); // null}다대일 양방향 매핑Member - Team : 한 팀에 여러 멤버가 속한다. (@ManyToOne, @OneToMany : 일대다)팀에 속한 전체 멤버를 조회할 상황이 발생할 수 있다.@Entity@Getter@Setter@NoArgsConstructorpublic class Member { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Long id; private String email; @OneToOne @JoinColumn(name = \"profile_id\") private Profile profile; @ManyToOne @JoinColumn(name = \"team_id\") private Team team; public void setProfile(Profile profile) { profile.setMember(this); this.profile = profile; } public void setTeam(Team team) { team.addMember(this); // 👈🏻 this.team = team; }}만약 Team의 addMember()를 작성하지 않았다면team.addMember(this); 대신 team.getMembers().add(this);라고 작성하면 된다.@Entity@Getter @Setter@NoArgsConstructorpublic class Team { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Long id; private String name; @OneToMany(mappedBy = \"team\") @JsonIgnore private List&lt;Member&gt; members = new ArrayList&lt;&gt;(); // 👈🏻 초기화 public void addMember(Member member) { member.setTeam(this); this.members.add(member); }}🐣 일대다 컬랙션 타입 필드는 “초기화”를 해줘야 한다.하이버네이트는 엔티티를 영속 상태로 만들 때, 컬렉션 필드를 하이버네이트에서 준비한 컬렉션으로 감싸서 사용한다.컬렉션을 효율적으로 관리하기 위해서이며, 이런 특징 때문에 컬렉션을 사용할 때 다음처럼 즉시 초기화해서 사용하는 것을 권장한다.초기화를 시키지 않으면 NullPointerException이 발생한다.일대다 혹은 다대일 매핑에서 일인 클래스에 다인 클래스를 컬렉션으로 적어준다.members가 list이기 때문에 내장 함수인 add()를 사용해서 this.members.add(member);라고 붙여준 것이다.collection은 List, Set, Map이 있다. Collection : 자바가 제공하는 최상위 컬렉션이다. List : 순서가 있고, 중복을 허용한다. Set : 순서가 없고, 중복은 허용하지 않는다 Map : Key, Value로 되어있으며 키는 중복을 불허한다.인프런 관련 글출처 연관관계 매핑 기초 [JPA] JPA가 지원하는 컬렉션 java.lang.StackOverflowError: null" }, { "title": "Jpql", "url": "/posts/JPQL/", "categories": "Study", "tags": "Java, study, summary", "date": "2022-10-10 00:00:00 +0900", "snippet": "JPQL(Java Persistence Query Language)JPA만의 기술을 사용했을 때는 DB의 데이터 조회를 식별자를 통한 조회와 객체 그래프를 통한 탐색만 가능했다. 식별자를 통한 조회: em.find() 객체 그래프 탐색: a.getB().getC()두 가지 조회 방법으로만 어플리케이션 개발을 한다면 모든 엔티티를 메모리에 올려두고 애플리케이션에서 필터링하는 등의 성능 낭비가 발생하게 된다.이러한 낭비를 막기 위해 JPA는 데이터베이스에서 상황별 조건에 맞게 필터링하여 필요한 데이터를 가져오는 JPQL을 제공한다.JPQL은 Java Persistence Query Language의 약자로 JPA에서 SQL을 추상화하여 만든 객체 지향 쿼리 언어이다.SQL을 추상화하였기에 특정 데이터베이스에 의존적이지 않다.SELECT, FROM, WHERE, GROUP BY, HAVING, JOIN 등 SQL과 문법이 유사하다.SQL은 데이터베이스 테이블을 대상으로 쿼리를 작성하지만 JPQL은 엔티티 객체를 대상으로 쿼리를 작성한다.select m From Member m where m.name like ‘%hello%' 에서 Member는 테이블 이름이 아니다.JPQL에서는 테이블이 아닌 @Entity(name = “”)에 지정된 엔티티 이름을 가르키고 있다. (지정하지 않았다면 default 값 → 클래스 이름)Query Method사용하려는 Repository에 JpaRepository만 상속해주면 스프링의 AOP 기능을 사용하여 구현까지 자동으로 해준다.간단한 문법으로 객체의 CRUD가 가능하다.기본적으로 find + \"객체\" + By + \"변수\" 로 사용하는데 중간에 객체는 생략 가능하다.public interface CommentRepository extends JpaRepository&lt;Comment, Long&gt; { List&lt;Comment&gt; findAllByRegistryId(int idx);}Query Method를 통해서 간단하게 필요한 객체를 조회할 수 있지만 조금 더 복잡한 조건을 사용하려면 메소드의 길이가 증가하게 된다는 단점이 있다.이에 대한 해결로는 JPQL(Java Persistence Query Language)가 있다.코드로 보는 JPQL 사용 이유정렬public interface ProductRepository extends JpaRepository&lt;Product, Long&gt; { List&lt;Product&gt; findByNameContainsOrderByPriceAsc(String name);}findByNameContainsOrderByPriceAsc를 보면 name을 포함하고 가격을 오름차순으로 정렬해서 출력한다.그런데 찾는 조건이 많아질 수록 이름이 너무 길어진다.그래서 정렬 부분을 따로 파라미터로 받아 올 수 있다.→ List&lt;Product&gt; findByNameContains(String name, Sort sort);test 코드로 실행을 하면 아래와 같이 사용할 수 있다.@DataJpaTest@AutoConfigureTestDatabase(replace = AutoConfigureTestDatabase.Replace.NONE)class ProductRepositoryTest { @Test void findByNameContains() { List&lt;Product&gt; products = productRepository.findByNameContains(\"네스프레소\", Sort.by(Sort.Order.asc(\"name\"), Sort.Order.asc(\"price\")));}Sort.by(Sort.Order.asc(\"name\"), Sort.Order.asc(\"price\"))페이징public interface ProductRepository extends JpaRepository&lt;Product, Long&gt; { Page&lt;Product&gt; findAll(Pageable pageable);}@DataJpaTest@AutoConfigureTestDatabase(replace = AutoConfigureTestDatabase.Replace.NONE)class ProductRepositoryTest {void findAllPaging() { Page&lt;Product&gt; products = productRepository.findAll(PageRequest.of(0, 5)); }PageRequest가 Pageable의 구현체다. PageRequest.of로 Pageable 객체를 생성해서 넣어준다.페이징을 할때 sort.by() 까지 통해서 페이징과 정렬을 한꺼번에 할 수 있다.위 코드들을 보면 불필요하게 메소드 명이 길다.복잡한 조건을 메소드로 표현하기 어려울 수 있기 때문에 JPQL을 사용하여 직접 쿼리문을 작성해 객체를 조회할 수 있다.객체를 대상으로 하는 쿼리문이며 SQL을 추상화해서 사용하기 때문에 어떤 DB를 사용하더라도 문제없이 사용할 수 있다.Query Method는 쿼리문이 길든 짧든 쿼리문이 날라가는데 (날아간다 = 쿼리문 실행) 불필요하게 이중으로 쿼리문을 날리는 경우가 있다.db 언어로 쓸수는 있지만 db를 변경하게 되면 다시 언어를 바꿔 써야 하므로 jpql 언어로 쓰는 것을 권장한다. *아래 예시를 보면서 참고한다.기본 문법 JPQL은 엔티티와 속성은 대소문자를 구분한다. 하지만 SELECT, FROM, WHERE과 같은 JPQL 키워드는 대소문자를 구분하지 않는다. from Member m에서 m과 같은 별칭(alias)은 필수이다. 하지만 SQL문에서 별칭 지정을 위해 사용하는 as는 생략 가능하다. ex) SELECT m FROM Member m , SELECT m.team FROM Member m @Query(\" query 문 \") 으로 사용한다. JPQL 작성하기@Query@Query(\"SELECT p FROM Product AS p WHERE p.category = ?1\")List&lt;Product&gt; findByCategory(String category);@Query(\"SELECT p FROM Product p WHERE p.category LIKE %:category%\")List&lt;Product&gt; findByCategory2(@Param(\"category\") String category);@Query(\"SELECT p.name, p.category, p.price FROM Product p WHERE p.category LIKE %:category%\")List&lt;Object[]&gt; findByCategory3(@Param(\"category\") String category);@Query 어노테이션 JPQL을 직접 작성하여 사용한다. 직접 사용하는 데이터베이스의 SQL문을 작성해도 가능하다. 단, 데이터베이스를 변경하게 되면 SQL문도 바꿔야한다.@Param 어노테이션 메서드 인자를 쿼리문에 사용하는 방법 메서드 인자의 위치를 쿼리문에 넣어주는 방법 @Param 어노테이션을 사용하는 방법전자의 경우 파라미터의 순서가 바뀌면 오류가 발생할 가능성이 있다. 따라서, @Param 어노테이션을 사용하는 것을 권장한다.첫번째 파라미터 가져오기 p.category = ?1 → 언어 바뀌면 또 바꿔야한다. p.category like %:category% Like 연산자는 특정 패턴을 포함하는 데이터만을 검색하기 위해 사용한다. ’%’는 0개 이상의 문자라는 의미의 와일드카드(wildcard) 문자이다. 와일드카드(wildcard)란 문자열 내에서 임의의 문자나 문자열을 대체하기 위해 사용되는 기호를 의미한다. 카테고리를 검색하는데 카테고리에 포함되어있는지 검색하고 싶다.:category 커피라는 글자가 무조건 맞아야 한다. 커피믹스나 믹스커피는 값에 포함되지 않는다.%:category% 앞이나 뒤에 어떤게 오든 커피라는 글자만 있으면 가져오고 싶으면 %를 사용한다. 믹스커피, 커피믹스 둘 다 출력된다.:category% 앞에는 무조건 커피로 시작하고 뒤에는 상관없다. 믹스커피는 안나오고 커피믹스는 출력되지 않는다.모델 class에서 변수설정한 4개중에 3개만 select 하는 경우 object 배열로 받아야한다.public class Product { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Long id; private String name; private String category; private int price;}List&lt;Object[]&gt; findByCategory(@Param(\"category\") String category);*모델로 받을 수 없다. List&lt;Product&gt; findByCategory(@Param(\"category\") String category); ❌JPQL은 직접 쿼리문을 문자열로 작성하기 때문에 오타로 인한 컴파일 에러를 통해 확인이 불가능하다.QueryDSL 이란?Querydsl 정적 타입을 이용해서 SQL과 같은 쿼리를 생성할 수 있도록 해 주는 프레임워크@query 사용시 오타가 발생하면 컴파일 에러를 못 잡는 문제가 있는데 queryDSL은 오타 발생 시 컴파일에러를 잡을 수 있고 query문의 문법적 오류를 잡아주는 등의 장점이 있다. @query(seletc ~~ ) 오타가 났을 때 컴파일에러가 발생하지 않는다. (실행할 때 까지 모른다.) → QueryDSL을 쓰면 미리 문법적 오류를 발견할 수 있다.QueryDSL 장점 문자가 아닌 코드로 쿼리를 작성함으로써, 컴파일 시점에 문법 오류를 쉽게 확인할 수 있다. 자동 완성 등 IDE의 도움을 받을 수 있다. 동적인 쿼리 작성이 편리하다. 쿼리 작성 시 제약 조건 등을 메서드 추출을 통해 재사용할 수 있다.&lt;QueryDSL 단점설정하기가 까다롭다.출처 [JPA] JPQL이란? Spring Data JPA(쿼리 메소드) Spring Data JPA - 쿼리 메서드 기능 Spring Data JPA - Reference Documentation 쿼리 메소드 [JPA] JPQL Query 정리 QueryDSL Querydsl: 소개와 사용법 패턴 매칭 쿼리 메소드, JPQL, Querydsl 요약" }, { "title": "자료형", "url": "/posts/%EC%9E%90%EB%A3%8C%ED%98%95/", "categories": "Study", "tags": "Java, study, summary", "date": "2022-09-28 00:00:00 +0900", "snippet": "자바의 자료형은 크게 Primitive Type과 Reference Type으로 나눌 수 있다.Primitive Type (기본형 타입)char, int, long, float, double, boolean 등 비객체 타입이다. 따라서 null 값을 가질 수 없다. 만약 Primitive type에 Null을 넣고 싶다면 Wrapper Class를 활용한다. 스택(Stack) 메모리에 저장된다. Reference Type (참조형 타입)클래스 타입(class type) , 인터페이스 타입(interface type) , 배열 타입(array type) , 열거 타입(enum type) JAVA에서 Primitive type을 제외한 타입들이 모두 Reference type new로 인하여 생성하는 것들은 메모리 영역인 Heap 영역에 생성을 하게되고, Garbage Collector가 돌면서 메모리를 해제 빈 객체를 의미하는 Null이 존재 String 은 “Happy Java”와 같이 리터럴로 표기가 가능하지만 primitive 자료형은 아니다.String은 리터럴 표현식을 사용할 수 있도록 자바에서 특별 대우 해 주는 자료형이다.참조형에 속하지만 기본적인 사용은 기본형 처럼 사용한다.리터럴 표기리터럴이란? 변수의 값이 변하지 않는 데이터(메모리 위치안의 값)를 의미→ 객체 생성없이 고정된 값을 그대로 대입하는 방법String a = \"Dal\";String b = \"a\";String c = \"123\";primitive 자료형은 new  키워드로 그 값을 생성할 수 없다.primitive 자료형은 다음과 같이 리터럴(literal)로만 값을 세팅할 수 있다.boolean result = true;char item = 'S';int num = 10;이러한 primitive type 등을 객체로 만들어서 사용해야 하는 경우가 프로그래밍을 하다 보면 종종 존재하는데이럴 때 사용하는것이 Wrapper class 라고 한다.Wrap 말그대로 포장한다는 느낌의 클래스이다.Primitive type의 변수들을 포장하는 것으로 Character, Integer, Long, Float, Double, Boolean 등이 있다. 원시자료형 Wrapper 클래스 int Integer long Long double Double float Float boolean Boolean char Char 출처 3. 9 Reference Type vs Primitive Type 03-04 문자열 (String) Primitive type &amp; Reference type" }, { "title": "싱글톤, static, final", "url": "/posts/%EC%8B%B1%EA%B8%80%ED%86%A4,-static,-final/", "categories": "Study", "tags": "spring, study, summary", "date": "2022-09-27 00:00:00 +0900", "snippet": "싱글톤 생성 과정을 정리하면서 final과 static에 대해서 정리해봤다.Singleton생성 과정예제로 든 싱글톤은 Thread Safe 하지는 않다.1. final로 써서 초기화 시켜주는 방법 자기 자신을 private static final으로 선언 public으로 getInstance를 선언해서 이 메소드를 통해서만 조회하도록 허용 생성자를 private 으로 선언해서 외부에서 new 키워드를 사용한 객체 생성을 못하게 막는다class Singleton{ private static final Singleton instance = new Singleton(); private Singleton(){ } public static Singleton getInstance(){ return instance; }}public class SingletonTest { public static void main(String[] args) { Singleton singleton1 = Singleton.getInstance(); Singleton singleton2 = Singleton.getInstance(); System.out.println(singleton1); System.out.println(singleton2); }}2. final을 쓰지 않고 null로 체크해서 작성하는 방법class Singleton{\tprivate static Singleton instance;\tprivate Singleton(){\t}\tpublic static Singleton getInstance(){\t\tif (instance == null) {\t\t\tinstance = new Singleton();\t\t}\t\treturn instance;\t}}public class SingletonTest {\tpublic static void main(String[] args) {\t\tSingleton singleton1 = Singleton.getInstance();\t\tSingleton singleton2 = Singleton.getInstance();\t\tSystem.out.println(singleton1);\t\tSystem.out.println(singleton2);\t}}final을 사용하는 1번 같은 경우에는 초기화를 해줘야 한다.final이 상수이기 때문에 한번 초기화 시켜줘야한다.(*상수란 변하지 않고 항상 일정한 값)2번은 final을 사용하지 않아서 초기화를 시켜주지 않은 것이다.private Singleton(){}을 생성해야지 new Singleton()을 만들 수 있다.→ 생성자를 호출해야지 객체를 만들 수 있다.new 객체(); : 객체 생성 == 인스턴스 생성객체를 변수에 처음 담는게 초기화이다.finalfinal은 값을 한 번만 설정할 수 있도록 강제하는 키워드다.즉, 한 번 초기화된 값은 다시 변경할 수 없다.final의 특징 기본 자료형(int, String 등) final로 선언되면 값 자체를 변경할 수 없다. final String str = \"하이\";str = \"바이\"; // 불가능 : 참조 변경이 불가능str.charAt(0); // 가능 : 객체의 메서드 호출은 참조 변경이 아님// 객체의 메서드 호출이 str = \"바이\"; 처럼 객체 값을 변경하는게 아니니까메서드 호출은 객체의 내부 상태를 읽는 작업이므로 가능하다. 객체final로 선언된 객체의 참조는 변경할 수 없지만 객체 내부 상태는 변경할 수 있다.public class A { private int x = 4; public void setX(int x) { this.x = x; } public int getX() { return x; }}public class Service { private final A a = new A(); // a는 한 번 초기화되면 다른 객체로 재할당할 수 없음 public void updateX() { a.setX(8); // a의 내부 상태는 변경 가능 } public int getX() { return a.getX(); // 변경된 값 확인 가능 }}a 객체의 참조는 변경할 수 없지만 객체 내부의 x 값은 변경 가능하다.따라서 final은 상수가 아니라 한 번만 초기화가 가능하다고 보면 된다.*상수 : 변경되지 않는 값예시private final UserService userService;위 코드에서는 final로 UserSerivce를 두고 있는데 이는 userService 참조를 고정한다는 의미를 담고 있다.다른 서비스(예: BoardService)로 userService를 대체할 수 없지만 userService 내부 상태는 변할 수 있다.final이 제한하는 것은 참조의 변경이지 객체 내부 상태의 변경은 아니다.userService.setName(\"name\"); // 가능: 메서드 호출로 내부 상태는 변경 가능userService.setName(\"name\")으로 값을 지정하는데 final은 값을 지정 못하지 않을까?클래스.set메소드는 메소드 사정이지 클래스 사정이 아니다.Service에 final왔으니깐 set 하면 안되는거 아닌가?라는 질문에 관한 답은final 이 제한을 두는 건 userService 의 대한 변화를 제한하는 것이다.즉 userService.setName(); 같은 메서드 호출은 userSerivce 에 영향을 주는 로직이 아니기 때문에 관련이 없다.사용 방법final + 초기화final로 선언된 변수는 반드시 한 번만 초기화되어야 한다.초기화는 선언과 동시에 하거나, 생성자에서 초기화할 수 있다.public class Example { private final int x; // final이므로 반드시 초기화 필요 public Example(int value) { this.x = value; // 생성자에서 초기화 가능 }}초기화 코드 작성 전에 해당 코드를 사용하면 컴파일 에러가 뜬다.초기화 하지 않았을 때초기화 했을 때staticstatic은 메모리에 한 번만 할당되고, 프로그램이 종료될 때 해제된다.해당 변수를 클래스 레벨에서 공유하도록 한다.*클래스 레벨: 해당 클래스에서 모든 인스턴스가 동일한 값을 공유하는 것클래스 안에서 static 키워드가 붙는 경우는 2가지가 존재한다. static 변수 혹은 정적 변수(static 변수 = 정적 변수 = 클래스 변수 = 공용 변수) static 메서드 혹은 정적 메서드🐣 공유 메모리(공유 변수)라고 생각하면 이해가 쉽다.public class Study { static int staticVal = 7; int globalScope = 10; public static void main(String[] args) { Study v1 = new Study(); Study v2 = new Study(); v1.globalScope = 20; v2.globalScope = 30; System.out.println(v1.globalScope); // 20 System.out.println(v2.globalScope); // 30 v1.staticVal = 10; v2.staticVal = 20; System.out.println(v1.staticVal); // 20 System.out.println(v2.staticVal); // 20 }}static을 사용하면 모든 인스턴스가 같은 값을 공유한다.변수 앞에 static 키워드가 붙는 케이스public static double pi = 3.14메서드 앞에 static 키워드가 붙는 케이스public static int plus ( int x , int y ){ return x + y; } static의 장점메모리 효율성 : 메모리에 한 번만 할당되어 여러 인스턴스가 공유하므로, 메모리 사용이 효율적이다.공유 메모리 : static 변수를 사용하면 모든 인스턴스가 같은 값을 공유한다.객체 생성없이 클래스를 통해 메서드를 직접 호출할 수 있다.static과 finalstatic final을 함께 사용하면 클래스 레벨에서 공유되면서 변경할 수 없는 상수를 의미한다.public static final double PI = 3.14;final 멤버 변수에 static을 사용하지 않는 경우→ DI(Dependency Injection) 기법을 사용해 클래스 내부에 외부 클래스 의존성을 집어넣는 경우bean을 주입하는 경우에는 static을 쓰면 안된다. (ex. @Component)@Controllerpublic class UserController { private final UserService userService; public UserController(UserService userService) { this.userService = userService; }}DI(의존성 주입)의 목적은 유연성과 확장성이다.각 객체는 독립적으로 관리되고 환경에 따라 다른 의존성을 주입받아야 할 수 있다.static은 모든 인스턴스가 동일한 객체를 공유하므로 유연성이 떨어진다.→ 모든 사용자에게 동일한 객체가 적용되어 각자의 상태를 독립적으로 관리할 수 없게된다.참고로 생성자를 만들어야 객체를 만들 수 있는데위에서 객체 생성 없이 바로 클래스.메소드를 사용할 수 있었던 이유는Spring IoC 컨테이너는 객체(Bean)를 생성하고 관리하며, 의존성을 주입해주기 때문이다.예시[점프 투 자바 - 03 정적(static) 변수와 메소드] 에서class Counter { int count = 0; Counter() { this.count++; System.out.println(this.count); }}⬇️class Counter { static int count = 0; Counter() { count++; // count는 더이상 객체변수가 아니므로 this를 제거하는 것이 좋다. System.out.println(count); // this 제거 }}위 코드와 아래 코드의 차이점은 static 유무이다.아래 코드에서 static을 붙이면서 this를 뺐다. 왜일까?그 객체만의 것이 아니니깐 this를 뺀 것이다.c1.count, c2.count 가 아니라 counter의 count이므로공유 count이기 때문에 counter 전체를 아우르는 것이어서 this를 없앤 것이다.JVM 메모리 구조JVM은 크게 Garbage collector, Execution Engine, Class Loader, Runtime Data Area 4가지 영역으로 나누어진다.이 중에서 static을 이해하는 데 필요한 Class Loader와 Runtime Data Area(메모리 영역)에 관해 작성했다.Class Loader와 Runtime Data Areajava 코드를 작성면 확장자가 java인 *.java 인 소스 파일을 생성한다.해당 java 파일들은 Java 컴파일러(javac)에 의해 .class 파일인 Byte Code로 컴파일된다.Class Loader는 이 바이트코드를 JVM의 메모리 영역인 Runtime Data Area에 적재한다.Java Virtual MachineRuntime Data Area은 Method Area, Heap Area, Stack Area, PC register, Native Method Stack 총 5가지로 구분된다. Method Area (Static Area): 클래스 정보, 상수, static 변수, final 변수 등 항상 메모리에 상주하는 영역 Heap Area: new 키워드로 생성된 객체와 배열이 저장되는 영역 Stack Area: 메서드 호출 시 사용되는 지역 변수, 파라미터, 리턴 값 등이 저장 PC Register: 현재 실행 중인 JVM 명령의 주소를 저장 Native Method Stack: 네이티브 메서드를 위한 스택 static과 메모리 구조Class Loader가 .class 파일을 적재하는 동안 static 키워드가 붙은 멤버를 발견하면JVM은 이를 객체가 생성되지 않았더라도 Method Area에 즉시 메모리 할당을 한다.→ static 멤버가 클래스에 소속된 변수이므로static 변수나 메서드는 인스턴스와 무관하게 클래스 레벨에서 공유된다.static 멤버는 모든 객체가 동일한 메모리 영역을 바라보며 이를 클래스 변수 또는 클래스 메서드라고 부른다.public class Counter { public static int count = 0; // static 변수 Counter() { this.count++; System.out.println(this.count); } public static void main(String[] args) { Counter c1 = new Counter(); Counter c2 = new Counter(); }}위 코드에서 count는 static 변수이기 때문에 c1, c2 두 객체가 같은 메모리 공간을 공유한다.따라서 c1이 생성되면서 증가된 값은 c2에서도 동일하게 반영된다.같은 이유로 static 메서드 안에서 사용할 변수들은 메모리에 올라가는 순서 때문에 아래와 같은 코드는 불가능하다. (스태틱 메서드 안에서는 인스턴스 변수 접근이 불가능하다)public class Counter { public int count = 0; // 인스턴스 변수 Counter() { this.count++; } public static int getCount() { return count; // 에러 발생 } public static void main(String[] args) { Counter c1 = new Counter(); Counter c2 = new Counter(); System.out.println(Counter.getCount()); }}위 코드에서 count는 인스턴스 변수이므로 static 메서드 getCount() 내에서 접근할 수 없어 에러가 발생한다.이를 해결하려면 count를 static 변수로 선언해야 한다.public class JvmStack {\tpublic static void main(String[] args) {\t\tadd(); // static 메서드 호출\t}\tpublic static void add(){\t\tminus();\t\tmul();\t}\tpublic static void minus(){\t\tSystem.out.println(\"minus\");\t}\tpublic static void mul(){\t\tSystem.out.println(\"mul\");\t}}위 코드에서 모든 메서드가 static으로 선언되었다.static이 아닌 메서드는 JVM에서 메모리에 올라가는 타이밍이 달라져 호출할 수 없기 때문이다.따라서 메모리에 적재 시점을 고려해야 static을 올바르게 사용할 수 있다.따라서 아래와 같이 인스턴스 생성으로 작성한다.public class JvmStack {\tpublic static void main(String[] args) {\t\tJvmStack jvmStack = new JvmStack();\t\tjvmStack.add();\t}\tpublic void add(){\t\tmul();\t\tminus();\t}\tpublic void minus(){\t\tSystem.out.println(\"minus\");\t}\tpublic void mul(){\t\tSystem.out.println(\"mul\");\t}}무분별한 static 사용의 문제점이러한 static의 특징들 때문에 메서드의 호출 시간이 짧아진다고 무분별한 static의 사용은 java에서 지양된다. 캡슐화 문제: static 변수는 객체 간에 공유되기 때문에 객체지향 프로그래밍의 캡슐화 원칙을 깨뜨릴 수 있다. 테스트의 복잡성: static 변수는 전역적으로 공유되므로, 독립적인 테스트가 어렵다. 오버라이딩 불가: static 메서드는 오버라이딩이 불가능해 코드의 재사용성이 떨어진다. 메모리 낭비: 프로그램이 종료되기 전까지 메모리에 남아 있어 자주 사용하지 않는 static 메서드나 변수는 메모리 낭비로 이어질 수 있다. 🐣 static을 사용하는 것이 좋을 때 : 자주 사용하는 객체, 생성 시간이 오래 걸리거나 메모리를 많이 사용하는 객체REFERENCE final 을 쓰는 이유가 궁금합니다. 03-11 형변환과 final 07-03 정적(static) 변수와 메소드 Java에서 자주 보이는 Static이란 무엇일까? 왜 자바에서 final 멤버 변수는 관례적으로 static을 붙일까?" }, { "title": "데이터베이스 연동", "url": "/posts/%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B2%A0%EC%9D%B4%EC%8A%A4-%EC%97%B0%EB%8F%99/", "categories": "Study", "tags": "spring, study, summary, ch4, DB", "date": "2022-09-25 00:00:00 +0900", "snippet": "DB*스프링 부트 핵심 가이드 책으로 스터디 진행관련 글 : Controller, Service, RepositoryORM(Object Relational Mapping) : 객체 관계 매핑 객체지향 언어에서 의미하는 객체(클래스)와 RDB(관계형 데이터 베이스 : Relational Database)의 테이블을 자동으로 매핑하는 방법 ( 영속화하는 것 ) 객체(자바 클래스)와 데이터베이스의 테이블 사이의 차이와 제약사항을 해결하는 역할 → 클래스는 데이터베이스의 테이블과 매핑하기 위해 만들어진 것이 아니기 때문에 RDB 테이블과 어쩔 수 없는 불일치가 존재 장점 쿼리문 작성이 아닌 코드(메서드)로 데이터를 조작할 수 있다. 데이터베이스 쿼리를 객체지향적으로 조작할 수 있다. 재사용 및 유지보수가 편리하다. 데이터베이스에 대한 종속성이 줄어든다. 단점 ORM 만으로 온전한 서비스를 구현 하기에는 한계가 있다. 객체와 데이터베이스 관점의 불일치가 발생한다. 세분성(Granularity) : ORM의 자동 설계 방법에 따라 데이터베이스에 있는 테이블의 수와 애플리케이션의 엔티티(Entity)클래스의 수가 다른 경우가 생긴다. (보통 객체모델 &gt; 관계형 모델) 상속성(Inheritance) : RDBMS에는 상속이라는 개념이 없다. 식별성(Identity) : RDBMS는 기본키(primary key)로 동일성을 정의한다. 하지만 자바는 두 객체의 값이 같아도 다르다고 판단할 수 있다. (식별과 동일성의 문제) 연관성(Association) 객체지향 언어는 객체를 참조 함으로써 연관성을 나타내지만 RDBMS 에서는 외래 키(foreign key)를 삽입 함으로써 연관성을 표시한다. 탐색(Navigation) 자바와 RDBMS 는 어떤 값(객체)에 접근하는 방식이 다르다. 자바 에서는 특정 값에 접근하기 위해 객체 참조 같은 연결 수단을 활용한다. 이 방식은 객체를 연결하고 또 연결해서 접근하는 그래프 형태의 접근 방식이다. (ex. member.getOranization().getAddress()) 반면 RDBMS 에서는 쿼리를 최소화하고 조인(JOIN)을 통해 여러 테이블을 로드 하고 값을 추출하는 접근 방식을 채택하고 있다. JPA(Java Persistance API) JPA는 자바에서 ORM 기술 표준으로 채택된 인터페이스 JPA가 실제로 동작하는 것이 아니라 동작 방법, 방식을 정리해둔 것 자바에서 사용할 ORM을 구현하기 위한 설계도면 JPA는 ORM을 사용하기 위한 인터페이스를 모아둔 것 ( = 기술 명세서 ) → 단순 명세로 구현체가 없다. ORM 이 큰 개념이라면 JPA 는 더 구체화된 스펙을 포함한다. 특징 내부적으로 JDBC 를 사용한다. (데이터베이스에 접속할 수 있도록 하는 자바 API) 개발자 대신 SQL 을 생성하고 데이터베이스를 조작해 객체를 자동 매핑 하는 역할을 수행한다. JPA 기반의 구현체 : EclipseLink, Hibernate, DataNucleus JPA는 값을 갱신할 때 update 키워드를 사용하지 않는다.영속성 컨텍스트를 활용해 값을 갱신하는데 find() method를 통해 db에서 값을 가져오면가져온 객체가 영속성 컨텍스트에 추가된다.영속성 컨텍스트가 유지되는 상황에서 객체의 값을 변경하고 다시 save()를 실행하면JPA에서는 Dirty Check라고 하는 변경 감지를 수행한다.Hibernate 자바의 ORM 프레임워크로 JPA가 정의하는 인터페이스를 구현하고 있는 JPA 구현체 중 하나 DB 의 데이터와 코드를 매핑 시켜주기 위한 프레임 워크 javax.persistence.EntityManager 와 같은 인터페이스를 직접 구현한 라이브러리이다. 특징 생산성 SQL 을 직접 사용하지 않고, 메서드 호출만으로 쿼리가 수행된다. → 단, 직접 SQL 을 작성하는 것보다는 성능상 좋지 않다. → 메서드 호출만으로 DB 데이터를 조작 하기에는 한계가 있다. 유지보수 SQL 반복 작업을 하지 않음으로 생산성이 높다. → 유지 보수 측면에서 좋다. 설정 파일에서 JPA 에게 어떤 DB 를 사용하고 있는지를 알려주기만 하면 얼마든지 DB 를 바꿀 수 있다. 패러다임 불일치 해결 상속, 연관 관계, 객체 그래프 탐색, 비교 등 객체와 관계형 DB와의 패러다임 불일치를 해결할 수 있다. Spring Data JPA CRUD 처리에 필요한 인터페이스를 제공 hibernate의 EntityManager를 직접 다루지 않고 Repository를 정의해 사용 → 내부적으로 EntityManager 사용 Spring Data JPA는 JPA를 추상화한 Repository를 제공하여 스프링이 적합한 쿼리를 동적으로 생성해 데이터베이스를 조작 JPA 를 편리하게 사용할 수 있도록 지원 Hibernate에서 자주 사용되는 기능을 더 쉽게 사용할 수 있게 구현한 라이브러리 Spring Data JPA는 Hibernate와 같은 JPA 구현체 필요 JpaRepository를 기반으로 쉽게 db를 사용할 수 있는 아키텍처를 제공 JpaRepository를 상속받을 때는 대상 entity와 기본 값 타입을 지정해야한다.( JpaRepository&lt;Member, Long&gt; ) 영속성 컨텍스트 영속성 컨텍스트는 객체를 보관하는 기능을 수행한다. 엔티티를 영구히 저장하는 환경 애플리케이션과 데이터베이스 사이에서 엔티티와 레코드의 괴리를 해소하는 기능과 객체를 보관하는 기능을 수행 엔티티 객체가 영속성 컨텍스트에 들어오면 JPA는 엔티티 객체의 매핑 정보를 데이터베이스에 반영하는 작업을 수행 엔티티 객체가 영속성 컨텍스트에 들어와 JPA의 관리 대상이 되는 시점부터는 해당 객체를 영속 객체(Persistence Object)라고 부른다. 세션단위의 생명주기를 가진다.→ 데이터베이스에 접근하기 위한 세션이 생성되면 영속성 컨텍스트가 만들어지고, 세션이 종료되면 영속성 컨텍스트도 없어진다. 엔티티 매니저는 이러한 일련의 과정에서 영속성 컨텍스트에 접근하기 위한 수단으로 사용된다. → 이것을 우리는 spring data jpa가 jpa를 가지고 해주고 있어서 편하게 해왔던 것이다.엔티티 매니저 (Entity Manager) 엔티티를 관리하는 객체 DB에 접근해서 CRUD 작업을 수행한다. Transaction 단위마다 EntityManager 생성 EntityManager가 생성되면 영속성 컨텍스트 생성 한 Transaction 안에서는 같은 영속성 컨텍스트 사용 Spring Data JPA 를 사용하면 Repository를 사용해서 데이터베이스에 접근한다. → 실제 내부 구현체인 SimpleJpaRepository 가 Repository에서 엔티티 매니저를 사용한다. @Transactional 어노테이션이 지정되어 있으면 method 내 작업을 마칠 경우 자동으로 flush() 를 실행한다. EntityManager는 엔티티 매니저 팩토리( EntityManagerFactory )가 만든다. 엔티티 매니저 팩토리는 데이터베이스에 대응하는 객체로서 스프링 부트 에서는 자동 설정 기능이 있어 application.properties 에서 최소한의 설정만으로 동작하지만 하이버네이트에서는 설정파일을 구성하고 사용해야 한다. maven : persistence.xml gradle : build.gradle, application.properties ☑️ EntityManagerFactory: 애플리케이션이 시작될 때 단 한 번 생성되며, 데이터베이스와의 연결을 관리하는 역할을 한다.여러 개의 EntityManager를 생성할 때 기반이 되는 팩토리 역할을 한다.☑️ EntityManager: 클라이언트가 원하는 요구에 따라 생성되고, 트랜잭션 범위 내에서 독립적으로 동작한다.데이터베이스와의 상호작용을 위해 필요한 작업들을 수행하며, 엔티티들을 조회, 저장, 수정, 삭제할 수 있다.☑️ 영속성 컨텍스트: EntityManager가 관리하는 핵심 개념으로, 엔티티들의 상태를 추적하고 관리한다.1차 캐시를 가지고 있어 자주 사용되는 엔티티를 메모리에 보관하여 조회 성능을 향상시키고, 엔티티들의 동일성을 보장한다.트랜잭션 범위 내에서 동작하며, 트랜잭션이 커밋되면 변경된 엔티티들이 데이터베이스에 동기화되고 롤백되면 변경 사항이 취소된다.→ EntityManagerFactory는 한 번만 생성되고, EntityManager는 필요에 따라 생성되고 독립적으로 동작하며,영속성 컨텍스트는 EntityManager가 관리하는 엔티티들의 상태를 추적하고 관리한다.이러한 개념들을 활용하여 JPA를 효과적으로 사용할 수 있다.Gradle 설정 예시dependencies { implementation 'org.springframework.boot:spring-boot-starter-data-jpa' runtimeOnly 'mysql:mysql-connector-java'} spring.datasource.driver-class-name=com.mysql.jdbc.Driverspring.datasource.url=jdbc:mysql://localhost:3306/test # jdbc:mysql://'DB-EndPoint':'Port'/'DBName'spring.datasource.username= haedalspring.datasource.password= 123456789# SQL outputspring.jpa.properties.hibernate.format_sql=true# show sql consolespring.jpa.show-sql=trueHibernate 설정 시 엔티티 매니저 팩토리는 애플리케이션에 단 하나만 생성 되며, 모든 엔티티가 공유해서 사용한다. 엔티티 매니저 팩토리로 생성된 엔티티 매니저는 엔티티를 영속성 컨텍스트에 추가해서 영속 객체로 만드는 작업을 수행한다. 영속성 컨텍스트와 데이터베이스를 비교하면서 실제 데이터베이스를 대상으로 작업을 수행한다. 엔티티의 생명주기비영속성(New) : 영속성 컨텍스트에 추가되지 않은 엔티티 객체의 상태를 의미영속(Managed) : 영속성 컨텍스트에 의해 엔티티 객체가 관리되는 상태준영속(Detached) : 영속성 컨텍스트에 의해 관리되던 엔티티 객체가 컨텍스트와 분리된 상태삭제(Removed) : 데이터베이스에서 레코드를 삭제하기 위해 영속성 컨텍스트에 삭제요청을 한 상태DataBase테이블 자동 생성 application.properties 설정spring.jpa.hibernate.ddl-auto= create : create 옵션은 해당하는 테이블이 있으면 DROP하고 새로 만들어 버린다. *로컬 환경에서만 사용한다.spring.jpa.show-sql=true : SQL이 보이도록 세팅데이터 베이스 자동 조작 옵션 create : 기존 테이블을 지우고 새로 생성 create-drop : 애플리케이션을 종료하는 시점에 테이블을 지운다. update : 실행될 객체를 검사해서 변경된 스키마를 갱신, 기존에 저장된 데이터는 유지 validate : update처럼 객체를 검사하지만 스키마는 건들지 않는다. (데이터베이스의 테이블 정보와 객체정보가 다른면 에러 발생) none : ddl-auto 기능을 사용하지 않는다. → 운영 환경: create, create-drop, update (X) ➡️ validate, none (O)→ 개발 환경: create, update (O)Entity Spring Data JPA를 사용해 데이터베이스에 테이블을 생성하기 위해 직접 쿼리를 작성할 필요가 없게 해준다. 데이터베이스에 쓰일 테이블과 칼럼을 정의하면 알아서 테이블을 생성 해준다. 엔티티 관련 기본 어노테이션@Entity 클래스가 엔티티임을 명시하기 위한 어노테이션 해당 클래스의 인스턴스는 매핑되는 테이블에서 하나의 레코드를 의미한다. @Entity가 붙은 클래스는 JPA가 관리 ➡️ JPA를 사용해서 DB 테이블과 매핑할 클래스는 @Entity를 꼭 붙여야만 매핑이 가능 주의사항 접근 제어자가 public 혹은 protected 인 기본 생성자가 필수 final 클래스, enum, interface, inner 클래스에는 사용이 불가@Enumerated를 사용하면 enum 클래스는 사용 가능하다. 저장하려는 속성은 final 이면 안된다.@Table(속성=?)→ 엔티티와 매핑할 테이블을 지정클래스의 이름과 테이블의 이름을 다르게 지정해야하는 경우가 아니면 필요X속성name : 매핑할 테이블 이름 지정catalog : catalog 기능이 있는 데이터베이스에서 catalog를 매핑schema : schema 기능이 있는 데이터베이스에서 schema를 매핑uniqueConstraints (DDL) : DDL 생성 시에 유니크 제약조건을 만든다. 스키마 자동 생성 기능을 사용해서 DDL을 만들 때만 사용@Id테이블 기본 값 역할로 사용모든 엔티티는 @Id 어노테이션이 필요하다.@GeneratedValue해당 필드의 값을 어떤 방식으로 자동으로 생성할지 결정할 때 사용 GeneratedValue를 사용하지 않는 방식(직접 할당) 자체적으로 고유한 기본값을 생성할 경우 사용 내부에 정해진 규칙에 의해 기본값을 생성하고 식별자로 사용 AUTO @GeneratedValue의 기본 설정값 기본값을 사용하는 데이터베이스에 맞게 자동 생성 IDENTITY 기본값 생성을 데이터베이스에 위임 데이터베이스의 AUTO_INCREMENT를 사용해 기본값을 생성 (데이터베이스에 INSERT SQL 을 실행한 후에 엔티티의 식별자 값을 알 수 있다.) SEQUENCE @SequenceGenerator 어노테이션으로 식별자 생성기를 설정하고 이를 통해 값을 자동 주입 받는다. SequenceGenerator를 정의할 때는 name, SequenceGenerator, allocationSize를 활용 @GeneratedValue에 생성기를 설정 Table 어떤 DBMS를 사용하더라도 동일하게 동작하기를 원할 경우 사용 @TableGenerator 어노테이션으로 테이블 정보를 설정 @Column데이터베이스를 설정하는 어노테이션별다른 설정을 하지 않을 예정이라면 필요X name : 데이터베이스의 컬럼명을 설정 nullable : 컬럼 값에 null 처리가 가능한지를 명시 length : 데이터 최대 길이를 설정 unique : 유니크로 설정@Transient엔티티 클래스에는 선언돼 있는 필드지만 데이터베이스에서는 필요 없을 경우 사용출처 ddl-auto 옵션 관련 주의할 점!!!!!!!!! [Spring Boot] JPA(Hibernate) 적용 스프링 부트 핵심 가이드" }, { "title": "다양한 방법으로 api 작성하기", "url": "/posts/%EB%8B%A4%EC%96%91%ED%95%9C-%EB%B0%A9%EB%B2%95%EC%9C%BC%EB%A1%9C-API-%EC%9E%91%EC%84%B1%ED%95%98%EA%B8%B0/", "categories": "Study", "tags": "spring, study, summary, ch3, API", "date": "2022-09-24 00:00:00 +0900", "snippet": "다양한 방법으로 API 작성하기HTTP Code2xx : 통신 성공성공적으로 요청이 처리되었음을 의미. 200 [OK] : 요청 성공(GET) 201 [Created] : 생성 성공(POST) 204 [No Contents] : 요청 성공, 반환할 데이터 없음3xx : 리다이렉트 301 [Moved Permanently] : 요청 URI가 새 위치로 옮겨감 302 [Found] : 일시적으로 컨텐츠가 이동했을때. 304 [Not Modified] : 요청 URI의 내용이 변경X4xx : client 오류요청이 올바르지 않음을 의미. 400 [Bad Request] : 잘못된 요청(정의되지 않은 요청) 401 [Unauthorized] : 인증 실패(인증 없이 접근할 경우 발생) 403 [Forbidden] : 서버가 요청을 거부할 때 발생. 권한(인가)이 없을 때. 404 [Not Found] : 요청 URI에 대한 리소스 존재X 405 [Method Not Allowed] : 서버에서 허용되지 않은 메소드로 요청시 사용. 415 [Unsupported Media Type] : 잘못된 데이터 형식 429 [Too Many Requests] : 너무 많은 요청 발생5xx : 서버 오류 500 [Internal Server Error] : 서버 내부 오류@Controller &amp; @RestController@ControllerHTML 등 view 반환@RestController데이터를 JSON/XML 형식으로 반환내부적으로 @Controller와 @ResponseBody를 조합한 형태로응답 데이터를 자동으로 JSON 형식으로 변환하며 Content-Type을 application/json으로 설정한다.@ResponseBody데이터 응답을 JSON 형식으로 변환해 HTTP 응답 본문에 추가@RequestBody : HTTP 요청의 본문(body)에 담긴 값을 자바 객체로 매핑하는 역할@ResponseBody :자바 객체를 HTTP 응답 본문(body)에 담긴 값으로 매핑하는 역할@RestController@RequestMapping(\"/api\")public class ExampleController { @GetMapping(\"/hello\") public String sayHello() { return \"Hello, World!\"; // JSON 응답: { \"message\": \"Hello, World!\" } }}요청 매핑과 데이터 처리GET/DELETE 메서드: URL에 데이터 포함GET과 DELETE 메서드는 URL 경로나 쿼리 파라미터를 통해 데이터를 전달받는다.@PathVariable: URL 경로에서 데이터 추출@RestController@RequestMapping(\"/api\")public class MyController { // http://localhost:8080/api/hello/coco @GetMapping(\"/hello/{name}\") public String hello(@PathVariable String name) { return \"Hello, \" + name; // Hello, coco }}@RestController@RequestMapping(\"/api\")public class MyController { // http://localhost:8080/api/hello/coco @GetMapping(\"/hello/{name}\") public String hello(@PathVariable(\"name\") String userName) { return \"Hello, \" + userName; // Hello, coco }}@GetMapping에 지정한 변수의 이름과 메소드 매개변수의 이름을 동일하게 맞추기 어려울 때 위와 같이 작성@RequestParam : 쿼리 파라미터로 데이터 추출쿼리 파라미터(Query Parameter)는 URL 뒤에 물음표(?)와 함께 붙는 키-값(Key-Value) 쌍이다.여러 개의 쿼리 파라미터를 전달하려면 파라미터 사이에 앰퍼샌드(&amp;)를 추가해서 하나의 문자열(string)로 전달한다.@RestController@RequestMapping(\"/api\")public class MyController { // http://localhost:8080/api/hello?name=coco&amp;age=5 @GetMapping(\"/hello\") public String hello(@RequestParam(\"name\") String name, @RequestParam(\"age\") int age) { return \"Hello, \" + name + \", \" + age; // Hello, coco, 5 }}POST/PUT 메서드: HTTP Body에 데이터 포함🐣 POST와 PUT 메서드는 데이터를 HTTP Body에 JSON 형식으로 전달한다.@RequestBody: JSON 데이터를 Java 객체로 변환클라이언트가 전송하는 Json(application/json) 형태의 HTTP Body를MessageConverter를 통해 Java 객체로 변환시켜주는 역할→ Body가 존재하지 않는 HTTP Get 메소드에 @RequestBody를 활용하려고 한다면 에러가 발생@RestController@RequestMapping(\"/api\")public class MyController { @PostMapping(\"/user\") public MyDTO postUser(@RequestBody MyDTO myDTO) { return myDTO; }} DTO와 같이 객체를 리턴해주는 경우 getter가 없다면 값에 접근하지 못한다.HttpMediaTypeNotAcceptableException 발생@RequestBody 관련 작성 글@ModelAttribute: Form 데이터를 객체로 바인딩Form 데이터를 객체로 매핑할 때 사용let form_data = new FormData()form_data.append(\"comment\", $(\"#comment\").val())form_data.append(\"nickname\", nickname)form_data.append(\"registryIdx\", $(\"#RegistryId\").html())@PostMapping(\"/comment\")public Comment setComment(@ModelAttribute CommentDto commentDto) { return commentService.setComment(commentDto);}@ModelAttribute에는 매핑시키는 파라미터의 타입이 객체의 타입과 일치하는지 등을 포함한다양한 검증(Validiation) 작업이 추가적으로 진행되는데,int형 index 변수에 “1번” 이라는 String형을 넣으려고 한다면, BindException이 발생하게 된다.Dto와 ResponseEntityDTO (Data Transfer Object)계층 간 데이터를 전달하는 데 사용한다.따라서 로직을 포함하지 않고 순수 데이터만 작성한다.public class UserDto { private String username; private String email; // Getters and Setters}ResponseEntity응답 데이터와 상태 코드를 명시적으로 제어할 때 사용@PostMapping(\"/user\")public ResponseEntity&lt;UserDto&gt; createUser(@RequestBody UserDto userDto) { return ResponseEntity.status(HttpStatus.CREATED).body(userDto);}URI Mapping특정 uri로 요청을 보내면 Controller에서 어떠한 방식으로 처리할지 정의를 한다.이때 들어온 요청을 특정 메서드와 매핑하기 위해 사용하는 것이 @RequestMapping이다.@RequestMapping에서 가장 많이사용하는 부분은 value와 method이다.*value : 요청 받을 url *method :어떤 요청으로 받을지 정의(POST, GET, PUT, DELETE 등등)@RestController@RequestMapping(\"/api\")public class MyController { @RequestMapping(value = \"/study\", method = RequestMethod.POST) public String createStudy() { return \"Study Created\"; }}간편하게 설정하기스프링 4.3부터는 @PostMapping, @GetMapping, @PutMapping, @DeleteMapping으로 간결하게 설정 가능하다.@RestController@RequestMapping(value = \"/study\")public class StudyController { @GetMapping(\"/ch3\") public String studyNoCh3(...) { ... }}studyNoCh3에 들어가기 위해서는 /study/ch3으로 들어가야 한다.*@RequestMapping은 Class와 Method에 붙일 수 있고@GetMapping, @PostMapping, @PutMapping, @DeleteMapping들은 Method에만 붙일 수 있다.HTTP 메서드별 데이터 처리 예시데이터 전달 방식POST/PUT 메서드: 데이터를 HTTP Body에 JSON 형태로 전달.반드시 JSON.stringify()를 사용하여 JSON 문자열로 변환 후 전송let data = { username: 'example', contents: 'message' };$.ajax({ type: \"PUT\", url: `/api/${id}`, contentType: \"application/json\", data: JSON.stringify(data), success: function (response) { console.log(response); }});GET/DELETE 메서드: 데이터를 URL에 포함하여 전달$.ajax({ type: \"DELETE\", url: `/api/${id}`, success: function (response) { console.log(response); }});POST@PostMapping(\"/create\")public UserDto createUser(@RequestBody UserDto userDto) { return userDto;}GET@GetMapping(\"/user/{id}\")public String getUser(@PathVariable Long id) { return \"User ID: \" + id;}PUT@PutMapping(\"/update\")public ResponseEntity&lt;UserDto&gt; updateUser(@RequestBody UserDto userDto) { return ResponseEntity.ok(userDto);}DELETE@DeleteMapping(\"/user/{id}\")public String deleteUser(@PathVariable Long id) { return \"Deleted User ID: \" + id;}REFERENCE 쿼리 파라미터(Query Parameter) [Spring] @RequestMapping이란? [Spring] @RequestBody, @ModelAttribute, @RequestParam의 차이 Spring / @RequestBody vs @RequestParam 이해하기 [Spring] @RequestBody / @ResponseBody 어노테이션 이란?" }, { "title": "기초 지식", "url": "/posts/%EA%B8%B0%EC%B4%88-%EC%A7%80%EC%8B%9D/", "categories": "Study", "tags": "spring, study, summary, ch2", "date": "2022-09-23 00:00:00 +0900", "snippet": "서버 간 통신스프링 부트의 동작 방식용어Servlet [서블릿] : 클라이언트의 요청을 처리하고 결과를 반환하는 자바 웹 프로그래밍 기술Servlet Container [서블릿 컨테이너] : 서블릿 인스턴스를 생성, 관리. 스프링 부트의 경우 톰캣이 WAS의 역할과 서블릿 컨테이너의 역할을 수행한다.Dispatcher Servlet [디스패처 서블릿] : 스프링 내부의 서블릿HandlerMapping : 특정 요청 경로를 처리해주는 핸들러를 찾아주는 객체 요청 정보를 기준으로 어떤 controller를 사용할지 선정하는 인터페이스Servlet Container가 스프링 Dispatcher Servlet에 클라이언트 요청을 전달한다. (Servlet Container 와 Dispatcher Servlet 사이에 여러 filter 들이 존재.)스프링에서는 DispatcherServlet이 서블릿의 역할을 수행한다.DispatcherServlet으로 요청(HttpServletRequest)이 들어오면 DispatcherServlet은 Handler Mapping을 통해 요청 URI에 매핑된 핸들러(≒Controller)를 탐색한다.HandlerAdapter로 Controller를 호출한다.HandlerAdapter에 Controller의 응답이 돌아오면 ModelAndView로 응답을 가공해 반환한다.view 형식으로 리턴하는 Controller를 사용할 때는 view Resolver를 통해 view를 받아 리턴한다.위의 과정을 거쳐 클라이언트의 요청에 따라 응답한다.뷰가 없는 REST 형식을 적용할 경우 스프링 내부의 MessageConverter가 요청과 응답 Body를 알아서 변환한다.이러한 복잡한 과정을 스프링에서 해주고있기 때문에 개발자는 비즈니스 로직에 집중할 수 있다.*REST 형식은 view Resolver를 호출하지 않고 MessageConverter를 거쳐 JSON 형식으로 변환해서 응답한다.레이어드 아키텍처스프링 MVC 모델 레이어드 아키텍처 컴포넌트를 비슷한 관심사에 따라 레이어로 묶어 구성한 구조. 일반적으로 3계층 또는 4계층으로 구성. 레이어드 아키텍처 특징 가장 가까운 하위 레이어의 의존성을 주입. 다른 레이어의 역할을 침범하지 않음. 다른 레이어의 의존성을 낮춰 단위 테스트에 용이. 계층프레젠테이션 계층 유저 인터페이스 계층이라고도 함. 클라이언트이 요청을 해석하고 응답. UI나 API를 제공. 비즈니스 로직을 포함하고 있지 않음. 비즈니스 계층으로 요청을 위임, 전달해주고 받은 결과를 응답. 비즈니스 계층 서비스 계층이라고도 함. 기능을 정의하고 세부 작업을 수행. 도메인 객체를 통해 업무를 위임. DDD (Domain-Driven Design) 개발 시 비즈니스 로직에 도메인이 포함되기도 하고, 별도로 도메인 계층을 두기도 함. 트랜잭션 처리나 유효성 검사 등의 작업도 수행. 데이터 접근 계층 영속(Persistence) 계층이라고도 함. 데이터베이스에 접근하는 작업 수행. 디자인 패턴소프트웨어 공학의 소프트웨어 설계에서 공통으로 발생하는 문제에 대해 자주 쓰이는 설계 방법을 정리한 패턴이다.디자인 패턴을 참고하여 개발할 경우 개발의 효율성과 유지보수성, 운용성이 높아지며, 프로그램의 최적화에 도움이 된다.디자인 패턴 구성요소 구성요소 설명 패턴의 이름 디자인 패턴을 부를 때 사용하는 이름과 디자인 패턴의 유형 문제 및 배경 디자인 패턴이 사용되는 분야 또는 배경, 해결하는 문제를 의미 솔루션 디자인 패턴을 이루는 요소들, 관계, 협동 과정 사례 디자인 패턴의 간단한 적용 사례 결과 디자인 패턴을 사용하면 얻게 되는 이점이나 영향 샘플 코드 디자인 패턴이 적용된 원시 코드 디자인 패턴의 종류생성 패턴객체 생성에 관련된 패턴으로 객체를 수정해도 호출부가 영향을 받지 않게 한다.객체의 생성과 조합을 캡슐화해 특정 객체가 생성되거나 변경되어도 프로그램 구조에 영향을 받지 않도록 유연성을 제공한다. 패턴 설명 Builder 복잡한 인스턴스를 조립하여 만드는 구조로, 복합 객체를 생성할 때 객체를 생성하는 방법(과정)과 객체를 구현(표현)하는 방법을 분리함으로써 동일한 생성 절차에서 서로 다른 표현 결과를 만들 수 있는 디자인 패턴, 생성과 표기를 분리해서 복잡한 객체를 생성 Prototype 기존 객체를 복제함으로써 객체를 생성 Factory Method 생성할 객체의 클래스를 국한하지 않고 객체를 생성 Abstract Factory 동일한 주제의 다른 팩토리를 묶음 Singleton 한 클래스에 한 객체만 존재하도록 제한 구조 패턴클래스나 객체를 조합해 더 큰 구조를 만드는 패턴이다.예를 들어 서로 다른 인터페이스를 지닌 2개의 객체를 묶어 단일 인터페이스를 제공하거나객체들을 서로 묶어 새로운 기능을 제공하는 패턴이다. 패턴 설명 Bridge 구현뿐만 아니라, 추상화된 부분까지 변경해야 하는 경우 활용 Decorator 객체의 결합을 통해 기능을 동적으로 유연하게 확장 Facade 통합된 인터페이스 제공 Flyweight 여러 개의 ‘가상 인스턴스’를 제공하여 메모리 절감 Proxy 특정 객체로의 접근을 제어하기 위한 용도로 사용 Composite 복합 객체와 단일 객체를 동일하게 취급 Adapter 인터페이스가 호환되지 않는 클래스들을 함께 이용할 수 있도록 타 클래스의 인터페이스를 기존 인터페이스에 덧씌움 행위 패턴객체 간의 알고리즘이나 책임 분배에 관한 패턴이다.객체 하나로는 수행할 수 없는 작업을 여러 객체를 이용해 작업을 분배한다.또한, 객체 사이의 결합도를 최소화하는 것에 중점을 둔다. 패턴 설명 Mediator 상호작용의 유연한 변경을 지원 Interpreter 문법 자체를 캡슐화하여 사용 Iterator 내부구조를 노출하지 않고, 복잡 객체의 원소를 순차적으로 접근 가능하게 해주는 행위 패턴 Template Method 상위 작업의 구조를 바꾸지 않으면서 서브 클래스로 작업의 일부분을 수행 Observer 객체의 상태 변화에 따라 다른 객체의 상태도 연동, 일대다 의존 State 객체의 상태 변화에 따라 행위 내용을 변경 Visitor 특정 구조를 이루는 복합 객체의 원소 특성에 따라 동작을 수행할 수 있도록 지원하는 행위 Command 요구사항을 객체로 캡슐화 Strategy 행위 객체를 클래스로 캡슐화해 동적으로 행위를 자유롭게 변환 Memento 객체를 이전 상태로 복구시켜야 하는 경우 ‘작업취소(Undo)’ 요청 가능 Chain of Responsibility 한 요청을 2개 이상의 객체에서 처리 REST APIREST란?자원(resource)의 표현(representation)에 의한 상태 전달자원을 이름(자원의 표현)으로 구분하여 해당 자원의 상태(정보)를 주고 받는 모든 것을 의미한다.REST API란?API란? 데이터와 기능의 집합을 제공하여 컴퓨터 프로그램간 상호작용을 촉진하며, 서로 정보를 교환가능 하도록 하는 것REST API REST 기반으로 서비스 API를 구현한 것REST의 특징 서버-클라이언트 구조 자원이 있는 쪽이 Server, 자원을 요청하는 쪽이 Client 무상태(Stateless)REST의 URI 설계 규칙resource에 동사보다는 명사를 사용한다.resource에 대문자 보다는 소문자를 사용한다.URI에 HTTP Method가 들어가면 안된다.URI에 행위에 대한 동사 표현이 들어가면 안된다. (CRUD 기능을 나타내는 것은 URI에 사용하지 않는다.) ex. /members/show/1 → /members/1출처 [디자인패턴 분류] 생성/구조/행위 패턴 [정보처리기사 실기 vol.1] [Network] REST란? REST API란? RESTful이란? 10. 스프링 MVC 프레임워크 동작 방식 스프링 부트 핵심 가이드" }, { "title": "Spring boot", "url": "/posts/Spring-Boot/", "categories": "Study", "tags": "spring, study, summary, ch1", "date": "2022-09-22 00:00:00 +0900", "snippet": "Spring Boot?Spring FrameworkIoC (Inversion of Control) : 제어 역전 사용할 객체를 직접 생성하지 않고 객체의 생명주기 관리를 외부에 위임 외부란? 스프링 컨테이너 또는 IoC 컨테이너.IoC를 통해 DI (Dependency Injection) : 의존성 주입, AOP (Aspect-Oriented Programming) : 관점 지향 프로그래밍이 가능해지고 개발자는 비즈니스 로직에 집중할 수 있다.프로그래밍에서 의존관계는 new로 표현된다.운전자가 자동차를 생산한다.자동차는 내부적으로 타이어를 생산한다.///////////////////////////////////////////new Car();Car 객체 생성자에서 new Tire();///////////////////////////////////////////의존성을 단순하게 정의하면 아래와 같다.의존성은 new다.new를 실행하는 Car와 Tire 사이에서 Car가 Tire에 의존한다.DI (Dependency Injection) : 의존성 주입 주입이란 외부에서라는 뜻을 내포하고 있는 단어다. 객체를 직접 생성하지 않고 외부 컨테이너가 생성한 객체를 주입 스프링 공식 문서에서는 생성자를 통해 의존성을 주입받는 방식을 권장. 레퍼런스 객체 없이는 객체를 초기화할 수 없게 설계되기 때문. AOP (Aspect-Oriented Programming) : 관점 지향 프로그래밍스프링 DI가 의존성(new)에 대한 주입이라면 스프링 AOP는 로직(code) 주입이라고 할 수 있다.다수의 모듈에 공통적으로 나타나는 부분이 존재하는데 이것을 횡단 관심사라고 한다.코드 = 핵심 관심사 + 횡단 관심사핵심 관심사는 모듈별로 다르지만 횡단 관심사는 모듈 별로 반복되어 중복해서 나타나는 부분이다. 어떤 기능을 구현할 때 그 기능을 핵심 기능과 부가 기능으로 구분해 각각을 하나의 관점으로 보는 것을 의미.핵심 기능?핵심 기능은 비즈니스 로직이 처리하려는 목적을 말한다.예를 들면 정보를 데이터베이스에 저장하는것, 데이터를 보여주는 것이 핵심 기능이다.부가 기능?핵심 기능들 사이에 로깅 처리를 하거나 트랜잭션을 처리하는 기능들.→ AOP는 여러 비즈니스 로직에서 반복되는 부가 기능을 하나의 공통 로직으로 처리하도록 모듈화해 삽입하는 방식.A의 하루키패드로 문을 열고 집에 들어간다.**컴퓨터로 게임을 한다.**불을 끄고 잔다.B의 하루키패드로 문을 열고 집에 들어간다.**요리를 한다.**불을 끄고 잔다.스프링 프레임워크의 다양한 모듈 JDBC, ORM, Transactions, Web, Servlet, Beans, Core 등등 여러개의 모듈을 제공한다. 모든 모듈을 사용할 필요 없이 개발에 필요한 모듈만 선택해서 사용할 수 있다. Spring Framework vs. Spring BootSpringBoot필요한 모듈을 추가하다보며 복잡해지는 문제를 해결하기 위해 등장한 것이 스프링 부트공식 사이트 문구 “스프링 부트를 이용하면 단독으로 실행 가능한 상용 수준의 스프링 기반 애플리케이션을 손쉽게 만들 수 있다.”의존성 관리스프링 프레임 워크 개발에 필요한 각 모듈의 의존성을 직접 설정 호환되는 버전을 명시해야 정상 동작 애플리케이션에서 사용하는 스프링 프레임워크나 라이브러리의 버전을 올리는 상황에서는 연관된 다른 라이브러리의 버전까지 고려 → 스프링 프레임워크나 라이브러리의 버전을 변경하려면 관련된 다른 라이브러리의 호환성까지 확인해야함스프링 부트 ‘spring-boot-starter’라는 의존성을 제공 (종류가 여러 개다) 각 라이브러리의 기능과 관련해서 자주 사용되고 서로 호환되는 버전의 모듈 조합을 제공 많이 사용되는 ‘spring-boot-starter’ 라이브러리 스프링 부트에서는 spring-boot-start-xxx 들로 자주 사용되고 서로 호환되는 버전의 모듈 조합을 제공. spring-boot-starter-web : 스프링 MVC를 사용하는 RESTful 애플리케이션을 만들기 위한 의존성, 기본으로 내장 톰캣(Tomcat)이 포함돼 있어 jar 형식으로 실행 가능 spring-boot-starter-test : JUnit Jupiter, Mockito 등의 테스트용 라이브러리를 포함 spring-boot-starter-jdbc : HikariCP 커넥션 풀을 활용한 JDBC 기능을 제공 spring-boot-starter-security : 스프링 시큐리티(인증, 권한, 인가 등) 기능을 제공 spring-boot-starter-data-jpa : 하이버네이트를 활용한 JPA 기능을 제공 spring-boot-starter-cache : 스프링 프레임워크의 캐시 기능을 지원 자동 설정 @ComponentScan 과 @EnableAutoConfiguration 어노테이션으로 @Component 시리즈 어노테이션이 붙은 클래스를 발견해 빈(Bean)을 등록 @EnableAutoConfiguration 어노테이션을 통해 다양한 자동 설정이 일부 조건을 거쳐 적용 WAS (Web Application Server)DB 조회나 다양한 로직 처리를 요구하는 동적인 컨텐츠를 제공하기 위해 만들어진 Application ServerHTTP를 통해 컴퓨터나 장치에 애플리케이션을 수행해주는 미들웨어(소프트웨어 엔진)이다.웹컨테이너 혹은 서블릿 컨테이너라고도 불린다. (즉, WAS는 JSP, Servlet 구동 환경을 제공 ) 스프링 부트는 내장 WAS가 존재 spring-boot-starter-web의 경우 톰캣을 내장 스프링 부트의 자동 설정 기능이 톰캣에도 적용되어 특별한 설정 없이도 톰캣을 실행할 수 있다. Web Server 정적인 컨텐츠(html, css, js)를 제공하는 서버 소프트웨어와 하드웨어로 구분 하드웨어 : Web 서버가 설치되어 있는 컴퓨터 소프트웨어 : 웹 브라우저 클라이언트로부터 HTTP 요청을 받아 정적인 컨텐츠를 제공하는 컴퓨터 프로그램기능HTTP 프로토콜을 기반으로 하여 클라이언트(웹 브라우저 또는 웹 크롤러)의 요청을 서비스 하는 기능을 담당 → Apache Server, Nginx, IIS(Windows 전용 Web 서버) 등등사용하는 이유WAS가 해야할 일의 부담을 줄이기 위해서 사용WAS 앞에 웹서버를 둬서 웹서버에서는 정적인 문서만 처리하도록 하고, WAS는 애플리케이션의 로직만 수행하도록 기능을 분배하여 서버의 부담을 줄이기 위함" }, { "title": "Tdd 정리(service, repository)", "url": "/posts/TDD-%EC%A0%95%EB%A6%AC(Service,-Repository)/", "categories": "Spring", "tags": "spring, TDD, test", "date": "2022-09-19 00:00:00 +0900", "snippet": "Service Mockito.when(boardRepository.save(new Board(\"3\",\"title\",\"main\",\"writer\"))) .thenReturn(new Board(\"3\",\"title\",\"main\",\"writer\"));객체를 새로 생성을 여러번 함으로써 메모리를 많이 차지하므로변수를 생성해서 하나만 생성하게 한다. Board board = new Board(\"3\", \"title\", \"main\", \"writer\"); //given Mockito.when(boardRepository.save(board)) .thenReturn(board);Service test 코드 정리 마지막 내용으로 아래 post test 코드를 본다. @Test public void postBoard() { Board board = new Board(\"3\", \"title\", \"main\", \"writer\"); //given Mockito.when(boardRepository.save(board)) .thenReturn(board); Board boardSave = boardService.saveBoard(new BoardDto(\"3\", \"title\", \"main\", \"writer\")); Assertions.assertEquals(boardSave.getBoardId(), \"3\"); Assertions.assertEquals(boardSave.getBoardTitle(), \"title\"); Assertions.assertEquals(boardSave.getBoardMain(), \"main\"); Assertions.assertEquals(boardSave.getBoardWriter(), \"writer\"); verify(boardRepository).save(new Board(\"3\", \"title\", \"main\", \"writer\")); }Service 테스트 이므로 boardService로 적는다. (boardRepository.save(new BoardDto(\"3\", \"title\", \"main\", \"writer\")) ❌ )Board boardSave = boardService.saveBoard(new BoardDto(\"3\", \"title\", \"main\", \"writer\"));Repository @DataJpaTest : Repository들에 대한 빈들을 등록하여 단위 테스트의 작성을 용이하게 한다.테스트를 위해서는 테스트 컨텍스트를 잡아주어야 할텐데, @DataJpaTest는 내부적으로 @ExtendWith(SpringExtension.class) 어노테이션을 가지고 있다.마찬가지로 @DataJpaTest에는 @Transactional 어노테이션이 있어서, 테스트의 롤백 등을 위해 별도로 트랜잭션 어노테이션을 추가하지 않아도 된다.public interface Repository extends JpaRepository&lt;Entity, PK&gt;PK를 String으로 하기 위해 PK에 @Id를 사용했다. @Id @NotNull private String boardId;⬇️public interface BoardRepository extends JpaRepository&lt;Board, String&gt; {}출처[Spring] TDD로 멤버십 등록 API 구현 예제 - (3/5)" }, { "title": "Tdd 정리(controller)", "url": "/posts/TDD-%EC%A0%95%EB%A6%AC(Controller)/", "categories": "Spring", "tags": "spring, TDD, test", "date": "2022-09-15 00:00:00 +0900", "snippet": "Controller나는 Controller를 이전에 작성한 방법처럼 객체를 return했다.@PostMapping(\"/registry\")public Board saveBoard(@RequestBody BoardDto boardDto){ return boardService.saveBoard(boardDto); }그런데 내가 tdd를 하면서 본 영상에서는 아래 코드처럼 ResponseEntity를 사용했다. @PutMapping(\"/music/modification\") public ResponseEntity&lt;MusicResponseDto&gt; putMusic(@RequestBody MusicDto musicDto) { MusicResponseDto musicResponseDto = musicService.modifyMusic(musicDto); return ResponseEntity.status(HttpStatus.OK).body(musicResponseDto); }그래서 ResponseEntity에 대해 알아봤다.ResponseEntityResponseEntity : 응답 자체의 독립된 값이나 표현 형태Spring Framework에서 제공하는 클래스인 HttpEntity를 상속받고 있으며, RestTemplate 및 @Controller 메서드에 사용하고 있다.HttpEntity는 HTTP 요청(Request) 또는 응답(Response)에 해당하는 HttpHeader와 HttpBody를 포함하는 클래스이다.HttpEntity 클래스를 상속받아 구현한 클래스가 RequestEntity, ResponseEntity 클래스이다.ResponseEntity는 사용자의 HttpRequest에 대한 응답 데이터를 포함하는 클래스이다.따라서 HttpStatus, HttpHeaders, HttpBody를 포함한다.ResponseEntity는 StatusField를 가지고 있기 때문에 상태코드는 필수적으로 포함해줘야 한다.그런데 왜 dto를 사용할까?ResponseEntity&lt;MusicResponseDto&gt; 엔티티 내부 구현을 캡슐화할 수 있다.엔티티란 도메인의 핵심 로직과 속성을 가지고 있고, 실제 DB의 테이블과 매칭되는 클래스이다.그렇기 때문에 엔티티가 getter와 setter를 갖게 된다면, controller와 같은 비즈니스 로직과 크게 상관없는 곳에서 자원의 속성이 실수로라도 변경될 수 있다.또한 엔티티를 UI계층에 노출하는 것은 테이블 설계를 화면에 공개하는 것이나 다름없기 때문에 보안상으로도 바람직하지 못한 구조가 된다.따라서 엔티티의 내부 구현을 캡슐화하고 UI계층에 노출시키지 않아야하는 것은 충분히 데이터 전달 역할로 DTO를 사용해야 할 이유로 볼 수 있다. 화면에 필요한 데이터를 선별할 수 있다.애플리케이션이 확장되면 엔티티의 크기는 점차 커지게 된다. 엔티티의 크기만 커질까?화면도 다양해지고, API 스펙도 더 많아질 것이다.이때 요청과 응답으로 엔티티를 사용한다면, 요청하는 화면에 필요하지 않은 속성까지도 함께 보내지게 된다.단순히 사용자의 이름만 보여주면 되는 상황에서 필요 이상으로 사용자가 가지고 있는 다른 속성들까지 항상 데이터 전송에 참여하게 되는 것이다.엔티티에서도 @JsonIgnore같은 어노테이션을 사용하면 화면으로 보내지 않을 속성을 지정할 수 있는데, 이 역시 근본적인 해결책이 될 수는 없다. 순환참조를 예방할 수 있다.양방향 참조된 엔티티를 컨트롤러에서 응답으로 return하게 되면, 엔티티가 참조하고 있는 객체는 지연 로딩되고,로딩된 객체는 또 다시 본인이 참조하고 있는 객체를 호출하게 된다.이렇게 서로 참조하는 객체를 계속 호출하면서 결국 무한 루프에 빠지게 되는 문제가 발생한다. validation 코드와 모델링 코드를 분리할 수 있다.엔티티 클래스는 DB의 테이블과 매칭되는 필드가 속성으로 선언되어 있고, 복잡한 비즈니스 로직이 작성되어있는 곳이다.그렇기 때문에, 속성에는 @Column, @JoinColumn , @ManyToOne, @OneToOne 등의 모델링을 위한 코드가 추가된다.여기에 만약 @NotNull, @NotEmpty, @NotBlank 등과 같은 요청에 대한 값의 validation코드가 들어간다면 엔티티 클래스는 더 복잡해지고 그만큼 가독성이 저하된다.이 글을 읽고 entity로 코드를 작성했었는데Comment를 새로 추가해서 Dto를 활용한 코드를 작성해봤다.기존 코드BoardService → BoardDto → BoardService → BoardServiceImpl → BoardRepository → Board이후 dto 사용 코드 추가BoardService → CommentDto, RegistryDto → BoardService → BoardServiceImpl → CommentRepository → Comment코드 보기코드 뜯어보기@WebMvcTest(BoardController.class)public class BoardControllerTest { @Autowired private MockMvc mockMvc;\t @MockBean BoardServiceImpl boardService; //http://localhost:8080/registry?boardId={boardId} @Test @DisplayName(\"GET test 해보기\") void getRegistry() throws Exception { given(boardService.getBoard(\"23\")).willReturn(new Board(\"23\", \"title\", \"main\", \"writer\")); String boardId = \"23\"; mockMvc.perform(get(\"/registry?boardId=\" + boardId)) .andExpect(status().isOk()) .andExpect(jsonPath(\"$.boardId\").exists()) .andExpect(jsonPath(\"$.boardTitle\").exists()).andExpect(jsonPath(\"$.boardMain\").exists()) .andExpect(jsonPath(\"$.boardWriter\").exists()).andDo(print()); verify(boardService).getBoard(\"23\"); }}@WebMvcTest(BoardController.class)test 하고자 하는 class를 넣어주면 된다.// BoardController에서 잡고 있는 Bean 객체에 대해 Mock 형태의 객체를 설명해준다. @MockBean BoardServiceImpl boardService;본 코드의 Controller를 보면 BoardService를 자동으로 주입받고 있다.given(boardService.getBoard(\"23\")).willReturn( new Board(\"23\", \"title\", \"main\", \"writer\"));여기서 사용되는 것은 @MockBean으로 만든 boardService를 사용한다.given → 어떠한 상황이 주어지면getBoard 자체가 Board를 return 해주는 메소드로 설정했기 때문에willReturn 값도 Board 객체를 return 값으로 넘겨줘야 한다.String boardId = \"23\";String boardId 필드 값 생성// http://localhost:8080/registry/{registryId}// local test라서 앞부분을 생략시켰다. mockMvc.perform(get(\"/registry?boardId=\" + boardId)) .andExpect(status().isOk()) .andExpect(jsonPath(\"$.boardId\").exists()) .andExpect(jsonPath(\"$.boardTitle\").exists()) .andExpect(jsonPath(\"$.boardMain\").exists()) .andExpect(jsonPath(\"$.boardWriter\").exists()) .andDo(print());perform() 이라는 메소드를 사용해서 RestApi 테스트를 할 수 있는 하나의 환경을 만들어 준다.mockMvc.perform(get(\"/registry?boardId=\" + boardId))MockHttpServletRequestBuilder 라는 곳에 있는 get이라는 메소드이다.실제로 어떤 통신을 할 것인지에 대해서 정의를 해준다.andExpect : 기대하는 값이 나왔는지 체크해볼 수 있는 메소드andExpect() 메소드는 builder 구조를 가지고 있기 때문에 .을 구분해서 사용한다.http request를 날리면 기본적으로 json 형태의 body 값을 받기 때문에jsonPath를 사용해서 각각의 값들(boardId, boardTitle)이 존재 하는지 확인한다.verify(boardService).getBoard(\"23\");verify : 해당 객체의 메소드가 실행되었는지 체크해준다.출처 JPA PK String 관련 문의드립니다 ResponseEntity란? 요청과 응답으로 엔티티(Entity) 대신 DTO를 사용하자" }, { "title": "Tdd 과정", "url": "/posts/TDD-%EA%B3%BC%EC%A0%95/", "categories": "Spring", "tags": "spring, TDD, test", "date": "2022-09-14 00:00:00 +0900", "snippet": "TDDtest코드를 먼저 작성 후에 빨간 줄이 뜨는 메소드를 실행 전에 실제 코드에 작성해주면 되는 형식이 tdd관련 글 : TDD란?annotationtdd를 작성하면서 새로 알게 된 부분들은 설명이 있고 원래 알고 있는 어노테이션은 간략하게 적었다.test■ @SpringBootTest : 통합 테스트를 제공하는 기본적인 어노테이션여러 단위 테스트를 하나의 통합된 테스트로 수행할 때 사용한다.단, 어플리케이션의 설정을 모두 로드하기 때문에 어플리케이션의 규모가 클수록 느려진다.■ @DataJpaTest : SpringBoot에서 JPA를 테스트 할 수 있도록 제공하는 어노테이션단위 테스트가 끝날 때 마다 자동으로 DB를 롤백시켜준다.인메모리 DB를 사용한다.실제 DB에서 테스트를 하고 싶다면 @AutoConfigureTestDatabase(replace = AutoConfigureTestDatabase.Replace.NONE) 어노테이션을 추가한다. 참고 Annotation 설명 Bean @SpringBootTest 통합 테스트, 전체 Bean 전체 @WebMvcTest 단위 테스트, Mvc 테스트 MVC 관련된 Bean @DataJpaTest 단위 테스트, Jpa 테스트 JPA 관련 Bean @RestClientTest 단위 테스트, Rest API 테스트 일부 Bean @JsonTest 단위 테스트, Json 테스트 일부 Bean ■ @Disabled : 테스트를 실행하지 않게 설정하는 어노테이션■ @AutoConfigureMockMvc : 이 어노테이션을 통해 MockMvc를 Builder 없이 주입 받을 수 있다.■ @ExtendWith(SpringExtension.class) : JUnit5의 lifecycle에 test에서 사용할 기능을 확장할 때 사용된다.Spring TestContext Framework와 Junit5와 통합하여 사용하게 된다.■ @Import(BoardServiceImpl.class) : BoardServiceImpl도 설정파일임을 명시■ @MockBean : @WebMvcTest를 이용한 테스트에서 사용할 수 있다.@WebMvcTest는 Controller를 테스트할 때 주로 이용되며,단일 클래스의 테스트를 진행하므로 @MockBean을 통해 가짜 객체를 만들어 준다.→ Controller 객체까지만 생성되고 Service 객체는 생성하지 않는다.@MockBean은 위와 같이 Bean 컨테이너에 객체(Service)가 있어야 다른 객체(Controller)와 협력할 수 있는데,객체를 만들 수 없는 경우 @WebMvcTest에 사용할 수 있다.SpringBootTest에서 Mock 사용(테스트 더블)mock이란 가짜 객체라고 불리며, 행위를 검증하기 위해 사용되는 객체이다.테스트 더블 : 테스트를 진행하기 어려운 경우 테스트를 대신 진행할 수 있게 만드는 객체 *Mock 객체의 상위호환SpringBootTest에서 테스트 더블 → MockitoMockito는 아래와 같은 동작들을 할 수 있다.■ Mock 만들기(CreateMock)■ Mock의 동작 지정 (Stub)■ Mock의 사용(Exercise)■ 검증(Verify)@Mock와 @MockBean은 Mock 객체를 선언할 때 쓰이는 어노테이션이다.Spring Boot Container가 테스트 시에 필요하고,Bean이 Container에 존재한다면 @MockBean을 사용하고 아닌 경우에는 @Mock을 사용한다.model■ @entity : JPA가 관리하는 클래스■ @Data : @ToString, @EqualsAndHashCode, @Getter, @Setter, @RequiredArgsConstructor이 포함된 어노테이션*개별 어노테이션의 설정 값을 기본 값이 아닌 값을 사용할 때는 @Data 대신 개별 어노테이션을 사용한다.■ @Builder@Builder : 매개변수가 많아지면 코드를 읽기 어렵고 어떤 순서로 매개변수를 넣어야하는지 헷갈리는데 @Builder를 활용하면 가독성이 좋아진다.Registry registry = new Registry(\"hello\", \"hi\", \"uni\", \"etc\")Registry 클래스는 생성자 파라미터를 4개를 받지만 파라미터로 받아야하는 값이 많아지면각 값들이 어떤 값을 의미하는지 이해하기 힘들다.이를 @Builder 패턴으로 구현하면 무슨 값을 의미하는지 파악하기 쉽다.만약 파라미터가 5개인 경우에 5개 파라미터를 모두 사용하는 경우에는 직접 설정하는 대신 @Builder만 작성해도 된다.5개 중에 한 두개만 사용하는 경우에는 직접 설정한다.모델명.테이블 명(설정할 변수 명) *모델명 생략public Registry toEntity(){ return Registry.builder() .id(registryId) .title(registryTitle) .main(registryMain) .writer(registryWriter) .build();}*생성자 체인생성자 체인은 this 또는 super 키워드를 사용해서 생성자에서 다른 생성자를 호출하는 기술Java에서 생성자의 이름을 직접 호출할 수 없으므로 this와 super 키워드를 사용한다.this는 동일한 클래스의 생성자에서 다른 생성자를 호출할 때 사용한다.super는 자식 클래스 생성자에서 부모 클래스 생성자를 호출할 때 사용한다.public Registry(RegistryDto registryDto){ this.registryId = registryDto.getRegistryId(); this.registryTitle = registryDto.getRegistryTitle(); this.registryMain = registryDto.getRegistryMain(); this.registryWriter = registryDto.getRegistryWriter();}this는 entity를 의미dto를 이용해서 체인 기술을 사용했다.ErrorController를 tdd Post 코드를 작성 하면서 오류를 해결한 과정을 적어봤다.☝🏻 DTO처음에 내가 dto에 값을 담아준 것으로 생각하고 왜 에러가 떴는지 몰랐다.알고보니 dto에 값을 담아준 것이 아니라 이 자리에 BoardDto가 들어와야 한다고 알려준 것이다.그리고 dto로 설정에서 dto에 담아서 보내줘야 한다.그래서 new BoardDto를 작성해준 것이다.GET도 dto로 작성?내가 작성한 get 코드는 아래처럼 dto를 사용하지 않았다.given(boardService.getRegistry(\"23\")).willReturn( new Board(\"23\", \"title\", \"main\", \"writer\") );그 이유는 본 코드를 보면 알 수 있는데 파라미터를 post에서는 dto를 담고 있고get에서는 String BoardId를 담고 있었기 때문에 dto가 아닌 값을 주어서 dto를 사용하지 않은 것이다.무조건 dto를 쓰는 것이 아니라 어떻게 짜냐에 따라 쓸 수 있고 안쓸 수도 있다.✌🏻 메모리 주소가 달라서 생기는 오류1번에서 말한 대로 수정한 후에 실행을 했더니 에러가 나타났다.ERROR : java.lang.AssertionError: No value at JSON path \"$.boardId\"new Dto → any(Dto.class)로 해결given(boardService.saveRegistry(new BoardDto(\"23\",\"title\", \"main\", \"writer\"))) .willReturn(new Board(\"23\",\"title\", \"main\", \"writer\"));⬇️given(boardService.saveRegistry(any(BoardDto.class))) .willReturn(new Board(\"23\",\"title\", \"main\", \"writer\"));new BoardDto(~~) → any(BoardDto.class)로 변경했다.RegistryDto 클래스 타입으로 들어오는 값을 사용한다는 의미로new 로 새로운 객체를 만들어서 작성하지 않고 구현체 객체를 사용해 메모리 주소가 다르지 않아서 오류가 해결 된 것 같다.본 코드처럼 dto는 들어오는 값을 쓴다라는 느낌출처[Java] Lombok @Data 어노테이션 빌더 패턴(Builder pattern)을 써야하는 이유, @Builder Builder란? [Java]생성자 체인(Constructor Chaining) Spring Junit5 Test정리 [Spring Boot]스프링부트 사용하기 - Structuring Your Code / Configuration Classes(a.k.a Bean 설정) / Auto-configuration [Mock과 Mocktio] @Mock @MockBean JPA repository.save is Null (NullPointerException) - feat. @RunWith &amp; @SpringBootTest &amp; @DataJpaTest" }, { "title": "Enum 기초", "url": "/posts/enum-%EA%B8%B0%EC%B4%88/", "categories": "Spring", "tags": "spring, enum", "date": "2022-09-03 00:00:00 +0900", "snippet": "이 전에는 열거형 상수를 선언하려면 클래스 내에 final static로 변수 선언 interface에 상수 선언을 했어야 했다.→ 한 클래스에 final static으로 선언하면 네임 충돌이 발생할 수도 있고 복잡하다.→ 인터페이스를 사용하면 위 문제는 해결되나 타입 안정성이 떨어진다. (컴파일 때 형검사를 하지 않으므로 오류 발생 소지→ 서로 다른 집합에 정의된 상수들은 서로 비교하면 안된다.)*interface에서 선언된 변수는 public static final 속성을 생략할 수 있는 특징을 이용하여 코드를 조금 더 간결하게 작성할 수 있다. 타입 안정성 Type Safe(타입 세이프) 란 말그대로 타입에 안정적인 것을 의미한다. 타입에 불안정적이다 라고 하는것은 타입을 판별(Type Check) 하지 못해 Runtime 시 타입으로 인한 문제가 발생하는 것이다. Type Safe 하다 라는 것은 그 반대로 타입을 판별(Type Check) 할 수 있어 Runtime시가 아닌 컴파일시 문제를 잡을 수 있는 것이다. 열거형이란 열거형(Enum)은 서로 연관된 상수들의 집합이라고 할 수 있다. 자바의 열거형은 C언어의 열거형과 달리 값과 타입을 함께 비교하기 때문에 보다 논리적인 오류를 줄일 수 있다. enum을 사용하는 이유class Amart { static final int WATER = 500; static final int APPLE = 1000; static final int MILK = 1500;}class BreadRestaurant { static final int PASTA = 500; static final int SALAD = 1000; static final int PIZZA = 1500;}public class Main { private static void main(String[] args){\t System.out.println(Amart.WATER == BreadRestaurant.PASTA ? \"TRUE\" : \"FALSE\");}출력 결과는 true이다. 500 == 500 과 같은 코드이므로 참이다.하지만 WATER와 PASTA는 의미적으로 같지 않다.또, Amart의 상수 값들이 변경된다면 결과는 달라진다.WATER와 PASTA 등 똑같이 사용하고 싶은데 상수의 값이 변해버리면 다시 코딩해야하는 상황이 생겨버린다.그래서 Enum을 사용하는 것이다.enum Amart{WATER, APPLE, MILK}enum BreadRestaurant {PASTA, SALAD, PIZZA}public class Main { private static void main(String[] args) { // compile 에러가 뜬다.\t System.out.println(Amart.WATER == BreadRestaurant.PASTA ? \"TRUE\" : \"FALSE\");}Type에 대해 검사를 하기 때문에 안정적인 코딩이 가능하다.*타입이 다르다는 얘기 클래스를 다른걸로(ex. 메소드) 활용하면 타입으로 사용한다고 볼 수 있다. (검증 x)public enum Student { ASTUDENT, BSTUDENT, CSTUDENT;}클래스 내부에서 이렇게 된다. → public static final Student ASTUDENT = new Student ();enum은 클래스처럼 사용하거나 내부에서 사용될 수 있다. enum만 선언해서 클래스처럼 사용 클래스 내부에 enum을 내부 클래스처럼 사용생성자enum의 생성자는 private이다.enum은 컴파일타임에 모든 값을 알아야 하고, 런타임 때 동적으로 어떤 값을 정해줄 수 없다.그러므로 new할 수도 없고, public으로 접근해서도 안되니 private 생성자 밖에 안되는 것이다.관련 메소드 메소드명 설명 valueOf(String) String 값을 enum에서 가져옴 valueOf(Class, String) 넘겨받은 class에서 String찾아, enum에 가져옴 values() enum의 요소들을 순서대로 enum타입의 배열로 리턴 Q. 여러 형태의 enum 데이터를 바인딩 하지 못해서 오류가 발생할 수 있기 때문에 Typehandler를 사용한다. 그런데 상수 안에 있는 변수가 2개 이상이면 typeHandler를 만들고 1개면 TypeHandler가 필요없었다. 알아서 매핑을 시켜주는걸까? 그래서 enum 수정 후에는 TypeHandler를 없애는 이유일까???A. 변수가 2개 이상이라서가 아니라, DB에 저장된 값이 enum과 동일하지 않기 때문에 type handler 를 사용한다. 동일하면 자동으로 매핑된다.Q. 파라미터가 2개 이상인 경우에는 @Param을 통해 parameter를 구분해서 사용한다. 그 이유가 파라미터가 2개 이상일 경우 mybatis에서 인식을 못하기 때문이다. 그러면 이것과 동일하게 enum의 변수가 2개 이상이면 TypeHandler를 만드는 이유도 mybatis에서 2개 이상은 인식을 하지 못하기 때문일까??A. @Param 과 type handler 는 전혀 다른 이유이다. https://mybatis.org/mybatis-3/configuration.html#typeHandlers관련 글 enum handler출처[JAVA] TYPE SAFE란? https://www.nextree.co.kr/p11686/ https://cotak.tistory.com/162 https://onejunu.tistory.com/116 https://sjh836.tistory.com/134" }, { "title": "Handler", "url": "/posts/handler/", "categories": "Spring", "tags": "spring, enum, handler", "date": "2022-08-30 00:00:00 +0900", "snippet": "handler관련 글 : enum기존 enum 값에서 변경을 할 때 처음에 작성을 변경 값만 작성했다.@Getter@AllArgsConstructorpublic enum Answer{ Y(\"정답\"), N(\"오답\"); private final String name;}“A”에서 “정답”으로 변경하는 것이니깐 둘다 적어줘야 한다는 걸 알아서 아래와 같이 작성했었다.@Getter@AllArgsConstructorpublic enum Answer{ Y(\"A\", \"정답\"), N(\"B\", \"오답\"); private final String team; private final String name;}그리고 handler를 작성했다.// 일부 생략 return Arrays.stream(Answer.values()) .filter(Answer -&gt; (Answer.getTeam().equals(string) || Answer.name().equals(string))) .orElse(null);}Answer.name().equals(string) 로 작성하면 실행이 잘 되는데Answer.getName().equals(string) 으로 작성하면 제대로 실행이 되지 않는다.그래서 enum의 name 대신 la로 작성하고 테스트해봤다.@Getter@AllArgsConstructorpublic enum Answer{ Y(\"A\", \"정답\"), N(\"B\", \"오답\"); private final String team; private final String la;}handler에서 Answer.name().equals(string) 로 작성을 해야 실행이 된다..getLa()로 작성하면 .getName()으로 작성했던 방법과 동일한 결과가 나온다.결론적으로 get변수명을 쓰는게 아니라 name을 쓴다.enum의 메소드인 name()과 toString()은 상수로 정의된 자기 자신의 이름을 그대로 반환한다. → Y, N그래서 이 name은 enum의 변수 name이 아니라 getNumber에 해당하는 상수 이름을 가져온다. *getName은 정답, 오답을 가져오는 것이다.따라서 name으로 설정한 변수와 enum에서 제공하는 name과 혼동할 수 있기 때문에 name 변수의 사용을 지양하는 편이라고 한다.출처 : [Java] 열거형 enum" }, { "title": "Git 테마 설정하기", "url": "/posts/git-%ED%85%8C%EB%A7%88-%EC%84%A4%EC%A0%95%ED%95%98%EA%B8%B0/", "categories": "Git", "tags": "git", "date": "2022-08-29 00:00:00 +0900", "snippet": "git 테마 설정하기 (chirpy)코드 다운받기테마 설정하면서 수 없이 봐왔던 --- layout : home # index page --- 오류를 해결한 과정을 적어봤다.base (요약)자세한건 Tistory 를 참고한다. 폴더를 하나 생성한다.git bash를 켜서 해당 폴더로 들어간다.아래 명령어 입력git initgit remote add origin \"gitRepo 주소 입력\"git pull origin main 참고로 pull or push할 때git push -u origin main으로 -u 옵션을 넣어주면 그 이후에 커밋할 때에는 git pull , git push 라고만 입력해도 된다.코드 다운 받은 파일을 압축 해제한 후 새로 생성한 폴더에 넣는다. (대부분 git clone으로 많이 하는 듯 하다.) 항목 설명 lang ko : 한글 설정 timezone Asia/Seoul title blog 제목 tagline title 아래 부연 설명 description SEO에 대한 키워드 입력 : 구글 검색에 어떤 키워드로 내 블로그를 검색하게 할 것인가를 결정해서 넣기 url ‘https://username.github.io’ github: username github_username twitter: username twitter_username social: name post 등에 표시할 이름 social: email 이메일 계정 social: links SNS 링크넣기 google_analytics 구글 애널리틱스 연결 google_analytics: pv 구글 애널리틱스 GA 연결 avatar 프로필 사진 넣기 disqus: shortname 닉네임 넣기 toc true : 포스팅 된 글의 오른쪽에 목차를 표시 pagination 한 목록에 몇개의 글을 표시해 줄 것인지 선택 (ex. 10) local에서 확인하기bundle installbundle exec jekyll servehttp://127.0.0.1:4000/ 주소로 들어가면 로컬에서 확인가능하다.파일 삭제하기$ tools/init.sh위 명령을 수행하면 아래 파일들이 삭제된다고 하였으나 잘 되지 않아서 직접 삭제했다. .travis.yml _posts 폴더 하위의 파일들 docs 폴더 (Chirpy 테마에서는 docs가 없었음)추가로 아래 파일도 삭제했다. Gemfile.lock 파일 .travis.tml 파일 .github 폴더에서 workflows 폴더를 남겨두고 파일 모두 지우기 .github/workflows/에서 commitlint.yml과 page-deploy.yml.hook 외 모두 지우기 page-deploy.yml.hook파일의 .hook를 지우기 → page-deploy.ymlurl_config.yml 파일에 baseurl이 아닌 url에 github url 넣기branch 변경하기Settings &gt; Pages의 Branch 에서 main을 gh-page로 변경.github/workflows/pages-deploy.yml에서 branches를 master → main 으로 변경ruby versionruby -v 을 통해 버전이 3.1임을 확인해서 .github/workflows/pages-deploy.yml 에 ruby-version을 2.7에서 3.1로 변경Github Blog 만들기-2 Jekyll Chirpy 테마 사용하여 블로그 만들기 Github 블로그 테마적용하기(Chirpy)" }, { "title": "Ammend", "url": "/posts/ammend/", "categories": "Git", "tags": "git", "date": "2022-08-25 00:00:00 +0900", "snippet": "amendgit commit --amend파일 저장 할 때 저장이랑 다른이름으로 저장이 있는데amend는 저장과 같은 기능을 한다고 보면 된다.(해당 커밋 위에 새로운 내용을 덮어서 저장하는 기능이다.)Git(25) git commit –amend 커밋 수정 후 덮어쓰기" }, { "title": "디버깅", "url": "/posts/%EB%94%94%EB%B2%84%EA%B9%85/", "categories": "Spring", "tags": "spring", "date": "2022-08-24 00:00:00 +0900", "snippet": "디버깅코드를 작성하다가 에러가 계속 나는데 나의 경우 커스텀 에러 메세지가 떠서 몇가지의 경우를 벗어난 case의 경우 해당 에러를 내뱉어라 하는 코드가 계속 실행되서 정확히 어느 부분에서 에러가 발생하는지 몰라 디버깅을 찾아보게 되었다.코드라인 넘버 옆에 클릭을 하면 BreakPoint가 설정된다. BreakPoint는 디버깅 시 프로그램 실행 중 멈추는 구간을 설정하는 기능이다.[디버깅 메뉴 버튼]Resume Program : 다음 BreakPoint로 이동하는 버튼 Stop DropFrame : 디버깅을 종료시키는 버튼 View Breakpoint : Breakpoint에 대해 옵션값을 설정하는 메뉴를 여는 버튼 Mute Breakpoints : Break를 비활성화해서 그냥 넘어갈 수 있도록 설정하는 버튼[프로그램 흐름 제어 버튼]Step over: 현재 Breakpoint를 실행한 다음에 다음 라인으로 이동하는 버튼 Step into: 현재 Breakpoint에서 흐름상 다음 라인으로 이동하는 버튼 Force Step Into: step into에서 stepping* 설정을 무시하고 실행하는 버튼 Step Out: 현재 메서드에서 나와 호출된 상위 메서드로 이동하는 버튼 Drop Frame: 현재 라인이 실행되기 전으로 되돌리는 버튼 Run to Cursor: 캐럿의 위치에 도달할 때까지 계속 실행하는 버튼 Evaluate Expression: 디버깅 중에 코드를 실행시킬 수 있는 버튼[값 체크하기]Evaluate Expression(Alt + F8) : 특정 객체 값을 확인하고 싶을 때 사용하면 된다.IntelliJ 초기 설정 세 번째 이야기-디버깅-[Intellij] - 디버깅 시 값 확인하는 법(Evaluate)" }, { "title": "Git checkout이 되지 않을 때", "url": "/posts/git-checkout%EC%9D%B4-%EB%90%98%EC%A7%80-%EC%95%8A%EC%9D%84-%EB%95%8C/", "categories": "Git", "tags": "git, error", "date": "2022-08-23 00:00:00 +0900", "snippet": "git checkout이 되지 않을 때git checkout이 되지 않는다.Please commit your changes or stash them before you switch branches. 에러가 뜬다.# 현재 Staging 영역에 있는 파일의 변경사항을 스택에 넣어둔다. $ git stash# stash 명령어로 스택에 넣어둔 변경 사항을 적용하고, 스택에서 제거해준다.$ git stash pop[Git] Git Merge 또는 Git checkout 오류 해결하기" }, { "title": "Primitive type", "url": "/posts/primitive-type/", "categories": "Spring", "tags": "spring", "date": "2022-08-20 00:00:00 +0900", "snippet": "primitive type*리팩토링을 하던 중 공부하게 된 내용SQL에 # 태그에 appleId와 ball이 적혀있다.APPLEID = #{appleId}&lt;if test='ball != null'&gt;\tand BALL = #{ball}&lt;/if&gt;코드를 작성하면서 ServiceImpl과 DAO를 연결시키기 위해서 SQL의 # 태그를 보고ServiceImpl에 # 태그에 해당하는 값이 있는 Apple 객체를 파라미터로 넣어주자 appleId는 인식이 되었다.해당 # 태그는 2개 존재해서 또 다른 Ball 객체를 추가로 파라미터에 넣어줘야 했는데Apple 객체와 Ball 객체를 같이 넣어주니깐 SQL에서 인식을 하지 못했다.ReturnType method (Apple apple, Ball ball)기존에 작성된 코드는 @Param으로 어떤 값을 사용할지 명시를 해서 2개의 값 모두 인식이 되었다.@Param(\"appleId\") String appleId그래서 궁금증이 생겼다.내가 여태까지 코드를 짜면서 늘 파라미터로 객체를 주고 있었는데다른 코드들을 살펴보면 객체가 아니라 @Param으로 명시를 해서 주고 있는 코드들이 몇 개 보였다.그리고 파라미터 값이 하나여도 @Param으로 명시를 해주는 코드도 있는데 왜 이런건지 의문이 들었다.이 경우를 primitive type 을 사용한다고 표현한다.파라미터는 객체를 사용하거나 primitive를 사용하건 상관없으나 가급적 객체를 사용하는 것을 권장한다.객체건 primitive이건 파라메터가 2개이상인 경우에는 @Param을 통해 parameter를 구분해서 사용한다.*관련 글 : 자료형@param 사용 이유public void gitBlog(@Param(\"haedal\") String githubName);이렇게 @Param 어노테이션을 붙이면 본인이 원하는 명으로 mapper에서 사용할 수 있다.위와 같은 경우는 #{haedal} 이다. 파라미터가 두 개 일 경우 MyBatis에서 인식을 못하기 때문에 @param을 사용해야한다.어노테이션을 쓰지 않아도 mapper에서 #{paramNum} 이라던지, #{githubName} 으로 파라미터 명을 적으면 사용이 가능하다.String gitBlog(String githubId); where USERID = #{githubId}[Spring] @param 사용이유" }, { "title": "Enum", "url": "/posts/enum/", "categories": "Spring", "tags": "spring, enum", "date": "2022-08-16 00:00:00 +0900", "snippet": "enum아래가 enum이다.public enum Answer{ Y, N}그런데 Y라고 갖고오는게 아니라 “정답”이라는 단어로 바꿔서 갖고오고 싶다. 그래서 Y(“정답”) 이라고 작성을 하고 “정답”을 작성하면서 private final String name;을 적었다.“정답”을 갖고 오기 위해서 @Getter를 사용하는 것이고 Y(“정답”) ← 이 구문이 생성자 같이 생겼는데 필드에 쓴 모든 생성자를 만들어주기 위해서 @AllArgsConstructor 를 넣어준 것이다.@Getter@AllArgsConstructorpublic enum Answer{ Y(\"정답\"), N(\"오답\"); private final String name;}@AllArgsConstructor를 안넣어주면public Answer(String name) { this.name = name;}이런식으로 적어줘야 한다.추가로 팀 변수를 추가한다면 값을 갖고올 때 “정답이고 A이다”를 한꺼번에 갖고오게 되는 것이다.@Getter@AllArgsConstructorpublic enum Answer{ Y(\"정답\", \"A\"), N(\"오답\", \"B\"); private final String name; private final String team;}관련 글 : handler" }, { "title": "절차, 객체, 함수형", "url": "/posts/%EC%A0%88%EC%B0%A8,-%EA%B0%9D%EC%B2%B4,-%ED%95%A8%EC%88%98%ED%98%95/", "categories": "Spring", "tags": "spring", "date": "2022-08-15 00:00:00 +0900", "snippet": "프로그래밍 패러다임은 프로그래밍 언어에도 자연스럽게 반영되는데, C언어는 대표적인 절차지향 언어이며, 자바는 대표적인 객체 지향 언어다. 이 두 패러다임을 모두 수용하기도 하는데, 파이썬이 이런 멀티 패러다임 언어라고 볼 수 있다.현재 가장 대중적인 프로그래밍 패러다임은 객체 지향 프로그래밍이지만 silver bullet(정답)은 없듯이 무조건 객체지향이 옳다고 볼 수 없다.절차 지향데이터와 함수가 분리되어서 각각 동작한다. 프로그램이 수행하는 알고리즘이 명확하고, 기능 확장 등이 자주 일어나지 않는 상황에서 사용하기에 좋다. (top → down)객체 지향객체 지향의 가장 큰 특징은 같은 역할을 하는 객체를 쉽게 바꾸도록 설계할 수 있다. → 다형성 어떤 객체에 필요한 객체를 때에 따라 다르게 주입해주는 것을 “의존성 주입”이라고 한다.데이터, 함수가 하나가 되어서 객체 하나가 하나의 책임을 수행한다. 여러 명의 개발자들이 협력을 해야 하거나, 확장 가능하도록 코드를 설계해야 하는 경우에 적합하다.함수형 프로그래밍함수를 입력과 출력으로 쓸 수 있다. 순수함수 : 외부상태를 갖지 않고 항상 동일한 결과를 출력상태를 가지지 않기 때문에 예측에서 벗어나는 결과(사이드 이펙트)가 없다. *예측하지 못한 결과 → side effect 하지만 실제로 상태를 가지지 않는 함수를 작성하고 활용하는 코드를 작성하는 것은 어렵다." }, { "title": "Controller, service, repository", "url": "/posts/Controller,-Service,-Repository/", "categories": "Spring", "tags": "spring", "date": "2022-08-14 00:00:00 +0900", "snippet": "Controller해당 요청 url에 따라 적절한 view와 mapping 처리@ControllerAPI와 view를 동시에 사용하는 경우에 사용 대신 API 서비스로 사용하는 경우는 @ResponseBody를 사용하여 객체를 반환한다. view(화면) return이 주목적@RestControllerview가 필요없는 API만 지원하는 서비스에서 사용 (Spring 4.0.1부터 제공) @RequestMapping 메서드가 기본적으로 @ResponseBody 의미를 가정한다.data(json, xml 등) return이 주목적: return ResponseEntity 즉, @RestController = @Controller + @ResponseBodyService비즈니스 로직Service interface와 ServiceImpl로 나누는 이유1. AOPSpring AOP는 빈 등록 시 사용자의 특정 메서드 호출 시점에 AOP를 수행하는 Proxy Bean을 생성해주며크게 2가지 프록시 객체 생성 방법이 존재한다.JDK Dinamic Proxy는 프록시 객체 생성 시 인터페이스 존재가 필수적이고CGLib은 프록시 객체 생성 시 인터페이스가 존재하지 않아도 클래스 기반으로 프록시 객체를 생성할 수 있다.옛날 spring framework에서는 spring AOP 사용 시 CGLib의 여러 문제점으로 인해 JDK Dinamic Proxy을 사용하는 것을 권장했다.CGLib 문제점 net.sf.cglib.proxy.Enhancer 의존성 추가 default 생성자가 무조건 필요함 타깃의 생성자 두 번 호출JDK Dinamic Proxy는 인터페이스를 기반으로 프록시 객체를 생성한다.반드시 인터페이스가 존재해야 프록시 객체를 정상적으로 만들어 낼 수 있었다.하지만 요즘 spring boot는 인터페이스를 구현한 클래스임에도 프록시 객체 생성 시 CGLib를 사용한다.spring 3.2 이후부터는 CGLib의 위에서 언급한 문제점이 외부 라이브러리의 도움을 받아 개선이 이루어졌다고 판단되어 spring core 패키지에 포함되었고 spring boot 사용 시 인터페이스를 구현한 클래스여도 JDK Dynamic Proxy보다 성능이 좋은 CGLib를 디폴트(spring.aop.proxy-target-class=true)로 사용하여 프록시 객체를 생성한다.만약 직접 JDK Dynamic Proxy와 CGLib를 활용한 프록시 객체 생성을 눈으로 확인해보고 싶다면 아래와 같이 입력한다.// application.propertiesspring.aop.proxy-target-class=false // CGLib 사용하지 않음spring.aop.proxy-target-class=true // CGLib 사용 - 디폴트)2. OOP객체 간의 결합도를 낮추어 변화에 유연한 개발을 하기 위해서이다.하나의 인터페이스를 구현하는 여러 구현체가 있고 기능에 따라 적절한 구현체가 들어가서 다형성을 주기 위함이다.또 하나의 인터페이스만 바라보니 의존관계도 줄일 수 있다.OCP(개방 폐쇄 원칙)기존의 코드는 잘 변경하지 않으면서도 확장은 쉽게 할 수 있어야 한다.DIP(의존관계 역전의 원칙)자신보다 변하기 쉬운 것에 의존 하던 것을 추상화된 인터페이스나 상위 클래스를 두어 변하기 쉬운 것의 변화에 영향받지 않게 하는 원칙→ 구현 클래스에 의존하지 말고, 인터페이스에 의존하라는 뜻어떨 때 나눠서 사용할까?구현체를 2개 이상 갖게 될 때 인터페이스를 두는 것이 바람직하다.일반적으로 카드는 결제가 있으면 반드시 취소 기능도 있어야 한다.인터페이스가 ‘카드 결제’라는 하나의 책임을 가질지라도 카드 결제와 관련된 다양한 메소드가 존재할 수 있음을 확인할 수 있다.트랜잭션트랜잭션은 데이터베이스의 상태를 변환시키는 하나의 논리적 기능을 수행하기 위한 작업의 단위 또는 한꺼번에 수행되어야할 일련의 연산들을 의미한다.트랜잭션은 작업의 완전성을 보장해준다. 즉, 논리적인 작업 셋을 모두 완벽하게 처리하거나 또는 처리하지 못할 경우에는원 상태로 복구해서 작업의 일부만 적용되는 현상이 발생하지 않게 만들어주는 기능이다.사용자의 입장에서는 작업의 논리적 단위로 이해를 할 수 있고 시스템의 입장에서는 데이터들을 접근 또는 변경하는 프로그램의 단위가 된다.트랜잭션은 SELECT, UPDATE, INSERT, DELETE와 같은 연산을 수행하여 데이터베이스의 상태를 변화시키는 작업의 단위다.스프링에서 트랜잭션 처리 방법스프링에서는 트랜잭션 처리를 지원하는데 그 중 어노테이션 방식으로 @Transactional을 선언하여 사용하는 방법이 일반적이며, 선언적 트랜잭션이라 부른다.클래스, 메서드위에 @Transactional 이 추가되면, 이 클래스에 트랜잭션 기능이 적용된 프록시 객체가 생성된다.이 프록시 객체는 @Transactional이 포함된 메소드가 호출 될 경우, PlatformTransactionManager를 사용하여 트랜잭션을 시작하고, 정상 여부에 따라 Commit 또는 Rollback 한다.트랜잭션을 중구난방으로 적용하는 것은 좋지 않다.대신 특정 계층의 경계를 트랜잭션 경계와 일치시키는 것이 좋은데, 일반적으로 비지니스 로직을 담고 있는 서비스 계층의 메소드와 결합시키는 것이 좋다.왜냐하면 데이터 저장 계층으로부터 읽어온 데이터를 사용하고 변경하는 등의 작업을 하는 곳이 서비스 계층이기 때문이다.트랜잭션 사용에 대해 잘 정리 된 글이 있어 참고한다. [Java]@Transactional Annotation 알고 쓰자RepositoryRepository는 Entity에 의해 생성된 데이터베이스 테이블에 접근하는 메서드들(ex. findAll, save 등)을 사용하기 위한 interface다.데이터 처리를 위해서는 테이블에 어떤 값을 넣거나 값을 조회하는 등의 CRUD(Create, Read, Update, Delete)가 필요하다.이 때 이러한 CRUD를 어떻게 처리할지 정의하는 계층이 바로 Repository다. DB에 접근하는 코드Spring Data JPAEntity만으로는 데이터베이스에 데이터를 저장하거나 조회 할 수 없다.데이터 처리를 위해서는 실제 데이터베이스와 연동하는 JPA Repository가 필요하다.JPA (Java Persistence API)JPA : 애플리케이션을 객체지향 언어로 개발하고 관계형 DB 로 관리한 다음 객체-관계형간의 차이를 해결하기 위해 JPA를 사용 JPA는 자바 진영에서 ORM 기술 표준으로 Application 과 JDBC 사이에서 동작한다. ORM (Object Relational Mapper) : 직접 SQL을 작성하지 않고도 객체지향 방식으로 DB에 접근 JDBC (Java Database Connectivity) : Java에서 DB에 접속할 수 있도록 하는 자바 APIHibernateHibernate는 JPA의 대표적인 프레임워크이다. JPA는 Interface의 모음이며 이를 구현한 구현체로 Hibernate, EclipseLink, DataNucleus 등 여러 ORM framework가 존재하는데 주로 Hibernate를 사용한다.즉, JPA 핵심인 EntityManagerFactory, EntityManager, EntityTransaction Interface를 Hibernate에서 Interface로 상속받아 Impl로 구현했다.Spring Data JPASpring Data JPA 란 JPA를 추상화시킨 Repository Interface를 제공하여 개발자가 JPA를 더 편하게 사용할 수 있게 하는 모듈이다.Spring Data JPA를 사용하지 않는다면 클래스에 @Repository annotation 을 작성하고 JPA를 적용한 다음 EntityManager의 API 를 직접 호출해야 entity CRUD 가 처리된다.JpaRepository에는 EntityManager가 포함되어 있기 때문에 직접 작성하지 않아도 내부에서 자동으로 호출된다. 또한, @Repository annotation 작성하지 않아도 spring data JPA가 알아서 Bean으로 등록해준다.작성 방법public interface RegistryRepository extends JpaRepository&lt;Registry, Long&gt; {}RegistryRepository는 repository로 만들기 위해서 JpaRepository를 상속했다.JpaRepository를 상속할 때는 제네릭스 타입으로 &lt;Registry, Long&gt; 처럼Repository의 대상이 되는 Entity의 타입(Registry)과 해당 엔티티의 PK의 속성 타입(Long)을 지정해야 한다.정리 JPA : ORM 기술 표준으로 채택된 인터페이스의 모음 ( = 기술 명세서 ) Spring Data JPA 란 JPA를 추상화시킨 Repository Interface를 제공하여 개발자가 JPA를 더 편하게 사용할 수 있게 하는 모듈 → JPA를 추상화 시킨게 Repository Interface ORM을 구현하기 위한 인터페이스(JPA) != JPA를 추상화 시킨 Repository Interface(Spring Data JPA) JPA 구현체가 Hibernate(ORM framework) JPA(인터페이스)를 구현해둔 Hibernate(ORM) Repository인터페이스를 Spring Data JPA가 JPA화하고(JPA로 번역해준다) 그 JPA를 Hibernate로 실행하는 것 같다. JPA를 추상화한게 Spring Data JPA이고 Spring Data JPA가 Repository를 제공 *추상화 : 불필요한 것을 지우고 핵심을 남겨둔다. (추상화 라는 단어가 어렵다면? → 반대로 생각하면 구체화)*인터페이스 : 완전한 추상화를 제공한다.Dto, Repository, EntityDto : 로직을 갖고 있지 않는 순수한 데이터 객체이며, getter/setter 메서드만을 갖는다.*Vo : VO는 DTO와 동일한 개념이지만 read only 속성을 갖는다. VO는 특정한 비즈니스 값을 담는 객체이고, DTO는 Layer간의 통신 용도로 오고가는 객체를 말한다.Repository : 실제로 DB에 접근하는 객체 Entity에 의해 생성된 DB에 접근하는 메서드 ex. findAll() 들을 사용하기 위한 인터페이스Entity : 실제 DB의 테이블과 매칭될 클래스 (Entity는 DB 테이블과 1대1로 대응 되는 객체) model에 @Entity를 넣어줌 *@Entity가 붙은 클래스는 JPA가 관리하는 클래스Client ←(dto) → Controller ←(dto) → Service ←(dto) → Repository ← Entity → DBDAO, MODELDAO(repository 대신 DAO 사용), model(JPA를 사용안해서 @Entity가 없다.) *model에 @entity를 넣어주면 entity라고 부르고 안붙으면 model이라 부르는 것 같다.DAO : 실제 DB에 접근하는 객체, Service와 DB를 연결하는 고리의 역할 @Repository : DAO를 인식시켜주기 위한 설정 해당 클래스가 DAO라는 것을 알리기 위해서 @Repository라고 적어준다.Client ↔ Controller ↔ Service ↔ DAO ↔ DBService에서 DAO를 호출하여 DB에 접근한다.mapper안에 정의된 xml 파일에는 요청한 정보를 처리하기 위한 SQL들이 있다.&lt;mapper namespace=\"project.dao.PracticeDAO\"&gt; &lt;select id = \"DAO 메소드 이름\" resultType = \"\"&gt; &lt;/select&gt; 출처 스프링 부트 : 기본 개념 1) Entity, Repository 개념 [JPA] 엔티티 매핑 방법 (Entity Mapping) Entitiy 와 DTO 의 분리 [DAO] DAO, DTO, Entity Class의 차이 [Spring - 어노테이션(Annotation) ] @Repository → DAO 인식, @Service → Service 인식 Spring MVC 디렉토리 구조 및 실행순서 (controller, service, dao, view ) 스프링 부트 : 기본 개념 1) Entity, Repository 개념 JPA와 Spring Data JPA의 차이 Java에서 추상화 란 무엇인가 – 예제로 배우기 [OOP] 추상화(Abstraciton)란? 리포지터리[Spring] Transactional 정리 및 예제 [개발자 블로그] Spring에서 Service ServiceImpl 사용해야하는지 서비스 구현 시 인터페이스를 구현하는 형태로 하는 이유 (spring AOP) [DB] 트랜잭션(Transaction)이란? ACID란? [Spring] Spring에서 트랜잭션의 사용법 - (3/3)" }, { "title": "Resulttype", "url": "/posts/resultType/", "categories": "Spring", "tags": "spring, DAO", "date": "2022-08-13 00:00:00 +0900", "snippet": "resultType이 int? 객체?관련 글 : Dao와 mybatisselect count(USER.USERID)select avg(USER.USERSTAR)resultType에서 select count는 int, select avg는 객체로 반환이 되는걸 보고 왜 하나는 int로 설정하고 왜 다른 하나는 객체로 설정을 할까 의문이 들었다.여기서 답은 “db”에 있다. select count(USER.USERID) : db에서 userId는 pk이다. → pk는 not null이다.따라서 userId는 notNull이고 userStar은 null이 될 수 있어서 각각 0과 null로 뜬다. USER.USERSTAR 컬럼에 데이터가 없으면 null로 나오기 때문에 계산을 할 수가 없고 무조건 에러가 뜰 수 밖에 없다. count는 없으면 0으로 뜬다.그래서 각각 int와 객체로 설정을 하게 된 것이다.resultType = “int”카운트를 하는 경우에 resultType이 int 형식이 된다.* 객체면 조회하려는 sql 구문한테 DAO 랑 맞게 alias 써서 매칭시킨다. (대문자)*보통 카운트 처럼 조회하는 게 하나이고 다른곳에서 많이 사용하지 않는 경우는 객체로 안 받고 그냥 int로 받는 경우가 있다." }, { "title": "단축키", "url": "/posts/%EB%8B%A8%EC%B6%95%ED%82%A4/", "categories": "Intellij", "tags": "Intellij", "date": "2022-08-10 00:00:00 +0900", "snippet": "단축키 정리alt + 1(숫자 1) : project 창 띄우기End 키를 누른 다음 Shift+Home : 한 줄의 끝부터 시작까지리팩토링Ctrl + Alt + L : Reformat codectrl + alt + O : 필요없는 import 지우기검색/교체/이동Shift + Shift : 파일, 클래스, 설정 등 키워드에 관련된 가능한 모든 것을 검색 (Search Everywhere)Ctrl + Shift + F : 전체에서 검색 (Find in path)Ctrl + Shift + R : 전체에서 교체(Replace in path)Ctrl + N : 검색창 열기Shift + Enter : 다음줄로 바로 넘어가기(문장 끝에 커서를 옮기고 enter를 치지않아도 된다.)code(fori or iter) + tab : 반복문 자동완성Alt + insert : GenerateShift + F6 : 변수 명 변경(rename)[IntelliJ] 인텔리제이 자주 쓰는 단축키 정리 Intellij IDEA(인텔리제이) 단축키 정리 [Intellij] 유용한 인텔리제이 단축키 모음" }, { "title": "Unsatisfied dependency expressed through constructor parameter", "url": "/posts/Unsatisfied-dependency-expressed-through-constructor-parameter/", "categories": "Error", "tags": "error", "date": "2022-08-09 00:00:00 +0900", "snippet": "Unsatisfied dependency expressed through constructor parameteravailable: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {}블로그를 보니 어노테이션 문제라는 것을 알 수 있다.ex) @Service를 명시안했다던지,,,나는 어노테이션을 명시한게 아니라 @Service와 연결된 파일들을 적는 private final에 model을 넣어서 에러가 뜬 것이었다.→ @Service가 아닌 model을 넣었으니 @Service라고 안적혀있는데? 하고 에러가 뜬 것 같다.1. blog 2. blog : [스프링 Error]org.springframework.beans.factory.NoSuchBeanDefinitionException 에러메시지" }, { "title": "Method 분리", "url": "/posts/method-%EB%B6%84%EB%A6%AC/", "categories": "Spring", "tags": "spring", "date": "2022-08-06 00:00:00 +0900", "snippet": "메소드 분리예를 하나 들어본다.userCount와 userStar 값을 담는 userCountAndStar 메소드가 있다고 가정한다.return 되는 결과물이 2개 이상 있을 때, 2개를 같이 쓰는 곳에서만 쓸 수 있는 재사용성이 없는 메소드가 된다.userCount가 필요한곳에서는 userCount만 불러오고 userStar가 필요한곳에서는 userStar만 불러올 수 있게끔 분리시키는 것이다.A페이지는 userCount, userStar 둘다 필요 → userCount 메소드, userStar 메소드 둘다 호출B페이지는 userCount만 필요 → userCount 메소드 호출C페이지는 userStar만 필요 → userStar 메소드 호출" }, { "title": "Mapping", "url": "/posts/Mapping/", "categories": "Spring", "tags": "spring", "date": "2022-08-04 00:00:00 +0900", "snippet": "기존 project에서 내가 원래 작성했던 코드랑 달라 궁금증이 생겨서 검색해보게 되었다. 그리고 코드를 변경하게 되었다.😄 *Notion 참고Mapping특정 uri로 요청을 보내면 Controller에서 어떠한 방식으로 처리할지 정의 한다.이때 들어온 요청을 특정 메서드와 매핑하기 위해 사용하는 것이 @RequestMapping이다.@RequestMapping에서 가장 많이 사용하는 부분은 value와 method이다.*value : 요청받을 url*method : 어떤 요청으로 받을지 정의@RequestMapping(value = \"/hello\", method = RequestMethod.GET) public String helloGet(...) { ... } @RequestMapping(value = \"/hello\", method = RequestMethod.POST) public String helloPost(...) { ... } @RequestMapping(value = \"/hello\", method = RequestMethod.PUT) public String helloPut(...) { ... } @RequestMapping(value = \"/hello\", method = RequestMethod.DELETE) public String helloDelete(...) {⬇️@GetMapping() public String helloGet(...) { ... } @PostMapping() public String helloPost(...) { ... } @PutMapping() public String helloPut(...) { ... } @DeleteMapping() public String helloDelete(...) { ... }@GetMapping, @PostMapping, @PutMapping, @DeleteMapping으로 간단하게 생략 가능하다.@RequestMapping에서는 다른 옵션을 넣어주는 경우에는 url 앞에 value를 붙여야 한다.그러나 옵션이 value 하나인 경우에는 그냥 url만 넣어준다.그렇게 되면서 코드가 점점 길어지니깐 이것을 하나의 어노테이션으로 제공한다고 한다. @GetMapping @PostMapping @PutMapping @DeleteMapping @PatchMappingSpring MVC - 기능 정리 [Spring] @RequestMapping이란?" }, { "title": "Escapexml", "url": "/posts/escapeXml/", "categories": "Spring", "tags": "spring", "date": "2022-07-30 00:00:00 +0900", "snippet": "fn:escapeXml()이란XML마크업 문자로 인식될 문자열을 삭제한다. [JSTL] Functions Tag - fn:escapeXml() 사용하기마크업이란 : ex) &lt;script&gt; &lt;div&gt;블로그를 보면 fn:escapeXml()이란 글들은 많지만 왜 문자열을 삭제하는 건지는 나와있지 않고 어떻게 사용하는지만 나와있다.나는 fn:escapeXml()과 동일하게 쓰이는 &lt;c:out&gt;로 검색해서 그 이유를 찾았다.왜 삭제할까? html이나 스크립트가 실행되어 위험하다. ⭐ 엄격한 태그 규칙을 위해 사용한다. 개행문자 파싱의 차이 때문에 사용한다. 보안성 때문에 사용한다.[JSP]&lt;c:out&gt;을 사용하는 이유fn:escapeXml() 와 &lt;c:out&gt;원래는 fn:escapeXml() 이나 &lt;c:out&gt; 둘 중에 아무거나 사용해도 된다.role을 정해서 만들다 보면 어디서는 fn:escapeXml() 어디서는 &lt;c:out&gt; 를 사용하는 걸 볼 수 있다.다만 현재 사용하고 있는 프로젝트에서 어떤 방식으로 정하냐에 따라 fn:escapeXml()와 &lt;c:out&gt;를 같이 사용할 수 있다." }, { "title": "Git reset 취소하기", "url": "/posts/git-reset-%EC%B7%A8%EC%86%8C%ED%95%98%EA%B8%B0/", "categories": "Git", "tags": "git", "date": "2022-07-29 00:00:00 +0900", "snippet": "git reset 취소하기git log에서 바로 이 전 commit으로 가야하는데 2개 전으로 돌아가게 되면서 reset을 취소해야 할 상황이 왔다.$ git reflog 를 입력하면 아래와 같이 보여진다. (아래는 예시임)a123456 HEAD@{0}: reset: moving to a1234567891011121314b123456 HEAD@{1}: checkout: moving from main to haedalc123456 HEAD@{2}: commit (amend): Merge branch ~~d123456 HEAD@{3}: reset: moving to HEADe123456 HEAD@{4}: reset: moving to HEADf123456 HEAD@{5}: reset: moving to HEADHEAD@{0}이 reset이 적혀있어서 그 전인 HEAD@{1}로 가면 될 것 같았다.git reset --hard HEAD@{1} 입력해서 해결했다..!! [GIT] reset 한거 취소하는 방법" }, { "title": "Dao와 mybatis", "url": "/posts/DAO%EC%99%80-MyBatis/", "categories": "Spring", "tags": "spring, DAO, maven, mybatis", "date": "2022-07-27 00:00:00 +0900", "snippet": "DAO와 MyBatisMapper 파일의 저장경로 설정Mapper란 MyBatis에서 SQL 문을 저장하는 존재를 말한다.Mapper를 저장할 폴더 mappers를 src/main/resources 에 추가해준다.DAOUserDAO 쿼리문에 던져주는 정보가 매개변수(User user) 부분이고 해당 정보를 토대로 쿼리에 다시 반환하는 값이 리턴 타입인 UserA부분이다.UserA userInfo(User user)MyBatisMapperMyBatis의 namespace에 Mapper 인터페이스의 경로를 적어준다.user.xml&lt;mapper namespace=\"haedal.uni.UserDAO\"&gt;전해주는 값 : 반환 값 메소드 (전해주는 값)SQL id에는 매핑하는 메소드의 이름을 지정한다. → DAO의 메소드 이름과 id 값이 같아야 한다.&lt;select id=\"userInfo\" resultType=\"UserA\"&gt;# 기호가 코드 로직에서 담기는 부분이기 때문에 userId가 User에 있어야 한다.&lt;select id=\"userInfo\" resultType=\"UserA\"&gt; select USERID , USERNAME from TABLE_USER where USERID = #{userId}&lt;/select&gt;UserA userInfo(User user)#{ }는 후에 삽입되어 대체될 값이다.ex. userId가 1로 정해지면 USERID = #{userId}는 USERID = 1이 된다.반환 하는 값 _ 반환 값 메소드 (전해주는 값)id = “DAO 메소드 명” resultType = “반환 값”(모델 or int 기타 등등)&lt;select id=\"userInfo\" resultType=\"UserA\"&gt; UserA에는 private string username; 과 private User user; 이 있고 User 에는 userId가 있다고 가정한다.@Alias(\"UserA\")public class UserA { private String username; private User user;}@Alias(\"User\")public class User { private UserId userId;} UserA userInfo(User user)UserA가 반환 값이다. sql에서는 resultType이 반환 값으로 적힌다.아래 코드를 보면 as(alias)가 추가되었다.&lt;select id=\"userInfo\" resultType=\"UserA\"&gt; select USERID as \"USER.USERID\" , USERNAME as \"USERNAME\" from TABLE_USER where USERID = #{userId}&lt;/select&gt;resultType이 UserA이며, UserA에는 username이 있으므로 해당 변수만 적으면 되지만userId는 User에 있으므로 해당 경로에 맞게 적어준다.변수 담기는 값 as vo 변수이름(명칭)참고로 resultType에서 패키지 명(ex. haedal-uni.project.UserA)을 다 적어줄 필요가 없던 이유는UserA 라는 model 객체에 @Alias를 추가했기 때문이다.관련 글 : resultType이 int? 객체? 출처 : [Spring] 7.DAO 구현" }, { "title": "@tostring", "url": "/posts/@ToString/", "categories": "Spring", "tags": "spring", "date": "2022-07-23 00:00:00 +0900", "snippet": "@ToStringclass SubClass extends SuperClassJAVA 상속 - 부모(슈퍼)클래스와 자식(서브)클래스@ToString@ToString(exclude = \"password\")public class User { private Long id; private String username; private String password; private int[] scores;}위와 같이 클래스에 @ToString 어노테이션을 붙이고, 아래와 같이 필드를 세팅 후 출력을 하면,User user = new User();user.setId(1L);user.setUsername(\"dale\");user.setUsername(\"1234\");user.setScores(new int[]{80, 70, 100});System.out.println(user);다음과 같이, 클래스명(필드1명=필드1값, 필드2명=필드2값,…) 식으로 출력된다.User(id=1, username=1234, scores=[80, 70, 100])[자바] 자주 사용되는 Lombok 어노테이션OptiontoString 기본 출력에는 슈퍼클래스 구현 데이터가 포함되지 않는다.@ToString(callSuper = true) 코드를 추가하면 슈퍼클래스 정보와 서브클래스 필드 및 값이 포함된 다음 출력이 생성된다.@ToString(callSuper = true)public class SavingAccount extends Account { private String savingAccountId; // standard getters and setters}출력 SavingAccount(super=Account(id=12345, name=An account), savingAccountId=6789)출처 롬복의 @ToString 주석" }, { "title": "첫 시작", "url": "/posts/%EC%B2%AB-%EC%8B%9C%EC%9E%91/", "categories": "Log", "tags": "log", "date": "2022-07-16 00:00:00 +0900", "snippet": "이제 여기로!이전에 Tistory에서 공부했던 부분이나 팀 프로젝트 했던 기록들을 적어왔었다. 회사 다니기 시작하면서 배우는 부분들을 그대로 이어서 작성해야 하나 고민했었는데 이제 여기에 배워 나가는 것들을 정리해보려고 한다😄Spring, mysql, mybatis" } ]
